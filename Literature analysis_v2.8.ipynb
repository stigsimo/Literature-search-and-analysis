{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33fc68ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 1: Imports and Setup\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import configparser\n",
    "import tiktoken\n",
    "import logging\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Phrases\n",
    "import openai\n",
    "from difflib import SequenceMatcher\n",
    "import itertools\n",
    "\n",
    "SAVE_DIR = \"Saved_files_new\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156bf246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Cell 2: OpenAI Setup and Utility (Updated for gpt-5-nano)\n",
    "class CreditTracker:\n",
    "    def __init__(self):\n",
    "        self.total_tokens = 0\n",
    "        self.total_cost = 0\n",
    "        self.cost_per_1k_tokens = 0.00015\n",
    "    def update(self, tokens):\n",
    "        self.total_tokens += tokens\n",
    "        self.total_cost += (tokens / 1000) * self.cost_per_1k_tokens\n",
    "    def get_stats(self):\n",
    "        return {\"total_tokens\": self.total_tokens, \"total_cost\": round(self.total_cost, 4)}\n",
    "\n",
    "def initialize_openai():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config_LLM.txt')\n",
    "    api_key = config['LLM'].get('OPENAI_API_KEY')\n",
    "    model_type = config['LLM'].get('MODEL_TYPE')\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    return client, model_type\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"Get token count with fallback for unsupported models like gpt-5-nano\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model_name)\n",
    "        return len(encoding.encode(string))\n",
    "    except KeyError:\n",
    "        # Fallback for unsupported models like gpt-5-nano\n",
    "        if model_name.startswith('gpt-5-nano'):\n",
    "            # Use o200k_base encoding as fallback for gpt-5-nano\n",
    "            encoding = tiktoken.get_encoding(\"o200k_base\")\n",
    "            return len(encoding.encode(string))\n",
    "        else:\n",
    "            # For other unsupported models, use a reasonable approximation\n",
    "            return len(string) // 4  # Rough approximation: 4 chars per token\n",
    "\n",
    "client, model_type = initialize_openai()\n",
    "credit_tracker = CreditTracker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "145755ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Cell 3: Data Preprocessing Utilities\n",
    "\n",
    "def extract_keywords_from_filename(filename):\n",
    "    base = os.path.splitext(os.path.basename(filename))[0]\n",
    "    parts = base.split('_')\n",
    "    return [part for i, part in enumerate(parts) if i > 2 and part != 'results' and not part.isdigit()]\n",
    "\n",
    "def get_custom_stop_words(search_keywords=None):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words_to_keep = set()\n",
    "    if search_keywords:\n",
    "        for keyword in search_keywords:\n",
    "            keyword = keyword.lower()\n",
    "            words_to_keep.add(keyword)\n",
    "            for word in keyword.split():\n",
    "                words_to_keep.add(word)\n",
    "    stop_words = stop_words - words_to_keep\n",
    "    scientific_terms = {'et', 'al', 'ref', 'reference', 'references', 'cited', 'cite',\n",
    "        'fig', 'figure', 'figures', 'table', 'tables', 'chart', 'charts',\n",
    "        'published', 'journal', 'conference', 'proceedings', 'vol', 'volume', 'pp', 'page', 'pages', 'doi'}\n",
    "    return stop_words.union(scientific_terms)\n",
    "\n",
    "def preprocess_text(text, search_keywords=None, min_word_length=2, remove_numbers=True):\n",
    "    if not isinstance(text, (str, int, float)):\n",
    "        return ''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    if remove_numbers:\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "    text = re.sub(r'--+', ' ', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = get_custom_stop_words(search_keywords)\n",
    "    tokens = [t for t in tokens if len(t) >= min_word_length and t not in stop_words and len(t) > 1 and not t.isdigit()]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    try:\n",
    "        tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    except:\n",
    "        pass\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_dataframe(df, text_col, search_keywords, processed_col='processed_text'):\n",
    "    df[text_col] = df[text_col].fillna('').astype(str)\n",
    "    df[processed_col] = df[text_col].apply(lambda x: preprocess_text(x, search_keywords))\n",
    "    return df[df[processed_col].str.strip() != '']\n",
    "\n",
    "def clean_fields_of_study(s):\n",
    "    valid_fields = ['Computer Science', 'Economics', 'Engineering', 'Physics', 'Mathematics',\n",
    "        'Medicine','Business','Environmental Science','Chemistry','Materials Science',\n",
    "        'Geography','Biology','Geology','Political Science','Psychology','Com']\n",
    "    if pd.isna(s) or s == '[]':\n",
    "        return [\"Unknown\"]\n",
    "    if isinstance(s, str):\n",
    "        fields = [field.strip().strip(\"'\\\"\") for field in s.strip('[]').split(',')]\n",
    "        return [f if f in valid_fields else \"Unknown\" for f in fields] or [\"Unknown\"]\n",
    "    return [\"Unknown\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a22896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:11:50,287 - INFO - Loaded and preprocessed 28934 papers\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 4: Data Loading & Cleaning\n",
    "\n",
    "filename = \"semantic_scholar_2025_02_14_reliability_resilience_power_systems_results.csv\"\n",
    "filepath = os.path.join(\"Saved_files\", filename)\n",
    "df = pd.read_csv(filepath, sep=\";\")\n",
    "df['text'] = df['title'].fillna('') + ' ' + df['abstract'].fillna('')\n",
    "search_keywords = extract_keywords_from_filename(filename)\n",
    "df = preprocess_dataframe(df, text_col='text', search_keywords=search_keywords)\n",
    "df['fieldsOfStudy'] = df['fieldsOfStudy'].apply(clean_fields_of_study)\n",
    "logger.info(f\"Loaded and preprocessed {len(df)} papers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feef6bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 5: Enhanced Method Detection Functions (COMPLETE CORRECTED VERSION)\n",
    "\n",
    "def extract_candidate_terms(df, text_col='processed_text', max_features=20000):\n",
    "    \"\"\"Extract candidate terms from processed text using CountVectorizer.\"\"\"\n",
    "    vectorizer = CountVectorizer(\n",
    "        ngram_range=(1, 4), max_df=0.95, min_df=2, max_features=max_features, token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "    matrix = vectorizer.fit_transform(df[text_col].fillna(''))\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    freqs = matrix.sum(axis=0).A1\n",
    "    return [term for term, freq in sorted(zip(terms, freqs), key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "def parse_llm_python_list(output_text):\n",
    "    \"\"\"Improved parsing function for LLM outputs\"\"\"\n",
    "    import re\n",
    "    import ast\n",
    "    \n",
    "    content = output_text.strip()\n",
    "    content = re.sub(r'```(?:python|json)?\\n?', '', content)\n",
    "    content = re.sub(r'```', '', content)\n",
    "    \n",
    "    list_patterns = [\n",
    "        r'\\[([^\\]]+)\\]',  # Standard list format\n",
    "        r'List:\\s*\\[([^\\]]+)\\]',  # List: [items]\n",
    "        r'Result:\\s*\\[([^\\]]+)\\]'  # Result: [items]\n",
    "    ]\n",
    "    \n",
    "    for pattern in list_patterns:\n",
    "        match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)\n",
    "        if match:\n",
    "            try:\n",
    "                return ast.literal_eval('[' + match.group(1) + ']')\n",
    "            except:\n",
    "                items = [item.strip().strip(\"'\\\"\") for item in match.group(1).split(',')]\n",
    "                return [item for item in items if item.strip()]\n",
    "    \n",
    "    lines = content.split('\\n')\n",
    "    items = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line and not line.startswith('#') and not line.startswith('//'):\n",
    "            line = re.sub(r'^\\d+\\.?\\s*[-*]?\\s*', '', line)\n",
    "            line = line.strip(\"'\\\"\")\n",
    "            if line:\n",
    "                items.append(line)\n",
    "    \n",
    "    return items[:1500]\n",
    "\n",
    "def get_method_phrases_enhanced(\n",
    "    corpus_terms, client, model_type, credit_tracker, prompt,\n",
    "    n_runs=3, temp=0.2, top_p=0.95, show_progress=True, batch_size=500\n",
    "):\n",
    "    \"\"\"Enhanced method extraction with configurable prompt.\"\"\"\n",
    "    import collections\n",
    "    from math import ceil\n",
    "\n",
    "    all_phrases_sets = []\n",
    "    n_batches = ceil(len(corpus_terms) / batch_size)\n",
    "    \n",
    "    for batch_idx in range(n_batches):\n",
    "        batch_terms = corpus_terms[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "\n",
    "        # Format the prompt with current batch terms\n",
    "        formatted_prompt = prompt.format(candidate_terms=batch_terms)\n",
    "\n",
    "        for i in range(n_runs):\n",
    "            try:\n",
    "                api_params = {\n",
    "                    \"model\": model_type,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"You are a comprehensive research method extraction expert. Your primary goal is maximum coverage of specific technical methods.\"},\n",
    "                        {\"role\": \"user\", \"content\": formatted_prompt}\n",
    "                    ],\n",
    "                }\n",
    "                if model_type.startswith('gpt-5-nano'):\n",
    "                    api_params[\"max_completion_tokens\"] = 8000\n",
    "                else:\n",
    "                    api_params[\"temperature\"] = temp\n",
    "                    api_params[\"top_p\"] = top_p\n",
    "                    api_params[\"max_tokens\"] = 8000\n",
    "\n",
    "                response = client.chat.completions.create(**api_params)\n",
    "                content = response.choices[0].message.content\n",
    "                phrases = parse_llm_python_list(content)\n",
    "                phrases = [p.lower().strip() for p in phrases if p.strip() and len(p.strip()) > 2]\n",
    "                all_phrases_sets.append(set(phrases))\n",
    "                credit_tracker.update(num_tokens_from_string(content, model_type))\n",
    "                if show_progress:\n",
    "                    print(f\"BATCH {batch_idx+1}/{n_batches}, run {i+1}: found {len(phrases)}\")\n",
    "                    print(f\"  Sample: {phrases[:10]}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in LLM call for batch {batch_idx+1}, run {i+1}: {e}\")\n",
    "                all_phrases_sets.append(set())\n",
    "\n",
    "    all_flat = [p for s in all_phrases_sets for p in s]\n",
    "    counts = collections.Counter(all_flat)\n",
    "    sorted_methods = sorted(counts.keys(), key=lambda x: (-counts[x], x))\n",
    "    print(f\"\\nTotal unique phrases: {len(counts)}\")\n",
    "    print(f\"Most frequent (top 10): {sorted_methods[:10]}\")\n",
    "    return sorted_methods, counts\n",
    "\n",
    "\n",
    "def filter_generic_phrases(phrases, min_specificity_words=1):\n",
    "    \"\"\"Remove generic phrases using comprehensive blacklist.\"\"\"\n",
    "    \n",
    "    # Comprehensive blacklist of generic terms\n",
    "    generic_blacklist = {\n",
    "        # Domain generic\n",
    "        'energy', 'power', 'system', 'network', 'control', 'data',\n",
    "        \n",
    "        # Method generic  \n",
    "        'analysis', 'method', 'approach', 'technique', 'procedure', \n",
    "        'framework', 'model', 'design', 'optimization', 'algorithm',\n",
    "        \n",
    "        # Process generic\n",
    "        'application', 'implementation', 'development', 'evaluation',\n",
    "        'assessment', 'review', 'study', 'research', 'investigation'\n",
    "    }\n",
    "    \n",
    "    # Patterns to exclude (domain + generic combinations)\n",
    "    generic_patterns = [\n",
    "        r'^(energy|power|system|network|electrical)\\s+(analysis|method|approach|design|optimization)$',\n",
    "        r'^(control|data|signal)\\s+(analysis|method|processing)$',\n",
    "        r'^(system|network)\\s+(optimization|design|analysis)$'\n",
    "    ]\n",
    "    \n",
    "    filtered_phrases = []\n",
    "    \n",
    "    for phrase in phrases:\n",
    "        phrase_lower = phrase.lower().strip()\n",
    "        words = phrase_lower.split()\n",
    "        \n",
    "        # Skip if too generic (most words are in blacklist)\n",
    "        generic_word_count = sum(1 for word in words if word in generic_blacklist)\n",
    "        if generic_word_count >= len(words) - min_specificity_words:\n",
    "            continue\n",
    "            \n",
    "        # Skip if matches generic patterns\n",
    "        if any(re.match(pattern, phrase_lower) for pattern in generic_patterns):\n",
    "            continue\n",
    "            \n",
    "        # Skip obvious generic combinations\n",
    "        if len(words) == 2 and all(word in generic_blacklist for word in words):\n",
    "            continue\n",
    "            \n",
    "        filtered_phrases.append(phrase)\n",
    "    \n",
    "    return filtered_phrases\n",
    "\n",
    "def load_method_phrases_from_csv(filename=\"extracted_method_phrases.csv\"):\n",
    "    \"\"\"Load method phrases from CSV with cleaning\"\"\"\n",
    "    try:\n",
    "        filepath = os.path.join(SAVE_DIR, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        method_phrases = df['Method Phrase'].tolist()\n",
    "        method_counts = df['Count'].tolist()\n",
    "        \n",
    "        # CRITICAL: Clean CSV artifacts before returning\n",
    "        method_phrases = prefilter_obvious_duplicates(method_phrases)\n",
    "        \n",
    "        # Rebuild counts for cleaned phrases (set to 1 if not available)\n",
    "        if len(method_counts) != len(method_phrases):\n",
    "            method_counts = [1] * len(method_phrases)\n",
    "            \n",
    "        return method_phrases, method_counts\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to load method phrases: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def validate_method_groups_enhanced(groups, original_batch):\n",
    "    \"\"\"Enhanced validation to catch problematic groupings.\"\"\"\n",
    "    validated_groups = {}\n",
    "    \n",
    "    # Define forbidden groupings (methods that should never be grouped)\n",
    "    forbidden_pairs = [\n",
    "        (\"linear programming\", \"nonlinear programming\"),\n",
    "        (\"first order\", \"second order\"), \n",
    "        (\"generation shift\", \"injection shift\"),\n",
    "        (\"lstm\", \"gru\"),\n",
    "        (\"genetic algorithm\", \"particle swarm\"),\n",
    "        (\"saifi\", \"saidi\"),  # Different reliability indices\n",
    "        (\"form\", \"sorm\"),    # Different reliability methods\n",
    "    ]\n",
    "    \n",
    "    for canonical, variants in groups.items():\n",
    "        # Check for forbidden groupings\n",
    "        valid_group = True\n",
    "        for forbidden in forbidden_pairs:\n",
    "            variants_text = \" \".join(variants).lower()\n",
    "            canonical_text = canonical.lower()\n",
    "            \n",
    "            if ((forbidden[0] in variants_text or forbidden[0] in canonical_text) and \n",
    "                (forbidden[1] in variants_text or forbidden[1] in canonical_text)):\n",
    "                valid_group = False\n",
    "                logger.warning(f\"Splitting forbidden grouping: {canonical}\")\n",
    "                break\n",
    "        \n",
    "        if valid_group:\n",
    "            # Ensure canonical is the longest/most descriptive term (not abbreviation)\n",
    "            full_forms = [v for v in variants if len(v) > 5 and ' ' in v]  # Prefer multi-word terms\n",
    "            if full_forms:\n",
    "                canonical = max(full_forms, key=len)\n",
    "            else:\n",
    "                canonical = max(variants, key=len)\n",
    "            \n",
    "            validated_groups[canonical] = variants\n",
    "        else:\n",
    "            # Split into individual methods\n",
    "            for variant in variants:\n",
    "                validated_groups[variant] = [variant]\n",
    "    \n",
    "    return validated_groups\n",
    "\n",
    "\n",
    "def save_method_phrases_to_csv(method_phrases, method_counts, filename=\"extracted_method_phrases.csv\"):\n",
    "    \"\"\"Save method phrases to CSV file.\"\"\"\n",
    "    filename = os.path.join(SAVE_DIR, filename)\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Method Phrase\", \"Count\"])\n",
    "        if hasattr(method_counts, 'items'):\n",
    "            for phrase, count in method_counts.items():\n",
    "                clean_phrase = phrase.strip().replace('\\n', ' ')\n",
    "                writer.writerow([clean_phrase, count])\n",
    "        else:\n",
    "            for phrase, count in zip(method_phrases, method_counts):\n",
    "                clean_phrase = phrase.strip().replace('\\n', ' ')\n",
    "                writer.writerow([clean_phrase, count])\n",
    "    print(f\"✓ Saved method phrases to {filename}\")\n",
    "\n",
    "# ================================================================\n",
    "# ENHANCED METHOD CONSOLIDATION FUNCTIONS - ALL MISSING FUNCTIONS\n",
    "# ================================================================\n",
    "\n",
    "def prefilter_obvious_duplicates(method_list, similarity_threshold=0.95):\n",
    "    \"\"\"Remove obvious near-duplicates before LLM processing to improve efficiency.\"\"\"\n",
    "    from difflib import SequenceMatcher\n",
    "    \n",
    "    filtered_methods = []\n",
    "    seen_methods = set()\n",
    "    \n",
    "    for method in sorted(method_list, key=len):  # Process shorter methods first\n",
    "        method_lower = method.lower().strip()\n",
    "        \n",
    "        is_duplicate = False\n",
    "        for seen in seen_methods:\n",
    "            similarity = SequenceMatcher(None, method_lower, seen).ratio()\n",
    "            if similarity >= similarity_threshold:\n",
    "                is_duplicate = True\n",
    "                break\n",
    "        \n",
    "        if not is_duplicate:\n",
    "            filtered_methods.append(method)\n",
    "            seen_methods.add(method_lower)\n",
    "    \n",
    "    print(f\"Pre-filtering: {len(method_list)} → {len(filtered_methods)} methods ({len(method_list) - len(filtered_methods)} obvious duplicates removed)\")\n",
    "    return filtered_methods\n",
    "\n",
    "def are_methods_truly_similar(method_variants):\n",
    "    \"\"\"Check if methods in a group are truly the same technique by analyzing core words.\"\"\"\n",
    "    if len(method_variants) <= 1:\n",
    "        return True\n",
    "    \n",
    "    # Extract core words (remove common qualifiers that indicate different techniques)\n",
    "    qualifiers = {'improved', 'enhanced', 'adaptive', 'advanced', 'modified', 'sequential', 'parallel', \n",
    "                 'distributed', 'hybrid', 'multi', 'bi', 'tri', 'sub', 'quasi'}\n",
    "    \n",
    "    core_words_sets = []\n",
    "    for method in method_variants:\n",
    "        words = set(method.lower().split())\n",
    "        core_words = words - qualifiers\n",
    "        core_words_sets.append(core_words)\n",
    "    \n",
    "    # Check if core words overlap significantly across all variants\n",
    "    if len(core_words_sets) < 2:\n",
    "        return True\n",
    "    \n",
    "    base_core = core_words_sets[0]  # FIXED: was incorrectly `core_words_sets`\n",
    "    for other_core in core_words_sets[1:]:\n",
    "        if not base_core or not other_core:  # Handle empty sets\n",
    "            continue\n",
    "        overlap = len(base_core & other_core) / len(base_core | other_core) if (base_core | other_core) else 0\n",
    "        if overlap < 0.7:  # Less than 70% overlap in core words\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\"\"\"def validate_method_groups(groups, original_batch):\n",
    "   #SIMPLIFIED validation that preserves LLM groupings\n",
    "    validated = {}\n",
    "    original_batch_lower = [m.lower() for m in original_batch]\n",
    "    \n",
    "    for canonical, variants in groups.items():\n",
    "        if not isinstance(variants, list):\n",
    "            variants = [variants]\n",
    "        \n",
    "        # Keep variants that exist in original batch (case insensitive)\n",
    "        clean_variants = []\n",
    "        for variant in variants:\n",
    "            variant_lower = str(variant).strip().lower()\n",
    "            if variant_lower in original_batch_lower:\n",
    "                # FIXED: Keep original casing from original_batch\n",
    "                original_idx = original_batch_lower.index(variant_lower)\n",
    "                clean_variants.append(original_batch[original_idx])\n",
    "        \n",
    "        if clean_variants:\n",
    "            # Use provided canonical name (don't change it)\n",
    "            canonical_clean = canonical.lower()  # Normalize casing only\n",
    "            validated[canonical_clean] = clean_variants\n",
    "    \n",
    "    print(f\"  Validation preserved {len(validated)} groups from LLM\")\n",
    "    return validated\n",
    "\"\"\"\n",
    "\n",
    "def have_common_core_terms(method1, method2):\n",
    "    \"\"\"Check if two methods share meaningful core terms beyond stop words.\"\"\"\n",
    "    stop_words = {'and', 'or', 'the', 'a', 'an', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}\n",
    "    \n",
    "    words1 = set(method1.split()) - stop_words\n",
    "    words2 = set(method2.split()) - stop_words\n",
    "    \n",
    "    if len(words1) == 0 or len(words2) == 0:\n",
    "        return False\n",
    "    \n",
    "    # Require at least 50% overlap in core terms\n",
    "    overlap = len(words1 & words2) / min(len(words1), len(words2))\n",
    "    return overlap >= 0.5\n",
    "\n",
    "def fallback_similarity_grouping(method_batch, similarity_threshold=0.85):\n",
    "    \"\"\"Fallback grouping using string similarity when LLM fails.\"\"\"\n",
    "    from difflib import SequenceMatcher\n",
    "    \n",
    "    groups = {}\n",
    "    processed = set()\n",
    "    \n",
    "    for method in sorted(method_batch, key=len):\n",
    "        if method in processed:\n",
    "            continue\n",
    "        \n",
    "        # Find similar methods using both string similarity and semantic checks\n",
    "        similar_methods = [method]\n",
    "        method_lower = method.lower()\n",
    "        \n",
    "        for other_method in method_batch:\n",
    "            if other_method != method and other_method not in processed:\n",
    "                other_lower = other_method.lower()\n",
    "                similarity = SequenceMatcher(None, method_lower, other_lower).ratio()\n",
    "                \n",
    "                if similarity >= similarity_threshold:\n",
    "                    # Additional check: ensure they're not just coincidentally similar\n",
    "                    if have_common_core_terms(method_lower, other_lower):\n",
    "                        similar_methods.append(other_method)\n",
    "                        processed.add(other_method)\n",
    "        \n",
    "        canonical = min(similar_methods, key=len)  # Use shortest as canonical\n",
    "        groups[canonical] = similar_methods\n",
    "        processed.add(method)\n",
    "    \n",
    "    return groups\n",
    "\n",
    "def post_process_method_groups(variant_groups):\n",
    "    \"\"\"MINIMAL post-processing that preserves LLM consolidation work\"\"\"\n",
    "    final_groups = {}\n",
    "    \n",
    "    for canonical, variants in variant_groups.items():\n",
    "        # Remove duplicates but keep groups intact\n",
    "        clean_variants = list(set(variants))\n",
    "        \n",
    "        # Only split if canonical name is obviously generic (very restrictive)\n",
    "        truly_generic = ['method', 'analysis', 'approach', 'technique'] \n",
    "        if any(canonical.lower() == generic for generic in truly_generic):\n",
    "            # Only split if canonical is EXACTLY one of these generic terms\n",
    "            for variant in clean_variants:\n",
    "                final_groups[variant] = [variant]\n",
    "        else:\n",
    "            # PRESERVE the group as-is\n",
    "            final_groups[canonical] = clean_variants\n",
    "    \n",
    "    print(f\"  Post-processing preserved {len(final_groups)} groups\")\n",
    "    return final_groups\n",
    "\n",
    "\n",
    "def build_method_variant_groups_enhanced(\n",
    "    method_list, client, model_type, credit_tracker, prompt,\n",
    "    batch_size=50, top_p=0.85, temp=0.15\n",
    "):\n",
    "    \"\"\"Enhanced method grouping with configurable prompt.\"\"\"\n",
    "    variant_groups = {}\n",
    "    processed_methods = set()\n",
    "    \n",
    "    # Step 1: Pre-filter obvious duplicates to improve LLM efficiency\n",
    "    method_list = prefilter_obvious_duplicates(method_list)\n",
    "    \n",
    "    # Step 2: Process methods in batches using configurable prompting\n",
    "    for i in range(0, len(method_list), batch_size):\n",
    "        batch = method_list[i:i + batch_size]\n",
    "        batch = [m for m in batch if m not in processed_methods]\n",
    "        \n",
    "        if not batch:\n",
    "            continue\n",
    "            \n",
    "        # Format the prompt with current batch of methods\n",
    "        formatted_prompt = prompt.format(method_list=batch)\n",
    "\n",
    "        try:\n",
    "            # Configure API parameters for different model types\n",
    "            api_params = {\n",
    "                \"model\": model_type,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a scientific method classification expert. Group only true variants while preserving distinct techniques.\"},\n",
    "                    {\"role\": \"user\", \"content\": formatted_prompt}\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            if model_type.startswith('gpt-5-nano'):\n",
    "                api_params[\"max_completion_tokens\"] = 3000\n",
    "            else:\n",
    "                api_params[\"temperature\"] = temp\n",
    "                api_params[\"top_p\"] = top_p\n",
    "                api_params[\"max_tokens\"] = 3000\n",
    "            \n",
    "            # Make LLM call and process response\n",
    "            response = client.chat.completions.create(**api_params)\n",
    "            logger.info(f\"LLM raw response: {response}\")\n",
    "            content = response.choices[0].message.content\n",
    "            logger.info(f\"LLM content: {content}\")\n",
    "            credit_tracker.update(num_tokens_from_string(content, model_type))\n",
    "            \n",
    "            print(f\"✓ Batch {i//batch_size + 1} LLM response received: {len(content)} characters\")\n",
    "            \n",
    "            # Parse the dictionary response with error handling\n",
    "            try:\n",
    "                content = content.strip()\n",
    "                if content.startswith('```'):\n",
    "                    content = re.sub(r'```(?:python|json)?\\n?', '', content)\n",
    "                    content = re.sub(r'```$', '', content)\n",
    "                \n",
    "                dict_match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
    "                if dict_match:\n",
    "                    groups = ast.literal_eval(dict_match.group(0))\n",
    "                    \n",
    "                    # Validate and clean the groups using enhanced validation\n",
    "                    validated_groups = validate_method_groups_enhanced(groups, batch)\n",
    "                    variant_groups.update(validated_groups)\n",
    "                    processed_methods.update(batch)\n",
    "                    \n",
    "                    print(f\"✓ Processed batch {i//batch_size + 1}: {len(validated_groups)} groups created\")\n",
    "                else:\n",
    "                    print(f\"⚠️ No dictionary found in LLM response for batch {i//batch_size + 1}\")\n",
    "                    fallback_groups = fallback_similarity_grouping(batch)\n",
    "                    variant_groups.update(fallback_groups)\n",
    "                    processed_methods.update(batch)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to parse LLM response, using fallback similarity grouping: {e}\")\n",
    "                fallback_groups = fallback_similarity_grouping(batch)\n",
    "                variant_groups.update(fallback_groups)\n",
    "                processed_methods.update(batch)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"LLM call failed, using fallback: {e}\")\n",
    "            fallback_groups = fallback_similarity_grouping(batch)\n",
    "            variant_groups.update(fallback_groups)\n",
    "            processed_methods.update(batch)\n",
    "\n",
    "    # Step 3: Post-process to ensure quality and remove inappropriate groupings\n",
    "    final_groups = post_process_method_groups(variant_groups)\n",
    "    \n",
    "    logger.info(f\"Created {len(final_groups)} method variant groups from {len(method_list)} original methods\")\n",
    "    return final_groups\n",
    "\n",
    "\n",
    "def create_variant_mapping(variant_groups):\n",
    "    \"\"\"Create mapping from any variant to its canonical form for method consolidation.\"\"\"\n",
    "    variant_to_canonical = {}\n",
    "    canonical_to_variants = {}\n",
    "    \n",
    "    for canonical, variants in variant_groups.items():\n",
    "        canonical_to_variants[canonical] = variants\n",
    "        for variant in variants:\n",
    "            variant_to_canonical[variant.lower()] = canonical\n",
    "    \n",
    "    return variant_to_canonical, canonical_to_variants\n",
    "\n",
    "def consolidate_variant_scores(scores, method_names, variant_to_canonical):\n",
    "    \"\"\"\n",
    "    Consolidate method scores to prevent double-counting of variants.\n",
    "    Uses MAXIMUM score among variants (not sum) to avoid inflating scores.\n",
    "    \"\"\"\n",
    "    canonical_methods = list(set(variant_to_canonical.values()))\n",
    "    canonical_scores = np.zeros((scores.shape[0], len(canonical_methods)))  # FIXED: was scores.shape\n",
    "    \n",
    "    canonical_to_idx = {method: i for i, method in enumerate(canonical_methods)}\n",
    "    \n",
    "    for j, method_name in enumerate(method_names):\n",
    "        method_lower = method_name.lower()\n",
    "        canonical = variant_to_canonical.get(method_lower, method_name)\n",
    "        \n",
    "        if canonical in canonical_to_idx:\n",
    "            canonical_idx = canonical_to_idx[canonical]\n",
    "            # Use MAXIMUM score among variants (not sum) to prevent double-counting\n",
    "            canonical_scores[:, canonical_idx] = np.maximum(\n",
    "                canonical_scores[:, canonical_idx], \n",
    "                scores[:, j]\n",
    "            )\n",
    "    \n",
    "    return canonical_scores, canonical_methods\n",
    "\n",
    "# ================================================================\n",
    "# METHOD SCORING FUNCTIONS\n",
    "# ================================================================\n",
    "\n",
    "def compute_enhanced_tfidf_scores(processed_texts, method_variants_dict, ngram_range=(1, 4), min_df=1, max_df=0.95):\n",
    "    \"\"\"Compute TF-IDF scores for all method variants\"\"\"\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "    \n",
    "    existing_variants = []\n",
    "    for variant in all_variants:\n",
    "        variant_pattern = r'\\b' + re.escape(variant.lower()) + r'\\b'\n",
    "        found = False\n",
    "        for text in processed_texts[:1000]:  # Sample check for efficiency\n",
    "            if re.search(variant_pattern, text.lower()):\n",
    "                existing_variants.append(variant)\n",
    "                found = True\n",
    "                break\n",
    "        if not found and len(existing_variants) < 5000:\n",
    "            for text in processed_texts:\n",
    "                if re.search(variant_pattern, text.lower()):\n",
    "                    existing_variants.append(variant)\n",
    "                    break\n",
    "    \n",
    "    print(f\"Found {len(existing_variants)} variants that exist in corpus out of {len(all_variants)} total\")\n",
    "    \n",
    "    if not existing_variants:\n",
    "        logger.warning(\"No method variants found in corpus!\")\n",
    "        return np.zeros((len(processed_texts), 1)), ['no_methods_found']\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        vocabulary=existing_variants,\n",
    "        ngram_range=ngram_range,\n",
    "        min_df=min_df,\n",
    "        max_df=max_df,\n",
    "        norm='l2',\n",
    "        token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(processed_texts)\n",
    "        scores = tfidf_matrix.toarray()\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        return scores, feature_names\n",
    "    except Exception as e:\n",
    "        logger.error(f\"TF-IDF computation failed: {e}\")\n",
    "        return np.zeros((len(processed_texts), len(existing_variants))), existing_variants\n",
    "\n",
    "def compute_enhanced_lda_scores(processed_texts, method_variants_dict, ngram_range=(1, 4), n_topics=None, max_iter=20):\n",
    "    \"\"\"Compute LDA scores for method variants. FIXED VERSION\"\"\"\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "\n",
    "    if n_topics is None:\n",
    "        n_topics = min(len(all_variants), 100)\n",
    "\n",
    "    vectorizer = CountVectorizer(\n",
    "        vocabulary=all_variants,\n",
    "        ngram_range=ngram_range,\n",
    "        token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        doc_term_matrix = vectorizer.fit_transform(processed_texts)\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        \n",
    "        print(f\"  LDA Debug: doc_term_matrix.shape = {doc_term_matrix.shape}\")\n",
    "        print(f\"  LDA Debug: len(all_variants) = {len(all_variants)}\")\n",
    "        print(f\"  LDA Debug: len(feature_names) = {len(feature_names)}\")\n",
    "        \n",
    "        if n_topics >= 2 and doc_term_matrix.shape[1] > 0:\n",
    "            # FIXED: Use min to prevent n_topics > n_features\n",
    "            actual_topics = min(n_topics, doc_term_matrix.shape[1], len(all_variants))\n",
    "            \n",
    "            lda = LatentDirichletAllocation(\n",
    "                n_components=actual_topics,\n",
    "                learning_method='batch',\n",
    "                random_state=42,\n",
    "                max_iter=max_iter\n",
    "            )\n",
    "            \n",
    "            # Fit LDA and get topic distributions\n",
    "            doc_topic_matrix = lda.fit_transform(doc_term_matrix)\n",
    "            topic_term_matrix = lda.components_  # Shape: (n_topics, n_features)\n",
    "            \n",
    "            print(f\"  LDA Debug: doc_topic_matrix.shape = {doc_topic_matrix.shape}\")\n",
    "            print(f\"  LDA Debug: topic_term_matrix.shape = {topic_term_matrix.shape}\")\n",
    "            \n",
    "            # FIXED: Convert topic-document matrix back to document-term space\n",
    "            # We want scores for each method variant in each document\n",
    "            # Method: multiply doc-topic scores by topic-term weights\n",
    "            lda_scores = np.dot(doc_topic_matrix, topic_term_matrix)\n",
    "            \n",
    "            print(f\"  LDA Debug: final lda_scores.shape = {lda_scores.shape}\")\n",
    "            \n",
    "            # Ensure correct dimensions\n",
    "            if lda_scores.shape[1] != len(all_variants):\n",
    "                print(f\"  LDA Warning: Score matrix columns ({lda_scores.shape[1]}) != variants ({len(all_variants)})\")\n",
    "                # Pad or truncate to match expected dimensions\n",
    "                if lda_scores.shape[1] < len(all_variants):\n",
    "                    padding = np.zeros((lda_scores.shape[0], len(all_variants) - lda_scores.shape[1]))\n",
    "                    lda_scores = np.hstack([lda_scores, padding])\n",
    "                else:\n",
    "                    lda_scores = lda_scores[:, :len(all_variants)]\n",
    "                    \n",
    "                print(f\"  LDA Debug: adjusted lda_scores.shape = {lda_scores.shape}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"  LDA: Creating zero matrix due to insufficient topics/features\")\n",
    "            lda_scores = np.zeros((len(processed_texts), len(all_variants)))\n",
    "\n",
    "        return lda_scores, feature_names\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"LDA computation failed: {e}\")\n",
    "        print(f\"LDA Error details: {e}\")\n",
    "        return np.zeros((len(processed_texts), len(all_variants))), all_variants\n",
    "\n",
    "    \n",
    "def compute_enhanced_compound_scores(df, method_variants_dict, processed_col='processed_text', window=150):\n",
    "    \"\"\"Enhanced compound scoring that handles variants\"\"\"\n",
    "    n_docs = len(df)\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "    \n",
    "    n_methods = len(all_variants)\n",
    "    scores = np.zeros((n_docs, n_methods), dtype=np.float32)\n",
    "    docs = df[processed_col].fillna('').str.lower().tolist()\n",
    "    \n",
    "    for j, variant in enumerate(all_variants):\n",
    "        variant_l = variant.lower()\n",
    "        \n",
    "        for i, text in enumerate(docs):\n",
    "            if variant_l in text:\n",
    "                scores[i, j] = 1.0\n",
    "            elif len(variant_l.split()) > 1:\n",
    "                words = variant_l.split()\n",
    "                if all(word in text for word in words):\n",
    "                    scores[i, j] = 0.7\n",
    "            elif len(variant_l) <= 5 and variant_l.upper() in text.upper():\n",
    "                scores[i, j] = 0.8\n",
    "    \n",
    "    return scores, all_variants\n",
    "\n",
    "def assign_methods_improved(df, scores, method_names, top_n=5, min_score=0.005):\n",
    "    \"\"\"Improved method assignment with better diagnostics.\"\"\"\n",
    "    n_papers, n_methods = scores.shape\n",
    "    \n",
    "    # Initialize method columns\n",
    "    for i in range(top_n):\n",
    "        df[f'Method_{i+1}'] = ''\n",
    "        df[f'Method_{i+1}_Score'] = 0.0\n",
    "    \n",
    "    df['Primary_Method'] = ''\n",
    "    df['Primary_Method_Score'] = 0.0\n",
    "    df['Method_Confidence'] = 'Low'\n",
    "    df['Total_Method_Score'] = 0.0\n",
    "    \n",
    "    assigned_count = 0\n",
    "    \n",
    "    for paper_idx in range(n_papers):\n",
    "        paper_scores = scores[paper_idx, :]\n",
    "        \n",
    "        top_indices = np.argsort(paper_scores)[::-1][:top_n]\n",
    "        top_scores = paper_scores[top_indices]\n",
    "        \n",
    "        valid_mask = top_scores >= min_score\n",
    "        valid_indices = top_indices[valid_mask]\n",
    "        valid_scores = top_scores[valid_mask]\n",
    "        \n",
    "        if len(valid_indices) > 0:\n",
    "            assigned_count += 1\n",
    "            \n",
    "            # FIXED: Use [0] to get first element, not entire array\n",
    "            df.loc[paper_idx, 'Primary_Method'] = method_names[valid_indices[0]]\n",
    "            df.loc[paper_idx, 'Primary_Method_Score'] = valid_scores[0]\n",
    "            df.loc[paper_idx, 'Total_Method_Score'] = valid_scores.sum()\n",
    "            \n",
    "            if valid_scores[0] > 0.1:\n",
    "                df.loc[paper_idx, 'Method_Confidence'] = 'High'\n",
    "            elif valid_scores[0] > 0.05:\n",
    "                df.loc[paper_idx, 'Method_Confidence'] = 'Medium'\n",
    "            \n",
    "            for i, (idx, score) in enumerate(zip(valid_indices, valid_scores)):\n",
    "                if i < top_n:\n",
    "                    df.loc[paper_idx, f'Method_{i+1}'] = method_names[idx]\n",
    "                    df.loc[paper_idx, f'Method_{i+1}_Score'] = score\n",
    "    \n",
    "    logger.info(f\"  Assigned methods to {assigned_count}/{n_papers} papers ({100*assigned_count/n_papers:.1f}%)\")\n",
    "    return df\n",
    "\n",
    "def aggressive_fallback_grouping(method_list, similarity_threshold=0.75):\n",
    "    \"\"\"\n",
    "    Enhanced fallback grouping with aggressive similarity matching and pattern recognition.\n",
    "    This will handle cases where LLM API fails.\n",
    "    \"\"\"\n",
    "    from difflib import SequenceMatcher\n",
    "    \n",
    "    groups = {}\n",
    "    processed = set()\n",
    "    \n",
    "    # First pass: Handle obvious patterns\n",
    "    pattern_groups = handle_common_patterns(method_list)\n",
    "    for canonical, variants in pattern_groups.items():\n",
    "        groups[canonical] = variants\n",
    "        processed.update(variants)\n",
    "    \n",
    "    # Second pass: Similarity-based grouping for remaining methods\n",
    "    remaining_methods = [m for m in method_list if m not in processed]\n",
    "    \n",
    "    for method in sorted(remaining_methods, key=len):\n",
    "        if method in processed:\n",
    "            continue\n",
    "            \n",
    "        group = [method]\n",
    "        method_lower = method.lower()\n",
    "        method_tokens = set(method_lower.split())\n",
    "        \n",
    "        for other_method in remaining_methods:\n",
    "            if other_method == method or other_method in processed:\n",
    "                continue\n",
    "                \n",
    "            other_lower = other_method.lower()\n",
    "            other_tokens = set(other_lower.split())\n",
    "            \n",
    "            # Multiple similarity checks\n",
    "            string_sim = SequenceMatcher(None, method_lower, other_lower).ratio()\n",
    "            token_overlap = len(method_tokens & other_tokens) / len(method_tokens | other_tokens) if (method_tokens | other_tokens) else 0\n",
    "            \n",
    "            # Check for containment (one is substring of other)\n",
    "            containment = method_lower in other_lower or other_lower in method_lower\n",
    "            \n",
    "            # Group if any condition met\n",
    "            if (string_sim >= similarity_threshold or \n",
    "                token_overlap >= 0.6 or \n",
    "                containment):\n",
    "                group.append(other_method)\n",
    "                processed.add(other_method)\n",
    "        \n",
    "        # Use shortest name as canonical\n",
    "        canonical = min(group, key=lambda x: (len(x), x))\n",
    "        groups[canonical] = group\n",
    "        processed.add(method)\n",
    "    \n",
    "    return groups\n",
    "\n",
    "def handle_common_patterns(method_list):\n",
    "    \"\"\"Handle common method name patterns that should be grouped together.\"\"\"\n",
    "    import re\n",
    "    \n",
    "    pattern_groups = {}\n",
    "    processed = set()\n",
    "    \n",
    "    # Common abbreviation patterns\n",
    "    abbreviation_patterns = [\n",
    "        (r'^ga$', r'genetic algorithm.*'),\n",
    "        (r'^pso$', r'particle swarm optimization.*'),\n",
    "        (r'^abc$', r'.*bee colony.*'),\n",
    "        (r'^gwo$', r'grey wolf.*'),\n",
    "        (r'^opf$', r'optimal power flow.*'),\n",
    "        (r'^milp$', r'.*integer.*linear.*programming.*'),\n",
    "        (r'^dnn.*', r'.*neural network.*'),\n",
    "        (r'^cnn$', r'convolutional neural network.*'),\n",
    "        (r'^rnn$', r'.*neural network rnn.*'),\n",
    "        (r'^svm$', r'support vector machine.*'),\n",
    "        (r'^pca$', r'principal component analysis.*'),\n",
    "    ]\n",
    "    \n",
    "    # Method variant patterns\n",
    "    variant_patterns = [\n",
    "        # Neural network variants\n",
    "        (r'.*neural network.*', ['neural network', 'bp neural network', 'neural network algorithm', 'artificial neural network']),\n",
    "        # Genetic algorithm variants  \n",
    "        (r'.*genetic algorithm.*', ['genetic algorithm', 'genetic algorithm ga', 'adaptive genetic algorithm']),\n",
    "        # Monte Carlo variants\n",
    "        (r'.*monte carlo.*', ['monte carlo simulation', 'sequential monte carlo', 'carlo simulation result']),\n",
    "        # Particle swarm variants\n",
    "        (r'.*particle swarm.*', ['particle swarm optimization', 'binary particle swarm', 'improved particle swarm optimization']),\n",
    "        # Random forest variants\n",
    "        (r'.*random forest.*', ['random forest', 'random forest rf', 'random forest algorithm']),\n",
    "        # Machine learning variants\n",
    "        (r'.*machine learning.*', ['machine learning', 'ensemble learning']),\n",
    "    ]\n",
    "    \n",
    "    # Group by abbreviation patterns\n",
    "    for abbrev_pattern, full_pattern in abbreviation_patterns:\n",
    "        abbrev_matches = []\n",
    "        full_matches = []\n",
    "        \n",
    "        for method in method_list:\n",
    "            if method in processed:\n",
    "                continue\n",
    "            if re.search(abbrev_pattern, method.lower()):\n",
    "                abbrev_matches.append(method)\n",
    "            elif re.search(full_pattern, method.lower()):\n",
    "                full_matches.append(method)\n",
    "        \n",
    "        if abbrev_matches and full_matches:\n",
    "            all_matches = abbrev_matches + full_matches\n",
    "            canonical = min(full_matches, key=len) if full_matches else min(abbrev_matches, key=len)\n",
    "            pattern_groups[canonical] = all_matches\n",
    "            processed.update(all_matches)\n",
    "    \n",
    "    # Group by variant patterns\n",
    "    for base_pattern, known_variants in variant_patterns:\n",
    "        matches = []\n",
    "        for method in method_list:\n",
    "            if method in processed:\n",
    "                continue\n",
    "            if (re.search(base_pattern, method.lower()) or \n",
    "                method.lower() in [v.lower() for v in known_variants]):\n",
    "                matches.append(method)\n",
    "        \n",
    "        if len(matches) > 1:\n",
    "            canonical = min(matches, key=len)\n",
    "            pattern_groups[canonical] = matches\n",
    "            processed.update(matches)\n",
    "    \n",
    "    return pattern_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35425ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Cell 6: Method Scoring Functions (Enhanced)\n",
    "\n",
    "def compute_enhanced_tfidf_scores(processed_texts, method_variants_dict, ngram_range=(1, 4), min_df=1, max_df=0.95):\n",
    "    \"\"\"Compute TF-IDF scores for all method variants\"\"\"\n",
    "    # Get all variants\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "    \n",
    "    # Create vocabulary from actual variants that exist in corpus\n",
    "    existing_variants = []\n",
    "    for variant in all_variants:\n",
    "        # Check if variant appears in any document\n",
    "        variant_pattern = r'\\b' + re.escape(variant.lower()) + r'\\b'\n",
    "        found = False\n",
    "        for text in processed_texts:  # Sample check for efficiency\n",
    "            if re.search(variant_pattern, text.lower()):\n",
    "                existing_variants.append(variant)\n",
    "                found = True\n",
    "                break\n",
    "        if not found and len(existing_variants) < 5000:  # Keep checking if we don't have too many\n",
    "            for text in processed_texts:\n",
    "                if re.search(variant_pattern, text.lower()):\n",
    "                    existing_variants.append(variant)\n",
    "                    break\n",
    "    \n",
    "    print(f\"Found {len(existing_variants)} variants that exist in corpus out of {len(all_variants)} total\")\n",
    "    \n",
    "    if not existing_variants:\n",
    "        logger.warning(\"No method variants found in corpus!\")\n",
    "        return np.zeros((len(processed_texts), 1)), ['no_methods_found']\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        vocabulary=existing_variants,\n",
    "        ngram_range=ngram_range,\n",
    "        min_df=min_df,\n",
    "        max_df=max_df,\n",
    "        norm='l2',\n",
    "        token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(processed_texts)\n",
    "        scores = tfidf_matrix.toarray()\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        return scores, feature_names\n",
    "    except Exception as e:\n",
    "        logger.error(f\"TF-IDF computation failed: {e}\")\n",
    "        return np.zeros((len(processed_texts), len(existing_variants))), existing_variants\n",
    "\n",
    "def compute_enhanced_lda_scores(processed_texts, method_variants_dict, ngram_range=(1, 4), n_topics=None, max_iter=20):\n",
    "    \"\"\"Compute LDA scores for method variants.\"\"\"\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "\n",
    "    if n_topics is None:\n",
    "        n_topics = min(len(all_variants), 100)\n",
    "\n",
    "    vectorizer = CountVectorizer(\n",
    "        vocabulary=all_variants,\n",
    "        ngram_range=ngram_range,\n",
    "        token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        doc_term_matrix = vectorizer.fit_transform(processed_texts)\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "        if n_topics >= 2 and doc_term_matrix.shape[1] > 0:\n",
    "            lda = LatentDirichletAllocation(\n",
    "                n_components=min(n_topics, doc_term_matrix.shape[1]),\n",
    "                learning_method='batch',\n",
    "                random_state=42,\n",
    "                max_iter=max_iter\n",
    "            )\n",
    "            lda_matrix = lda.fit_transform(doc_term_matrix)\n",
    "        else:\n",
    "            lda_matrix = np.zeros((doc_term_matrix.shape[0], len(all_variants)))\n",
    "\n",
    "        return lda_matrix, feature_names\n",
    "    except Exception as e:\n",
    "        logger.error(f\"LDA computation failed: {e}\")\n",
    "        return np.zeros((len(processed_texts), len(all_variants))), all_variants\n",
    "    \n",
    "def compute_enhanced_compound_scores(df, method_variants_dict, processed_col='processed_text', window=150):\n",
    "    \"\"\"Enhanced compound scoring with proximity matching and filtering common stop/context words\"\"\"\n",
    "    import re\n",
    "    from itertools import product\n",
    "    \n",
    "    n_docs = len(df)\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "    \n",
    "    n_methods = len(all_variants)\n",
    "    scores = np.zeros((n_docs, n_methods), dtype=np.float32)\n",
    "    docs = df[processed_col].fillna('').str.lower().tolist()\n",
    "    \n",
    "    # Common distracting words that indicate figure/table/diagram context\n",
    "    forbidden_context_words = {\n",
    "        \"figure\", \"table\", \"diagram\", \"plot\", \"chart\", \"graph\", \"section\", \n",
    "        \"appendix\", \"equation\", \"formula\", \"example\", \"case\", \"study\", \n",
    "        \"shown\", \"presented\", \"illustrated\", \"depicts\", \"shows\"\n",
    "    }\n",
    "    \n",
    "    for j, variant in enumerate(all_variants):\n",
    "        variant_l = variant.lower().strip()\n",
    "        variant_words = variant_l.split()\n",
    "        \n",
    "        for i, text in enumerate(docs):\n",
    "            # 1. Exact phrase match (highest priority)\n",
    "            pattern = r'\\b' + re.escape(variant_l) + r'\\b'\n",
    "            if re.search(pattern, text):\n",
    "                scores[i, j] = 1.0\n",
    "                continue\n",
    "            \n",
    "            # 2. Hyphenated form matching\n",
    "            hyphenated_pattern = r'\\b' + re.escape(variant_l.replace(' ', '-')) + r'\\b'\n",
    "            if re.search(hyphenated_pattern, text):\n",
    "                scores[i, j] = 1.0\n",
    "                continue\n",
    "            \n",
    "            # 3. Pure abbreviation matching (≤4 chars, single word)\n",
    "            if len(variant_l) <= 4 and variant_l.isalpha() and len(variant_words) == 1:\n",
    "                abbrev_pattern = r'\\b' + variant_l.upper() + r'\\b'\n",
    "                if re.search(abbrev_pattern, text.upper()):\n",
    "                    scores[i, j] = 0.9\n",
    "                continue\n",
    "            \n",
    "            # 4. Proximity matching for compound terms (2-5 words only)\n",
    "            if 2 <= len(variant_words) <= 5:\n",
    "                word_positions = []\n",
    "                \n",
    "                # Find positions of each word\n",
    "                for word in variant_words:\n",
    "                    # Skip very common words that might cause false positives\n",
    "                    if word in {\"of\", \"the\", \"a\", \"an\", \"and\", \"or\", \"in\", \"on\", \"at\", \"to\", \"for\"}:\n",
    "                        continue\n",
    "                        \n",
    "                    word_pattern = r'\\b' + re.escape(word) + r'\\b'\n",
    "                    matches = [m.start() for m in re.finditer(word_pattern, text)]\n",
    "                    if not matches:\n",
    "                        word_positions = []\n",
    "                        break\n",
    "                    word_positions.append(matches)\n",
    "                \n",
    "                # Check if all words found and proximity conditions met\n",
    "                if word_positions and len(word_positions) >= len(variant_words) - 1:  # Allow missing 1 stop word\n",
    "                    found_valid_match = False\n",
    "                    \n",
    "                    for pos_tuple in product(*word_positions):\n",
    "                        min_pos = min(pos_tuple)\n",
    "                        max_pos = max(pos_tuple)\n",
    "                        span = max_pos - min_pos\n",
    "                        \n",
    "                        # Check if within window and no forbidden context words nearby\n",
    "                        if span <= window:\n",
    "                            # Extract snippet around the match\n",
    "                            snippet_start = max(0, min_pos - 50)\n",
    "                            snippet_end = min(len(text), max_pos + 50)\n",
    "                            snippet = text[snippet_start:snippet_end]\n",
    "                            \n",
    "                            # Check for forbidden context words in the snippet\n",
    "                            has_forbidden_context = any(\n",
    "                                fw in snippet for fw in forbidden_context_words\n",
    "                            )\n",
    "                            \n",
    "                            if not has_forbidden_context:\n",
    "                                scores[i, j] = 0.7  # Lower score for proximity match\n",
    "                                found_valid_match = True\n",
    "                                break\n",
    "                    \n",
    "                    if found_valid_match:\n",
    "                        continue\n",
    "    \n",
    "    return scores, all_variants\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def aggregate_variant_scores_to_canonical(scores, variant_names, variant_to_canonical):\n",
    "    \"\"\"Aggregate variant scores back to canonical method names\"\"\"\n",
    "    canonical_methods = list(set(variant_to_canonical.values()))\n",
    "    canonical_scores = np.zeros((scores.shape[0], len(canonical_methods)))\n",
    "    \n",
    "    canonical_to_idx = {method: i for i, method in enumerate(canonical_methods)}\n",
    "    \n",
    "    for j, variant in enumerate(variant_names):\n",
    "        canonical = variant_to_canonical.get(variant.lower(), variant)\n",
    "        if canonical in canonical_to_idx:\n",
    "            canonical_idx = canonical_to_idx[canonical]\n",
    "            canonical_scores[:, canonical_idx] += scores[:, j]  # Sum scores for variants\n",
    "    \n",
    "    return canonical_scores, canonical_methods\n",
    "\n",
    "def prefilter_obvious_duplicates(method_list):\n",
    "    \"\"\"Clean CSV artifacts and normalize method names before LLM processing.\"\"\"\n",
    "    cleaned_methods = []\n",
    "    for method in method_list:\n",
    "        # Remove CSV artifacts (trailing quotes, commas, escaped characters)\n",
    "        cleaned = method.strip().strip('\"').strip(\"'\").rstrip(',').strip()\n",
    "        # Remove escaped quotes\n",
    "        cleaned = cleaned.replace('\\\\\"', '').replace(\"\\\\'\", '')\n",
    "        # Remove empty or very short entries\n",
    "        if len(cleaned) > 1:\n",
    "            cleaned_methods.append(cleaned)\n",
    "    \n",
    "    return list(set(cleaned_methods))  # Remove exact duplicates\n",
    "\n",
    "\n",
    "def assign_top_methods_enhanced(\n",
    "    df, canonical_scores, canonical_methods, variant_scores, variant_names,\n",
    "    top_n=5, min_score=0.005\n",
    "):\n",
    "    \"\"\"Enhanced method assignment with granular variant tracking\"\"\"\n",
    "    \n",
    "    # Assign top canonical methods\n",
    "    for rank in range(top_n):\n",
    "        top_method = []\n",
    "        top_score = []\n",
    "        top_variants = []\n",
    "        confidence = []\n",
    "\n",
    "        for i, row in enumerate(canonical_scores):\n",
    "            if np.allclose(row, row):  # All equal\n",
    "                top_method.append(\"\")\n",
    "                top_score.append(0.0)\n",
    "                top_variants.append(\"\")\n",
    "                confidence.append(\"\")\n",
    "                continue\n",
    "\n",
    "            idxs = np.argsort(row)[::-1]\n",
    "            if rank < len(idxs):\n",
    "                method_idx = idxs[rank]\n",
    "                method = canonical_methods[method_idx]\n",
    "                score = row[method_idx]\n",
    "                \n",
    "                if score >= min_score:\n",
    "                    # Find contributing variants\n",
    "                    variant_contributions = []\n",
    "                    for v_idx, variant in enumerate(variant_names):\n",
    "                        if variant_scores[i, v_idx] > 0:\n",
    "                            # Check if this variant belongs to the current canonical method\n",
    "                            variant_canonical = variant_to_canonical.get(variant.lower(), variant)\n",
    "                            if variant_canonical == method:\n",
    "                                variant_contributions.append(f\"{variant}({variant_scores[i, v_idx]:.2f})\")\n",
    "                    \n",
    "                    top_method.append(method)\n",
    "                    top_score.append(score)\n",
    "                    top_variants.append(\"; \".join(variant_contributions[:3]))  # Top 3 variants\n",
    "                    confidence.append(\"confident\" if score > min_score * 2 else \"low_confidence\")\n",
    "                else:\n",
    "                    top_method.append(\"\")\n",
    "                    top_score.append(0.0)\n",
    "                    top_variants.append(\"\")\n",
    "                    confidence.append(\"\")\n",
    "            else:\n",
    "                top_method.append(\"\")\n",
    "                top_score.append(0.0)\n",
    "                top_variants.append(\"\")\n",
    "                confidence.append(\"\")\n",
    "\n",
    "        df[f'Top_{rank+1}_Method'] = top_method\n",
    "        df[f'Top_{rank+1}_Score'] = top_score\n",
    "        df[f'Top_{rank+1}_Variants'] = top_variants\n",
    "        df[f'Top_{rank+1}_Confidence'] = confidence\n",
    "\n",
    "    # Set primary columns\n",
    "    df['Primary_Method'] = df['Top_1_Method']\n",
    "    df['Primary_Method_Score'] = df['Top_1_Score']\n",
    "    df['Primary_Method_Variants'] = df['Top_1_Variants']\n",
    "    df['Method_Confidence'] = df['Top_1_Confidence']\n",
    "\n",
    "    return df\n",
    "def save_method_phrases_to_csv(method_phrases, method_counts, filename=\"extracted_method_phrases.csv\"):\n",
    "    filename = os.path.join(SAVE_DIR, filename)\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Method Phrase\", \"Count\"])\n",
    "        # If method_counts is a Counter, convert to dict\n",
    "        if hasattr(method_counts, 'items'):\n",
    "            for phrase, count in method_counts.items():\n",
    "                clean_phrase = phrase.strip().replace('\\n', ' ')\n",
    "                writer.writerow([clean_phrase, count])\n",
    "        else:\n",
    "            # fallback: zipped lists\n",
    "            for phrase, count in zip(method_phrases, method_counts):\n",
    "                clean_phrase = phrase.strip().replace('\\n', ' ')\n",
    "                writer.writerow([clean_phrase, count])\n",
    "    print(f\"✓ Saved method phrases to {filename}\")\n",
    "    \n",
    "def assign_methods_improved(df, scores, method_names, top_n=5, min_score=0.005):\n",
    "    \"\"\"\n",
    "    Improved method assignment with better diagnostics.\n",
    "    \"\"\"\n",
    "    n_papers, n_methods = scores.shape\n",
    "    \n",
    "    # Initialize method columns\n",
    "    for i in range(top_n):\n",
    "        df[f'Method_{i+1}'] = ''\n",
    "        df[f'Method_{i+1}_Score'] = 0.0\n",
    "    \n",
    "    df['Primary_Method'] = ''\n",
    "    df['Primary_Method_Score'] = 0.0\n",
    "    df['Method_Confidence'] = 'Low'\n",
    "    df['Total_Method_Score'] = 0.0\n",
    "    \n",
    "    assigned_count = 0\n",
    "    \n",
    "    for paper_idx in range(n_papers):\n",
    "        paper_scores = scores[paper_idx, :]\n",
    "        \n",
    "        # Get top methods for this paper\n",
    "        top_indices = np.argsort(paper_scores)[::-1][:top_n]\n",
    "        top_scores = paper_scores[top_indices]\n",
    "        \n",
    "        # Filter by minimum score\n",
    "        valid_mask = top_scores >= min_score\n",
    "        valid_indices = top_indices[valid_mask]\n",
    "        valid_scores = top_scores[valid_mask]\n",
    "        \n",
    "        if len(valid_indices) > 0:\n",
    "            assigned_count += 1\n",
    "            \n",
    "            # Assign primary method\n",
    "            df.loc[paper_idx, 'Primary_Method'] = method_names[valid_indices[0]]\n",
    "            df.loc[paper_idx, 'Primary_Method_Score'] = valid_scores[0]\n",
    "            df.loc[paper_idx, 'Total_Method_Score'] = valid_scores.sum()\n",
    "            \n",
    "            # Assign confidence based on top score\n",
    "            if valid_scores[0] > 0.1:\n",
    "                df.loc[paper_idx, 'Method_Confidence'] = 'High'\n",
    "            elif valid_scores[0] > 0.05:\n",
    "                df.loc[paper_idx, 'Method_Confidence'] = 'Medium'\n",
    "            \n",
    "            # Assign all valid methods\n",
    "            for i, (idx, score) in enumerate(zip(valid_indices, valid_scores)):\n",
    "                if i < top_n:\n",
    "                    df.loc[paper_idx, f'Method_{i+1}'] = method_names[idx]\n",
    "                    df.loc[paper_idx, f'Method_{i+1}_Score'] = score\n",
    "    \n",
    "    logger.info(f\"  Assigned methods to {assigned_count}/{n_papers} papers ({100*assigned_count/n_papers:.1f}%)\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a86210a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 7: Enhanced Topic Analysis Functions with Multi-N-gram Support\n",
    "\n",
    "def run_lda_topic_modeling(df, num_topics=10, num_words=25):\n",
    "    tokenized_texts = df['processed_text'].apply(lambda x: x.split()).tolist()\n",
    "    bigram = Phrases(tokenized_texts, min_count=10, threshold=50, delimiter='_')\n",
    "    trigram = Phrases(bigram[tokenized_texts], threshold=50, delimiter='_')\n",
    "    phrased = []\n",
    "    for doc in tokenized_texts:\n",
    "        bigrams_ = [w for w in bigram[doc] if '_' in w]\n",
    "        trigrams_ = [w for w in trigram[bigram[doc]] if '_' in w]\n",
    "        combined = doc + bigrams_ + trigrams_\n",
    "        phrased.append(' '.join(combined))\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 1), token_pattern=r'\\b[\\w_-]+\\b', max_df=0.95, min_df=2, max_features=10000)\n",
    "    doc_term_matrix = vectorizer.fit_transform(phrased)\n",
    "    lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "    topic_distributions = lda_model.fit_transform(doc_term_matrix)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    topic_keywords = {}\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        top_indices = topic.argsort()[:-num_words-1:-1]\n",
    "        top_words = [feature_names[i] for i in top_indices]\n",
    "        topic_keywords[topic_idx] = {'top_words': top_words}\n",
    "    return lda_model, vectorizer, topic_distributions, topic_keywords\n",
    "\n",
    "def assign_papers_to_topics(topic_distributions):\n",
    "    paper_classifications = []\n",
    "    for idx, dist in enumerate(topic_distributions):\n",
    "        top_2_topics = np.argsort(dist)[-2:][::-1]\n",
    "        primary_score = dist[top_2_topics]\n",
    "        other_topics_sum = sum(dist) - primary_score\n",
    "        dominance_ratio = primary_score / (other_topics_sum + 1e-10)\n",
    "        paper_classifications.append({\n",
    "            'paper_idx': idx,\n",
    "            'primary_topic': top_2_topics[0],\n",
    "            'secondary_topic': top_2_topics[1],\n",
    "            'primary_score': primary_score,\n",
    "            'dominance_ratio': dominance_ratio\n",
    "        })\n",
    "    return paper_classifications\n",
    "\n",
    "def string_similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def topic_name_llm_robust(\n",
    "    lda_keywords, tfidf_ngrams, top_titles,\n",
    "    client, model_type, credit_tracker,\n",
    "    initial_iterations=3, max_iterations=10, similarity_threshold=0.7,\n",
    "    temp=0, top_p=1.0\n",
    "):\n",
    "    prompt = (\n",
    "        \"Based on the following keywords and n-grams from LDA and TF-IDF, plus top paper titles, provide a concise topic name \"\n",
    "        \"(bigram or trigram, single word if very specific):\\n\"\n",
    "        f\"LDA: {', '.join(lda_keywords)}\\n\"\n",
    "        f\"TFIDF: {', '.join(tfidf_ngrams)}\\n\"\n",
    "        f\"TITLES: {', '.join(top_titles)}\\n\"\n",
    "        \"Return ONLY the topic name.\"\n",
    "    )\n",
    "    iterations = initial_iterations\n",
    "    from collections import Counter\n",
    "    while iterations <= max_iterations:\n",
    "        generated_names = []\n",
    "        for _ in range(iterations):\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_type,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a science topic-naming assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=temp,\n",
    "                top_p=top_p\n",
    "            )\n",
    "            content = response.choices[0].message.content.strip()\n",
    "            if content:\n",
    "                generated_names.append(content)\n",
    "        for i, name in enumerate(generated_names):\n",
    "            matches = [other for j, other in enumerate(generated_names)\n",
    "                       if i != j and string_similarity(name, other) >= similarity_threshold]\n",
    "            if len(matches) >= len(generated_names)//2:\n",
    "                print(f\"Topic name stabilized after {iterations} iterations: {name}\")\n",
    "                return name\n",
    "        iterations += 2\n",
    "        print(f\"No majority topic name found, increasing iterations to {iterations}.\")\n",
    "    most_common = Counter(generated_names).most_common(1)\n",
    "    print(f\"Returning most common topic name after {max_iterations} iterations: {most_common}\")\n",
    "    return most_common\n",
    "\n",
    "def get_top_titles_for_topic(df, paper_classifications, topic_idx, n_titles=10):\n",
    "    dominant_papers = [p for p in paper_classifications if p['primary_topic'] == topic_idx]\n",
    "    paper_infos = [\n",
    "        (df.iloc[p['paper_idx']]['citationCount'] if 'citationCount' in df.columns else 0, df.iloc[p['paper_idx']]['title'])\n",
    "        for p in dominant_papers if not pd.isna(df.iloc[p['paper_idx']]['title'])\n",
    "    ]\n",
    "    # Correctly sort by citation count (descending)\n",
    "    top_titles = [title for _, title in sorted(paper_infos, key=lambda x: -x[0])[:n_titles]]\n",
    "    return top_titles\n",
    "\n",
    "def get_top_tfidf_ngrams_per_topic_enhanced(df, topic_col='Primary_Topic_Index', text_col='processed_text', \n",
    "                                          top_k=15, min_df=2, max_df=0.8):\n",
    "    \"\"\"\n",
    "    Enhanced function to extract top TF-IDF keywords, bigrams, and trigrams for each topic.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with topic assignments and text\n",
    "    - topic_col: Column name for topic indices\n",
    "    - text_col: Column name for processed text\n",
    "    - top_k: Number of top n-grams to extract per topic per type\n",
    "    - min_df: Minimum document frequency for TF-IDF\n",
    "    - max_df: Maximum document frequency for TF-IDF\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with structure: {topic_id: {'keywords': {...}, 'bigrams': {...}, 'trigrams': {...}}}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🔍 Extracting topic-specific n-grams...\")\n",
    "    \n",
    "    # Ensure text column exists and is not empty\n",
    "    if text_col not in df.columns:\n",
    "        print(f\"❌ Text column '{text_col}' not found in DataFrame\")\n",
    "        return {}\n",
    "    \n",
    "    # Remove rows with missing text or topic assignments\n",
    "    df_clean = df.dropna(subset=[text_col, topic_col]).copy()\n",
    "    print(f\"📊 Processing {len(df_clean)} documents across {df_clean[topic_col].nunique()} topics\")\n",
    "    \n",
    "    # Initialize result structure\n",
    "    topic_ngrams = {}\n",
    "    \n",
    "    # Get unique topics\n",
    "    unique_topics = sorted(df_clean[topic_col].dropna().unique())\n",
    "    \n",
    "    # Define n-gram configurations\n",
    "    ngram_configs = {\n",
    "        'keywords': (1, 1),    # Unigrams\n",
    "        'bigrams': (2, 2),     # Bigrams  \n",
    "        'trigrams': (3, 3)     # Trigrams\n",
    "    }\n",
    "    \n",
    "    for ngram_type, (min_n, max_n) in ngram_configs.items():\n",
    "        print(f\"📈 Processing {ngram_type} ({min_n}-{max_n} grams)...\")\n",
    "        \n",
    "        try:\n",
    "            # Create TF-IDF vectorizer for this n-gram type\n",
    "            vectorizer = TfidfVectorizer(\n",
    "                ngram_range=(min_n, max_n),\n",
    "                min_df=min_df,\n",
    "                max_df=max_df,\n",
    "                stop_words='english',\n",
    "                lowercase=True,\n",
    "                token_pattern=r'\\b[a-zA-Z][a-zA-Z0-9]*\\b'  # Only alphanumeric tokens starting with letter\n",
    "            )\n",
    "            \n",
    "            # Fit on all documents\n",
    "            tfidf_matrix = vectorizer.fit_transform(df_clean[text_col])\n",
    "            feature_names = vectorizer.get_feature_names_out()\n",
    "            \n",
    "            print(f\"  ✅ Created {len(feature_names)} {ngram_type} features\")\n",
    "            \n",
    "            # Extract top terms for each topic\n",
    "            for topic_idx in unique_topics:\n",
    "                topic_idx = int(topic_idx)\n",
    "                \n",
    "                # Initialize topic entry if not exists\n",
    "                if topic_idx not in topic_ngrams:\n",
    "                    topic_ngrams[topic_idx] = {}\n",
    "                \n",
    "                # Get documents for this topic\n",
    "                doc_indices = df_clean[df_clean[topic_col] == topic_idx].index\n",
    "                topic_doc_positions = [df_clean.index.get_loc(idx) for idx in doc_indices]\n",
    "                \n",
    "                if len(topic_doc_positions) == 0:\n",
    "                    topic_ngrams[topic_idx][ngram_type] = {}\n",
    "                    continue\n",
    "                \n",
    "                # Calculate mean TF-IDF scores for this topic\n",
    "                topic_tfidf = tfidf_matrix[topic_doc_positions].mean(axis=0).A1\n",
    "                \n",
    "                # Get top terms\n",
    "                top_indices = topic_tfidf.argsort()[-top_k:][::-1]\n",
    "                top_terms = {\n",
    "                    feature_names[i]: float(topic_tfidf[i]) \n",
    "                    for i in top_indices \n",
    "                    if topic_tfidf[i] > 0\n",
    "                }\n",
    "                \n",
    "                topic_ngrams[topic_idx][ngram_type] = top_terms\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error processing {ngram_type}: {e}\")\n",
    "            # Initialize empty entries for all topics for this n-gram type\n",
    "            for topic_idx in unique_topics:\n",
    "                topic_idx = int(topic_idx)\n",
    "                if topic_idx not in topic_ngrams:\n",
    "                    topic_ngrams[topic_idx] = {}\n",
    "                topic_ngrams[topic_idx][ngram_type] = {}\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n📊 N-gram Extraction Summary:\")\n",
    "    for topic_idx in sorted(topic_ngrams.keys()):\n",
    "        topic_data = topic_ngrams[topic_idx]\n",
    "        print(f\"  Topic {topic_idx}:\")\n",
    "        for ngram_type in ['keywords', 'bigrams', 'trigrams']:\n",
    "            count = len(topic_data.get(ngram_type, {}))\n",
    "            print(f\"    {ngram_type}: {count} terms\")\n",
    "    \n",
    "    return topic_ngrams\n",
    "\n",
    "# Legacy function for backward compatibility\n",
    "def get_top_tfidf_ngrams_per_topic(df, tfidf_matrix, feature_names, topic_col='Primary_Topic_Index', top_k=10):\n",
    "    \"\"\"\n",
    "    Legacy function - now calls the enhanced version for keywords only.\n",
    "    \"\"\"\n",
    "    print(\"⚠️  Using legacy function - consider switching to get_top_tfidf_ngrams_per_topic_enhanced\")\n",
    "    \n",
    "    result = get_top_tfidf_ngrams_per_topic_enhanced(\n",
    "        df, topic_col=topic_col, text_col='processed_text', top_k=top_k\n",
    "    )\n",
    "    \n",
    "    if not result:\n",
    "        return {}\n",
    "    \n",
    "    # Convert to legacy format (keywords only)\n",
    "    legacy_result = {}\n",
    "    for topic_idx, topic_data in result.items():\n",
    "        keywords = topic_data.get('keywords', {})\n",
    "        # Convert to list of tuples format\n",
    "        legacy_result[topic_idx] = [(term, score) for term, score in keywords.items()]\n",
    "    \n",
    "    return legacy_result\n",
    "\n",
    "def get_author_stats(paper_classifications, df_field, n_top=5):\n",
    "    top_papers = {}\n",
    "    author_topic_stats = {}\n",
    "    \n",
    "    for topic in set(p['primary_topic'] for p in paper_classifications):\n",
    "        topic_papers = [p for p in paper_classifications if p['primary_topic'] == topic]\n",
    "        \n",
    "        # Fix: Handle various numpy array cases for dominance_ratio\n",
    "        for p in topic_papers:\n",
    "            dominance_ratio = p['dominance_ratio']\n",
    "            \n",
    "            if isinstance(dominance_ratio, np.ndarray):\n",
    "                if dominance_ratio.size == 1:\n",
    "                    p['dominance_ratio'] = float(dominance_ratio.item())\n",
    "                else:\n",
    "                    # Take the first element if it's a multi-element array\n",
    "                    p['dominance_ratio'] = float(dominance_ratio.flat[0])\n",
    "            elif hasattr(dominance_ratio, 'item'):\n",
    "                p['dominance_ratio'] = float(dominance_ratio.item())\n",
    "            else:\n",
    "                p['dominance_ratio'] = float(dominance_ratio)\n",
    "            \n",
    "            # Also fix primary_score if needed\n",
    "            primary_score = p['primary_score']\n",
    "            if isinstance(primary_score, np.ndarray):\n",
    "                if primary_score.size == 1:\n",
    "                    p['primary_score'] = float(primary_score.item())\n",
    "                else:\n",
    "                    p['primary_score'] = float(primary_score.flat[0])\n",
    "            elif hasattr(primary_score, 'item'):\n",
    "                p['primary_score'] = float(primary_score.item())\n",
    "            else:\n",
    "                p['primary_score'] = float(primary_score)\n",
    "        \n",
    "        topic_papers.sort(key=lambda x: x['dominance_ratio'], reverse=True)\n",
    "        top_papers[topic] = []\n",
    "        \n",
    "        for p in topic_papers[:n_top]:\n",
    "            paper_idx = p['paper_idx']\n",
    "            try:\n",
    "                authors = df_field.iloc[paper_idx]['authors']\n",
    "                if isinstance(authors, str):\n",
    "                    try: \n",
    "                        authors = ast.literal_eval(authors)\n",
    "                    except (ValueError, SyntaxError): \n",
    "                        authors = []\n",
    "                if isinstance(authors, list):\n",
    "                    author_list = []\n",
    "                    for author in authors:\n",
    "                        if isinstance(author, dict):\n",
    "                            author_list.append({'name': author.get('name', 'Unknown'), 'id': author.get('authorId', 'Unknown')})\n",
    "                else: \n",
    "                    author_list = []\n",
    "                    \n",
    "                top_papers[topic].append({\n",
    "                    'paperId': df_field.iloc[paper_idx].get('paperId',''),\n",
    "                    'title': df_field.iloc[paper_idx].get('title',''),\n",
    "                    'authors': author_list,\n",
    "                    'score': float(p['primary_score']),\n",
    "                    'dominance_ratio': float(p['dominance_ratio'])\n",
    "                })\n",
    "            except Exception as e: \n",
    "                continue\n",
    "                \n",
    "    return top_papers, author_topic_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfa79b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 8: Enhanced Utility Functions for Saving with Topic N-grams\n",
    "\n",
    "def save_term_frequencies(df, suffix_string, save_dir=SAVE_DIR, max_keywords=5000):\n",
    "    \"\"\"Save .json containing keywords, bigrams, trigrams with their counts for later visualization.\"\"\"\n",
    "    freq_data = {}\n",
    "    processed_text = df['processed_text'].fillna('').astype(str)\n",
    "    \n",
    "    for n in range(1, 4):\n",
    "        vectorizer = CountVectorizer(ngram_range=(n, n), stop_words='english', max_features=max_keywords)\n",
    "        matrix = vectorizer.fit_transform(processed_text)\n",
    "        terms = vectorizer.get_feature_names_out()\n",
    "        freqs = matrix.sum(axis=0).A1\n",
    "        \n",
    "        # Fix: Access the frequency (x[1]) for sorting, not the whole tuple (x)\n",
    "        freq_dict = {term: int(freq) for term, freq in sorted(zip(terms, freqs), key=lambda x: -x[1])}\n",
    "        \n",
    "        if n == 1: \n",
    "            freq_data['keywords'] = freq_dict\n",
    "        elif n == 2: \n",
    "            freq_data['bigrams'] = freq_dict\n",
    "        elif n == 3: \n",
    "            freq_data['trigrams'] = freq_dict\n",
    "    \n",
    "    out_fn = os.path.join(save_dir, f'term_frequencies_{suffix_string}.json')\n",
    "    with open(out_fn, 'w', encoding='utf-8') as f:\n",
    "        json.dump(freq_data, f, indent=2)\n",
    "    print(f\"✓ Saved term frequency summary to {out_fn}\")\n",
    "    return out_fn\n",
    "\n",
    "def save_author_and_venue_frequencies(df, suffix_string, save_dir=SAVE_DIR):\n",
    "    if 'authors' in df.columns:\n",
    "        authors_all = []\n",
    "        for item in df['authors']:\n",
    "            if isinstance(item, str) and item.strip():\n",
    "                try:\n",
    "                    obj = eval(item) if (item.strip().startswith(\"[\") or item.strip().startswith(\"{\")) else item.strip()\n",
    "                except Exception:\n",
    "                    obj = item.strip()\n",
    "            else:\n",
    "                obj = item\n",
    "            if isinstance(obj, list):\n",
    "                for author in obj:\n",
    "                    if isinstance(author, dict) and 'name' in author:\n",
    "                        authors_all.append(author['name'])\n",
    "                    elif isinstance(author, str):\n",
    "                        authors_all.append(author)\n",
    "            elif isinstance(obj, dict) and 'name' in obj:\n",
    "                authors_all.append(obj['name'])\n",
    "            elif isinstance(obj, str):\n",
    "                authors_all.append(obj)\n",
    "        author_counts = pd.Series(authors_all).value_counts().reset_index()\n",
    "        author_counts.columns = ['Author', 'Frequency']\n",
    "        author_fn = os.path.join(save_dir, f\"semantic_scholar_{suffix_string}_author_analysis.csv\")\n",
    "        author_counts.to_csv(author_fn, sep=';', encoding='utf-8', index=False)\n",
    "        print(f\"✓ Saved author frequencies: {author_fn}\")\n",
    "    else:\n",
    "        print(\"No 'authors' column found in DF: skipping author frequencies.\")\n",
    "        \n",
    "    if 'venue' in df.columns:\n",
    "        venue_counts = df['venue'].value_counts().reset_index()\n",
    "        venue_counts.columns = ['Venue', 'Frequency']\n",
    "        venue_fn = os.path.join(save_dir, f\"semantic_scholar_{suffix_string}_venue_frequencies.csv\")\n",
    "        venue_counts.to_csv(venue_fn, sep=';', encoding='utf-8', index=False)\n",
    "        print(f\"✓ Saved venue frequencies: {venue_fn}\")\n",
    "    else:\n",
    "        print(\"No 'venue' column found in DF: skipping venue frequencies.\")\n",
    "\n",
    "def save_topic_analysis_outputs(\n",
    "    df, lda_model, lda_vectorizer, topic_distributions, topic_keywords, topic_names, topic_ngrams,\n",
    "    author_stats, top_papers, tfidf_ngrams, suffix_string\n",
    "):\n",
    "    topic_metadata = {\n",
    "        \"topics\": {int(k): v for k,v in topic_keywords.items()},\n",
    "        \"topic_names\": {int(k): v for k,v in topic_names.items()},\n",
    "        \"topic_ngrams\": {int(k): v for k,v in topic_ngrams.items()},\n",
    "    }\n",
    "    with open(os.path.join(SAVE_DIR, f\"topics_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(topic_metadata, f, indent=2)\n",
    "    with open(os.path.join(SAVE_DIR, f\"topic_names_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({int(k):v for k,v in topic_names.items()}, f, indent=2)\n",
    "    np.save(os.path.join(SAVE_DIR, f\"topic_distributions_{suffix_string}.npy\"), topic_distributions)\n",
    "    import joblib\n",
    "    joblib.dump(lda_model, os.path.join(SAVE_DIR, f\"lda_model_{suffix_string}.joblib\"))\n",
    "    joblib.dump(lda_vectorizer, os.path.join(SAVE_DIR, f\"lda_vectorizer_{suffix_string}.joblib\"))\n",
    "    with open(os.path.join(SAVE_DIR, f\"top_papers_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({int(k): v for k, v in top_papers.items()}, f, ensure_ascii=False, indent=2, default=str)\n",
    "    pd.DataFrame.from_dict(author_stats, orient='index').to_csv(\n",
    "        os.path.join(SAVE_DIR, f\"author_stats_{suffix_string}.csv\"))\n",
    "    \n",
    "    # ENHANCED: Save topic-specific TF-IDF n-grams in the new format\n",
    "    if topic_ngrams and isinstance(list(topic_ngrams.values())[0], dict):\n",
    "        # New format with keywords/bigrams/trigrams structure\n",
    "        with open(os.path.join(SAVE_DIR, f\"topic_specific_tfidf_ngrams_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({int(k): v for k, v in topic_ngrams.items()}, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"✓ Saved enhanced topic-specific TF-IDF n-grams to topic_specific_tfidf_ngrams_{suffix_string}.json\")\n",
    "    else:\n",
    "        # Legacy format fallback\n",
    "        with open(os.path.join(SAVE_DIR, f\"topic_specific_tfidf_ngrams_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({int(k):[(term,float(score)) for term,score in v] for k,v in topic_ngrams.items()}, f, indent=2)\n",
    "        print(f\"✓ Saved legacy topic-specific TF-IDF n-grams to topic_specific_tfidf_ngrams_{suffix_string}.json\")\n",
    "\n",
    "def diagnostics_enhanced(df, canonical_scores, variant_scores, canonical_methods, variant_names):\n",
    "    n_docs, n_canonical = canonical_scores.shape\n",
    "    n_variants = variant_scores.shape[1]\n",
    "    \n",
    "    print(\"=== ENHANCED DIAGNOSTICS ===\")\n",
    "    print(f\"Total documents: {n_docs}\")\n",
    "    print(f\"Canonical methods: {n_canonical}\")\n",
    "    print(f\"Method variants: {n_variants}\")\n",
    "    print(f\"Canonical coverage: {(canonical_scores > 0).any(axis=1).sum()}/{n_docs} ({100*(canonical_scores>0).any(axis=1).mean():.1f}%)\")\n",
    "    print(f\"Variant coverage: {(variant_scores > 0).any(axis=1).sum()}/{n_docs} ({100*(variant_scores>0).any(axis=1).mean():.1f}%)\")\n",
    "    \n",
    "    if 'Primary_Method' in df.columns:\n",
    "        print(\"\\nMethod distribution (top 10):\")\n",
    "        method_dist = df['Primary_Method'].value_counts().head(10)\n",
    "        for method, count in method_dist.items():\n",
    "            if method:  # Skip empty strings\n",
    "                print(f\"  {method}: {count}\")\n",
    "    \n",
    "    if 'Method_Confidence' in df.columns:\n",
    "        print(\"\\nConfidence distribution:\")\n",
    "        conf_dist = df['Method_Confidence'].value_counts()\n",
    "        for conf, count in conf_dist.items():\n",
    "            if conf:  # Skip empty strings\n",
    "                print(f\"  {conf}: {count}\")\n",
    "    \n",
    "    print(f\"\\nCanonical methods sample: {canonical_methods[:5]}\")\n",
    "    print(f\"Variant methods sample: {variant_names[:10]}\")\n",
    "    print(f\"\\nCanonical scores stats: mean={canonical_scores.mean():.3f}, std={canonical_scores.std():.3f}\")\n",
    "    print(f\"Variant scores stats: mean={variant_scores.mean():.3f}, std={variant_scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "687dd62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_scores_robust(scores, current_features, target_features):\n",
    "    \n",
    "    #Enhanced alignment with dimension safety checks and detailed error handling.\n",
    "    \n",
    "    if not target_features:\n",
    "        return np.array([]).reshape(scores.shape[0], 0)\n",
    "    \n",
    "    # SAFETY CHECK: Verify dimensions match expectations\n",
    "    expected_cols = len(current_features)\n",
    "    actual_cols = scores.shape[1]\n",
    "    \n",
    "    if expected_cols != actual_cols:\n",
    "        print(f\"⚠️  DIMENSION MISMATCH DETECTED:\")\n",
    "        print(f\"    Expected columns: {expected_cols} (from feature names)\")\n",
    "        print(f\"    Actual columns: {actual_cols} (from score matrix)\")\n",
    "        print(f\"    Using actual matrix dimensions for safety\")\n",
    "        \n",
    "        # Use only the features that actually exist in the matrix\n",
    "        safe_current_features = current_features[:actual_cols]\n",
    "        print(f\"    Truncated feature list: {len(safe_current_features)} features\")\n",
    "    else:\n",
    "        safe_current_features = current_features\n",
    "    \n",
    "    # Initialize aligned matrix with zeros\n",
    "    aligned_scores = np.zeros((scores.shape[0], len(target_features)))\n",
    "    current_to_idx = {feat: i for i, feat in enumerate(safe_current_features)}\n",
    "    \n",
    "    # Map existing features to aligned positions with bounds checking\n",
    "    found_features = 0\n",
    "    skipped_features = 0\n",
    "    \n",
    "    for j, feat in enumerate(target_features):\n",
    "        if feat in current_to_idx:\n",
    "            source_idx = current_to_idx[feat]\n",
    "            \n",
    "            # BOUNDS CHECK: Ensure source index is valid\n",
    "            if source_idx < scores.shape[1]:\n",
    "                aligned_scores[:, j] = scores[:, source_idx]\n",
    "                found_features += 1\n",
    "            else:\n",
    "                print(f\"⚠️  Skipping feature '{feat}': index {source_idx} >= {scores.shape[1]}\")\n",
    "                skipped_features += 1\n",
    "    \n",
    "    print(f\"    ✓ Aligned {found_features}/{len(target_features)} features\")\n",
    "    if skipped_features > 0:\n",
    "        print(f\"    ⚠️  Skipped {skipped_features} features due to bounds issues\")\n",
    "    \n",
    "    return aligned_scores\n",
    "\n",
    "def normalize_scores(scores):\n",
    "    #Normalize scores to  range per matrix for fair weighting.[1]\n",
    "    if scores.max() == 0:\n",
    "        return scores\n",
    "    return scores / scores.max()\n",
    "def enhanced_method_diagnostics(df, scores, method_names, variant_groups):\n",
    "    \n",
    "    #Comprehensive diagnostics for method assignment quality and consolidation effectiveness.\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPREHENSIVE METHOD DETECTION DIAGNOSTICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Basic assignment statistics\n",
    "    n_papers = len(df)\n",
    "    assigned_papers = (df['Primary_Method'] != '').sum()\n",
    "    assignment_rate = 100 * assigned_papers / n_papers\n",
    "    \n",
    "    print(f\"\\n📊 ASSIGNMENT OVERVIEW:\")\n",
    "    print(f\"  Total papers processed: {n_papers:,}\")\n",
    "    print(f\"  Papers with methods assigned: {assigned_papers:,} ({assignment_rate:.1f}%)\")\n",
    "    print(f\"  Papers without methods: {n_papers - assigned_papers:,} ({100-assignment_rate:.1f}%)\")\n",
    "    \n",
    "    # Score distribution analysis\n",
    "    print(f\"\\n📈 SCORE DISTRIBUTION ANALYSIS:\")\n",
    "    print(f\"  Final score matrix shape: {scores.shape}\")\n",
    "    print(f\"  Total canonical methods: {len(method_names)}\")\n",
    "    print(f\"  Score range: [{scores.min():.4f}, {scores.max():.4f}]\")\n",
    "    print(f\"  Mean score: {scores.mean():.4f}\")\n",
    "    print(f\"  Standard deviation: {scores.std():.4f}\")\n",
    "    \n",
    "    # Score threshold analysis\n",
    "    thresholds = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "    for threshold in thresholds:\n",
    "        count = (scores > threshold).sum()\n",
    "        print(f\"  Scores > {threshold}: {count:,} ({100*count/scores.size:.2f}% of all scores)\")\n",
    "    \n",
    "    # Method popularity and assignment quality\n",
    "    if assigned_papers > 0:\n",
    "        print(f\"\\n🔥 TOP ASSIGNED METHODS:\")\n",
    "        method_counts = df['Primary_Method'].value_counts()\n",
    "        \n",
    "        for i, (method, count) in enumerate(method_counts.head(15).items()):\n",
    "            if method:  # Skip empty strings\n",
    "                percentage = 100 * count / assigned_papers\n",
    "                # Check if method was consolidated from variants\n",
    "                variants = variant_groups.get(method, [method])\n",
    "                variant_info = f\" (from {len(variants)} variants)\" if len(variants) > 1 else \"\"\n",
    "                print(f\"  {i+1:2d}. {method}: {count:,} papers ({percentage:.1f}%){variant_info}\")\n",
    "    \n",
    "    # Confidence distribution analysis\n",
    "    if 'Method_Confidence' in df.columns:\n",
    "        print(f\"\\n🎯 CONFIDENCE DISTRIBUTION:\")\n",
    "        conf_counts = df['Method_Confidence'].value_counts()\n",
    "        for conf, count in conf_counts.items():\n",
    "            percentage = 100 * count / n_papers\n",
    "            print(f\"  {conf}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Consolidation effectiveness analysis\n",
    "    print(f\"\\n🔧 CONSOLIDATION EFFECTIVENESS:\")\n",
    "    total_variants = sum(len(variants) for variants in variant_groups.values())\n",
    "    consolidated_groups = len([v for v in variant_groups.values() if len(v) > 1])\n",
    "    \n",
    "    print(f\"  Total method variants processed: {total_variants:,}\")\n",
    "    print(f\"  Final canonical methods: {len(variant_groups):,}\")\n",
    "    print(f\"  Groups with multiple variants: {consolidated_groups:,}\")\n",
    "    print(f\"  Consolidation ratio: {total_variants/len(variant_groups):.2f}:1\")\n",
    "    \n",
    "    # Quality assessment and recommendations\n",
    "    print(f\"\\n⚠️  QUALITY ASSESSMENT:\")\n",
    "    \n",
    "    if assignment_rate < 50:\n",
    "        print(f\"  ⚠️  Low assignment rate ({assignment_rate:.1f}%) - consider:\")\n",
    "        print(f\"      -  Lowering MIN_ASSIGN_SCORE (current: {MIN_ASSIGN_SCORE})\")\n",
    "        print(f\"      -  Reviewing method extraction quality\")\n",
    "        print(f\"      -  Checking text preprocessing effectiveness\")\n",
    "    else:\n",
    "        print(f\"  ✅ Good assignment rate ({assignment_rate:.1f}%)\")\n",
    "    \n",
    "    if scores.max() < 0.1:\n",
    "        print(f\"  ⚠️  Low maximum scores ({scores.max():.4f}) - scoring method may need adjustment\")\n",
    "    else:\n",
    "        print(f\"  ✅ Reasonable maximum scores ({scores.max():.4f})\")\n",
    "    \n",
    "    zero_score_methods = (scores.max(axis=0) == 0).sum()\n",
    "    if zero_score_methods > 0:\n",
    "        zero_percentage = 100 * zero_score_methods / len(method_names)\n",
    "        print(f\"  ⚠️  {zero_score_methods} methods ({zero_percentage:.1f}%) have zero scores across all papers\")\n",
    "        print(f\"      Consider reviewing method extraction or scoring parameters\")\n",
    "    else:\n",
    "        print(f\"  ✅ All methods have non-zero scores in at least some papers\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    return {\n",
    "        'assignment_rate': assignment_rate,\n",
    "        'total_papers': n_papers,\n",
    "        'assigned_papers': assigned_papers,\n",
    "        'score_stats': {\n",
    "            'min': scores.min(),\n",
    "            'max': scores.max(),\n",
    "            'mean': scores.mean(),\n",
    "            'std': scores.std()\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db56121",
   "metadata": {},
   "source": [
    "### Topic and author analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f31ba70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved term frequency summary to Saved_files_new\\term_frequencies_2025_09_11_reliability_resilience_power_systems.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:12:16,575 - INFO - Starting topic modeling workflow...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved author frequencies: Saved_files_new\\semantic_scholar_2025_09_11_reliability_resilience_power_systems_author_analysis.csv\n",
      "✓ Saved venue frequencies: Saved_files_new\\semantic_scholar_2025_09_11_reliability_resilience_power_systems_venue_frequencies.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:12:16,835 - INFO - collecting all words and their counts\n",
      "2025-09-11 00:12:16,836 - INFO - PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2025-09-11 00:12:18,435 - INFO - PROGRESS: at sentence #10000, processed 1524957 words and 863761 word types\n",
      "2025-09-11 00:12:20,018 - INFO - PROGRESS: at sentence #20000, processed 3004878 words and 1467564 word types\n",
      "2025-09-11 00:12:21,367 - INFO - collected 1902495 token types (unigram + bigrams) from a corpus of 4290297 words and 28934 sentences\n",
      "2025-09-11 00:12:21,368 - INFO - merged Phrases<1902495 vocab, min_count=10, threshold=50, max_vocab_size=40000000>\n",
      "2025-09-11 00:12:21,368 - INFO - Phrases lifecycle event {'msg': 'built Phrases<1902495 vocab, min_count=10, threshold=50, max_vocab_size=40000000> in 4.53s', 'datetime': '2025-09-11T00:12:21.368620', 'gensim': '4.3.2', 'python': '3.11.13 (main, Jun 12 2025, 12:41:34) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "2025-09-11 00:12:21,369 - INFO - collecting all words and their counts\n",
      "2025-09-11 00:12:21,370 - INFO - PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2025-09-11 00:12:24,871 - INFO - PROGRESS: at sentence #10000, processed 1471162 words and 886074 word types\n",
      "2025-09-11 00:12:28,326 - INFO - PROGRESS: at sentence #20000, processed 2890563 words and 1519087 word types\n",
      "2025-09-11 00:12:31,472 - INFO - collected 1981629 token types (unigram + bigrams) from a corpus of 4117577 words and 28934 sentences\n",
      "2025-09-11 00:12:31,472 - INFO - merged Phrases<1981629 vocab, min_count=5, threshold=50, max_vocab_size=40000000>\n",
      "2025-09-11 00:12:31,473 - INFO - Phrases lifecycle event {'msg': 'built Phrases<1981629 vocab, min_count=5, threshold=50, max_vocab_size=40000000> in 10.10s', 'datetime': '2025-09-11T00:12:31.473454', 'gensim': '4.3.2', 'python': '3.11.13 (main, Jun 12 2025, 12:41:34) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "2025-09-11 00:14:52,264 - INFO - ✓ LDA topic modeling completed.\n",
      "2025-09-11 00:14:52,437 - INFO - ✓ Papers assigned to topics based on LDA distributions.\n",
      "2025-09-11 00:14:52,437 - INFO - Extracting enhanced topic-specific TF-IDF n-grams...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Extracting topic-specific n-grams...\n",
      "📊 Processing 28934 documents across 10 topics\n",
      "📈 Processing keywords (1-1 grams)...\n",
      "  ✅ Created 31701 keywords features\n",
      "📈 Processing bigrams (2-2 grams)...\n",
      "  ✅ Created 411874 bigrams features\n",
      "📈 Processing trigrams (3-3 grams)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:15:08,062 - INFO - ✓ Extracted enhanced topic-specific TF-IDF n-grams for naming.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Created 244770 trigrams features\n",
      "\n",
      "📊 N-gram Extraction Summary:\n",
      "  Topic 0:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 1:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 2:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 3:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 4:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 5:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 6:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 7:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 8:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 9:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:15:09,653 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:12,967 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:14,357 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:14,370 - INFO - Topic 0: Thermal Energy Systems\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Thermal Energy Systems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:15:15,278 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:16,012 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:17,005 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:17,014 - INFO - Topic 1: Wireless Communication Systems\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Wireless Communication Systems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:15:18,454 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:19,173 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:19,902 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:19,933 - INFO - Topic 2: Wireless Sensor Network Applications\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Wireless Sensor Network Applications\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:15:21,083 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:21,999 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:22,463 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No majority topic name found, increasing iterations to 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:15:23,360 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:23,927 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:24,526 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:25,135 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:25,746 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:25,755 - INFO - Topic 3: Smart Grid Technology\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 5 iterations: Smart Grid Technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:15:26,901 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:27,719 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:28,839 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:28,842 - INFO - Topic 4: Power System Control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Power System Control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:15:30,000 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:30,642 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:31,490 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:31,498 - INFO - Topic 5: Wind Energy Optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Wind Energy Optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:15:32,456 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:32,932 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:33,513 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:33,521 - INFO - Topic 6: Renewable Energy Storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Renewable Energy Storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:15:35,347 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:36,074 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:36,785 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:36,798 - INFO - Topic 7: Reliability and Resilience Assessment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Reliability and Resilience Assessment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:15:37,752 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:38,606 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:39,449 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:39,457 - INFO - Topic 8: High-Performance Battery Materials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: High-Performance Battery Materials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:15:40,082 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:41,085 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:41,700 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:15:41,719 - INFO - Topic 9: Renewable Energy Systems\n",
      "2025-09-11 00:15:41,726 - INFO - ✓ Topic naming and assignment completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Renewable Energy Systems\n",
      "✓ Saved enhanced topic-specific TF-IDF n-grams to topic_specific_tfidf_ngrams_2025_09_11_reliability_resilience_power_systems.json\n",
      "\n",
      "Sample topics and names:\n",
      "{0: 'Thermal Energy Systems', 1: 'Wireless Communication Systems', 2: 'Wireless Sensor Network Applications', 3: 'Smart Grid Technology', 4: 'Power System Control'}\n",
      "\n",
      "📊 Enhanced N-grams Structure Sample:\n",
      "Topic 0 (Thermal Energy Systems):\n",
      "  keywords: [('heat', 0.08320521744256197), ('cooling', 0.046850935226352065), ('temperature', 0.04088639765946179), ('plant', 0.040525551834016675), ('gas', 0.03979704864835042)]\n",
      "  bigrams: [('power plant', 0.019979301691567784), ('fuel cell', 0.015297183506756053), ('gas turbine', 0.01448446007269745), ('waste heat', 0.013601408575671874), ('power generation', 0.012452353028140536)]\n",
      "  trigrams: [('thermal energy storage', 0.00752598208271986), ('organic rankine cycle', 0.006598230500100499), ('nuclear power plant', 0.006214901675069471), ('waste heat recovery', 0.006048844127119306), ('thermal power plant', 0.006016461973114782)]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 9: Enhanced Topic Analysis Workflow with Multi-N-gram Support\n",
    "\n",
    "NUM_TOPICS = 10\n",
    "NUM_TOPIC_WORDS = 15\n",
    "TOPIC_LLM_ITER_INIT = 3\n",
    "TOPIC_LLM_ITER_MAX = 9\n",
    "TOPIC_LLM_SIM_THRESH = 0.72\n",
    "TOPIC_LLM_TEMP = 1\n",
    "TOPIC_LLM_TOP_P = 1.0\n",
    "\n",
    "current_date = datetime.now().strftime(\"%Y_%m_%d\")\n",
    "keyword_str = '_'.join(extract_keywords_from_filename(filename)) if 'filename' in locals() else \"\"\n",
    "suffix_string = f\"{current_date}_{keyword_str}\"\n",
    "\n",
    "# Save basic term frequencies and author/venue analysis\n",
    "save_term_frequencies(df, suffix_string)\n",
    "save_author_and_venue_frequencies(df, suffix_string)\n",
    "\n",
    "logger.info(\"Starting topic modeling workflow...\")  \n",
    "lda_model, lda_vectorizer, topic_distributions, topic_keywords = run_lda_topic_modeling(\n",
    "    df, num_topics=NUM_TOPICS, num_words=NUM_TOPIC_WORDS)\n",
    "logger.info(\"✓ LDA topic modeling completed.\")\n",
    "\n",
    "paper_classifications = assign_papers_to_topics(topic_distributions)\n",
    "df['Primary_Topic_Index'] = [int(p['primary_topic']) for p in paper_classifications]\n",
    "df['Primary_Score'] = [p['primary_score'] for p in paper_classifications]\n",
    "df['Dominance_Ratio'] = [p['dominance_ratio'] for p in paper_classifications]\n",
    "\n",
    "logger.info(\"✓ Papers assigned to topics based on LDA distributions.\")\n",
    "\n",
    "# ENHANCED: Use the new multi-n-gram extraction function\n",
    "logger.info(\"Extracting enhanced topic-specific TF-IDF n-grams...\")\n",
    "topic_ngrams = get_top_tfidf_ngrams_per_topic_enhanced(\n",
    "    df, topic_col='Primary_Topic_Index', text_col='processed_text', top_k=15, min_df=2, max_df=0.8\n",
    ")\n",
    "logger.info(\"✓ Extracted enhanced topic-specific TF-IDF n-grams for naming.\")\n",
    "\n",
    "# Generate topic names using enhanced n-grams\n",
    "topic_names = {}\n",
    "for topic_idx, keywords in topic_keywords.items():\n",
    "    lda_ngrams = keywords['top_words'][:NUM_TOPIC_WORDS]\n",
    "    \n",
    "    # ENHANCED: Use keywords from the new structure\n",
    "    topic_data = topic_ngrams.get(topic_idx, {})\n",
    "    tfidf_keywords = list(topic_data.get('keywords', {}).keys())[:NUM_TOPIC_WORDS]\n",
    "    \n",
    "    top_titles = get_top_titles_for_topic(df, paper_classifications, topic_idx, n_titles=10)\n",
    "    topic_name = topic_name_llm_robust(\n",
    "        lda_ngrams, tfidf_keywords, top_titles,\n",
    "        client, model_type, credit_tracker,\n",
    "        initial_iterations=TOPIC_LLM_ITER_INIT,\n",
    "        max_iterations=TOPIC_LLM_ITER_MAX,\n",
    "        similarity_threshold=TOPIC_LLM_SIM_THRESH,\n",
    "        temp=TOPIC_LLM_TEMP, top_p=TOPIC_LLM_TOP_P\n",
    "    )\n",
    "    topic_names[topic_idx] = topic_name\n",
    "    logger.info(f\"Topic {topic_idx}: {topic_name if topic_name else 'Unnamed'}\")\n",
    "\n",
    "df['Primary_Topic'] = df['Primary_Topic_Index'].map(lambda x: topic_names.get(x, f\"Topic_{x}\"))\n",
    "logger.info(\"✓ Topic naming and assignment completed.\")\n",
    "\n",
    "top_papers, author_stats = get_author_stats(paper_classifications, df, n_top=5)\n",
    "\n",
    "# ENHANCED: Save with the new n-grams structure\n",
    "save_topic_analysis_outputs(df, lda_model, lda_vectorizer, topic_distributions, \n",
    "                           topic_keywords, topic_names, topic_ngrams, author_stats, \n",
    "                           top_papers, topic_ngrams, suffix_string)\n",
    "\n",
    "print(\"\\nSample topics and names:\")\n",
    "print({k: topic_names[k] for k in list(topic_names)[:5]})\n",
    "\n",
    "# Show sample of enhanced n-grams structure\n",
    "if topic_ngrams:\n",
    "    print(f\"\\n📊 Enhanced N-grams Structure Sample:\")\n",
    "    sample_topic = list(topic_ngrams.keys())[0]\n",
    "    sample_data = topic_ngrams[sample_topic]\n",
    "    topic_name = topic_names.get(sample_topic, f\"Topic {sample_topic}\")\n",
    "    print(f\"Topic {sample_topic} ({topic_name}):\")\n",
    "    for ngram_type in ['keywords', 'bigrams', 'trigrams']:\n",
    "        terms = sample_data.get(ngram_type, {})\n",
    "        if terms:\n",
    "            top_terms = list(terms.items())[:5]\n",
    "            print(f\"  {ngram_type}: {top_terms}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddcaf9d",
   "metadata": {},
   "source": [
    "### Method analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "877ab3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are a comprehensive research methodology expert analyzing power systems literature.\\n\\nTASK: Extract ONLY, but ALL phrases that can be strictly defined as a specific research method, algorithm, and/or techniques from these candidate terms.\\nGOAL: Find all the qualified phrases in this batch. Be thorough and comprehensive. Generic terms or terms that are describing the objectiv or result of analysis does not qualify\\n\\nCandidate terms: {candidate_terms}\\n\\nCOMPREHENSIVE EXTRACTION CRITERIA:\\n✅ INCLUDE specific methods, algorithms and/or techniques in these categories:\\n1. Named algorithms: genetic algorithm, differential evolution...\\n2. Mathematical methods: monte carlo simulation, linear programming...\\n3. Machine learning: neural network, support vector machine...\\n4. Analysis techniques: fault tree analysis, load flow analysis...\\n5. Power system analysis methods: unit commitment, optimal power flow...\\n6. Power system indicator terms: LOLE, EENS, PTDF...\\n\\nDistinguish between actuall analysis-method, algorithms and/or technique phrases and objectives of an anlysis.\\nDiscard typicall generic phrases or phrases that describe the objective(goal) rather than the method, algoritm and/or technique, e.g.  'Risk assesment', 'Capacity utilization', 'Control Strategy' \\nKeep method, algorithm and/or technique phrases used in connection to such objectives\\n\\nTARGET: Extract only specific research methods, algorithm and/or techniques that are qualified by the above criteriasfrom this batch.\\nReview the list before finalizing to make sure it only contains qualified terms are \\nReturn as Python list with comprehensive coverage:\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#old prompt versions\n",
    "\"\"\"You are a comprehensive research methodology expert analyzing power systems literature.\n",
    "\n",
    "TASK: Extract ONLY, but ALL phrases that can be strictly defined as a specific research method, algorithm, and/or techniques from these candidate terms.\n",
    "GOAL: Find all the qualified phrases in this batch. Be thorough and comprehensive. Generic terms or terms that are describing the objectiv or result of analysis does not qualify\n",
    "\n",
    "Candidate terms: {candidate_terms}\n",
    "\n",
    "COMPREHENSIVE EXTRACTION CRITERIA:\n",
    "✅ INCLUDE specific methods, algorithms and/or techniques in these categories:\n",
    "1. Named algorithms: genetic algorithm, differential evolution...\n",
    "2. Mathematical methods: monte carlo simulation, linear programming...\n",
    "3. Machine learning: neural network, support vector machine...\n",
    "4. Analysis techniques: fault tree analysis, load flow analysis...\n",
    "5. Power system analysis methods: unit commitment, optimal power flow...\n",
    "6. Power system indicator terms: LOLE, EENS, PTDF...\n",
    "\n",
    "Distinguish between actuall analysis-method, algorithms and/or technique phrases and objectives of an anlysis.\n",
    "Discard typicall generic phrases or phrases that describe the objective(goal) rather than the method, algoritm and/or technique, e.g.  'Risk assesment', 'Capacity utilization', 'Control Strategy' \n",
    "Keep method, algorithm and/or technique phrases used in connection to such objectives\n",
    "\n",
    "TARGET: Extract only specific research methods, algorithm and/or techniques that are qualified by the above criteriasfrom this batch.\n",
    "Review the list before finalizing to make sure it only contains qualified terms are \n",
    "Return as Python list with comprehensive coverage:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ed7bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your extraction prompt\n",
    "extraction_prompt = improved_extraction_prompt = \"\"\"You are a research methodology extraction expert specializing in power systems literature.\n",
    "\n",
    "TASK: From the candidate terms below, extract ALL terms that represent specific, named research methodologies, algorithms, or techniques.\n",
    "\n",
    "Candidate terms: {candidate_terms}\n",
    "\n",
    "QUALIFICATION CRITERIA - A term qualifies if it is:\n",
    "✅ A NAMED algorithm, method, or technique with specific definition\n",
    "✅ A SPECIFIC mathematical/computational approach \n",
    "✅ A WELL-DEFINED analysis technique with established procedure\n",
    "✅ A RECOGNIZED power systems methodology\n",
    "\n",
    "INCLUDE these categories:\n",
    "1. Named algorithms: \"genetic algorithm\", \"particle swarm optimization\", \"differential evolution\"\n",
    "2. Mathematical methods: \"monte carlo simulation\", \"linear programming\", \"quadratic programming\" \n",
    "3. Machine learning: \"neural network\", \"support vector machine\", \"random forest\", \"k-means clustering\"\n",
    "4. Analysis techniques: \"fault tree analysis\", \"load flow analysis\", \"modal analysis\", \"sensitivity analysis\"\n",
    "5. Power system methods: \"unit commitment\", \"optimal power flow\", \"economic dispatch\", \"state estimation\"\n",
    "6. Power system indicators: \"LOLE\", \"EENS\", \"PTDF\", \"LODF\" (specific technical acronyms)\n",
    "\n",
    "EXCLUDE these patterns:\n",
    "❌ Generic nouns: \"method\", \"analysis\", \"approach\", \"technique\", \"framework\", \"system\", \"procedure\"\n",
    "❌ Generic combinations: \"energy analysis\", \"power method\", \"system approach\", \"network optimization\"\n",
    "❌ Process descriptions: \"optimization process\", \"analysis procedure\", \"design methodology\" \n",
    "❌ Objective descriptions: \"performance improvement\", \"efficiency enhancement\", \"cost reduction\"\n",
    "❌ Research activities: \"literature review\", \"case study\", \"experimental analysis\", \"field research\"\n",
    "\n",
    "DECISION PROCESS:\n",
    "1. Scan each candidate term\n",
    "2. Ask: \"Is this a specific, named methodology that a researcher could implement?\"\n",
    "3. If yes and fits categories above → INCLUDE\n",
    "4. If generic or describes outcome/process → EXCLUDE\n",
    "\n",
    "EXAMPLES:\n",
    "✅ INCLUDE: \"monte carlo simulation\" (specific technique), \"unit commitment\" (specific power systems method)\n",
    "❌ EXCLUDE: \"energy analysis\" (generic), \"optimization approach\" (too broad), \"case study\" (research activity)\n",
    "\n",
    "Extract ALL qualifying terms from the candidate list. Be comprehensive within the qualification criteria.\n",
    "\n",
    "Return as a clean Python list: [\"term1\", \"term2\", \"term3\", ...]\"\"\"\n",
    "\n",
    "\n",
    "# Define your grouping prompt  \n",
    "grouping_prompt = \"\"\"You are an expert in power systems analysis methods. Your task is to group ONLY true variants of the same core technique.\n",
    "\n",
    "Methods to analyze: {method_list}\n",
    "\n",
    "STRICT GROUPING RULES:\n",
    "\n",
    "✅ GROUP these cases (same core method):\n",
    "- Abbreviation + full form: e.g. opf\" with \"optimal power flow\" and \"copt\" with \"capacity outage probability table\"\n",
    "- Method + descriptor: \"neural network\" with \"artificial neural network\" \n",
    "- Acronym + full name: e.g. \"anfis\" with \"adaptive neuro fuzzy inference system\"\n",
    "- Slight variations: \"monte carlo\" with \"monte carlo simulation\"\n",
    "- Same indices: \"saifi\" with \"system average interruption frequency index\"\n",
    "\n",
    "❌ NEVER GROUP these cases (different methods):\n",
    "- Different algorithm types: \"linear programming\" ≠ \"nonlinear programming\"\n",
    "- Different orders/levels: \"first order\" ≠ \"second order reliability method\"  \n",
    "- Different shift factors: \"generation shift factors\" ≠ \"injection shift factors\"\n",
    "- Different optimization algorithms: \"genetic algorithm\" ≠ \"particle swarm\"\n",
    "- Different neural networks: \"lstm\" ≠ \"gru\"\n",
    "\n",
    "CANONICAL SELECTION:\n",
    "- Always use the FULL descriptive name as the canonical form\n",
    "- Never use abbreviations as canonical forms\n",
    "- Example: Use \"optimal power flow\" not \"opf\"\n",
    "\n",
    "Return a Python dictionary where:\n",
    "- Keys are FULL canonical method names (never abbreviations)\n",
    "- Values are lists of ALL variants including the canonical form itself\n",
    "\n",
    "Example format:\n",
    "{{\n",
    "  \"optimal power flow\": [\"optimal power flow\", \"opf\", \"power flow optimization\"],\n",
    "  \"monte carlo simulation\": [\"monte carlo simulation\", \"monte carlo\", \"monte-carlo\"]\n",
    "}}\n",
    "\n",
    "Be conservative - when in doubt, keep methods separate.\"\"\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6a72660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:15:41,964 - INFO - === Starting Method Extraction and Grouping Phase ===\n",
      "2025-09-11 00:15:41,964 - INFO - Step 1: Loading or extracting method phrases...\n",
      "2025-09-11 00:15:41,985 - INFO -   ✓ Loaded 168 method phrases from existing CSV\n",
      "2025-09-11 00:15:41,986 - INFO - ✓ Method phrase extraction complete: 168 phrases\n",
      "2025-09-11 00:15:41,987 - INFO - Step 2: Building enhanced method variant groups with consolidation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample methods: ['ant colony optimization', 'gauss-seidel load flow', 'alternating direction method of multipliers', 'total harmonic distortion', 'phasor measurement', 'mpp', 'reinforcement learning drl', 'hosting capacity assesment', 'loss of load probability', 'security-constrained economic dispatch']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:16:04,065 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-11 00:16:04,216 - INFO - LLM raw response: ChatCompletion(id='chatcmpl-CENOI5NnzZjtnK6ui86IFdCujOG6P', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\n{\\n  \"ant colony optimization\": [\"ant colony optimization\"],\\n  \"gauss-seidel load flow\": [\"gauss-seidel load flow\"],\\n  \"phasor measurement\": [\"phasor measurement\"],\\n  \"alternating direction method of multipliers\": [\"alternating direction method of multipliers\"],\\n  \"total harmonic distortion\": [\"total harmonic distortion\", \"total harmonic distortion thd\"],\\n  \"maximum power point\": [\"mpp\"],\\n  \"reinforcement learning deep reinforcement learning\": [\"reinforcement learning drl\", \"deep reinforcement learning drl\"],\\n  \"hosting capacity assessment\": [\"hosting capacity assesment\"],\\n  \"loss of load probability\": [\"loss of load probability\", \"lolp\"],\\n  \"security-constrained economic dispatch\": [\"security-constrained economic dispatch\"],\\n  \"dynamic programming\": [\"dynamic programming\"],\\n  \"system average interruption duration index\": [\"system average interruption duration index\", \"caidi\"],\\n  \"nonlinear programming\": [\"nonlinear programming\"],\\n  \"monte carlo simulation\": [\"monte carlo simulation\", \"monte-carlo simulation\"],\\n  \"discrete wavelet\": [\"discrete wavelet\"],\\n  \"system average interruption frequency index\": [\"system average interruption frequency index\", \"saifi\"],\\n  \"capacity ratio\": [\"capacity ratio\"],\\n  \"long short-term memory\": [\"long short-term memory\"],\\n  \"tabu search\": [\"tabu search\"],\\n  \"particle swarm optimization\": [\"particle swarm optimization\", \"particle swarm algorithm\", \"pso algorithm\", \"optimization pso algorithm\"],\\n  \"optimal utilization\": [\"optimal utilization\"],\\n  \"demand response\": [\"demand response dr\"],\\n  \"economic dispatch\": [\"economic dispatch\"],\\n  \"latin hypercube sampling\": [\"latin hypercube sampling\"],\\n  \"fast decoupled power flow\": [\"fast decoupled power flow\"],\\n  \"dynamic voltage restorer\": [\"dynamic voltage restorer\"],\\n  \"sliding mode control\": [\"sliding mode control\"],\\n  \"regression model\": [\"regression model\", \"linear regression\"],\\n  \"mixed-integer linear programming\": [\"mixed-integer linear\", \"mixed integer linear programming\"],\\n  \"support vector machine\": [\"support vector machine\", \"support vector machine svm\"],\\n  \"stochastic programming\": [\"stochastic programming\"],\\n  \"optimal power flow\": [\"optimal power flow\", \"opf\", \"optimal power flow opf\"],\\n  \"generation shift factors\": [\"generation shift factors\"],\\n  \"linear regression\": [\"linear regression\"],\\n  \"time series analysis\": [\"time series analysis\"],\\n  \"wide area measurement system\": [\"wide area measurement system\", \"wams\"],\\n  \"mean time to failure\": [\"mean time to failure\", \"mttf\"],\\n  \"autoregressive integrated moving average\": [\"autoregressive integrated moving average\", \"arima\"],\\n  \"mean time between failures\": [\"mean time between failures\", \"mtbf\"],\\n  \"load frequency control\": [\"load frequency control\"],\\n  \"line outage distribution factor\": [\"line outage distribution factor\", \"lodf\"],\\n  \"multi-carrier\": [\"multi-carrier\"],\\n  \"mean time to repair\": [\"mean time to repair\", \"mttr\"],\\n  \"dynamic line rating\": [\"dynamic line rating\"],\\n  \"neural network\": [\"neural network\", \"artificial neural network\", \"neural network ann\", \"neural network cnn\"],\\n  \"model predictive control\": [\"model predictive control mpc\"],\\n  \"security-constrained unit commitment\": [\"security-constrained unit commitment\", \"scuc\"],\\n  \"second order reliability method\": [\"second order reliability method\"],\\n  \"interior point method\": [\"interior point method\"],\\n  \"markov chain monte carlo\": [\"markov chain monte carlo\", \"mcmc\"],\\n  \"probabilistic reliability\": [\"probabilistic reliability\"],\\n  \"hierarchical level ii\": [\"hierarchical level ii\"],\\n  \"state estimation\": [\"state estimation\"],\\n  \"simulated annealing\": [\"simulated annealing\"],\\n  \"non-orthogonal multiple access\": [\"non-orthogonal multiple access noma\"],\\n  \"fuzzy control\": [\"fuzzy control\"],\\n  \"successive interference cancellation\": [\"successive interference cancellation\"],\\n  \"security-constrained optimal power flow\": [\"security-constrained optimal power flow\"],\\n  \"second order cone programming\": [\"second order cone programming\"],\\n  \"differential evolution\": [\"differential evolution\"],\\n  \"sequential quadratic programming\": [\"sequential quadratic programming\"],\\n  \"multi-objective optimization model\": [\"multi-objective optimization model\"],\\n  \"incremental conductance\": [\"incremental conductance\"],\\n  \"point estimate method\": [\"point estimate method\"],\\n  \"software-defined networking\": [\"sdn\"],\\n  \"sensitivity analysis\": [\"sensitivity analysis\"],\\n  \"adaptive neuro-fuzzy inference system\": [\"adaptive neuro-fuzzy\", \"anfis\"],\\n  \"optimal dispatch\": [\"optimal dispatch\"],\\n  \"cost-benefit analysis\": [\"cost-benefit analysis\"],\\n  \"multi-functional\": [\"multi-functional\"],\\n  \"multi-layer\": [\"multi-layer\"],\\n  \"injection shift factors\": [\"injection shift factors\"],\\n  \"decision tree\": [\"decision tree\"],\\n  \"generalized autoregressive conditional heteroskedasticity\": [\"generalized autoregressive conditional heteroskedasticity\", \"garch\"],\\n  \"kalman filter\": [\"kalman filter\"],\\n  \"first order reliability method\": [\"first order reliability method\"],\\n  \"support vector regression\": [\"support vector regression\", \"svr\"],\\n  \"multi-input multi-output\": [\"multi-input multi-output\", \"multi-input multiple output\"],\\n  \"dynamic condition\": [\"dynamic condition\"],\\n  \"stochastic optimization\": [\"stochastic optimization\"],\\n  \"firefly algorithm\": [\"firefly algorithm\"],\\n  \"system average interruption frequency index\": [\"system average interruption frequency index\", \"saifi\"],\\n  \"short-term load forecasting\": [\"short-term load forecasting\"],\\n  \"newton-raphson load flow\": [\"newton-raphson load flow\"],\\n  \"random forest\": [\"random forest\"],\\n  \"wavelet transform\": [\"wavelet transform\"],\\n  \"fault tree analysis\": [\"fault tree analysis\", \"fault tree\"],\\n  \"load frequency\": [\"load frequency\"],\\n  \"differential protection\": [\"differential protection\"],\\n  \"gated recurrent unit\": [\"gated recurrent unit\"],\\n  \"dynamic reactive power\": [\"dynamic reactive power\"],\\n  \"optimal power allocation\": [\"optimal power allocation\"],\\n  \"multi-terminal\": [\"multi-terminal\"],\\n  \"integer linear programming\": [\"integer linear programming\"],\\n  \"genetic algorithm\": [\"genetic algorithm\", \"genetic algorithm ga\"],\\n  \"multi-phase\": [\"multi-phase\"],\\n  \"quadratic programming\": [\"quadratic programming\"],\\n  \"hierarchical level iii\": [\"hierarchical level iii\"],\\n  \"model analysis\": [\"model analysis\"]\\n}\\n```', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1757542542, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_8bda4d3a2c', usage=CompletionUsage(completion_tokens=1387, prompt_tokens=1300, total_tokens=2687, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2025-09-11 00:16:04,217 - INFO - LLM content: ```python\n",
      "{\n",
      "  \"ant colony optimization\": [\"ant colony optimization\"],\n",
      "  \"gauss-seidel load flow\": [\"gauss-seidel load flow\"],\n",
      "  \"phasor measurement\": [\"phasor measurement\"],\n",
      "  \"alternating direction method of multipliers\": [\"alternating direction method of multipliers\"],\n",
      "  \"total harmonic distortion\": [\"total harmonic distortion\", \"total harmonic distortion thd\"],\n",
      "  \"maximum power point\": [\"mpp\"],\n",
      "  \"reinforcement learning deep reinforcement learning\": [\"reinforcement learning drl\", \"deep reinforcement learning drl\"],\n",
      "  \"hosting capacity assessment\": [\"hosting capacity assesment\"],\n",
      "  \"loss of load probability\": [\"loss of load probability\", \"lolp\"],\n",
      "  \"security-constrained economic dispatch\": [\"security-constrained economic dispatch\"],\n",
      "  \"dynamic programming\": [\"dynamic programming\"],\n",
      "  \"system average interruption duration index\": [\"system average interruption duration index\", \"caidi\"],\n",
      "  \"nonlinear programming\": [\"nonlinear programming\"],\n",
      "  \"monte carlo simulation\": [\"monte carlo simulation\", \"monte-carlo simulation\"],\n",
      "  \"discrete wavelet\": [\"discrete wavelet\"],\n",
      "  \"system average interruption frequency index\": [\"system average interruption frequency index\", \"saifi\"],\n",
      "  \"capacity ratio\": [\"capacity ratio\"],\n",
      "  \"long short-term memory\": [\"long short-term memory\"],\n",
      "  \"tabu search\": [\"tabu search\"],\n",
      "  \"particle swarm optimization\": [\"particle swarm optimization\", \"particle swarm algorithm\", \"pso algorithm\", \"optimization pso algorithm\"],\n",
      "  \"optimal utilization\": [\"optimal utilization\"],\n",
      "  \"demand response\": [\"demand response dr\"],\n",
      "  \"economic dispatch\": [\"economic dispatch\"],\n",
      "  \"latin hypercube sampling\": [\"latin hypercube sampling\"],\n",
      "  \"fast decoupled power flow\": [\"fast decoupled power flow\"],\n",
      "  \"dynamic voltage restorer\": [\"dynamic voltage restorer\"],\n",
      "  \"sliding mode control\": [\"sliding mode control\"],\n",
      "  \"regression model\": [\"regression model\", \"linear regression\"],\n",
      "  \"mixed-integer linear programming\": [\"mixed-integer linear\", \"mixed integer linear programming\"],\n",
      "  \"support vector machine\": [\"support vector machine\", \"support vector machine svm\"],\n",
      "  \"stochastic programming\": [\"stochastic programming\"],\n",
      "  \"optimal power flow\": [\"optimal power flow\", \"opf\", \"optimal power flow opf\"],\n",
      "  \"generation shift factors\": [\"generation shift factors\"],\n",
      "  \"linear regression\": [\"linear regression\"],\n",
      "  \"time series analysis\": [\"time series analysis\"],\n",
      "  \"wide area measurement system\": [\"wide area measurement system\", \"wams\"],\n",
      "  \"mean time to failure\": [\"mean time to failure\", \"mttf\"],\n",
      "  \"autoregressive integrated moving average\": [\"autoregressive integrated moving average\", \"arima\"],\n",
      "  \"mean time between failures\": [\"mean time between failures\", \"mtbf\"],\n",
      "  \"load frequency control\": [\"load frequency control\"],\n",
      "  \"line outage distribution factor\": [\"line outage distribution factor\", \"lodf\"],\n",
      "  \"multi-carrier\": [\"multi-carrier\"],\n",
      "  \"mean time to repair\": [\"mean time to repair\", \"mttr\"],\n",
      "  \"dynamic line rating\": [\"dynamic line rating\"],\n",
      "  \"neural network\": [\"neural network\", \"artificial neural network\", \"neural network ann\", \"neural network cnn\"],\n",
      "  \"model predictive control\": [\"model predictive control mpc\"],\n",
      "  \"security-constrained unit commitment\": [\"security-constrained unit commitment\", \"scuc\"],\n",
      "  \"second order reliability method\": [\"second order reliability method\"],\n",
      "  \"interior point method\": [\"interior point method\"],\n",
      "  \"markov chain monte carlo\": [\"markov chain monte carlo\", \"mcmc\"],\n",
      "  \"probabilistic reliability\": [\"probabilistic reliability\"],\n",
      "  \"hierarchical level ii\": [\"hierarchical level ii\"],\n",
      "  \"state estimation\": [\"state estimation\"],\n",
      "  \"simulated annealing\": [\"simulated annealing\"],\n",
      "  \"non-orthogonal multiple access\": [\"non-orthogonal multiple access noma\"],\n",
      "  \"fuzzy control\": [\"fuzzy control\"],\n",
      "  \"successive interference cancellation\": [\"successive interference cancellation\"],\n",
      "  \"security-constrained optimal power flow\": [\"security-constrained optimal power flow\"],\n",
      "  \"second order cone programming\": [\"second order cone programming\"],\n",
      "  \"differential evolution\": [\"differential evolution\"],\n",
      "  \"sequential quadratic programming\": [\"sequential quadratic programming\"],\n",
      "  \"multi-objective optimization model\": [\"multi-objective optimization model\"],\n",
      "  \"incremental conductance\": [\"incremental conductance\"],\n",
      "  \"point estimate method\": [\"point estimate method\"],\n",
      "  \"software-defined networking\": [\"sdn\"],\n",
      "  \"sensitivity analysis\": [\"sensitivity analysis\"],\n",
      "  \"adaptive neuro-fuzzy inference system\": [\"adaptive neuro-fuzzy\", \"anfis\"],\n",
      "  \"optimal dispatch\": [\"optimal dispatch\"],\n",
      "  \"cost-benefit analysis\": [\"cost-benefit analysis\"],\n",
      "  \"multi-functional\": [\"multi-functional\"],\n",
      "  \"multi-layer\": [\"multi-layer\"],\n",
      "  \"injection shift factors\": [\"injection shift factors\"],\n",
      "  \"decision tree\": [\"decision tree\"],\n",
      "  \"generalized autoregressive conditional heteroskedasticity\": [\"generalized autoregressive conditional heteroskedasticity\", \"garch\"],\n",
      "  \"kalman filter\": [\"kalman filter\"],\n",
      "  \"first order reliability method\": [\"first order reliability method\"],\n",
      "  \"support vector regression\": [\"support vector regression\", \"svr\"],\n",
      "  \"multi-input multi-output\": [\"multi-input multi-output\", \"multi-input multiple output\"],\n",
      "  \"dynamic condition\": [\"dynamic condition\"],\n",
      "  \"stochastic optimization\": [\"stochastic optimization\"],\n",
      "  \"firefly algorithm\": [\"firefly algorithm\"],\n",
      "  \"system average interruption frequency index\": [\"system average interruption frequency index\", \"saifi\"],\n",
      "  \"short-term load forecasting\": [\"short-term load forecasting\"],\n",
      "  \"newton-raphson load flow\": [\"newton-raphson load flow\"],\n",
      "  \"random forest\": [\"random forest\"],\n",
      "  \"wavelet transform\": [\"wavelet transform\"],\n",
      "  \"fault tree analysis\": [\"fault tree analysis\", \"fault tree\"],\n",
      "  \"load frequency\": [\"load frequency\"],\n",
      "  \"differential protection\": [\"differential protection\"],\n",
      "  \"gated recurrent unit\": [\"gated recurrent unit\"],\n",
      "  \"dynamic reactive power\": [\"dynamic reactive power\"],\n",
      "  \"optimal power allocation\": [\"optimal power allocation\"],\n",
      "  \"multi-terminal\": [\"multi-terminal\"],\n",
      "  \"integer linear programming\": [\"integer linear programming\"],\n",
      "  \"genetic algorithm\": [\"genetic algorithm\", \"genetic algorithm ga\"],\n",
      "  \"multi-phase\": [\"multi-phase\"],\n",
      "  \"quadratic programming\": [\"quadratic programming\"],\n",
      "  \"hierarchical level iii\": [\"hierarchical level iii\"],\n",
      "  \"model analysis\": [\"model analysis\"]\n",
      "}\n",
      "```\n",
      "2025-09-11 00:16:04,566 - WARNING - Splitting forbidden grouping: nonlinear programming\n",
      "2025-09-11 00:16:04,568 - INFO - Created 97 method variant groups from 168 original methods\n",
      "2025-09-11 00:16:04,569 - INFO - ✓ Created 97 canonical methods with 127 total variants\n",
      "2025-09-11 00:16:04,569 - INFO - Saving method phrases and groups for manual review and editing...\n",
      "2025-09-11 00:16:04,572 - INFO - ✅ Method extraction and grouping phase completed successfully!\n",
      "2025-09-11 00:16:04,573 - INFO - 💰 Credit usage so far: {'total_tokens': 1387, 'total_cost': 0.0002}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Batch 1 LLM response received: 6338 characters\n",
      "✓ Processed batch 1: 97 groups created\n",
      "  Post-processing preserved 97 groups\n",
      "✓ Saved method phrases to Saved_files_new\\extracted_method_phrases.csv\n",
      "\n",
      "📊 Method Extraction and Grouping Results:\n",
      "  Original methods: 168\n",
      "  Consolidated methods: 97\n",
      "  Reduction: 71 methods (42.3% reduction)\n",
      "\n",
      "⏸️  EDITING CHECKPOINT:\n",
      "  📝 Edit extracted_method_phrases.csv to add/remove/rename methods\n",
      "  📝 Edit method_variant_groups.json to adjust groupings\n",
      "  ✅ Files saved to: Saved_files_new\n",
      "  ➡️  Run Cell 10B when editing is complete\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 10A: Method Extraction and Grouping Phase (LLM-based)\n",
    "#Cell 10A (Extraction & Grouping)\n",
    "#Runs LLM calls for method extraction and grouping\n",
    "\n",
    "#Saves results to extracted_method_phrases.csv and method_variant_groups.json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION PARAMETERS - Adjust these for optimal method detection\n",
    "# =============================================================================\n",
    "MAX_FEATURES = 15000                    # Maximum features for candidate term extraction\n",
    "BATCH_SIZE = 5000                       # Batch size for LLM processing\n",
    "METHOD_LLM_N_RUNS = 3                   # Number of LLM runs for method extraction\n",
    "VARIANT_GROUP_BATCH_SIZE = 5000         # Batch size for method variant grouping\n",
    "TOP_P = 0.2\n",
    "TEMP = 0.2\n",
    "\n",
    "logger.info(\"=== Starting Method Extraction and Grouping Phase ===\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: LOAD OR EXTRACT METHOD PHRASES FROM CORPUS\n",
    "# =============================================================================\n",
    "logger.info(\"Step 1: Loading or extracting method phrases...\")\n",
    "\n",
    "# Try to load existing method phrases from previous runs\n",
    "try:\n",
    "    method_phrases, method_counts = load_method_phrases_from_csv(filename=\"extracted_method_phrases.csv\")\n",
    "except (FileNotFoundError, TypeError):\n",
    "    method_phrases, method_counts = None, None\n",
    "\n",
    "# If no existing phrases found or too few, extract new ones using LLM\n",
    "if (method_phrases is None) or (len(method_phrases) < 3):\n",
    "    logger.info(\"  1a: Extracting candidate terms from processed text...\")\n",
    "    \n",
    "    # Extract candidate n-grams (1-4 grams) from the corpus using CountVectorizer\n",
    "    candidate_terms = extract_candidate_terms(df, text_col='processed_text', max_features=MAX_FEATURES)\n",
    "    logger.info(f\"  ✓ Extracted {len(candidate_terms)} candidate terms\")\n",
    "    print(f\"  Sample candidate terms: {candidate_terms[:10]}\")\n",
    "    \n",
    "    logger.info(\"  1b: Using LLM to identify research methods from candidate terms...\")\n",
    "    \n",
    "    # Use LLM to intelligently identify research methods from candidate terms\n",
    "    method_phrases, method_counts = get_method_phrases_enhanced(\n",
    "        candidate_terms,\n",
    "        client,\n",
    "        model_type,\n",
    "        credit_tracker,\n",
    "        prompt=extraction_prompt,\n",
    "        n_runs=METHOD_LLM_N_RUNS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        top_p=TOP_P,\n",
    "        temp=TEMP\n",
    "    )\n",
    "    method_phrases = filter_generic_phrases(method_phrases)\n",
    "    save_method_phrases_to_csv(method_phrases, method_counts)\n",
    "else:\n",
    "    logger.info(f\"  ✓ Loaded {len(method_phrases)} method phrases from existing CSV\")\n",
    "\n",
    "# Validate that method extraction was successful\n",
    "if not method_phrases:\n",
    "    logger.error(\"No method phrases extracted! Check your LLM configuration and prompts.\")\n",
    "    raise RuntimeError(\"Method extraction failed - no phrases found\")\n",
    "\n",
    "logger.info(f\"✓ Method phrase extraction complete: {len(method_phrases)} phrases\")\n",
    "print(f\"  Sample methods: {method_phrases[:10]}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: ENHANCED METHOD VARIANT CONSOLIDATION\n",
    "# =============================================================================\n",
    "logger.info(\"Step 2: Building enhanced method variant groups with consolidation...\")\n",
    "\n",
    "# Use enhanced LLM-based variant grouping to consolidate similar methods\n",
    "variant_groups = build_method_variant_groups_enhanced(\n",
    "    method_phrases, \n",
    "    client, \n",
    "    model_type, \n",
    "    credit_tracker, \n",
    "    prompt=grouping_prompt, \n",
    "    top_p=TOP_P,\n",
    "    temp=TEMP,\n",
    "    batch_size=VARIANT_GROUP_BATCH_SIZE\n",
    ") if method_phrases else {}\n",
    "\n",
    "# Create fallback mapping if LLM-based grouping fails completely\n",
    "if not variant_groups and method_phrases:\n",
    "    logger.info(\"  LLM grouping failed completely - using enhanced aggressive fallback grouping...\")\n",
    "    variant_groups = aggressive_fallback_grouping(method_phrases, similarity_threshold=0.75)\n",
    "    logger.info(f\"  ✓ Aggressive fallback created {len(variant_groups)} groups from {len(method_phrases)} methods\")\n",
    "\n",
    "# Create bidirectional mappings for efficient lookup during scoring\n",
    "variant_to_canonical, canonical_to_variants = create_variant_mapping(variant_groups)\n",
    "logger.info(f\"✓ Created {len(canonical_to_variants)} canonical methods with {len(variant_to_canonical)} total variants\")\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE FOR MANUAL EDITING\n",
    "# =============================================================================\n",
    "logger.info(\"Saving method phrases and groups for manual review and editing...\")\n",
    "\n",
    "# Save method phrases (can be edited)\n",
    "save_method_phrases_to_csv(method_phrases, method_counts, filename=\"extracted_method_phrases.csv\")\n",
    "\n",
    "# Save variant groups (can be edited)\n",
    "with open(os.path.join(SAVE_DIR, \"method_variant_groups.json\"), 'w') as f:\n",
    "    json.dump(canonical_to_variants, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Display consolidation results\n",
    "print(f\"\\n📊 Method Extraction and Grouping Results:\")\n",
    "print(f\"  Original methods: {len(method_phrases) if method_phrases else 0}\")\n",
    "print(f\"  Consolidated methods: {len(canonical_to_variants)}\")\n",
    "reduction = len(method_phrases) - len(canonical_to_variants) if method_phrases else 0\n",
    "print(f\"  Reduction: {reduction} methods ({100*reduction/len(method_phrases):.1f}% reduction)\" if method_phrases and len(method_phrases) > 0 else \"\")\n",
    "\n",
    "print(f\"\\n⏸️  EDITING CHECKPOINT:\")\n",
    "print(f\"  📝 Edit extracted_method_phrases.csv to add/remove/rename methods\")\n",
    "print(f\"  📝 Edit method_variant_groups.json to adjust groupings\")\n",
    "print(f\"  ✅ Files saved to: {SAVE_DIR}\")\n",
    "print(f\"  ➡️  Run Cell 10B when editing is complete\")\n",
    "\n",
    "logger.info(\"✅ Method extraction and grouping phase completed successfully!\")\n",
    "logger.info(f\"💰 Credit usage so far: {credit_tracker.get_stats()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d8b289d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:16:04,598 - INFO - === Starting Scoring and Assignment Phase ===\n",
      "2025-09-11 00:16:04,599 - INFO - Loading method phrases and groups (potentially edited)...\n",
      "2025-09-11 00:16:04,615 - INFO - ✓ Loaded 168 method phrases\n",
      "2025-09-11 00:16:04,628 - INFO - ✓ Loaded 97 method groups\n",
      "2025-09-11 00:16:04,629 - INFO - Computing enhanced scoring matrices using multiple approaches...\n",
      "2025-09-11 00:16:04,635 - INFO -   Computing TF-IDF scores for method variants...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 114 variants that exist in corpus out of 127 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:16:34,062 - INFO -   ✓ TF-IDF: (28934, 114) with 114 features\n",
      "2025-09-11 00:16:34,063 - INFO -   Computing LDA scores for method variants...\n",
      "2025-09-11 00:17:04,729 - INFO -   ✓ LDA: (28934, 97) with 127 features\n",
      "2025-09-11 00:17:04,730 - INFO -   Computing compound scores for method variants...\n",
      "2025-09-11 00:20:33,931 - INFO -   ✓ Compound: (28934, 127) with 127 features\n",
      "2025-09-11 00:20:33,932 - INFO - Aligning and harmonizing features across scoring methods...\n",
      "2025-09-11 00:20:33,933 - INFO -   Feature alignment statistics:\n",
      "2025-09-11 00:20:33,934 - INFO -     Total unique features: 127\n",
      "2025-09-11 00:20:33,934 - INFO -     TF-IDF features: 114\n",
      "2025-09-11 00:20:33,935 - INFO -     LDA features: 127\n",
      "2025-09-11 00:20:33,935 - INFO -     Compound features: 127\n",
      "2025-09-11 00:20:34,015 - INFO - ✓ Feature alignment complete: (28934, 127)\n",
      "2025-09-11 00:20:34,016 - INFO - Normalizing scores and applying variant consolidation...\n",
      "2025-09-11 00:20:34,079 - INFO - ✓ Score combination complete: (28934, 127)\n",
      "2025-09-11 00:20:34,083 - INFO -   Combined score range: [0.0000, 0.9753]\n",
      "2025-09-11 00:20:34,085 - INFO -   Applying variant score consolidation to prevent double-counting...\n",
      "2025-09-11 00:20:34,125 - INFO -   ✓ Consolidated 127 methods to 97 canonical methods\n",
      "2025-09-11 00:20:34,126 - INFO - ✓ Final consolidated scores: (28934, 97)\n",
      "2025-09-11 00:20:34,129 - INFO -   Final score range: [0.0000, 0.9753]\n",
      "2025-09-11 00:20:34,130 - INFO - Assigning methods to papers using consolidated scores...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Aligned 114/127 features\n",
      "⚠️  DIMENSION MISMATCH DETECTED:\n",
      "    Expected columns: 127 (from feature names)\n",
      "    Actual columns: 97 (from score matrix)\n",
      "    Using actual matrix dimensions for safety\n",
      "    Truncated feature list: 97 features\n",
      "    ✓ Aligned 97/127 features\n",
      "    ✓ Aligned 127/127 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:21:46,164 - INFO -   Assigned methods to 28934/28934 papers (100.0%)\n",
      "2025-09-11 00:21:46,211 - INFO - Saving results and metadata...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Final Assignment Verification:\n",
      "  Papers assigned methods: 28934\n",
      "  Unique methods assigned: 92\n",
      "  Top assigned methods:\n",
      "    successive interference cancellation: 20787 papers\n",
      "    model analysis: 755 papers\n",
      "    artificial neural network: 614 papers (consolidated from: ['neural network ann', 'neural network', 'artificial neural network', 'neural network cnn'])\n",
      "    monte carlo simulation: 443 papers (consolidated from: ['monte carlo simulation', 'monte-carlo simulation'])\n",
      "    particle swarm optimization: 430 papers (consolidated from: ['particle swarm optimization', 'pso algorithm', 'optimization pso algorithm', 'particle swarm algorithm'])\n",
      "    genetic algorithm ga: 389 papers (consolidated from: ['genetic algorithm ga', 'genetic algorithm'])\n",
      "    capacity ratio: 381 papers\n",
      "    optimal utilization: 313 papers\n",
      "    sensitivity analysis: 257 papers\n",
      "    load frequency: 229 papers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-11 00:21:55,525 - INFO - ✓ Results saved:\n",
      "2025-09-11 00:21:55,526 - INFO -   Enhanced analysis: enhanced_method_analysis_2025_09_11_reliability_resilience_power_systems.csv\n",
      "2025-09-11 00:21:55,527 - INFO -   Method variant groups: method_variant_groups_2025_09_11_reliability_resilience_power_systems.json\n",
      "2025-09-11 00:21:55,528 - INFO -   Consolidated scores: consolidated_method_scores_2025_09_11_reliability_resilience_power_systems.csv\n",
      "2025-09-11 00:21:55,612 - INFO - Enhanced method detection pipeline with consolidation completed successfully!\n",
      "2025-09-11 00:21:55,613 - INFO - Credit usage: {'total_tokens': 1387, 'total_cost': 0.0002}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE METHOD DETECTION DIAGNOSTICS\n",
      "================================================================================\n",
      "\n",
      "📊 ASSIGNMENT OVERVIEW:\n",
      "  Total papers processed: 28,934\n",
      "  Papers with methods assigned: 28,934 (100.0%)\n",
      "  Papers without methods: 0 (0.0%)\n",
      "\n",
      "📈 SCORE DISTRIBUTION ANALYSIS:\n",
      "  Final score matrix shape: (28934, 97)\n",
      "  Total canonical methods: 97\n",
      "  Score range: [0.0000, 0.9753]\n",
      "  Mean score: 0.0043\n",
      "  Standard deviation: 0.0326\n",
      "  Scores > 0.001: 1,999,973 (71.26% of all scores)\n",
      "  Scores > 0.005: 19,063 (0.68% of all scores)\n",
      "  Scores > 0.01: 19,063 (0.68% of all scores)\n",
      "  Scores > 0.05: 18,874 (0.67% of all scores)\n",
      "  Scores > 0.1: 17,326 (0.62% of all scores)\n",
      "\n",
      "🔥 TOP ASSIGNED METHODS:\n",
      "   1. successive interference cancellation: 20,787 papers (71.8%)\n",
      "   2. model analysis: 755 papers (2.6%)\n",
      "   3. artificial neural network: 614 papers (2.1%) (from 4 variants)\n",
      "   4. monte carlo simulation: 443 papers (1.5%) (from 2 variants)\n",
      "   5. particle swarm optimization: 430 papers (1.5%) (from 4 variants)\n",
      "   6. genetic algorithm ga: 389 papers (1.3%) (from 2 variants)\n",
      "   7. capacity ratio: 381 papers (1.3%)\n",
      "   8. optimal utilization: 313 papers (1.1%)\n",
      "   9. sensitivity analysis: 257 papers (0.9%)\n",
      "  10. load frequency: 229 papers (0.8%)\n",
      "  11. optimal power flow opf: 213 papers (0.7%) (from 3 variants)\n",
      "  12. dynamic condition: 211 papers (0.7%)\n",
      "  13. optimal power allocation: 196 papers (0.7%)\n",
      "  14. mixed integer linear programming: 188 papers (0.6%) (from 2 variants)\n",
      "  15. probabilistic reliability: 187 papers (0.6%)\n",
      "\n",
      "🎯 CONFIDENCE DISTRIBUTION:\n",
      "  Low: 20,724 (71.6%)\n",
      "  High: 8,210 (28.4%)\n",
      "\n",
      "🔧 CONSOLIDATION EFFECTIVENESS:\n",
      "  Total method variants processed: 127\n",
      "  Final canonical methods: 97\n",
      "  Groups with multiple variants: 25\n",
      "  Consolidation ratio: 1.31:1\n",
      "\n",
      "⚠️  QUALITY ASSESSMENT:\n",
      "  ✅ Good assignment rate (100.0%)\n",
      "  ✅ Reasonable maximum scores (0.9753)\n",
      "  ⚠️  1 methods (1.0%) have zero scores across all papers\n",
      "      Consider reviewing method extraction or scoring parameters\n",
      "\n",
      "================================================================================\n",
      "\n",
      "✅ Enhanced Method Detection Pipeline Completed Successfully!\n",
      "📁 All results saved to: Saved_files_new\n",
      "📊 Assignment Rate: 100.0%\n",
      "🔧 Methods Consolidated: 168 → 97\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 10B: Scoring and Assignment Phase (Uses Edited Terms)\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION PARAMETERS FOR SCORING\n",
    "# =============================================================================\n",
    "TFIDF_WEIGHT = 0.5                      # Weight for TF-IDF scoring in final combination\n",
    "LDA_WEIGHT = 0.3                        # Weight for LDA scoring in final combination  \n",
    "COMPOUND_WEIGHT = 0.20                   # Weight for compound scoring in final combination\n",
    "TOP_METHODS_PER_PAPER = 10               # Number of top methods to assign per paper\n",
    "MIN_ASSIGN_SCORE = 0.003                  # Minimum score threshold for method assignment\n",
    "\n",
    "logger.info(\"=== Starting Scoring and Assignment Phase ===\")\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD EDITED METHODS AND GROUPS\n",
    "# =============================================================================\n",
    "logger.info(\"Loading method phrases and groups (potentially edited)...\")\n",
    "\n",
    "# Load method phrases (potentially edited by user)\n",
    "method_phrases, method_counts = load_method_phrases_from_csv(filename=\"extracted_method_phrases.csv\")\n",
    "logger.info(f\"✓ Loaded {len(method_phrases)} method phrases\")\n",
    "\n",
    "# Load variant groups (potentially edited by user)\n",
    "with open(os.path.join(SAVE_DIR, \"method_variant_groups.json\"), 'r') as f:\n",
    "    canonical_to_variants = json.load(f)\n",
    "logger.info(f\"✓ Loaded {len(canonical_to_variants)} method groups\")\n",
    "\n",
    "# Recreate mappings\n",
    "variant_to_canonical, _ = create_variant_mapping(canonical_to_variants)\n",
    "\n",
    "# =============================================================================\n",
    "# COMPUTE MULTIPLE SCORING MATRICES FOR ROBUST METHOD DETECTION\n",
    "# =============================================================================\n",
    "logger.info(\"Computing enhanced scoring matrices using multiple approaches...\")\n",
    "\n",
    "# Convert DataFrame text to list for processing\n",
    "processed_texts = df['processed_text'].fillna('').tolist()\n",
    "\n",
    "# 3a: TF-IDF Scoring - Captures term frequency and document importance\n",
    "logger.info(\"  Computing TF-IDF scores for method variants...\")\n",
    "tfidf_scores, tfidf_feature_names = compute_enhanced_tfidf_scores(\n",
    "    processed_texts, canonical_to_variants\n",
    ")\n",
    "logger.info(f\"  ✓ TF-IDF: {tfidf_scores.shape} with {len(tfidf_feature_names)} features\")\n",
    "\n",
    "# 3b: LDA Scoring - Captures topic-based method associations\n",
    "logger.info(\"  Computing LDA scores for method variants...\")  \n",
    "method_vocab = list(canonical_to_variants.keys())\n",
    "lda_scores, lda_feature_names = compute_enhanced_lda_scores(\n",
    "    processed_texts, canonical_to_variants, n_topics=len(method_vocab)\n",
    ")\n",
    "logger.info(f\"  ✓ LDA: {lda_scores.shape} with {len(lda_feature_names)} features\")\n",
    "\n",
    "# 3c: Compound Scoring - Captures exact phrase matches and partial matches\n",
    "logger.info(\"  Computing compound scores for method variants...\")\n",
    "compound_scores, compound_feature_names = compute_enhanced_compound_scores(\n",
    "    df, canonical_to_variants\n",
    ")\n",
    "logger.info(f\"  ✓ Compound: {compound_scores.shape} with {len(compound_feature_names)} features\")\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE ALIGNMENT AND HARMONIZATION\n",
    "# =============================================================================\n",
    "logger.info(\"Aligning and harmonizing features across scoring methods...\")\n",
    "\n",
    "# Create union of all features to preserve maximum method coverage\n",
    "all_features = set(tfidf_feature_names) | set(lda_feature_names) | set(compound_feature_names)\n",
    "all_features = sorted(list(all_features))  # Sort for consistency\n",
    "\n",
    "logger.info(f\"  Feature alignment statistics:\")\n",
    "logger.info(f\"    Total unique features: {len(all_features)}\")\n",
    "logger.info(f\"    TF-IDF features: {len(tfidf_feature_names)}\")\n",
    "logger.info(f\"    LDA features: {len(lda_feature_names)}\")  \n",
    "logger.info(f\"    Compound features: {len(compound_feature_names)}\")\n",
    "\n",
    "# Use your existing align_scores_robust function\n",
    "tfidf_aligned = align_scores_robust(tfidf_scores, tfidf_feature_names, all_features)\n",
    "lda_aligned = align_scores_robust(lda_scores, lda_feature_names, all_features)\n",
    "compound_aligned = align_scores_robust(compound_scores, compound_feature_names, all_features)\n",
    "\n",
    "logger.info(f\"✓ Feature alignment complete: {tfidf_aligned.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SCORE NORMALIZATION AND CONSOLIDATION\n",
    "# =============================================================================\n",
    "logger.info(\"Normalizing scores and applying variant consolidation...\")\n",
    "\n",
    "def normalize_scores(scores):\n",
    "    \"\"\"Normalize scores to [0,1] range per matrix for fair weighting.\"\"\"\n",
    "    if scores.max() == 0:\n",
    "        return scores\n",
    "    return scores / scores.max()\n",
    "\n",
    "# Normalize each scoring matrix to ensure fair contribution to final scores\n",
    "tfidf_normalized = normalize_scores(tfidf_aligned)\n",
    "lda_normalized = normalize_scores(lda_aligned)\n",
    "compound_normalized = normalize_scores(compound_aligned)\n",
    "\n",
    "# Combine normalized scores using weighted average\n",
    "combined_scores = (\n",
    "    TFIDF_WEIGHT * tfidf_normalized + \n",
    "    LDA_WEIGHT * lda_normalized + \n",
    "    COMPOUND_WEIGHT * compound_normalized\n",
    ")\n",
    "\n",
    "logger.info(f\"✓ Score combination complete: {combined_scores.shape}\")\n",
    "logger.info(f\"  Combined score range: [{combined_scores.min():.4f}, {combined_scores.max():.4f}]\")\n",
    "\n",
    "# Apply variant consolidation to prevent double-counting\n",
    "if variant_to_canonical:\n",
    "    logger.info(\"  Applying variant score consolidation to prevent double-counting...\")\n",
    "    \n",
    "    # Consolidate variant scores using maximum (not sum) to avoid inflating scores\n",
    "    final_scores, canonical_methods = consolidate_variant_scores(\n",
    "        combined_scores, all_features, variant_to_canonical\n",
    "    )\n",
    "    logger.info(f\"  ✓ Consolidated {len(all_features)} methods to {len(canonical_methods)} canonical methods\")\n",
    "else:\n",
    "    # No consolidation needed - use combined scores as-is\n",
    "    final_scores = combined_scores\n",
    "    canonical_methods = all_features\n",
    "    logger.info(\"  No variant consolidation applied (no variant mappings found)\")\n",
    "\n",
    "logger.info(f\"✓ Final consolidated scores: {final_scores.shape}\")\n",
    "logger.info(f\"  Final score range: [{final_scores.min():.4f}, {final_scores.max():.4f}]\")\n",
    "\n",
    "# =============================================================================\n",
    "# METHOD ASSIGNMENT TO PAPERS\n",
    "# =============================================================================\n",
    "logger.info(\"Assigning methods to papers using consolidated scores...\")\n",
    "\n",
    "# Assign top methods to each paper using the consolidated scores\n",
    "df = assign_methods_improved(\n",
    "    df, final_scores, canonical_methods, \n",
    "    top_n=TOP_METHODS_PER_PAPER, \n",
    "    min_score=MIN_ASSIGN_SCORE\n",
    ")\n",
    "\n",
    "# Additional diagnostic: Verify no double-counting occurred\n",
    "assigned_methods = df[df['Primary_Method'] != '']['Primary_Method'].tolist()\n",
    "method_assignment_counts = pd.Series(assigned_methods).value_counts()\n",
    "\n",
    "print(f\"\\n🔍 Final Assignment Verification:\")\n",
    "print(f\"  Papers assigned methods: {len(assigned_methods)}\")\n",
    "print(f\"  Unique methods assigned: {len(method_assignment_counts)}\")\n",
    "print(f\"  Top assigned methods:\")\n",
    "\n",
    "for method, count in method_assignment_counts.head(10).items():\n",
    "    # Check if this method has variants that were consolidated\n",
    "    variants = canonical_to_variants.get(method, [method])\n",
    "    if len(variants) > 1:\n",
    "        print(f\"    {method}: {count} papers (consolidated from: {variants})\")\n",
    "    else:\n",
    "        print(f\"    {method}: {count} papers\")\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE RESULTS AND METADATA\n",
    "# =============================================================================\n",
    "logger.info(\"Saving results and metadata...\")\n",
    "\n",
    "# Save method variant mappings for future reference and transparency\n",
    "with open(os.path.join(SAVE_DIR, f\"method_variant_groups_{suffix_string}.json\"), 'w') as f:\n",
    "    json.dump(canonical_to_variants, f, indent=2)\n",
    "\n",
    "# Save consolidated score matrix for analysis and debugging\n",
    "pd.DataFrame(final_scores, columns=canonical_methods).to_csv(\n",
    "    os.path.join(SAVE_DIR, f\"consolidated_method_scores_{suffix_string}.csv\")\n",
    ")\n",
    "\n",
    "# Save final enhanced dataframe with method assignments\n",
    "enhanced_analysis_filename = f\"enhanced_method_analysis_{suffix_string}.csv\"\n",
    "df.to_csv(os.path.join(SAVE_DIR, enhanced_analysis_filename), index=False)\n",
    "\n",
    "logger.info(f\"✓ Results saved:\")\n",
    "logger.info(f\"  Enhanced analysis: {enhanced_analysis_filename}\")\n",
    "logger.info(f\"  Method variant groups: method_variant_groups_{suffix_string}.json\")\n",
    "logger.info(f\"  Consolidated scores: consolidated_method_scores_{suffix_string}.csv\")\n",
    "\n",
    "# Run diagnostics\n",
    "diagnostic_results = enhanced_method_diagnostics(df, final_scores, canonical_methods, canonical_to_variants)\n",
    "\n",
    "print(f\"\\n✅ Enhanced Method Detection Pipeline Completed Successfully!\")\n",
    "print(f\"📁 All results saved to: {SAVE_DIR}\")\n",
    "print(f\"📊 Assignment Rate: {diagnostic_results['assignment_rate']:.1f}%\")\n",
    "print(f\"🔧 Methods Consolidated: {len(method_phrases) if method_phrases else 0} → {len(canonical_methods)}\")\n",
    "\n",
    "logger.info(\"Enhanced method detection pipeline with consolidation completed successfully!\")\n",
    "logger.info(f\"Credit usage: {credit_tracker.get_stats()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bb61ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# %%\\n# Cell 10: Complete Enhanced Method Extraction and Assignment Workflow - REFACTORED\\n\\n# =============================================================================\\n# CONFIGURATION PARAMETERS - Adjust these for optimal method detection\\n# =============================================================================\\nMAX_FEATURES = 10000                    # Maximum features for candidate term extraction\\nTFIDF_WEIGHT = 0.45                      # Weight for TF-IDF scoring in final combination\\nLDA_WEIGHT = 0.25                        # Weight for LDA scoring in final combination  \\nCOMPOUND_WEIGHT = 0.30                   # Weight for compound scoring in final combination\\nTOP_METHODS_PER_PAPER = 10              # Number of top methods to assign per paper\\nMIN_ASSIGN_SCORE = 0.02                # Minimum score threshold for method assignment\\nBATCH_SIZE = 5000                       # Batch size for LLM processing\\nMETHOD_LLM_N_RUNS = 3                   # Number of LLM runs for method extraction\\nVARIANT_GROUP_BATCH_SIZE = 5000           # Batch size for method variant grouping\\nTOP_P=0.92\\nTEMP=0.15\\n\\nlogger.info(\"=== Starting Enhanced Method Detection Pipeline with Consolidation ===\")\\n\\n# =============================================================================\\n# STEP 1: LOAD OR EXTRACT METHOD PHRASES FROM CORPUS\\n# =============================================================================\\nlogger.info(\"Step 1: Loading or extracting method phrases...\")\\n\\n# Try to load existing method phrases from previous runs\\ntry:\\n    method_phrases, method_counts = load_method_phrases_from_csv(filename=\"extracted_method_phrases.csv\")\\nexcept (FileNotFoundError, TypeError):\\n    method_phrases, method_counts = None, None\\n\\n# If no existing phrases found or too few, extract new ones using LLM\\nif (method_phrases is None) or (len(method_phrases) < 3):\\n    logger.info(\"  1a: Extracting candidate terms from processed text...\")\\n    \\n    # Extract candidate n-grams (1-4 grams) from the corpus using CountVectorizer\\n    candidate_terms = extract_candidate_terms(df, text_col=\\'processed_text\\', max_features=MAX_FEATURES)\\n    logger.info(f\"  ✓ Extracted {len(candidate_terms)} candidate terms\")\\n    print(f\"  Sample candidate terms: {candidate_terms[:10]}\")\\n    \\n    logger.info(\"  1b: Using LLM to identify research methods from candidate terms...\")\\n    \\n    # Use LLM to intelligently identify research methods from candidate terms\\n    # This filters out generic terms and focuses on actual research methodologies\\n    # Call the functions with your prompts\\n    \\n    method_phrases, method_counts = get_method_phrases_enhanced(\\n        candidate_terms,\\n        client,\\n        model_type,\\n        credit_tracker,\\n        prompt=extraction_prompt,\\n        n_runs=METHOD_LLM_N_RUNS,\\n        batch_size=BATCH_SIZE,\\n        top_p=TOP_P,\\n        temp=TEMP\\n    )\\n    method_phrases = filter_generic_phrases(method_phrases)\\n    # Save extracted phrases for future use\\n    save_method_phrases_to_csv(method_phrases, method_counts)\\nelse:\\n    logger.info(f\"  ✓ Loaded {len(method_phrases)} method phrases from existing CSV\")\\n\\n# Validate that method extraction was successful\\nif not method_phrases:\\n    logger.error(\"No method phrases extracted! Check your LLM configuration and prompts.\")\\n    raise RuntimeError(\"Method extraction failed - no phrases found\")\\n\\nlogger.info(f\"✓ Method phrase extraction complete: {len(method_phrases)} phrases\")\\nprint(f\"  Sample methods: {method_phrases[:10]}\")\\n# Apply after LLM extraction:\\n\\n\\n# =============================================================================\\n# STEP 2: ENHANCED METHOD VARIANT CONSOLIDATION\\n# =============================================================================\\nlogger.info(\"Step 2: Building enhanced method variant groups with consolidation...\")\\n\\n# Use enhanced LLM-based variant grouping to consolidate similar methods\\nvariant_groups = build_method_variant_groups_enhanced(\\n    method_phrases, \\n    client, \\n    model_type, \\n    credit_tracker, \\n    prompt=grouping_prompt, \\n    top_p=TOP_P,\\n    temp=TEMP,\\n    batch_size=VARIANT_GROUP_BATCH_SIZE\\n) if method_phrases else {}\\n\\n# Create fallback mapping if LLM-based grouping fails completely\\nif not variant_groups and method_phrases:\\n    logger.info(\"  LLM grouping failed completely - using enhanced aggressive fallback grouping...\")\\n    variant_groups = aggressive_fallback_grouping(method_phrases, similarity_threshold=0.75)\\n    logger.info(f\"  ✓ Aggressive fallback created {len(variant_groups)} groups from {len(method_phrases)} methods\")\\n\\n# Create bidirectional mappings for efficient lookup during scoring\\nvariant_to_canonical, canonical_to_variants = create_variant_mapping(variant_groups)\\nlogger.info(f\"✓ Created {len(canonical_to_variants)} canonical methods with {len(variant_to_canonical)} total variants\")\\n\\n\\n# Display consolidation results\\nprint(f\"\\n📊 Method Consolidation Results:\")\\nprint(f\"  Original methods: {len(method_phrases) if method_phrases else 0}\")\\nprint(f\"  Consolidated methods: {len(canonical_to_variants)}\")\\nreduction = len(method_phrases) - len(canonical_to_variants) if method_phrases else 0\\nprint(f\"  Reduction: {reduction} methods ({100*reduction/len(method_phrases):.1f}% reduction)\" if method_phrases and len(method_phrases) > 0 else \"\")\\n\\nprint(\"\\nSample variant groups (showing groups with multiple variants):\")\\nsample_count = 0\\nfor canonical, variants in canonical_to_variants.items():\\n    if len(variants) > 1 and sample_count < 5:  # Only show groups with multiple variants\\n        print(f\"  {canonical}: {variants}\")\\n        sample_count += 1\\n\\n# =============================================================================\\n# STEP 3: COMPUTE MULTIPLE SCORING MATRICES FOR ROBUST METHOD DETECTION\\n# =============================================================================\\nlogger.info(\"Step 3: Computing enhanced scoring matrices using multiple approaches...\")\\n\\n# Convert DataFrame text to list for processing\\nprocessed_texts = df[\\'processed_text\\'].fillna(\\'\\').tolist()\\n\\n# 3a: TF-IDF Scoring - Captures term frequency and document importance\\nlogger.info(\"  3a: Computing TF-IDF scores for method variants...\")\\ntfidf_scores, tfidf_feature_names = compute_enhanced_tfidf_scores(\\n    processed_texts, canonical_to_variants\\n)\\nlogger.info(f\"  ✓ TF-IDF: {tfidf_scores.shape} with {len(tfidf_feature_names)} features\")\\n\\n# 3b: LDA Scoring - Captures topic-based method associations\\nlogger.info(\"  3b: Computing LDA scores for method variants...\")  \\nmethod_vocab = list(canonical_to_variants.keys())\\nlda_scores, lda_feature_names = compute_enhanced_lda_scores(\\n    processed_texts, canonical_to_variants, n_topics=len(method_vocab)\\n)\\nlogger.info(f\"  ✓ LDA: {lda_scores.shape} with {len(lda_feature_names)} features\")\\n\\n# 3c: Compound Scoring - Captures exact phrase matches and partial matches\\nlogger.info(\"  3c: Computing compound scores for method variants...\")\\ncompound_scores, compound_feature_names = compute_enhanced_compound_scores(\\n    df, canonical_to_variants\\n)\\nlogger.info(f\"  ✓ Compound: {compound_scores.shape} with {len(compound_feature_names)} features\")\\n\\n# =============================================================================\\n# STEP 4: FEATURE ALIGNMENT AND HARMONIZATION\\n# =============================================================================\\nlogger.info(\"Step 4: Aligning and harmonizing features across scoring methods...\")\\n\\n# Create union of all features to preserve maximum method coverage\\n# This ensures we don\\'t lose methods that appear in only one scoring approach\\nall_features = set(tfidf_feature_names) | set(lda_feature_names) | set(compound_feature_names)\\nall_features = sorted(list(all_features))  # Sort for consistency\\n\\nlogger.info(f\"  Feature alignment statistics:\")\\nlogger.info(f\"    Total unique features: {len(all_features)}\")\\nlogger.info(f\"    TF-IDF features: {len(tfidf_feature_names)}\")\\nlogger.info(f\"    LDA features: {len(lda_feature_names)}\")  \\nlogger.info(f\"    Compound features: {len(compound_feature_names)}\")\\n\\ndef align_scores_robust(scores, current_features, target_features):\\n    \\n    #Enhanced alignment with dimension safety checks and detailed error handling.\\n    \\n    if not target_features:\\n        return np.array([]).reshape(scores.shape[0], 0)\\n    \\n    # SAFETY CHECK: Verify dimensions match expectations\\n    expected_cols = len(current_features)\\n    actual_cols = scores.shape[1]\\n    \\n    if expected_cols != actual_cols:\\n        print(f\"⚠️  DIMENSION MISMATCH DETECTED:\")\\n        print(f\"    Expected columns: {expected_cols} (from feature names)\")\\n        print(f\"    Actual columns: {actual_cols} (from score matrix)\")\\n        print(f\"    Using actual matrix dimensions for safety\")\\n        \\n        # Use only the features that actually exist in the matrix\\n        safe_current_features = current_features[:actual_cols]\\n        print(f\"    Truncated feature list: {len(safe_current_features)} features\")\\n    else:\\n        safe_current_features = current_features\\n    \\n    # Initialize aligned matrix with zeros\\n    aligned_scores = np.zeros((scores.shape[0], len(target_features)))\\n    current_to_idx = {feat: i for i, feat in enumerate(safe_current_features)}\\n    \\n    # Map existing features to aligned positions with bounds checking\\n    found_features = 0\\n    skipped_features = 0\\n    \\n    for j, feat in enumerate(target_features):\\n        if feat in current_to_idx:\\n            source_idx = current_to_idx[feat]\\n            \\n            # BOUNDS CHECK: Ensure source index is valid\\n            if source_idx < scores.shape[1]:\\n                aligned_scores[:, j] = scores[:, source_idx]\\n                found_features += 1\\n            else:\\n                print(f\"⚠️  Skipping feature \\'{feat}\\': index {source_idx} >= {scores.shape[1]}\")\\n                skipped_features += 1\\n    \\n    print(f\"    ✓ Aligned {found_features}/{len(target_features)} features\")\\n    if skipped_features > 0:\\n        print(f\"    ⚠️  Skipped {skipped_features} features due to bounds issues\")\\n    \\n    return aligned_scores\\n\\n\\n# Align all scoring matrices to the unified feature space\\ntfidf_aligned = align_scores_robust(tfidf_scores, tfidf_feature_names, all_features)\\nlda_aligned = align_scores_robust(lda_scores, lda_feature_names, all_features)\\ncompound_aligned = align_scores_robust(compound_scores, compound_feature_names, all_features)\\n\\nlogger.info(f\"✓ Feature alignment complete: {tfidf_aligned.shape}\")\\n\\n# =============================================================================\\n# STEP 5: SCORE NORMALIZATION AND CONSOLIDATION\\n# =============================================================================\\nlogger.info(\"Step 5: Normalizing scores and applying variant consolidation...\")\\n\\ndef normalize_scores(scores):\\n    #Normalize scores to  range per matrix for fair weighting.[1]\\n    if scores.max() == 0:\\n        return scores\\n    return scores / scores.max()\\n\\n# Normalize each scoring matrix to ensure fair contribution to final scores\\ntfidf_normalized = normalize_scores(tfidf_aligned)\\nlda_normalized = normalize_scores(lda_aligned)\\ncompound_normalized = normalize_scores(compound_aligned)\\n\\n# Combine normalized scores using weighted average\\ncombined_scores = (\\n    TFIDF_WEIGHT * tfidf_normalized + \\n    LDA_WEIGHT * lda_normalized + \\n    COMPOUND_WEIGHT * compound_normalized\\n)\\n\\nlogger.info(f\"✓ Score combination complete: {combined_scores.shape}\")\\nlogger.info(f\"  Combined score range: [{combined_scores.min():.4f}, {combined_scores.max():.4f}]\")\\n\\n# Apply variant consolidation to prevent double-counting\\nif variant_to_canonical:\\n    logger.info(\"  Applying variant score consolidation to prevent double-counting...\")\\n    \\n    # Consolidate variant scores using maximum (not sum) to avoid inflating scores\\n    final_scores, canonical_methods = consolidate_variant_scores(\\n        combined_scores, all_features, variant_to_canonical\\n    )\\n    logger.info(f\"  ✓ Consolidated {len(all_features)} methods to {len(canonical_methods)} canonical methods\")\\n    \\n    # Display consolidation statistics\\n    print(f\"\\n🔍 Score Consolidation Check:\")\\n    print(f\"  Methods before consolidation: {len(all_features)}\")\\n    print(f\"  Methods after consolidation: {len(canonical_methods)}\")\\n    print(f\"  Consolidation prevented potential double-counting of {len(all_features) - len(canonical_methods)} method variants\")\\n    \\nelse:\\n    # No consolidation needed - use combined scores as-is\\n    final_scores = combined_scores\\n    canonical_methods = all_features\\n    logger.info(\"  No variant consolidation applied (no variant mappings found)\")\\n\\nlogger.info(f\"✓ Final consolidated scores: {final_scores.shape}\")\\nlogger.info(f\"  Final score range: [{final_scores.min():.4f}, {final_scores.max():.4f}]\")\\n\\n# =============================================================================\\n# STEP 6: METHOD ASSIGNMENT TO PAPERS\\n# =============================================================================\\nlogger.info(\"Step 6: Assigning methods to papers using consolidated scores...\")\\n\\n# Assign top methods to each paper using the consolidated scores\\n# This creates columns Method_1, Method_2, etc. plus Primary_Method\\ndf = assign_methods_improved(\\n    df, final_scores, canonical_methods, \\n    top_n=TOP_METHODS_PER_PAPER, \\n    min_score=MIN_ASSIGN_SCORE\\n)\\n\\n# Additional diagnostic: Verify no double-counting occurred\\nassigned_methods = df[df[\\'Primary_Method\\'] != \\'\\'][\\'Primary_Method\\'].tolist()\\nmethod_assignment_counts = pd.Series(assigned_methods).value_counts()\\n\\nprint(f\"\\n🔍 Final Assignment Verification:\")\\nprint(f\"  Papers assigned methods: {len(assigned_methods)}\")\\nprint(f\"  Unique methods assigned: {len(method_assignment_counts)}\")\\nprint(f\"  Top assigned methods:\")\\n\\nfor method, count in method_assignment_counts.head(10).items():\\n    # Check if this method has variants that were consolidated\\n    variants = canonical_to_variants.get(method, [method])\\n    if len(variants) > 1:\\n        print(f\"    {method}: {count} papers (consolidated from: {variants})\")\\n    else:\\n        print(f\"    {method}: {count} papers\")\\n\\n# =============================================================================\\n# STEP 7: SAVE RESULTS AND METADATA\\n# =============================================================================\\nlogger.info(\"Step 7: Saving results and metadata...\")\\n\\n# Save method variant mappings for future reference and transparency\\nwith open(os.path.join(SAVE_DIR, f\"method_variant_groups_{suffix_string}.json\"), \\'w\\') as f:\\n    json.dump(canonical_to_variants, f, indent=2)\\n\\n# Save consolidated score matrix for analysis and debugging\\npd.DataFrame(final_scores, columns=canonical_methods).to_csv(\\n    os.path.join(SAVE_DIR, f\"consolidated_method_scores_{suffix_string}.csv\")\\n)\\n\\n# Save final enhanced dataframe with method assignments\\nenhanced_analysis_filename = f\"enhanced_method_analysis_{suffix_string}.csv\"\\ndf.to_csv(os.path.join(SAVE_DIR, enhanced_analysis_filename), index=False)\\n\\nlogger.info(f\"✓ Results saved:\")\\nlogger.info(f\"  Enhanced analysis: {enhanced_analysis_filename}\")\\nlogger.info(f\"  Method variant groups: method_variant_groups_{suffix_string}.json\")\\nlogger.info(f\"  Consolidated scores: consolidated_method_scores_{suffix_string}.csv\")\\n\\n# =============================================================================\\n# STEP 8: COMPREHENSIVE DIAGNOSTICS AND QUALITY ASSESSMENT\\n# =============================================================================\\nlogger.info(\"Step 8: Running comprehensive diagnostics...\")\\n\\ndef enhanced_method_diagnostics(df, scores, method_names, variant_groups):\\n    \\n    #Comprehensive diagnostics for method assignment quality and consolidation effectiveness.\\n    \\n    print(\"\\n\" + \"=\"*80)\\n    print(\"COMPREHENSIVE METHOD DETECTION DIAGNOSTICS\")\\n    print(\"=\"*80)\\n    \\n    # Basic assignment statistics\\n    n_papers = len(df)\\n    assigned_papers = (df[\\'Primary_Method\\'] != \\'\\').sum()\\n    assignment_rate = 100 * assigned_papers / n_papers\\n    \\n    print(f\"\\n📊 ASSIGNMENT OVERVIEW:\")\\n    print(f\"  Total papers processed: {n_papers:,}\")\\n    print(f\"  Papers with methods assigned: {assigned_papers:,} ({assignment_rate:.1f}%)\")\\n    print(f\"  Papers without methods: {n_papers - assigned_papers:,} ({100-assignment_rate:.1f}%)\")\\n    \\n    # Score distribution analysis\\n    print(f\"\\n📈 SCORE DISTRIBUTION ANALYSIS:\")\\n    print(f\"  Final score matrix shape: {scores.shape}\")\\n    print(f\"  Total canonical methods: {len(method_names)}\")\\n    print(f\"  Score range: [{scores.min():.4f}, {scores.max():.4f}]\")\\n    print(f\"  Mean score: {scores.mean():.4f}\")\\n    print(f\"  Standard deviation: {scores.std():.4f}\")\\n    \\n    # Score threshold analysis\\n    thresholds = [0.001, 0.005, 0.01, 0.05, 0.1]\\n    for threshold in thresholds:\\n        count = (scores > threshold).sum()\\n        print(f\"  Scores > {threshold}: {count:,} ({100*count/scores.size:.2f}% of all scores)\")\\n    \\n    # Method popularity and assignment quality\\n    if assigned_papers > 0:\\n        print(f\"\\n🔥 TOP ASSIGNED METHODS:\")\\n        method_counts = df[\\'Primary_Method\\'].value_counts()\\n        \\n        for i, (method, count) in enumerate(method_counts.head(15).items()):\\n            if method:  # Skip empty strings\\n                percentage = 100 * count / assigned_papers\\n                # Check if method was consolidated from variants\\n                variants = variant_groups.get(method, [method])\\n                variant_info = f\" (from {len(variants)} variants)\" if len(variants) > 1 else \"\"\\n                print(f\"  {i+1:2d}. {method}: {count:,} papers ({percentage:.1f}%){variant_info}\")\\n    \\n    # Confidence distribution analysis\\n    if \\'Method_Confidence\\' in df.columns:\\n        print(f\"\\n🎯 CONFIDENCE DISTRIBUTION:\")\\n        conf_counts = df[\\'Method_Confidence\\'].value_counts()\\n        for conf, count in conf_counts.items():\\n            percentage = 100 * count / n_papers\\n            print(f\"  {conf}: {count:,} ({percentage:.1f}%)\")\\n    \\n    # Consolidation effectiveness analysis\\n    print(f\"\\n🔧 CONSOLIDATION EFFECTIVENESS:\")\\n    total_variants = sum(len(variants) for variants in variant_groups.values())\\n    consolidated_groups = len([v for v in variant_groups.values() if len(v) > 1])\\n    \\n    print(f\"  Total method variants processed: {total_variants:,}\")\\n    print(f\"  Final canonical methods: {len(variant_groups):,}\")\\n    print(f\"  Groups with multiple variants: {consolidated_groups:,}\")\\n    print(f\"  Consolidation ratio: {total_variants/len(variant_groups):.2f}:1\")\\n    \\n    # Quality assessment and recommendations\\n    print(f\"\\n⚠️  QUALITY ASSESSMENT:\")\\n    \\n    if assignment_rate < 50:\\n        print(f\"  ⚠️  Low assignment rate ({assignment_rate:.1f}%) - consider:\")\\n        print(f\"      -  Lowering MIN_ASSIGN_SCORE (current: {MIN_ASSIGN_SCORE})\")\\n        print(f\"      -  Reviewing method extraction quality\")\\n        print(f\"      -  Checking text preprocessing effectiveness\")\\n    else:\\n        print(f\"  ✅ Good assignment rate ({assignment_rate:.1f}%)\")\\n    \\n    if scores.max() < 0.1:\\n        print(f\"  ⚠️  Low maximum scores ({scores.max():.4f}) - scoring method may need adjustment\")\\n    else:\\n        print(f\"  ✅ Reasonable maximum scores ({scores.max():.4f})\")\\n    \\n    zero_score_methods = (scores.max(axis=0) == 0).sum()\\n    if zero_score_methods > 0:\\n        zero_percentage = 100 * zero_score_methods / len(method_names)\\n        print(f\"  ⚠️  {zero_score_methods} methods ({zero_percentage:.1f}%) have zero scores across all papers\")\\n        print(f\"      Consider reviewing method extraction or scoring parameters\")\\n    else:\\n        print(f\"  ✅ All methods have non-zero scores in at least some papers\")\\n    \\n    print(\"\\n\" + \"=\"*80)\\n    return {\\n        \\'assignment_rate\\': assignment_rate,\\n        \\'total_papers\\': n_papers,\\n        \\'assigned_papers\\': assigned_papers,\\n        \\'score_stats\\': {\\n            \\'min\\': scores.min(),\\n            \\'max\\': scores.max(),\\n            \\'mean\\': scores.mean(),\\n            \\'std\\': scores.std()\\n        }\\n    }\\n\\n# Run comprehensive diagnostics\\ndiagnostic_results = enhanced_method_diagnostics(df, final_scores, canonical_methods, canonical_to_variants)\\n\\n# =============================================================================\\n# STEP 9: DISPLAY SAMPLE RESULTS FOR VERIFICATION\\n# =============================================================================\\nprint(\"\\n\" + \"=\"*80)\\nprint(\"SAMPLE RESULTS FOR VERIFICATION\")\\nprint(\"=\"*80)\\n\\n# Define columns to display in sample results\\nsample_cols = [\\'Primary_Method\\', \\'Primary_Method_Score\\', \\'Method_Confidence\\', \\'Total_Method_Score\\']\\navailable_cols = [col for col in sample_cols if col in df.columns]\\n\\n# Show sample of papers WITH methods assigned\\nassigned_mask = df[\\'Primary_Method\\'] != \\'\\'\\nif assigned_mask.sum() > 0:\\n    print(f\"\\n📄 SAMPLE PAPERS WITH METHODS ASSIGNED (first 10):\")\\n    sample_assigned = df[assigned_mask][available_cols].head(10)\\n    print(sample_assigned.to_string(index=False))\\n    \\n    # Show distribution of assigned methods\\n    print(f\"\\n📊 METHOD ASSIGNMENT DISTRIBUTION:\")\\n    for i in range(1, min(4, TOP_METHODS_PER_PAPER + 1)):  # Show top 3 method columns\\n        col_name = f\\'Method_{i}\\'\\n        if col_name in df.columns:\\n            non_empty = df[df[col_name] != \\'\\'][col_name].value_counts()\\n            print(f\"  {col_name} - {len(non_empty)} unique methods assigned to {non_empty.sum()} papers\")\\n\\n# Show sample of papers WITHOUT methods for diagnostic purposes\\nunassigned_mask = df[\\'Primary_Method\\'] == \\'\\'\\nif unassigned_mask.sum() > 0:\\n    print(f\"\\n❌ SAMPLE PAPERS WITHOUT METHODS (first 5 for diagnostic):\")\\n    unassigned_sample = df[unassigned_mask].head(5)\\n    \\n    if \\'processed_text\\' in df.columns:\\n        for idx, row in unassigned_sample.iterrows():\\n            text_preview = row.get(\\'processed_text\\', \\'\\')[:150] + \"...\" if len(str(row.get(\\'processed_text\\', \\'\\'))) > 150 else row.get(\\'processed_text\\', \\'\\')\\n            print(f\"  Paper {idx}: {text_preview}\")\\n\\n# Final completion message\\nprint(f\"\\n✅ Enhanced Method Detection Pipeline Completed Successfully!\")\\nprint(f\"📁 All results saved to: {SAVE_DIR}\")\\nprint(f\"📊 Assignment Rate: {diagnostic_results[\\'assignment_rate\\']:.1f}%\")\\nprint(f\"🔧 Methods Consolidated: {len(method_phrases) if method_phrases else 0} → {len(canonical_methods)}\")\\n\\nlogger.info(\"Enhanced method detection pipeline with consolidation completed successfully!\")\\nlogger.info(f\"Credit usage: {credit_tracker.get_stats()}\")\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# old \"one-fell swoup\"executing of method assignment\n",
    "\"\"\"\n",
    "# %%\n",
    "# Cell 10: Complete Enhanced Method Extraction and Assignment Workflow - REFACTORED\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION PARAMETERS - Adjust these for optimal method detection\n",
    "# =============================================================================\n",
    "MAX_FEATURES = 10000                    # Maximum features for candidate term extraction\n",
    "TFIDF_WEIGHT = 0.45                      # Weight for TF-IDF scoring in final combination\n",
    "LDA_WEIGHT = 0.25                        # Weight for LDA scoring in final combination  \n",
    "COMPOUND_WEIGHT = 0.30                   # Weight for compound scoring in final combination\n",
    "TOP_METHODS_PER_PAPER = 10              # Number of top methods to assign per paper\n",
    "MIN_ASSIGN_SCORE = 0.02                # Minimum score threshold for method assignment\n",
    "BATCH_SIZE = 5000                       # Batch size for LLM processing\n",
    "METHOD_LLM_N_RUNS = 3                   # Number of LLM runs for method extraction\n",
    "VARIANT_GROUP_BATCH_SIZE = 5000           # Batch size for method variant grouping\n",
    "TOP_P=0.92\n",
    "TEMP=0.15\n",
    "\n",
    "logger.info(\"=== Starting Enhanced Method Detection Pipeline with Consolidation ===\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: LOAD OR EXTRACT METHOD PHRASES FROM CORPUS\n",
    "# =============================================================================\n",
    "logger.info(\"Step 1: Loading or extracting method phrases...\")\n",
    "\n",
    "# Try to load existing method phrases from previous runs\n",
    "try:\n",
    "    method_phrases, method_counts = load_method_phrases_from_csv(filename=\"extracted_method_phrases.csv\")\n",
    "except (FileNotFoundError, TypeError):\n",
    "    method_phrases, method_counts = None, None\n",
    "\n",
    "# If no existing phrases found or too few, extract new ones using LLM\n",
    "if (method_phrases is None) or (len(method_phrases) < 3):\n",
    "    logger.info(\"  1a: Extracting candidate terms from processed text...\")\n",
    "    \n",
    "    # Extract candidate n-grams (1-4 grams) from the corpus using CountVectorizer\n",
    "    candidate_terms = extract_candidate_terms(df, text_col='processed_text', max_features=MAX_FEATURES)\n",
    "    logger.info(f\"  ✓ Extracted {len(candidate_terms)} candidate terms\")\n",
    "    print(f\"  Sample candidate terms: {candidate_terms[:10]}\")\n",
    "    \n",
    "    logger.info(\"  1b: Using LLM to identify research methods from candidate terms...\")\n",
    "    \n",
    "    # Use LLM to intelligently identify research methods from candidate terms\n",
    "    # This filters out generic terms and focuses on actual research methodologies\n",
    "    # Call the functions with your prompts\n",
    "    \n",
    "    method_phrases, method_counts = get_method_phrases_enhanced(\n",
    "        candidate_terms,\n",
    "        client,\n",
    "        model_type,\n",
    "        credit_tracker,\n",
    "        prompt=extraction_prompt,\n",
    "        n_runs=METHOD_LLM_N_RUNS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        top_p=TOP_P,\n",
    "        temp=TEMP\n",
    "    )\n",
    "    method_phrases = filter_generic_phrases(method_phrases)\n",
    "    # Save extracted phrases for future use\n",
    "    save_method_phrases_to_csv(method_phrases, method_counts)\n",
    "else:\n",
    "    logger.info(f\"  ✓ Loaded {len(method_phrases)} method phrases from existing CSV\")\n",
    "\n",
    "# Validate that method extraction was successful\n",
    "if not method_phrases:\n",
    "    logger.error(\"No method phrases extracted! Check your LLM configuration and prompts.\")\n",
    "    raise RuntimeError(\"Method extraction failed - no phrases found\")\n",
    "\n",
    "logger.info(f\"✓ Method phrase extraction complete: {len(method_phrases)} phrases\")\n",
    "print(f\"  Sample methods: {method_phrases[:10]}\")\n",
    "# Apply after LLM extraction:\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: ENHANCED METHOD VARIANT CONSOLIDATION\n",
    "# =============================================================================\n",
    "logger.info(\"Step 2: Building enhanced method variant groups with consolidation...\")\n",
    "\n",
    "# Use enhanced LLM-based variant grouping to consolidate similar methods\n",
    "variant_groups = build_method_variant_groups_enhanced(\n",
    "    method_phrases, \n",
    "    client, \n",
    "    model_type, \n",
    "    credit_tracker, \n",
    "    prompt=grouping_prompt, \n",
    "    top_p=TOP_P,\n",
    "    temp=TEMP,\n",
    "    batch_size=VARIANT_GROUP_BATCH_SIZE\n",
    ") if method_phrases else {}\n",
    "\n",
    "# Create fallback mapping if LLM-based grouping fails completely\n",
    "if not variant_groups and method_phrases:\n",
    "    logger.info(\"  LLM grouping failed completely - using enhanced aggressive fallback grouping...\")\n",
    "    variant_groups = aggressive_fallback_grouping(method_phrases, similarity_threshold=0.75)\n",
    "    logger.info(f\"  ✓ Aggressive fallback created {len(variant_groups)} groups from {len(method_phrases)} methods\")\n",
    "\n",
    "# Create bidirectional mappings for efficient lookup during scoring\n",
    "variant_to_canonical, canonical_to_variants = create_variant_mapping(variant_groups)\n",
    "logger.info(f\"✓ Created {len(canonical_to_variants)} canonical methods with {len(variant_to_canonical)} total variants\")\n",
    "\n",
    "\n",
    "# Display consolidation results\n",
    "print(f\"\\n📊 Method Consolidation Results:\")\n",
    "print(f\"  Original methods: {len(method_phrases) if method_phrases else 0}\")\n",
    "print(f\"  Consolidated methods: {len(canonical_to_variants)}\")\n",
    "reduction = len(method_phrases) - len(canonical_to_variants) if method_phrases else 0\n",
    "print(f\"  Reduction: {reduction} methods ({100*reduction/len(method_phrases):.1f}% reduction)\" if method_phrases and len(method_phrases) > 0 else \"\")\n",
    "\n",
    "print(\"\\nSample variant groups (showing groups with multiple variants):\")\n",
    "sample_count = 0\n",
    "for canonical, variants in canonical_to_variants.items():\n",
    "    if len(variants) > 1 and sample_count < 5:  # Only show groups with multiple variants\n",
    "        print(f\"  {canonical}: {variants}\")\n",
    "        sample_count += 1\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: COMPUTE MULTIPLE SCORING MATRICES FOR ROBUST METHOD DETECTION\n",
    "# =============================================================================\n",
    "logger.info(\"Step 3: Computing enhanced scoring matrices using multiple approaches...\")\n",
    "\n",
    "# Convert DataFrame text to list for processing\n",
    "processed_texts = df['processed_text'].fillna('').tolist()\n",
    "\n",
    "# 3a: TF-IDF Scoring - Captures term frequency and document importance\n",
    "logger.info(\"  3a: Computing TF-IDF scores for method variants...\")\n",
    "tfidf_scores, tfidf_feature_names = compute_enhanced_tfidf_scores(\n",
    "    processed_texts, canonical_to_variants\n",
    ")\n",
    "logger.info(f\"  ✓ TF-IDF: {tfidf_scores.shape} with {len(tfidf_feature_names)} features\")\n",
    "\n",
    "# 3b: LDA Scoring - Captures topic-based method associations\n",
    "logger.info(\"  3b: Computing LDA scores for method variants...\")  \n",
    "method_vocab = list(canonical_to_variants.keys())\n",
    "lda_scores, lda_feature_names = compute_enhanced_lda_scores(\n",
    "    processed_texts, canonical_to_variants, n_topics=len(method_vocab)\n",
    ")\n",
    "logger.info(f\"  ✓ LDA: {lda_scores.shape} with {len(lda_feature_names)} features\")\n",
    "\n",
    "# 3c: Compound Scoring - Captures exact phrase matches and partial matches\n",
    "logger.info(\"  3c: Computing compound scores for method variants...\")\n",
    "compound_scores, compound_feature_names = compute_enhanced_compound_scores(\n",
    "    df, canonical_to_variants\n",
    ")\n",
    "logger.info(f\"  ✓ Compound: {compound_scores.shape} with {len(compound_feature_names)} features\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 4: FEATURE ALIGNMENT AND HARMONIZATION\n",
    "# =============================================================================\n",
    "logger.info(\"Step 4: Aligning and harmonizing features across scoring methods...\")\n",
    "\n",
    "# Create union of all features to preserve maximum method coverage\n",
    "# This ensures we don't lose methods that appear in only one scoring approach\n",
    "all_features = set(tfidf_feature_names) | set(lda_feature_names) | set(compound_feature_names)\n",
    "all_features = sorted(list(all_features))  # Sort for consistency\n",
    "\n",
    "logger.info(f\"  Feature alignment statistics:\")\n",
    "logger.info(f\"    Total unique features: {len(all_features)}\")\n",
    "logger.info(f\"    TF-IDF features: {len(tfidf_feature_names)}\")\n",
    "logger.info(f\"    LDA features: {len(lda_feature_names)}\")  \n",
    "logger.info(f\"    Compound features: {len(compound_feature_names)}\")\n",
    "\n",
    "def align_scores_robust(scores, current_features, target_features):\n",
    "    \n",
    "    #Enhanced alignment with dimension safety checks and detailed error handling.\n",
    "    \n",
    "    if not target_features:\n",
    "        return np.array([]).reshape(scores.shape[0], 0)\n",
    "    \n",
    "    # SAFETY CHECK: Verify dimensions match expectations\n",
    "    expected_cols = len(current_features)\n",
    "    actual_cols = scores.shape[1]\n",
    "    \n",
    "    if expected_cols != actual_cols:\n",
    "        print(f\"⚠️  DIMENSION MISMATCH DETECTED:\")\n",
    "        print(f\"    Expected columns: {expected_cols} (from feature names)\")\n",
    "        print(f\"    Actual columns: {actual_cols} (from score matrix)\")\n",
    "        print(f\"    Using actual matrix dimensions for safety\")\n",
    "        \n",
    "        # Use only the features that actually exist in the matrix\n",
    "        safe_current_features = current_features[:actual_cols]\n",
    "        print(f\"    Truncated feature list: {len(safe_current_features)} features\")\n",
    "    else:\n",
    "        safe_current_features = current_features\n",
    "    \n",
    "    # Initialize aligned matrix with zeros\n",
    "    aligned_scores = np.zeros((scores.shape[0], len(target_features)))\n",
    "    current_to_idx = {feat: i for i, feat in enumerate(safe_current_features)}\n",
    "    \n",
    "    # Map existing features to aligned positions with bounds checking\n",
    "    found_features = 0\n",
    "    skipped_features = 0\n",
    "    \n",
    "    for j, feat in enumerate(target_features):\n",
    "        if feat in current_to_idx:\n",
    "            source_idx = current_to_idx[feat]\n",
    "            \n",
    "            # BOUNDS CHECK: Ensure source index is valid\n",
    "            if source_idx < scores.shape[1]:\n",
    "                aligned_scores[:, j] = scores[:, source_idx]\n",
    "                found_features += 1\n",
    "            else:\n",
    "                print(f\"⚠️  Skipping feature '{feat}': index {source_idx} >= {scores.shape[1]}\")\n",
    "                skipped_features += 1\n",
    "    \n",
    "    print(f\"    ✓ Aligned {found_features}/{len(target_features)} features\")\n",
    "    if skipped_features > 0:\n",
    "        print(f\"    ⚠️  Skipped {skipped_features} features due to bounds issues\")\n",
    "    \n",
    "    return aligned_scores\n",
    "\n",
    "\n",
    "# Align all scoring matrices to the unified feature space\n",
    "tfidf_aligned = align_scores_robust(tfidf_scores, tfidf_feature_names, all_features)\n",
    "lda_aligned = align_scores_robust(lda_scores, lda_feature_names, all_features)\n",
    "compound_aligned = align_scores_robust(compound_scores, compound_feature_names, all_features)\n",
    "\n",
    "logger.info(f\"✓ Feature alignment complete: {tfidf_aligned.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 5: SCORE NORMALIZATION AND CONSOLIDATION\n",
    "# =============================================================================\n",
    "logger.info(\"Step 5: Normalizing scores and applying variant consolidation...\")\n",
    "\n",
    "def normalize_scores(scores):\n",
    "    #Normalize scores to  range per matrix for fair weighting.[1]\n",
    "    if scores.max() == 0:\n",
    "        return scores\n",
    "    return scores / scores.max()\n",
    "\n",
    "# Normalize each scoring matrix to ensure fair contribution to final scores\n",
    "tfidf_normalized = normalize_scores(tfidf_aligned)\n",
    "lda_normalized = normalize_scores(lda_aligned)\n",
    "compound_normalized = normalize_scores(compound_aligned)\n",
    "\n",
    "# Combine normalized scores using weighted average\n",
    "combined_scores = (\n",
    "    TFIDF_WEIGHT * tfidf_normalized + \n",
    "    LDA_WEIGHT * lda_normalized + \n",
    "    COMPOUND_WEIGHT * compound_normalized\n",
    ")\n",
    "\n",
    "logger.info(f\"✓ Score combination complete: {combined_scores.shape}\")\n",
    "logger.info(f\"  Combined score range: [{combined_scores.min():.4f}, {combined_scores.max():.4f}]\")\n",
    "\n",
    "# Apply variant consolidation to prevent double-counting\n",
    "if variant_to_canonical:\n",
    "    logger.info(\"  Applying variant score consolidation to prevent double-counting...\")\n",
    "    \n",
    "    # Consolidate variant scores using maximum (not sum) to avoid inflating scores\n",
    "    final_scores, canonical_methods = consolidate_variant_scores(\n",
    "        combined_scores, all_features, variant_to_canonical\n",
    "    )\n",
    "    logger.info(f\"  ✓ Consolidated {len(all_features)} methods to {len(canonical_methods)} canonical methods\")\n",
    "    \n",
    "    # Display consolidation statistics\n",
    "    print(f\"\\n🔍 Score Consolidation Check:\")\n",
    "    print(f\"  Methods before consolidation: {len(all_features)}\")\n",
    "    print(f\"  Methods after consolidation: {len(canonical_methods)}\")\n",
    "    print(f\"  Consolidation prevented potential double-counting of {len(all_features) - len(canonical_methods)} method variants\")\n",
    "    \n",
    "else:\n",
    "    # No consolidation needed - use combined scores as-is\n",
    "    final_scores = combined_scores\n",
    "    canonical_methods = all_features\n",
    "    logger.info(\"  No variant consolidation applied (no variant mappings found)\")\n",
    "\n",
    "logger.info(f\"✓ Final consolidated scores: {final_scores.shape}\")\n",
    "logger.info(f\"  Final score range: [{final_scores.min():.4f}, {final_scores.max():.4f}]\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 6: METHOD ASSIGNMENT TO PAPERS\n",
    "# =============================================================================\n",
    "logger.info(\"Step 6: Assigning methods to papers using consolidated scores...\")\n",
    "\n",
    "# Assign top methods to each paper using the consolidated scores\n",
    "# This creates columns Method_1, Method_2, etc. plus Primary_Method\n",
    "df = assign_methods_improved(\n",
    "    df, final_scores, canonical_methods, \n",
    "    top_n=TOP_METHODS_PER_PAPER, \n",
    "    min_score=MIN_ASSIGN_SCORE\n",
    ")\n",
    "\n",
    "# Additional diagnostic: Verify no double-counting occurred\n",
    "assigned_methods = df[df['Primary_Method'] != '']['Primary_Method'].tolist()\n",
    "method_assignment_counts = pd.Series(assigned_methods).value_counts()\n",
    "\n",
    "print(f\"\\n🔍 Final Assignment Verification:\")\n",
    "print(f\"  Papers assigned methods: {len(assigned_methods)}\")\n",
    "print(f\"  Unique methods assigned: {len(method_assignment_counts)}\")\n",
    "print(f\"  Top assigned methods:\")\n",
    "\n",
    "for method, count in method_assignment_counts.head(10).items():\n",
    "    # Check if this method has variants that were consolidated\n",
    "    variants = canonical_to_variants.get(method, [method])\n",
    "    if len(variants) > 1:\n",
    "        print(f\"    {method}: {count} papers (consolidated from: {variants})\")\n",
    "    else:\n",
    "        print(f\"    {method}: {count} papers\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 7: SAVE RESULTS AND METADATA\n",
    "# =============================================================================\n",
    "logger.info(\"Step 7: Saving results and metadata...\")\n",
    "\n",
    "# Save method variant mappings for future reference and transparency\n",
    "with open(os.path.join(SAVE_DIR, f\"method_variant_groups_{suffix_string}.json\"), 'w') as f:\n",
    "    json.dump(canonical_to_variants, f, indent=2)\n",
    "\n",
    "# Save consolidated score matrix for analysis and debugging\n",
    "pd.DataFrame(final_scores, columns=canonical_methods).to_csv(\n",
    "    os.path.join(SAVE_DIR, f\"consolidated_method_scores_{suffix_string}.csv\")\n",
    ")\n",
    "\n",
    "# Save final enhanced dataframe with method assignments\n",
    "enhanced_analysis_filename = f\"enhanced_method_analysis_{suffix_string}.csv\"\n",
    "df.to_csv(os.path.join(SAVE_DIR, enhanced_analysis_filename), index=False)\n",
    "\n",
    "logger.info(f\"✓ Results saved:\")\n",
    "logger.info(f\"  Enhanced analysis: {enhanced_analysis_filename}\")\n",
    "logger.info(f\"  Method variant groups: method_variant_groups_{suffix_string}.json\")\n",
    "logger.info(f\"  Consolidated scores: consolidated_method_scores_{suffix_string}.csv\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 8: COMPREHENSIVE DIAGNOSTICS AND QUALITY ASSESSMENT\n",
    "# =============================================================================\n",
    "logger.info(\"Step 8: Running comprehensive diagnostics...\")\n",
    "\n",
    "def enhanced_method_diagnostics(df, scores, method_names, variant_groups):\n",
    "    \n",
    "    #Comprehensive diagnostics for method assignment quality and consolidation effectiveness.\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPREHENSIVE METHOD DETECTION DIAGNOSTICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Basic assignment statistics\n",
    "    n_papers = len(df)\n",
    "    assigned_papers = (df['Primary_Method'] != '').sum()\n",
    "    assignment_rate = 100 * assigned_papers / n_papers\n",
    "    \n",
    "    print(f\"\\n📊 ASSIGNMENT OVERVIEW:\")\n",
    "    print(f\"  Total papers processed: {n_papers:,}\")\n",
    "    print(f\"  Papers with methods assigned: {assigned_papers:,} ({assignment_rate:.1f}%)\")\n",
    "    print(f\"  Papers without methods: {n_papers - assigned_papers:,} ({100-assignment_rate:.1f}%)\")\n",
    "    \n",
    "    # Score distribution analysis\n",
    "    print(f\"\\n📈 SCORE DISTRIBUTION ANALYSIS:\")\n",
    "    print(f\"  Final score matrix shape: {scores.shape}\")\n",
    "    print(f\"  Total canonical methods: {len(method_names)}\")\n",
    "    print(f\"  Score range: [{scores.min():.4f}, {scores.max():.4f}]\")\n",
    "    print(f\"  Mean score: {scores.mean():.4f}\")\n",
    "    print(f\"  Standard deviation: {scores.std():.4f}\")\n",
    "    \n",
    "    # Score threshold analysis\n",
    "    thresholds = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "    for threshold in thresholds:\n",
    "        count = (scores > threshold).sum()\n",
    "        print(f\"  Scores > {threshold}: {count:,} ({100*count/scores.size:.2f}% of all scores)\")\n",
    "    \n",
    "    # Method popularity and assignment quality\n",
    "    if assigned_papers > 0:\n",
    "        print(f\"\\n🔥 TOP ASSIGNED METHODS:\")\n",
    "        method_counts = df['Primary_Method'].value_counts()\n",
    "        \n",
    "        for i, (method, count) in enumerate(method_counts.head(15).items()):\n",
    "            if method:  # Skip empty strings\n",
    "                percentage = 100 * count / assigned_papers\n",
    "                # Check if method was consolidated from variants\n",
    "                variants = variant_groups.get(method, [method])\n",
    "                variant_info = f\" (from {len(variants)} variants)\" if len(variants) > 1 else \"\"\n",
    "                print(f\"  {i+1:2d}. {method}: {count:,} papers ({percentage:.1f}%){variant_info}\")\n",
    "    \n",
    "    # Confidence distribution analysis\n",
    "    if 'Method_Confidence' in df.columns:\n",
    "        print(f\"\\n🎯 CONFIDENCE DISTRIBUTION:\")\n",
    "        conf_counts = df['Method_Confidence'].value_counts()\n",
    "        for conf, count in conf_counts.items():\n",
    "            percentage = 100 * count / n_papers\n",
    "            print(f\"  {conf}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Consolidation effectiveness analysis\n",
    "    print(f\"\\n🔧 CONSOLIDATION EFFECTIVENESS:\")\n",
    "    total_variants = sum(len(variants) for variants in variant_groups.values())\n",
    "    consolidated_groups = len([v for v in variant_groups.values() if len(v) > 1])\n",
    "    \n",
    "    print(f\"  Total method variants processed: {total_variants:,}\")\n",
    "    print(f\"  Final canonical methods: {len(variant_groups):,}\")\n",
    "    print(f\"  Groups with multiple variants: {consolidated_groups:,}\")\n",
    "    print(f\"  Consolidation ratio: {total_variants/len(variant_groups):.2f}:1\")\n",
    "    \n",
    "    # Quality assessment and recommendations\n",
    "    print(f\"\\n⚠️  QUALITY ASSESSMENT:\")\n",
    "    \n",
    "    if assignment_rate < 50:\n",
    "        print(f\"  ⚠️  Low assignment rate ({assignment_rate:.1f}%) - consider:\")\n",
    "        print(f\"      -  Lowering MIN_ASSIGN_SCORE (current: {MIN_ASSIGN_SCORE})\")\n",
    "        print(f\"      -  Reviewing method extraction quality\")\n",
    "        print(f\"      -  Checking text preprocessing effectiveness\")\n",
    "    else:\n",
    "        print(f\"  ✅ Good assignment rate ({assignment_rate:.1f}%)\")\n",
    "    \n",
    "    if scores.max() < 0.1:\n",
    "        print(f\"  ⚠️  Low maximum scores ({scores.max():.4f}) - scoring method may need adjustment\")\n",
    "    else:\n",
    "        print(f\"  ✅ Reasonable maximum scores ({scores.max():.4f})\")\n",
    "    \n",
    "    zero_score_methods = (scores.max(axis=0) == 0).sum()\n",
    "    if zero_score_methods > 0:\n",
    "        zero_percentage = 100 * zero_score_methods / len(method_names)\n",
    "        print(f\"  ⚠️  {zero_score_methods} methods ({zero_percentage:.1f}%) have zero scores across all papers\")\n",
    "        print(f\"      Consider reviewing method extraction or scoring parameters\")\n",
    "    else:\n",
    "        print(f\"  ✅ All methods have non-zero scores in at least some papers\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    return {\n",
    "        'assignment_rate': assignment_rate,\n",
    "        'total_papers': n_papers,\n",
    "        'assigned_papers': assigned_papers,\n",
    "        'score_stats': {\n",
    "            'min': scores.min(),\n",
    "            'max': scores.max(),\n",
    "            'mean': scores.mean(),\n",
    "            'std': scores.std()\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Run comprehensive diagnostics\n",
    "diagnostic_results = enhanced_method_diagnostics(df, final_scores, canonical_methods, canonical_to_variants)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 9: DISPLAY SAMPLE RESULTS FOR VERIFICATION\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE RESULTS FOR VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define columns to display in sample results\n",
    "sample_cols = ['Primary_Method', 'Primary_Method_Score', 'Method_Confidence', 'Total_Method_Score']\n",
    "available_cols = [col for col in sample_cols if col in df.columns]\n",
    "\n",
    "# Show sample of papers WITH methods assigned\n",
    "assigned_mask = df['Primary_Method'] != ''\n",
    "if assigned_mask.sum() > 0:\n",
    "    print(f\"\\n📄 SAMPLE PAPERS WITH METHODS ASSIGNED (first 10):\")\n",
    "    sample_assigned = df[assigned_mask][available_cols].head(10)\n",
    "    print(sample_assigned.to_string(index=False))\n",
    "    \n",
    "    # Show distribution of assigned methods\n",
    "    print(f\"\\n📊 METHOD ASSIGNMENT DISTRIBUTION:\")\n",
    "    for i in range(1, min(4, TOP_METHODS_PER_PAPER + 1)):  # Show top 3 method columns\n",
    "        col_name = f'Method_{i}'\n",
    "        if col_name in df.columns:\n",
    "            non_empty = df[df[col_name] != ''][col_name].value_counts()\n",
    "            print(f\"  {col_name} - {len(non_empty)} unique methods assigned to {non_empty.sum()} papers\")\n",
    "\n",
    "# Show sample of papers WITHOUT methods for diagnostic purposes\n",
    "unassigned_mask = df['Primary_Method'] == ''\n",
    "if unassigned_mask.sum() > 0:\n",
    "    print(f\"\\n❌ SAMPLE PAPERS WITHOUT METHODS (first 5 for diagnostic):\")\n",
    "    unassigned_sample = df[unassigned_mask].head(5)\n",
    "    \n",
    "    if 'processed_text' in df.columns:\n",
    "        for idx, row in unassigned_sample.iterrows():\n",
    "            text_preview = row.get('processed_text', '')[:150] + \"...\" if len(str(row.get('processed_text', ''))) > 150 else row.get('processed_text', '')\n",
    "            print(f\"  Paper {idx}: {text_preview}\")\n",
    "\n",
    "# Final completion message\n",
    "print(f\"\\n✅ Enhanced Method Detection Pipeline Completed Successfully!\")\n",
    "print(f\"📁 All results saved to: {SAVE_DIR}\")\n",
    "print(f\"📊 Assignment Rate: {diagnostic_results['assignment_rate']:.1f}%\")\n",
    "print(f\"🔧 Methods Consolidated: {len(method_phrases) if method_phrases else 0} → {len(canonical_methods)}\")\n",
    "\n",
    "logger.info(\"Enhanced method detection pipeline with consolidation completed successfully!\")\n",
    "logger.info(f\"Credit usage: {credit_tracker.get_stats()}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94e9db32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🔍 METHOD CONSOLIDATION VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "📊 COUNTS:\n",
      "  Original methods: 168\n",
      "  Canonical groups: 97\n",
      "  Assigned methods: 92\n",
      "\n",
      "✅ SUCCESS: All assigned methods are canonical groups\n",
      "\n",
      "✅ SUCCESS: No redundant methods in assignments\n",
      "\n",
      "🔍 CONSOLIDATION EXAMPLES:\n",
      "  'total harmonic distortion thd' consolidated: ['total harmonic distortion thd', 'total harmonic distortion']\n",
      "  'deep reinforcement learning drl' consolidated: ['reinforcement learning drl', 'deep reinforcement learning drl']\n",
      "  'loss of load probability' consolidated: ['lolp', 'loss of load probability']\n",
      "  'system average interruption duration index' consolidated: ['system average interruption duration index', 'caidi']\n",
      "  'monte carlo simulation' consolidated: ['monte carlo simulation', 'monte-carlo simulation']\n",
      "\n",
      "📈 TOP ASSIGNED METHODS (canonical):\n",
      "   1. successive interference cancellation: 20787 papers\n",
      "   2. model analysis: 755 papers\n",
      "   3. artificial neural network: 614 papers (from 4 variants)\n",
      "   4. monte carlo simulation: 443 papers (from 2 variants)\n",
      "   5. particle swarm optimization: 430 papers (from 4 variants)\n",
      "   6. genetic algorithm ga: 389 papers (from 2 variants)\n",
      "   7. capacity ratio: 381 papers\n",
      "   8. optimal utilization: 313 papers\n",
      "   9. sensitivity analysis: 257 papers\n",
      "  10. load frequency: 229 papers\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def verify_method_consolidation(df, canonical_to_variants, original_method_list):\n",
    "    \"\"\"\n",
    "    Comprehensive verification that consolidation worked properly.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"🔍 METHOD CONSOLIDATION VERIFICATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Extract assigned methods from DataFrame\n",
    "    assigned_methods = set(df[df['Primary_Method'] != '']['Primary_Method'].unique())\n",
    "    \n",
    "    # Extract canonical methods from groups\n",
    "    canonical_methods = set(canonical_to_variants.keys()) \n",
    "    \n",
    "    # Extract all original methods (for comparison)\n",
    "    original_methods = set(original_method_list)\n",
    "    \n",
    "    print(f\"\\n📊 COUNTS:\")\n",
    "    print(f\"  Original methods: {len(original_methods)}\")\n",
    "    print(f\"  Canonical groups: {len(canonical_methods)}\")\n",
    "    print(f\"  Assigned methods: {len(assigned_methods)}\")\n",
    "    \n",
    "    # Check 1: Are assigned methods from canonical set?\n",
    "    non_canonical_assigned = assigned_methods - canonical_methods\n",
    "    if non_canonical_assigned:\n",
    "        print(f\"\\n❌ PROBLEM: {len(non_canonical_assigned)} assigned methods are NOT canonical:\")\n",
    "        for method in list(non_canonical_assigned)[:10]:\n",
    "            print(f\"    '{method}'\")\n",
    "    else:\n",
    "        print(f\"\\n✅ SUCCESS: All assigned methods are canonical groups\")\n",
    "    \n",
    "    # Check 2: Are any original redundant methods still assigned?\n",
    "    all_variants = set()\n",
    "    for variants in canonical_to_variants.values():\n",
    "        all_variants.update(variants)\n",
    "    \n",
    "    redundant_assigned = assigned_methods & (original_methods - canonical_methods)\n",
    "    if redundant_assigned:\n",
    "        print(f\"\\n❌ PROBLEM: {len(redundant_assigned)} redundant methods still assigned:\")\n",
    "        for method in list(redundant_assigned)[:10]:\n",
    "            print(f\"    '{method}' (should be consolidated)\")\n",
    "    else:\n",
    "        print(f\"\\n✅ SUCCESS: No redundant methods in assignments\")\n",
    "    \n",
    "    # Check 3: Show consolidation examples\n",
    "    print(f\"\\n🔍 CONSOLIDATION EXAMPLES:\")\n",
    "    consolidation_examples = 0\n",
    "    for canonical, variants in canonical_to_variants.items():\n",
    "        if len(variants) > 1 and canonical in assigned_methods:\n",
    "            print(f\"  '{canonical}' consolidated: {variants}\")\n",
    "            consolidation_examples += 1\n",
    "            if consolidation_examples >= 5:\n",
    "                break\n",
    "    \n",
    "    # Check 4: Show assignment distribution\n",
    "    print(f\"\\n📈 TOP ASSIGNED METHODS (canonical):\")\n",
    "    method_counts = df[df['Primary_Method'] != '']['Primary_Method'].value_counts()\n",
    "    for i, (method, count) in enumerate(method_counts.head(10).items()):\n",
    "        variants = canonical_to_variants.get(method, [method])\n",
    "        variant_info = f\" (from {len(variants)} variants)\" if len(variants) > 1 else \"\"\n",
    "        print(f\"  {i+1:2d}. {method}: {count} papers{variant_info}\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    return len(non_canonical_assigned) == 0 and len(redundant_assigned) == 0\n",
    "\n",
    "# Run verification\n",
    "verification_passed = verify_method_consolidation(df, canonical_to_variants, method_phrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbbd873c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 SPOT CHECK: Sample Paper Method Assignments\n",
      "------------------------------------------------------------\n",
      "\n",
      "Paper 0:\n",
      "  Assigned Method: 'successive interference cancellation'\n",
      "  Score: 0.0032384690873405292\n",
      "  Variants in Group: ['successive interference cancellation']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 1:\n",
      "  Assigned Method: 'successive interference cancellation'\n",
      "  Score: 0.0032384690873405292\n",
      "  Variants in Group: ['successive interference cancellation']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 2:\n",
      "  Assigned Method: 'load frequency'\n",
      "  Score: 0.7\n",
      "  Variants in Group: ['load frequency']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 3:\n",
      "  Assigned Method: 'successive interference cancellation'\n",
      "  Score: 0.0032384690873405292\n",
      "  Variants in Group: ['successive interference cancellation']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 4:\n",
      "  Assigned Method: 'successive interference cancellation'\n",
      "  Score: 0.0032384690873405292\n",
      "  Variants in Group: ['successive interference cancellation']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 5:\n",
      "  Assigned Method: 'successive interference cancellation'\n",
      "  Score: 0.0032384690873405292\n",
      "  Variants in Group: ['successive interference cancellation']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 6:\n",
      "  Assigned Method: 'successive interference cancellation'\n",
      "  Score: 0.0032384690873405292\n",
      "  Variants in Group: ['successive interference cancellation']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 7:\n",
      "  Assigned Method: 'capacity ratio'\n",
      "  Score: 0.14323846670315474\n",
      "  Variants in Group: ['capacity ratio']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 8:\n",
      "  Assigned Method: 'successive interference cancellation'\n",
      "  Score: 0.0032384690873405292\n",
      "  Variants in Group: ['successive interference cancellation']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 9:\n",
      "  Assigned Method: 'successive interference cancellation'\n",
      "  Score: 0.0032384690873405292\n",
      "  Variants in Group: ['successive interference cancellation']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n"
     ]
    }
   ],
   "source": [
    "def spot_check_paper_assignments(df, canonical_to_variants, n_samples=10):\n",
    "    \"\"\"\n",
    "    Show sample paper assignments with their consolidated method info.\n",
    "    \"\"\"\n",
    "    print(\"🔍 SPOT CHECK: Sample Paper Method Assignments\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Get papers with assigned methods\n",
    "    assigned_papers = df[df['Primary_Method'] != ''].head(n_samples)\n",
    "    \n",
    "    for idx, row in assigned_papers.iterrows():\n",
    "        primary_method = row['Primary_Method']\n",
    "        score = row.get('Primary_Method_Score', 'N/A')\n",
    "        \n",
    "        # Check if this method has variants\n",
    "        variants = canonical_to_variants.get(primary_method, [primary_method])\n",
    "        \n",
    "        print(f\"\\nPaper {idx}:\")\n",
    "        print(f\"  Assigned Method: '{primary_method}'\")\n",
    "        print(f\"  Score: {score}\")\n",
    "        print(f\"  Variants in Group: {variants}\")\n",
    "        print(f\"  Group Size: {len(variants)} methods\")\n",
    "        \n",
    "        # Show if consolidation occurred\n",
    "        if len(variants) > 1:\n",
    "            print(f\"  ✅ CONSOLIDATED: {len(variants)-1} variants merged\")\n",
    "        else:\n",
    "            print(f\"  ℹ️  INDIVIDUAL: No variants to consolidate\")\n",
    "\n",
    "# Run spot check\n",
    "spot_check_paper_assignments(df, canonical_to_variants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "145252da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 SCORE MATRIX VERIFICATION\n",
      "----------------------------------------\n",
      "Score matrix shape: (28934, 97)\n",
      "Canonical methods count: 97\n",
      "✅ Score matrix columns match canonical method count\n",
      "\n",
      "First 10 canonical methods in score matrix:\n",
      "   0. ant colony optimization\n",
      "   1. gauss-seidel load flow\n",
      "   2. phasor measurement\n",
      "   3. alternating direction method of multipliers\n",
      "   4. hosting capacity assesment\n",
      "   5. mpp\n",
      "   6. loss of load probability\n",
      "   7. security-constrained economic dispatch\n",
      "   8. dynamic programming\n",
      "   9. system average interruption duration index\n"
     ]
    }
   ],
   "source": [
    "def verify_score_matrix_methods(canonical_methods, final_scores):\n",
    "    \"\"\"\n",
    "    Check that the final score matrix columns correspond to canonical methods.\n",
    "    \"\"\"\n",
    "    print(\"🔍 SCORE MATRIX VERIFICATION\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    print(f\"Score matrix shape: {final_scores.shape}\")\n",
    "    print(f\"Canonical methods count: {len(canonical_methods)}\")\n",
    "    \n",
    "    if final_scores.shape[1] == len(canonical_methods):\n",
    "        print(\"✅ Score matrix columns match canonical method count\")\n",
    "    else:\n",
    "        print(\"❌ Dimension mismatch between scores and canonical methods\")\n",
    "    \n",
    "    print(f\"\\nFirst 10 canonical methods in score matrix:\")\n",
    "    for i, method in enumerate(canonical_methods[:10]):\n",
    "        print(f\"  {i:2d}. {method}\")\n",
    "\n",
    "# Run verification  \n",
    "verify_score_matrix_methods(canonical_methods, final_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0ad7acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 BEFORE/AFTER CONSOLIDATION COMPARISON\n",
      "================================================================================\n",
      "BEFORE: 168 original methods\n",
      "AFTER:  97 canonical groups\n",
      "REDUCTION: 71 methods (42.3%)\n",
      "\n",
      "📋 CONSOLIDATION EXAMPLES:\n",
      "\n",
      "  GROUP: 'total harmonic distortion thd'\n",
      "    Consolidated: ['total harmonic distortion thd', 'total harmonic distortion']\n",
      "\n",
      "  GROUP: 'deep reinforcement learning drl'\n",
      "    Consolidated: ['reinforcement learning drl', 'deep reinforcement learning drl']\n",
      "\n",
      "  GROUP: 'loss of load probability'\n",
      "    Consolidated: ['lolp', 'loss of load probability']\n",
      "\n",
      "  GROUP: 'system average interruption duration index'\n",
      "    Consolidated: ['system average interruption duration index', 'caidi']\n",
      "\n",
      "  GROUP: 'monte carlo simulation'\n",
      "    Consolidated: ['monte carlo simulation', 'monte-carlo simulation']\n",
      "\n",
      "  GROUP: 'system average interruption frequency index'\n",
      "    Consolidated: ['saifi', 'system average interruption frequency index']\n",
      "\n",
      "  GROUP: 'particle swarm optimization'\n",
      "    Consolidated: ['particle swarm optimization', 'pso algorithm', 'optimization pso algorithm', 'particle swarm algorithm']\n",
      "\n",
      "  GROUP: 'mixed integer linear programming'\n",
      "    Consolidated: ['mixed-integer linear', 'mixed integer linear programming']\n",
      "\n",
      "📊 SUMMARY:\n",
      "  Groups with multiple variants: 25\n",
      "  Single-method groups: 72\n"
     ]
    }
   ],
   "source": [
    "def show_before_after_comparison(original_methods, canonical_to_variants):\n",
    "    \"\"\"\n",
    "    Show before/after consolidation comparison.\n",
    "    \"\"\"\n",
    "    print(\"🔄 BEFORE/AFTER CONSOLIDATION COMPARISON\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"BEFORE: {len(original_methods)} original methods\")\n",
    "    print(f\"AFTER:  {len(canonical_to_variants)} canonical groups\")\n",
    "    reduction = len(original_methods) - len(canonical_to_variants)\n",
    "    reduction_pct = 100 * reduction / len(original_methods)\n",
    "    print(f\"REDUCTION: {reduction} methods ({reduction_pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n📋 CONSOLIDATION EXAMPLES:\")\n",
    "    consolidation_count = 0\n",
    "    for canonical, variants in canonical_to_variants.items():\n",
    "        if len(variants) > 1:\n",
    "            print(f\"\\n  GROUP: '{canonical}'\")\n",
    "            print(f\"    Consolidated: {variants}\")\n",
    "            consolidation_count += 1\n",
    "            if consolidation_count >= 8:\n",
    "                break\n",
    "    \n",
    "    print(f\"\\n📊 SUMMARY:\")\n",
    "    multi_variant_groups = sum(1 for v in canonical_to_variants.values() if len(v) > 1)\n",
    "    print(f\"  Groups with multiple variants: {multi_variant_groups}\")\n",
    "    print(f\"  Single-method groups: {len(canonical_to_variants) - multi_variant_groups}\")\n",
    "\n",
    "# Run comparison\n",
    "show_before_after_comparison(method_phrases, canonical_to_variants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b7de75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ant colony optimization\n",
      "gauss-seidel load flow\n",
      "phasor measurement\n",
      "alternating direction method of multipliers\n",
      "total harmonic distortion\n",
      "mpp\n",
      "reinforcement learning drl\n",
      "hosting capacity assesment\n",
      "loss of load probability\n",
      "security-constrained economic dispatch\n",
      "dynamic programming\n",
      "system average interruption duration index\n",
      "nonlinear programming\n",
      "monte-carlo simulation\n",
      "discrete wavelet\n",
      "saifi\n",
      "capacity ratio\n",
      "long short-term memory\n",
      "tabu search\n",
      "particle swarm algorithm\n",
      "optimal utilization\n",
      "monte carlo simulation\n",
      "demand response dr\n",
      "caidi\n",
      "economic dispatch\n",
      "latin hypercube sampling\n",
      "swarm optimization pso algorithm\n",
      "fast decoupled power flow\n",
      "dynamic voltage restorer\n",
      "sliding mode control\n",
      "regression model\n",
      "mixed-integer linear\n",
      "support vector machine\n",
      "stochastic programming\n",
      "optimal power flow\n",
      "generation shift factors\n",
      "linear regression\n",
      "time series analysis\n",
      "optimization pso algorithm\n",
      "wide area measurement system\n",
      "mean time to failure\n",
      "arima\n",
      "mean time between failures\n",
      "load frequency control\n",
      "lodf\n",
      "multi-carrier\n",
      "mttr\n",
      "wams\n",
      "phasor measurement unit\n",
      "neural network\n",
      "model predictive control mpc\n",
      "scuc\n",
      "second order reliability method\n",
      "security-constrained unit commitment\n",
      "interior point method\n",
      "pso algorithm\n",
      "markov chain monte carlo\n",
      "probabilistic reliability\n",
      "hierarchical level ii\n",
      "state estimation\n",
      "simulated annealing\n",
      "non-orthogonal multiple access noma\n",
      "fuzzy control\n",
      "particle swarm optimization\n",
      "otdf\n",
      "multi-objective optimization model\n",
      "incremental conductance\n",
      "particle swarm optimization algorithm\n",
      "successive interference cancellation\n",
      "sced\n",
      "outage transfer distribution factors\n",
      "two-step stochastic\n",
      "capacity outage probability table\n",
      "garch\n",
      "mttf\n",
      "capacity outage probability density\n",
      "point estimate method\n",
      "sdn\n",
      "sensitivity analysis\n",
      "anfis\n",
      "deep reinforcement learning\n",
      "optimal dispatch\n",
      "cost-benefit analysis\n",
      "multi-functional\n",
      "multi-layer\n",
      "injection shift factors\n",
      "decision tree\n",
      "generalized autoregressive conditional heteroskedasticity\n",
      "kalman filter\n",
      "first order reliability method\n",
      "support vector regression\n",
      "multi-input multi-output\n",
      "dynamic condition\n",
      "stochastic optimization\n",
      "firefly algorithm\n",
      "system average interruption frequency index\n",
      "short-term load forecasting\n",
      "newton-raphson load flow\n",
      "neural network cnn\n",
      "random forest\n",
      "wavelet transform\n",
      "multi-input multiple output\n",
      "fault tree analysis\n",
      "fault tree\n",
      "total harmonic distortion thd\n",
      "load frequency\n",
      "differential protection\n",
      "gated recurrent unit\n",
      "mcmc\n",
      "mean time to repair\n",
      "forecasting method\n",
      "customer average interruption duration index\n",
      "ptdf\n",
      "deep reinforcement learning drl\n",
      "q-learning\n",
      "vector autoregression\n",
      "dynamic reactive power\n",
      "optimal power flow opf\n",
      "svr\n",
      "security-constrained optimal power flow\n",
      "second order cone programming\n",
      "differential evolution\n",
      "sequential quadratic programming\n",
      "autoregressive integrated moving average\n",
      "saidi\n",
      "load flow analysis\n",
      "multi-hop\n",
      "mixed integer nonlinear programming\n",
      "mixed integer linear\n",
      "dynamic line rating\n",
      "adaptive neuro-fuzzy\n",
      "genetic algorithm\n",
      "capacity outage probability\n",
      "lole\n",
      "copt\n",
      "rate of occurrence of failures\n",
      "state-of-charge\n",
      "pmu\n",
      "unit commitment\n",
      "eens\n",
      "minlp\n",
      "dynamic voltage\n",
      "neural network ann\n",
      "support vector machine svm\n",
      "multiobjective optimization\n",
      "lolp\n",
      "load shifting\n",
      "monte-carlo\n",
      "scopf\n",
      "line outage distribution factor\n",
      "time-domain\n",
      "linear programming\n",
      "semidefinite programming\n",
      "mtbf\n",
      "model synthesis\n",
      "optimal power allocation\n",
      "k-means\n",
      "optimal transmission\n",
      "pem\n",
      "time-dependent\n",
      "principal component analysis\n",
      "multi-terminal\n",
      "integer linear programming\n",
      "genetic algorithm ga\n",
      "multi-phase\n",
      "quadratic programming\n",
      "hierarchical level iii\n",
      "model analysis\n"
     ]
    }
   ],
   "source": [
    "for n in method_phrases:\n",
    "    print(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "literature-search-and-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
