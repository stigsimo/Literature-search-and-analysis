{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33fc68ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 1: Imports and Setup\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import configparser\n",
    "import tiktoken\n",
    "import logging\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Phrases\n",
    "import openai\n",
    "from difflib import SequenceMatcher\n",
    "import itertools\n",
    "\n",
    "SAVE_DIR = \"Saved_files_new\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "156bf246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Cell 2: OpenAI Setup and Utility (Updated for gpt-5-nano)\n",
    "class CreditTracker:\n",
    "    def __init__(self):\n",
    "        self.total_tokens = 0\n",
    "        self.total_cost = 0\n",
    "        self.cost_per_1k_tokens = 0.00015\n",
    "    def update(self, tokens):\n",
    "        self.total_tokens += tokens\n",
    "        self.total_cost += (tokens / 1000) * self.cost_per_1k_tokens\n",
    "    def get_stats(self):\n",
    "        return {\"total_tokens\": self.total_tokens, \"total_cost\": round(self.total_cost, 4)}\n",
    "\n",
    "def initialize_openai():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config_LLM.txt')\n",
    "    api_key = config['LLM'].get('OPENAI_API_KEY')\n",
    "    model_type = config['LLM'].get('MODEL_TYPE')\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    return client, model_type\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"Get token count with fallback for unsupported models like gpt-5-nano\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model_name)\n",
    "        return len(encoding.encode(string))\n",
    "    except KeyError:\n",
    "        # Fallback for unsupported models like gpt-5-nano\n",
    "        if model_name.startswith('gpt-5-nano'):\n",
    "            # Use o200k_base encoding as fallback for gpt-5-nano\n",
    "            encoding = tiktoken.get_encoding(\"o200k_base\")\n",
    "            return len(encoding.encode(string))\n",
    "        else:\n",
    "            # For other unsupported models, use a reasonable approximation\n",
    "            return len(string) // 4  # Rough approximation: 4 chars per token\n",
    "\n",
    "client, model_type = initialize_openai()\n",
    "credit_tracker = CreditTracker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145755ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Cell 3: Data Preprocessing Utilities\n",
    "\n",
    "def extract_keywords_from_filename(filename):\n",
    "    base = os.path.splitext(os.path.basename(filename))[0]\n",
    "    parts = base.split('_')\n",
    "    return [part for i, part in enumerate(parts) if i > 2 and part != 'results' and not part.isdigit()]\n",
    "\n",
    "def get_custom_stop_words(search_keywords=None):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words_to_keep = set()\n",
    "    if search_keywords:\n",
    "        for keyword in search_keywords:\n",
    "            keyword = keyword.lower()\n",
    "            words_to_keep.add(keyword)\n",
    "            for word in keyword.split():\n",
    "                words_to_keep.add(word)\n",
    "    stop_words = stop_words - words_to_keep\n",
    "    scientific_terms = {'et', 'al', 'ref', 'reference', 'references', 'cited', 'cite',\n",
    "        'fig', 'figure', 'figures', 'table', 'tables', 'chart', 'charts',\n",
    "        'published', 'journal', 'conference', 'proceedings', 'vol', 'volume', 'pp', 'page', 'pages', 'doi'}\n",
    "    return stop_words.union(scientific_terms)\n",
    "\n",
    "def preprocess_text(text, search_keywords=None, min_word_length=2, remove_numbers=True):\n",
    "    if not isinstance(text, (str, int, float)):\n",
    "        return ''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    if remove_numbers:\n",
    "        # Define patterns to preserve (contingency analysis terms)\n",
    "        preserve_patterns = [\n",
    "            r'\\bn-\\d+\\b',           # N-1, N-2, N-3, etc.\n",
    "            r'\\b\\d+-\\d+\\b',         # patterns like 1-2, 2-3 (if needed)\n",
    "        ]\n",
    "        \n",
    "        # Store protected terms with temporary replacements\n",
    "        protected_terms = {}\n",
    "        temp_counter = 0\n",
    "        \n",
    "        for pattern in preserve_patterns:\n",
    "            matches = re.findall(pattern, text)\n",
    "            for match in set(matches):  # Remove duplicates\n",
    "                temp_placeholder = f\"__PROTECTED_{temp_counter}__\"\n",
    "                protected_terms[temp_placeholder] = match\n",
    "                text = text.replace(match, temp_placeholder)\n",
    "                temp_counter += 1\n",
    "        \n",
    "        # Now remove all remaining numbers\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        \n",
    "        # Restore protected terms\n",
    "        for placeholder, original_term in protected_terms.items():\n",
    "            text = text.replace(placeholder, original_term)\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "    text = re.sub(r'--+', ' ', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = get_custom_stop_words(search_keywords)\n",
    "    tokens = [t for t in tokens if len(t) >= min_word_length and t not in stop_words and len(t) > 1 and not t.isdigit()]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    try:\n",
    "        tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    except:\n",
    "        pass\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "\n",
    "def preprocess_dataframe(df, text_col, search_keywords, processed_col='processed_text'):\n",
    "    df[text_col] = df[text_col].fillna('').astype(str)\n",
    "    df[processed_col] = df[text_col].apply(lambda x: preprocess_text(x, search_keywords))\n",
    "    return df[df[processed_col].str.strip() != '']\n",
    "\n",
    "def clean_fields_of_study(s):\n",
    "    valid_fields = ['Computer Science', 'Economics', 'Engineering', 'Physics', 'Mathematics',\n",
    "        'Medicine','Business','Environmental Science','Chemistry','Materials Science',\n",
    "        'Geography','Biology','Geology','Political Science','Psychology','Com']\n",
    "    if pd.isna(s) or s == '[]':\n",
    "        return [\"Unknown\"]\n",
    "    if isinstance(s, str):\n",
    "        fields = [field.strip().strip(\"'\\\"\") for field in s.strip('[]').split(',')]\n",
    "        return [f if f in valid_fields else \"Unknown\" for f in fields] or [\"Unknown\"]\n",
    "    return [\"Unknown\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a22896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 10:01:30,620 - INFO - Loaded and preprocessed 30917 papers\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 4: Data Loading & Cleaning\n",
    "\n",
    "#filename = \"semantic_scholar_2025_02_14_reliability_resilience_power_systems_results.csv\"\n",
    "filename = \"semantic_scholar_2025_09_14_reliability_resilience_power_systems_results.csv\"\n",
    "filepath = os.path.join(\"Saved_files\", filename)\n",
    "df = pd.read_csv(filepath, sep=\";\")\n",
    "df['text'] = df['title'].fillna('') + ' ' + df['abstract'].fillna('')\n",
    "search_keywords = extract_keywords_from_filename(filename)\n",
    "df = preprocess_dataframe(df, text_col='text', search_keywords=search_keywords)\n",
    "df['fieldsOfStudy'] = df['fieldsOfStudy'].apply(clean_fields_of_study)\n",
    "logger.info(f\"Loaded and preprocessed {len(df)} papers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef6bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 5: Enhanced Method Detection Functions (COMPLETE CORRECTED VERSION)\n",
    "\n",
    "def extract_candidate_terms(df, text_col='processed_text', max_features=20000):\n",
    "    \"\"\"Extract candidate terms from processed text using CountVectorizer.\"\"\"\n",
    "    vectorizer = CountVectorizer(\n",
    "        ngram_range=(1, 4), max_df=0.95, min_df=2, max_features=max_features, token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "    matrix = vectorizer.fit_transform(df[text_col].fillna(''))\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    freqs = matrix.sum(axis=0).A1\n",
    "    return [term for term, freq in sorted(zip(terms, freqs), key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "def parse_llm_python_list(output_text):\n",
    "    \"\"\"Improved parsing function for LLM outputs\"\"\"\n",
    "    import re\n",
    "    import ast\n",
    "    \n",
    "    content = output_text.strip()\n",
    "    content = re.sub(r'```(?:python|json)?\\n?', '', content)# Remove code block markers\n",
    "    content = re.sub(r'```', '', content)# Remove closing code block markers\n",
    "    \n",
    "    list_patterns = [\n",
    "        r'\\[([^\\]]+)\\]',  # Standard list format\n",
    "        r'List:\\s*\\[([^\\]]+)\\]',  # List: [items]\n",
    "        r'Result:\\s*\\[([^\\]]+)\\]'  # Result: [items]\n",
    "    ]\n",
    "    \n",
    "    for pattern in list_patterns:\n",
    "        match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)\n",
    "        if match:\n",
    "            try:\n",
    "                return ast.literal_eval('[' + match.group(1) + ']')\n",
    "            except:\n",
    "                items = [item.strip().strip(\"'\\\"\") for item in match.group(1).split(',')]\n",
    "                return [item for item in items if item.strip()]\n",
    "    \n",
    "    lines = content.split('\\n')\n",
    "    items = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line and not line.startswith('#') and not line.startswith('//'): # Ignore comments\n",
    "            line = re.sub(r'^\\d+\\.?\\s*[-*]?\\s*', '', line) # Remove leading numbers/bullets\n",
    "            line = line.strip(\"'\\\"\") # Remove surrounding quotes\n",
    "            if line:\n",
    "                items.append(line)\n",
    "    \n",
    "    return items\n",
    "\n",
    "def get_method_phrases_enhanced(\n",
    "    corpus_terms, client, model_type, credit_tracker, prompt,\n",
    "    n_runs=3, temp=None, top_p=None, show_progress=True, batch_size=500\n",
    "):\n",
    "    \"\"\"Enhanced method extraction with configurable prompt.\"\"\"\n",
    "    import collections\n",
    "    from math import ceil\n",
    "\n",
    "    all_phrases_sets = []\n",
    "    n_batches = ceil(len(corpus_terms) / batch_size)\n",
    "    \n",
    "    for batch_idx in range(n_batches):\n",
    "        batch_terms = corpus_terms[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "\n",
    "        # Format the prompt with current batch terms\n",
    "        formatted_prompt = prompt.format(candidate_terms=batch_terms)\n",
    "\n",
    "        for i in range(n_runs):\n",
    "            try:\n",
    "                api_params = {\n",
    "                    \"model\": model_type,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"You are a comprehensive research method extraction expert. Your primary goal is maximum coverage of specific technical methods.\"},\n",
    "                        {\"role\": \"user\", \"content\": formatted_prompt}\n",
    "                    ],\n",
    "                }\n",
    "                if model_type.startswith('gpt-5-nano'):\n",
    "                    api_params[\"max_completion_tokens\"] = 8000\n",
    "                else:\n",
    "                    if temp is not None: api_params[\"temperature\"] = temp\n",
    "                    if top_p is not None: api_params[\"top_p\"] = top_p\n",
    "                    api_params[\"max_tokens\"] = 8000\n",
    "\n",
    "                response = client.chat.completions.create(**api_params)\n",
    "                content = response.choices[0].message.content # Extract content\n",
    "                phrases = parse_llm_python_list(content) # Extract list of phrases\n",
    "                phrases = [p.lower().strip() for p in phrases if p.strip() and len(p.strip()) > 2]# Filter short/empty \n",
    "                all_phrases_sets.append(set(phrases)) # Store as set to avoid duplicates\n",
    "                credit_tracker.update(num_tokens_from_string(content, model_type))\n",
    "                if show_progress:\n",
    "                    print(f\"BATCH {batch_idx+1}/{n_batches}, run {i+1}: found {len(phrases)}\")\n",
    "                    print(f\"  Sample: {phrases[:10]}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in LLM call for batch {batch_idx+1}, run {i+1}: {e}\")\n",
    "                all_phrases_sets.append(set())\n",
    "\n",
    "    all_flat = [p for s in all_phrases_sets for p in s] # Flatten and deduplicate\n",
    "    counts = collections.Counter(all_flat) # Count occurrences\n",
    "    sorted_methods = sorted(counts.keys(), key=lambda x: (-counts[x], x)) # Sort by frequency then alphabetically\n",
    "    print(f\"\\nTotal unique phrases: {len(counts)}\") \n",
    "    print(f\"Most frequent (top 10): {sorted_methods[:10]}\")\n",
    "    return sorted_methods, counts\n",
    "\n",
    "\n",
    "def filter_generic_phrases(phrases, min_specificity_words=2):\n",
    "    \"\"\"Remove generic phrases using comprehensive blacklist.\"\"\"\n",
    "    \n",
    "    # Comprehensive blacklist of generic terms\n",
    "    generic_blacklist = {\n",
    "        # Domain generic\n",
    "        'energy', 'power', 'system', 'network', 'control', 'data',\n",
    "        \n",
    "        # Method generic  \n",
    "        'analysis', 'method', 'approach', 'technique', 'procedure', \n",
    "        'framework', 'model', 'design', 'optimization', 'algorithm',\n",
    "        \n",
    "        # Process generic\n",
    "        'application', 'implementation', 'development', 'evaluation',\n",
    "        'assessment', 'review', 'study', 'research', 'investigation'\n",
    "    }\n",
    "    \n",
    "    # Patterns to exclude (domain + generic combinations)\n",
    "    generic_patterns = [\n",
    "        r'^(energy|power|system|network|electrical)\\s+(analysis|method|approach|design|optimization)$',\n",
    "        r'^(control|data|signal)\\s+(analysis|method|processing)$',\n",
    "        r'^(system|network)\\s+(optimization|design|analysis)$'\n",
    "    ]\n",
    "    \n",
    "    filtered_phrases = []\n",
    "    \n",
    "    for phrase in phrases:\n",
    "        phrase_lower = phrase.lower().strip()\n",
    "        words = phrase_lower.split()\n",
    "        \n",
    "        # Skip if too generic (most words are in blacklist) \n",
    "        generic_word_count = sum(1 for word in words if word in generic_blacklist) # Count generic words\n",
    "        if generic_word_count >= len(words) - min_specificity_words: # Allow up to two generic words\n",
    "            continue\n",
    "            \n",
    "        # Skip if matches generic patterns\n",
    "        if any(re.match(pattern, phrase_lower) for pattern in generic_patterns):\n",
    "            continue\n",
    "            \n",
    "        # Skip obvious generic combinations\n",
    "        if len(words) == 2 and all(word in generic_blacklist for word in words):\n",
    "            continue\n",
    "            \n",
    "        filtered_phrases.append(phrase)\n",
    "    \n",
    "    return filtered_phrases\n",
    "\n",
    "def load_method_phrases_from_csv(filename=\"extracted_method_phrases.csv\"):\n",
    "    \"\"\"Load method phrases from CSV with cleaning\"\"\"\n",
    "    try:\n",
    "        filepath = os.path.join(SAVE_DIR, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        method_phrases = df['Method Phrase'].tolist()\n",
    "        method_counts = df['Count'].tolist()\n",
    "        \n",
    "        # CRITICAL: Clean CSV artifacts before returning\n",
    "        method_phrases = prefilter_obvious_duplicates(method_phrases)\n",
    "        \n",
    "        # Rebuild counts for cleaned phrases (set to 1 if not available)\n",
    "        if len(method_counts) != len(method_phrases):\n",
    "            method_counts = [1] * len(method_phrases)\n",
    "            \n",
    "        return method_phrases, method_counts\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to load method phrases: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def validate_method_groups_enhanced(groups, original_batch):\n",
    "    \"\"\"Enhanced validation to catch problematic groupings.\"\"\"\n",
    "    validated_groups = {}\n",
    "    \n",
    "    # Define forbidden groupings (methods that should never be grouped)\n",
    "    forbidden_pairs = [\n",
    "        (\"linear programming\", \"nonlinear programming\"),\n",
    "        (\"first order\", \"second order\"), \n",
    "        (\"generation shift\", \"injection shift\"),\n",
    "        (\"lstm\", \"gru\"),\n",
    "        (\"genetic algorithm\", \"particle swarm\"),\n",
    "        (\"saifi\", \"saidi\"),  # Different reliability indices\n",
    "        (\"form\", \"sorm\"),    # Different reliability methods\n",
    "    ]\n",
    "    \n",
    "    for canonical, variants in groups.items():\n",
    "        # Check for forbidden groupings\n",
    "        valid_group = True\n",
    "        for forbidden in forbidden_pairs:\n",
    "            variants_text = \" \".join(variants).lower()\n",
    "            canonical_text = canonical.lower()\n",
    "            \n",
    "            if ((forbidden[0] in variants_text or forbidden[0] in canonical_text) and \n",
    "                (forbidden[1] in variants_text or forbidden[1] in canonical_text)):\n",
    "                valid_group = False\n",
    "                logger.warning(f\"Splitting forbidden grouping: {canonical}\")\n",
    "                break\n",
    "        \n",
    "        if valid_group:\n",
    "            # Ensure canonical is the longest/most descriptive term (not abbreviation)\n",
    "            full_forms = [v for v in variants if len(v) > 5 and ' ' in v]  # Prefer multi-word terms\n",
    "            if full_forms:\n",
    "                canonical = max(full_forms, key=len)\n",
    "            else:\n",
    "                canonical = max(variants, key=len)\n",
    "            \n",
    "            validated_groups[canonical] = variants\n",
    "        else:\n",
    "            # Split into individual methods\n",
    "            for variant in variants:\n",
    "                validated_groups[variant] = [variant]\n",
    "    \n",
    "    return validated_groups\n",
    "\n",
    "\n",
    "def save_method_phrases_to_csv(method_phrases, method_counts, filename=\"extracted_method_phrases.csv\"):\n",
    "    \"\"\"Save method phrases to CSV file.\"\"\"\n",
    "    filename = os.path.join(SAVE_DIR, filename)\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Method Phrase\", \"Count\"])\n",
    "        if hasattr(method_counts, 'items'):\n",
    "            for phrase, count in method_counts.items():\n",
    "                clean_phrase = phrase.strip().replace('\\n', ' ')\n",
    "                writer.writerow([clean_phrase, count])\n",
    "        else:\n",
    "            for phrase, count in zip(method_phrases, method_counts):\n",
    "                clean_phrase = phrase.strip().replace('\\n', ' ')\n",
    "                writer.writerow([clean_phrase, count])\n",
    "    print(f\"✓ Saved method phrases to {filename}\")\n",
    "\n",
    "\n",
    "def prefilter_obvious_duplicates(method_list, similarity_threshold=0.95):\n",
    "    \"\"\"Remove obvious near-duplicates before LLM processing to improve efficiency.\"\"\"\n",
    "    from difflib import SequenceMatcher\n",
    "    \n",
    "    filtered_methods = []\n",
    "    seen_methods = set()\n",
    "    \n",
    "    for method in sorted(method_list, key=len):  # Process shorter methods first\n",
    "        method_lower = method.lower().strip()\n",
    "        \n",
    "        is_duplicate = False\n",
    "        for seen in seen_methods:\n",
    "            similarity = SequenceMatcher(None, method_lower, seen).ratio()\n",
    "            if similarity >= similarity_threshold:\n",
    "                is_duplicate = True\n",
    "                break\n",
    "        \n",
    "        if not is_duplicate:\n",
    "            filtered_methods.append(method)\n",
    "            seen_methods.add(method_lower)\n",
    "    \n",
    "    print(f\"Pre-filtering: {len(method_list)} → {len(filtered_methods)} methods ({len(method_list) - len(filtered_methods)} obvious duplicates removed)\")\n",
    "    return filtered_methods\n",
    "\n",
    "def are_methods_truly_similar(method_variants):\n",
    "    \"\"\"Check if methods in a group are truly the same technique by analyzing core words.\"\"\"\n",
    "    if len(method_variants) <= 1:\n",
    "        return True\n",
    "    \n",
    "    # Extract core words (remove common qualifiers that indicate different techniques)\n",
    "    qualifiers = {'improved', 'enhanced', 'adaptive', 'advanced', 'modified', 'sequential', 'parallel', \n",
    "                 'distributed', 'hybrid', 'multi', 'bi', 'tri', 'sub', 'quasi'}\n",
    "    \n",
    "    core_words_sets = []\n",
    "    for method in method_variants:\n",
    "        words = set(method.lower().split())\n",
    "        core_words = words - qualifiers\n",
    "        core_words_sets.append(core_words)\n",
    "    \n",
    "    # Check if core words overlap significantly across all variants\n",
    "    if len(core_words_sets) < 2:\n",
    "        return True\n",
    "    \n",
    "    base_core = core_words_sets[0]  # FIXED: was incorrectly `core_words_sets`\n",
    "    for other_core in core_words_sets[1:]:\n",
    "        if not base_core or not other_core:  # Handle empty sets\n",
    "            continue\n",
    "        overlap = len(base_core & other_core) / len(base_core | other_core) if (base_core | other_core) else 0\n",
    "        if overlap < 0.7:  # Less than 70% overlap in core words\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\"\"\"def validate_method_groups(groups, original_batch):\n",
    "   #SIMPLIFIED validation that preserves LLM groupings\n",
    "    validated = {}\n",
    "    original_batch_lower = [m.lower() for m in original_batch]\n",
    "    \n",
    "    for canonical, variants in groups.items():\n",
    "        if not isinstance(variants, list):\n",
    "            variants = [variants]\n",
    "        \n",
    "        # Keep variants that exist in original batch (case insensitive)\n",
    "        clean_variants = []\n",
    "        for variant in variants:\n",
    "            variant_lower = str(variant).strip().lower()\n",
    "            if variant_lower in original_batch_lower:\n",
    "                # FIXED: Keep original casing from original_batch\n",
    "                original_idx = original_batch_lower.index(variant_lower)\n",
    "                clean_variants.append(original_batch[original_idx])\n",
    "        \n",
    "        if clean_variants:\n",
    "            # Use provided canonical name (don't change it)\n",
    "            canonical_clean = canonical.lower()  # Normalize casing only\n",
    "            validated[canonical_clean] = clean_variants\n",
    "    \n",
    "    print(f\"  Validation preserved {len(validated)} groups from LLM\")\n",
    "    return validated\n",
    "\"\"\"\n",
    "\n",
    "def have_common_core_terms(method1, method2):\n",
    "    \"\"\"Check if two methods share meaningful core terms beyond stop words.\"\"\"\n",
    "    stop_words = {'and', 'or', 'the', 'a', 'an', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}\n",
    "    \n",
    "    words1 = set(method1.split()) - stop_words\n",
    "    words2 = set(method2.split()) - stop_words\n",
    "    \n",
    "    if len(words1) == 0 or len(words2) == 0:\n",
    "        return False\n",
    "    \n",
    "    # Require at least 50% overlap in core terms\n",
    "    overlap = len(words1 & words2) / min(len(words1), len(words2))\n",
    "    return overlap >= 0.5\n",
    "\n",
    "def fallback_similarity_grouping(method_batch, similarity_threshold=0.85):\n",
    "    \"\"\"Fallback grouping using string similarity when LLM fails.\"\"\"\n",
    "    from difflib import SequenceMatcher\n",
    "    \n",
    "    groups = {}\n",
    "    processed = set()\n",
    "    \n",
    "    for method in sorted(method_batch, key=len):\n",
    "        if method in processed:\n",
    "            continue\n",
    "        \n",
    "        # Find similar methods using both string similarity and semantic checks\n",
    "        similar_methods = [method]\n",
    "        method_lower = method.lower()\n",
    "        \n",
    "        for other_method in method_batch:\n",
    "            if other_method != method and other_method not in processed:\n",
    "                other_lower = other_method.lower()\n",
    "                similarity = SequenceMatcher(None, method_lower, other_lower).ratio()\n",
    "                \n",
    "                if similarity >= similarity_threshold:\n",
    "                    # Additional check: ensure they're not just coincidentally similar\n",
    "                    if have_common_core_terms(method_lower, other_lower):\n",
    "                        similar_methods.append(other_method)\n",
    "                        processed.add(other_method)\n",
    "        \n",
    "        canonical = min(similar_methods, key=len)  # Use shortest as canonical\n",
    "        groups[canonical] = similar_methods\n",
    "        processed.add(method)\n",
    "    \n",
    "    return groups\n",
    "\n",
    "def post_process_method_groups(variant_groups):\n",
    "    \"\"\"MINIMAL post-processing that preserves LLM consolidation work\"\"\"\n",
    "    final_groups = {}\n",
    "    \n",
    "    for canonical, variants in variant_groups.items():\n",
    "        # Remove duplicates but keep groups intact\n",
    "        clean_variants = list(set(variants))\n",
    "        \n",
    "        # Only split if canonical name is obviously generic (very restrictive)\n",
    "        truly_generic = ['method', 'analysis', 'approach', 'technique'] \n",
    "        if any(canonical.lower() == generic for generic in truly_generic):\n",
    "            # Only split if canonical is EXACTLY one of these generic terms\n",
    "            for variant in clean_variants:\n",
    "                final_groups[variant] = [variant]\n",
    "        else:\n",
    "            # PRESERVE the group as-is\n",
    "            final_groups[canonical] = clean_variants\n",
    "    \n",
    "    print(f\"  Post-processing preserved {len(final_groups)} groups\")\n",
    "    return final_groups\n",
    "\n",
    "\n",
    "def build_method_variant_groups_enhanced(\n",
    "    method_list, client, model_type, credit_tracker, prompt,\n",
    "    batch_size=50, top_p=None, temp=None\n",
    "):\n",
    "    \"\"\"Enhanced method grouping with configurable prompt.\"\"\"\n",
    "    variant_groups = {}\n",
    "    processed_methods = set()\n",
    "    \n",
    "    # Step 1: Pre-filter obvious duplicates to improve LLM efficiency\n",
    "    method_list = prefilter_obvious_duplicates(method_list)\n",
    "    \n",
    "    # Step 2: Process methods in batches using configurable prompting\n",
    "    for i in range(0, len(method_list), batch_size):\n",
    "        batch = method_list[i:i + batch_size]\n",
    "        batch = [m for m in batch if m not in processed_methods]\n",
    "        \n",
    "        if not batch:\n",
    "            continue\n",
    "            \n",
    "        # Format the prompt with current batch of methods\n",
    "        formatted_prompt = prompt.format(method_list=batch)\n",
    "\n",
    "        try:\n",
    "            # Configure API parameters for different model types\n",
    "            api_params = {\n",
    "                \"model\": model_type,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a scientific method classification expert. Group only true variants while preserving distinct techniques.\"},\n",
    "                    {\"role\": \"user\", \"content\": formatted_prompt}\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            if model_type.startswith('gpt-5-nano'):\n",
    "                api_params[\"max_completion_tokens\"] = 3000\n",
    "            else:\n",
    "                if temp is not None: api_params[\"temperature\"] = temp\n",
    "                if top_p is not None:  api_params[\"top_p\"] = top_p\n",
    "                api_params[\"max_tokens\"] = 3000\n",
    "            \n",
    "            # Make LLM call and process response\n",
    "            response = client.chat.completions.create(**api_params)\n",
    "            logger.info(f\"LLM raw response: {response}\")\n",
    "            content = response.choices[0].message.content\n",
    "            logger.info(f\"LLM content: {content}\")\n",
    "            credit_tracker.update(num_tokens_from_string(content, model_type))\n",
    "            \n",
    "            print(f\"✓ Batch {i//batch_size + 1} LLM response received: {len(content)} characters\")\n",
    "            \n",
    "            # Parse the dictionary response with error handling\n",
    "            try:\n",
    "                content = content.strip()\n",
    "                if content.startswith('```'):\n",
    "                    content = re.sub(r'```(?:python|json)?\\n?', '', content)\n",
    "                    content = re.sub(r'```$', '', content)\n",
    "                \n",
    "                dict_match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
    "                if dict_match:\n",
    "                    groups = ast.literal_eval(dict_match.group(0))\n",
    "                    \n",
    "                    # Validate and clean the groups using enhanced validation\n",
    "                    validated_groups = validate_method_groups_enhanced(groups, batch)\n",
    "                    variant_groups.update(validated_groups)\n",
    "                    processed_methods.update(batch)\n",
    "                    \n",
    "                    print(f\"✓ Processed batch {i//batch_size + 1}: {len(validated_groups)} groups created\")\n",
    "                else:\n",
    "                    print(f\"⚠️ No dictionary found in LLM response for batch {i//batch_size + 1}\")\n",
    "                    fallback_groups = fallback_similarity_grouping(batch)\n",
    "                    variant_groups.update(fallback_groups)\n",
    "                    processed_methods.update(batch)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to parse LLM response, using fallback similarity grouping: {e}\")\n",
    "                fallback_groups = fallback_similarity_grouping(batch)\n",
    "                variant_groups.update(fallback_groups)\n",
    "                processed_methods.update(batch)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"LLM call failed, using fallback: {e}\")\n",
    "            fallback_groups = fallback_similarity_grouping(batch)\n",
    "            variant_groups.update(fallback_groups)\n",
    "            processed_methods.update(batch)\n",
    "\n",
    "    # Step 3: Post-process to ensure quality and remove inappropriate groupings\n",
    "    final_groups = post_process_method_groups(variant_groups)\n",
    "    \n",
    "    logger.info(f\"Created {len(final_groups)} method variant groups from {len(method_list)} original methods\")\n",
    "    return final_groups\n",
    "\n",
    "\n",
    "def create_variant_mapping(variant_groups):\n",
    "    \"\"\"Create mapping from any variant to its canonical form for method consolidation.\"\"\"\n",
    "    variant_to_canonical = {}\n",
    "    canonical_to_variants = {}\n",
    "    \n",
    "    for canonical, variants in variant_groups.items():\n",
    "        canonical_to_variants[canonical] = variants\n",
    "        for variant in variants:\n",
    "            variant_to_canonical[variant.lower()] = canonical\n",
    "    \n",
    "    return variant_to_canonical, canonical_to_variants\n",
    "\n",
    "def consolidate_variant_scores(scores, method_names, variant_to_canonical):\n",
    "    \"\"\"\n",
    "    Consolidate method scores to prevent double-counting of variants.\n",
    "    Uses MAXIMUM score among variants (not sum) to avoid inflating scores.\n",
    "    \"\"\"\n",
    "    canonical_methods = list(set(variant_to_canonical.values()))\n",
    "    canonical_scores = np.zeros((scores.shape[0], len(canonical_methods)))  # FIXED: was scores.shape\n",
    "    \n",
    "    canonical_to_idx = {method: i for i, method in enumerate(canonical_methods)}\n",
    "    \n",
    "    for j, method_name in enumerate(method_names):\n",
    "        method_lower = method_name.lower()\n",
    "        canonical = variant_to_canonical.get(method_lower, method_name)\n",
    "        \n",
    "        if canonical in canonical_to_idx:\n",
    "            canonical_idx = canonical_to_idx[canonical]\n",
    "            # Use MAXIMUM score among variants (not sum) to prevent double-counting\n",
    "            canonical_scores[:, canonical_idx] = np.maximum(\n",
    "                canonical_scores[:, canonical_idx], \n",
    "                scores[:, j]\n",
    "            )\n",
    "    \n",
    "    return canonical_scores, canonical_methods\n",
    "\n",
    "# ================================================================\n",
    "# METHOD SCORING FUNCTIONS\n",
    "# ================================================================\n",
    "\n",
    "def compute_enhanced_tfidf_scores(processed_texts, method_variants_dict, ngram_range=(1, 4), min_df=1, max_df=0.95):\n",
    "    \"\"\"Compute TF-IDF scores for all method variants\"\"\"\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "    \n",
    "    existing_variants = []\n",
    "    for variant in all_variants:\n",
    "        variant_pattern = r'\\b' + re.escape(variant.lower()) + r'\\b'\n",
    "        found = False\n",
    "        for text in processed_texts[:1000]:  # Sample check for efficiency\n",
    "            if re.search(variant_pattern, text.lower()):\n",
    "                existing_variants.append(variant)\n",
    "                found = True\n",
    "                break\n",
    "        if not found and len(existing_variants) < 5000:\n",
    "            for text in processed_texts:\n",
    "                if re.search(variant_pattern, text.lower()):\n",
    "                    existing_variants.append(variant)\n",
    "                    break\n",
    "    \n",
    "    print(f\"Found {len(existing_variants)} variants that exist in corpus out of {len(all_variants)} total\")\n",
    "    \n",
    "    if not existing_variants:\n",
    "        logger.warning(\"No method variants found in corpus!\")\n",
    "        return np.zeros((len(processed_texts), 1)), ['no_methods_found']\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        vocabulary=existing_variants,\n",
    "        ngram_range=ngram_range,\n",
    "        min_df=min_df,\n",
    "        max_df=max_df,\n",
    "        norm='l2',\n",
    "        token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(processed_texts)\n",
    "        scores = tfidf_matrix.toarray()\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        return scores, feature_names\n",
    "    except Exception as e:\n",
    "        logger.error(f\"TF-IDF computation failed: {e}\")\n",
    "        return np.zeros((len(processed_texts), len(existing_variants))), existing_variants\n",
    "\n",
    "def compute_enhanced_lda_scores(processed_texts, method_variants_dict, ngram_range=(1, 4), n_topics=None, max_iter=20):\n",
    "    \"\"\"Compute LDA scores for method variants. FIXED VERSION\"\"\"\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "\n",
    "    if n_topics is None:\n",
    "        n_topics = min(len(all_variants), 100)\n",
    "\n",
    "    vectorizer = CountVectorizer(\n",
    "        vocabulary=all_variants,\n",
    "        ngram_range=ngram_range,\n",
    "        token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        doc_term_matrix = vectorizer.fit_transform(processed_texts)\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        \n",
    "        print(f\"  LDA Debug: doc_term_matrix.shape = {doc_term_matrix.shape}\")\n",
    "        print(f\"  LDA Debug: len(all_variants) = {len(all_variants)}\")\n",
    "        print(f\"  LDA Debug: len(feature_names) = {len(feature_names)}\")\n",
    "        \n",
    "        if n_topics >= 2 and doc_term_matrix.shape[1] > 0:\n",
    "            # FIXED: Use min to prevent n_topics > n_features\n",
    "            actual_topics = min(n_topics, doc_term_matrix.shape[1], len(all_variants))\n",
    "            \n",
    "            lda = LatentDirichletAllocation(\n",
    "                n_components=actual_topics,\n",
    "                learning_method='batch',\n",
    "                random_state=42,\n",
    "                max_iter=max_iter\n",
    "            )\n",
    "            \n",
    "            # Fit LDA and get topic distributions\n",
    "            doc_topic_matrix = lda.fit_transform(doc_term_matrix)\n",
    "            topic_term_matrix = lda.components_  # Shape: (n_topics, n_features)\n",
    "            \n",
    "            print(f\"  LDA Debug: doc_topic_matrix.shape = {doc_topic_matrix.shape}\")\n",
    "            print(f\"  LDA Debug: topic_term_matrix.shape = {topic_term_matrix.shape}\")\n",
    "            \n",
    "            # FIXED: Convert topic-document matrix back to document-term space\n",
    "            # We want scores for each method variant in each document\n",
    "            # Method: multiply doc-topic scores by topic-term weights\n",
    "            lda_scores = np.dot(doc_topic_matrix, topic_term_matrix)\n",
    "            \n",
    "            print(f\"  LDA Debug: final lda_scores.shape = {lda_scores.shape}\")\n",
    "            \n",
    "            # Ensure correct dimensions\n",
    "            if lda_scores.shape[1] != len(all_variants):\n",
    "                print(f\"  LDA Warning: Score matrix columns ({lda_scores.shape[1]}) != variants ({len(all_variants)})\")\n",
    "                # Pad or truncate to match expected dimensions\n",
    "                if lda_scores.shape[1] < len(all_variants):\n",
    "                    padding = np.zeros((lda_scores.shape[0], len(all_variants) - lda_scores.shape[1]))\n",
    "                    lda_scores = np.hstack([lda_scores, padding])\n",
    "                else:\n",
    "                    lda_scores = lda_scores[:, :len(all_variants)]\n",
    "                    \n",
    "                print(f\"  LDA Debug: adjusted lda_scores.shape = {lda_scores.shape}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"  LDA: Creating zero matrix due to insufficient topics/features\")\n",
    "            lda_scores = np.zeros((len(processed_texts), len(all_variants)))\n",
    "\n",
    "        return lda_scores, feature_names\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"LDA computation failed: {e}\")\n",
    "        print(f\"LDA Error details: {e}\")\n",
    "        return np.zeros((len(processed_texts), len(all_variants))), all_variants\n",
    "\n",
    "    \n",
    "def compute_enhanced_compound_scores(df, method_variants_dict, processed_col='processed_text', window=150):\n",
    "    \"\"\"Enhanced compound scoring that handles variants\"\"\"\n",
    "    n_docs = len(df)\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "    \n",
    "    n_methods = len(all_variants)\n",
    "    scores = np.zeros((n_docs, n_methods), dtype=np.float32)\n",
    "    docs = df[processed_col].fillna('').str.lower().tolist()\n",
    "    \n",
    "    for j, variant in enumerate(all_variants):\n",
    "        variant_l = variant.lower()\n",
    "        \n",
    "        for i, text in enumerate(docs):\n",
    "            if variant_l in text:\n",
    "                scores[i, j] = 1.0\n",
    "            elif len(variant_l.split()) > 1:\n",
    "                words = variant_l.split()\n",
    "                if all(word in text for word in words):\n",
    "                    scores[i, j] = 0.7\n",
    "            elif len(variant_l) <= 5 and variant_l.upper() in text.upper():\n",
    "                scores[i, j] = 0.8\n",
    "    \n",
    "    return scores, all_variants\n",
    "\n",
    "def assign_methods_improved(df, scores, method_names, top_n=5, min_score=0.005):\n",
    "    \"\"\"Improved method assignment with better diagnostics.\"\"\"\n",
    "    n_papers, n_methods = scores.shape\n",
    "    \n",
    "    # Initialize method columns\n",
    "    for i in range(top_n):\n",
    "        df[f'Method_{i+1}'] = ''\n",
    "        df[f'Method_{i+1}_Score'] = 0.0\n",
    "    \n",
    "    df['Primary_Method'] = ''\n",
    "    df['Primary_Method_Score'] = 0.0\n",
    "    df['Method_Confidence'] = 'Low'\n",
    "    df['Total_Method_Score'] = 0.0\n",
    "    \n",
    "    assigned_count = 0\n",
    "    \n",
    "    for paper_idx in range(n_papers):\n",
    "        paper_scores = scores[paper_idx, :]\n",
    "        \n",
    "        top_indices = np.argsort(paper_scores)[::-1][:top_n]\n",
    "        top_scores = paper_scores[top_indices]\n",
    "        \n",
    "        valid_mask = top_scores >= min_score\n",
    "        valid_indices = top_indices[valid_mask]\n",
    "        valid_scores = top_scores[valid_mask]\n",
    "        \n",
    "        if len(valid_indices) > 0:\n",
    "            assigned_count += 1\n",
    "            \n",
    "            # FIXED: Use [0] to get first element, not entire array\n",
    "            df.loc[paper_idx, 'Primary_Method'] = method_names[valid_indices[0]]\n",
    "            df.loc[paper_idx, 'Primary_Method_Score'] = valid_scores[0]\n",
    "            df.loc[paper_idx, 'Total_Method_Score'] = valid_scores.sum()\n",
    "            \n",
    "            if valid_scores[0] > 0.1:\n",
    "                df.loc[paper_idx, 'Method_Confidence'] = 'High'\n",
    "            elif valid_scores[0] > 0.05:\n",
    "                df.loc[paper_idx, 'Method_Confidence'] = 'Medium'\n",
    "            \n",
    "            for i, (idx, score) in enumerate(zip(valid_indices, valid_scores)):\n",
    "                if i < top_n:\n",
    "                    df.loc[paper_idx, f'Method_{i+1}'] = method_names[idx]\n",
    "                    df.loc[paper_idx, f'Method_{i+1}_Score'] = score\n",
    "    \n",
    "    logger.info(f\"  Assigned methods to {assigned_count}/{n_papers} papers ({100*assigned_count/n_papers:.1f}%)\")\n",
    "    return df\n",
    "\n",
    "def aggressive_fallback_grouping(method_list, similarity_threshold=0.75):\n",
    "    \"\"\"\n",
    "    Enhanced fallback grouping with aggressive similarity matching and pattern recognition.\n",
    "    This will handle cases where LLM API fails.\n",
    "    \"\"\"\n",
    "    from difflib import SequenceMatcher\n",
    "    \n",
    "    groups = {}\n",
    "    processed = set()\n",
    "    \n",
    "    # First pass: Handle obvious patterns\n",
    "    pattern_groups = handle_common_patterns(method_list)\n",
    "    for canonical, variants in pattern_groups.items():\n",
    "        groups[canonical] = variants\n",
    "        processed.update(variants)\n",
    "    \n",
    "    # Second pass: Similarity-based grouping for remaining methods\n",
    "    remaining_methods = [m for m in method_list if m not in processed]\n",
    "    \n",
    "    for method in sorted(remaining_methods, key=len):\n",
    "        if method in processed:\n",
    "            continue\n",
    "            \n",
    "        group = [method]\n",
    "        method_lower = method.lower()\n",
    "        method_tokens = set(method_lower.split())\n",
    "        \n",
    "        for other_method in remaining_methods:\n",
    "            if other_method == method or other_method in processed:\n",
    "                continue\n",
    "                \n",
    "            other_lower = other_method.lower()\n",
    "            other_tokens = set(other_lower.split())\n",
    "            \n",
    "            # Multiple similarity checks\n",
    "            string_sim = SequenceMatcher(None, method_lower, other_lower).ratio()\n",
    "            token_overlap = len(method_tokens & other_tokens) / len(method_tokens | other_tokens) if (method_tokens | other_tokens) else 0\n",
    "            \n",
    "            # Check for containment (one is substring of other)\n",
    "            containment = method_lower in other_lower or other_lower in method_lower\n",
    "            \n",
    "            # Group if any condition met\n",
    "            if (string_sim >= similarity_threshold or \n",
    "                token_overlap >= 0.6 or \n",
    "                containment):\n",
    "                group.append(other_method)\n",
    "                processed.add(other_method)\n",
    "        \n",
    "        # Use shortest name as canonical\n",
    "        canonical = min(group, key=lambda x: (len(x), x))\n",
    "        groups[canonical] = group\n",
    "        processed.add(method)\n",
    "    \n",
    "    return groups\n",
    "\n",
    "def handle_common_patterns(method_list):\n",
    "    \"\"\"Handle common method name patterns that should be grouped together.\"\"\"\n",
    "    import re\n",
    "    \n",
    "    pattern_groups = {}\n",
    "    processed = set()\n",
    "    \n",
    "    # Common abbreviation patterns\n",
    "    abbreviation_patterns = [\n",
    "        (r'^ga$', r'genetic algorithm.*'),\n",
    "        (r'^pso$', r'particle swarm optimization.*'),\n",
    "        (r'^abc$', r'.*bee colony.*'),\n",
    "        (r'^gwo$', r'grey wolf.*'),\n",
    "        (r'^opf$', r'optimal power flow.*'),\n",
    "        (r'^milp$', r'.*integer.*linear.*programming.*'),\n",
    "        (r'^dnn.*', r'.*neural network.*'),\n",
    "        (r'^cnn$', r'convolutional neural network.*'),\n",
    "        (r'^rnn$', r'.*neural network rnn.*'),\n",
    "        (r'^svm$', r'support vector machine.*'),\n",
    "        (r'^pca$', r'principal component analysis.*'),\n",
    "    ]\n",
    "    \n",
    "    # Method variant patterns\n",
    "    variant_patterns = [\n",
    "        # Neural network variants\n",
    "        (r'.*neural network.*', ['neural network', 'bp neural network', 'neural network algorithm', 'artificial neural network']),\n",
    "        # Genetic algorithm variants  \n",
    "        (r'.*genetic algorithm.*', ['genetic algorithm', 'genetic algorithm ga', 'adaptive genetic algorithm']),\n",
    "        # Monte Carlo variants\n",
    "        (r'.*monte carlo.*', ['monte carlo simulation', 'sequential monte carlo', 'carlo simulation result']),\n",
    "        # Particle swarm variants\n",
    "        (r'.*particle swarm.*', ['particle swarm optimization', 'binary particle swarm', 'improved particle swarm optimization']),\n",
    "        # Random forest variants\n",
    "        (r'.*random forest.*', ['random forest', 'random forest rf', 'random forest algorithm']),\n",
    "        # Machine learning variants\n",
    "        (r'.*machine learning.*', ['machine learning', 'ensemble learning']),\n",
    "    ]\n",
    "    \n",
    "    # Group by abbreviation patterns\n",
    "    for abbrev_pattern, full_pattern in abbreviation_patterns:\n",
    "        abbrev_matches = []\n",
    "        full_matches = []\n",
    "        \n",
    "        for method in method_list:\n",
    "            if method in processed:\n",
    "                continue\n",
    "            if re.search(abbrev_pattern, method.lower()):\n",
    "                abbrev_matches.append(method)\n",
    "            elif re.search(full_pattern, method.lower()):\n",
    "                full_matches.append(method)\n",
    "        \n",
    "        if abbrev_matches and full_matches:\n",
    "            all_matches = abbrev_matches + full_matches\n",
    "            canonical = min(full_matches, key=len) if full_matches else min(abbrev_matches, key=len)\n",
    "            pattern_groups[canonical] = all_matches\n",
    "            processed.update(all_matches)\n",
    "    \n",
    "    # Group by variant patterns\n",
    "    for base_pattern, known_variants in variant_patterns:\n",
    "        matches = []\n",
    "        for method in method_list:\n",
    "            if method in processed:\n",
    "                continue\n",
    "            if (re.search(base_pattern, method.lower()) or \n",
    "                method.lower() in [v.lower() for v in known_variants]):\n",
    "                matches.append(method)\n",
    "        \n",
    "        if len(matches) > 1:\n",
    "            canonical = min(matches, key=len)\n",
    "            pattern_groups[canonical] = matches\n",
    "            processed.update(matches)\n",
    "    \n",
    "    return pattern_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35425ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Cell 6: Method Scoring Functions (Enhanced)\n",
    "\n",
    "def compute_enhanced_tfidf_scores(processed_texts, method_variants_dict, ngram_range=(1, 4), min_df=1, max_df=0.95):\n",
    "    \"\"\"Compute TF-IDF scores for all method variants\"\"\"\n",
    "    # Get all variants\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "    \n",
    "    # Create vocabulary from actual variants that exist in corpus\n",
    "    existing_variants = []\n",
    "    for variant in all_variants:\n",
    "        # Check if variant appears in any document\n",
    "        variant_pattern = r'\\b' + re.escape(variant.lower()) + r'\\b'\n",
    "        found = False\n",
    "        for text in processed_texts:  # Sample check for efficiency\n",
    "            if re.search(variant_pattern, text.lower()):\n",
    "                existing_variants.append(variant)\n",
    "                found = True\n",
    "                break\n",
    "        if not found and len(existing_variants) < 5000:  # Keep checking if we don't have too many\n",
    "            for text in processed_texts:\n",
    "                if re.search(variant_pattern, text.lower()):\n",
    "                    existing_variants.append(variant)\n",
    "                    break\n",
    "    \n",
    "    print(f\"Found {len(existing_variants)} variants that exist in corpus out of {len(all_variants)} total\")\n",
    "    \n",
    "    if not existing_variants:\n",
    "        logger.warning(\"No method variants found in corpus!\")\n",
    "        return np.zeros((len(processed_texts), 1)), ['no_methods_found']\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        vocabulary=existing_variants,\n",
    "        ngram_range=ngram_range,\n",
    "        min_df=min_df,\n",
    "        max_df=max_df,\n",
    "        norm='l2',\n",
    "        token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(processed_texts)\n",
    "        scores = tfidf_matrix.toarray()\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        return scores, feature_names\n",
    "    except Exception as e:\n",
    "        logger.error(f\"TF-IDF computation failed: {e}\")\n",
    "        return np.zeros((len(processed_texts), len(existing_variants))), existing_variants\n",
    "    \n",
    "def compute_enhanced_tfidf_scores_adapted(processed_texts, method_variants_dict, ngram_range=(1, 4), min_df=1, max_df=0.9):\n",
    "    \"\"\"Compute adapted TF-IDF scores for method variants with binary TF weighting\"\"\"\n",
    "\n",
    "    \n",
    "    # Extract all variants from method_variants_dict - THIS IS WHERE IT'S USED\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "    \n",
    "    # Create vocabulary from actual variants that exist in corpus\n",
    "    existing_variants = []\n",
    "    for variant in all_variants:\n",
    "        variant_pattern = r'\\b' + re.escape(variant.lower()) + r'\\b'\n",
    "        found = False\n",
    "        for text in processed_texts:\n",
    "            if re.search(variant_pattern, text.lower()):\n",
    "                existing_variants.append(variant)\n",
    "                found = True\n",
    "                break\n",
    "        if not found and len(existing_variants) < 5000:\n",
    "            for text in processed_texts:\n",
    "                if re.search(variant_pattern, text.lower()):\n",
    "                    existing_variants.append(variant)\n",
    "                    break\n",
    "    \n",
    "    print(f\"Found {len(existing_variants)} variants that exist in corpus out of {len(all_variants)} total\")\n",
    "    \n",
    "    if not existing_variants:\n",
    "        logger.warning(\"No method variants found in corpus!\")\n",
    "        return np.zeros((len(processed_texts), 1)), ['no_methods_found']\n",
    "    \n",
    "    # Step 1: Binary term counting\n",
    "    count_vectorizer = CountVectorizer(\n",
    "        vocabulary=existing_variants,  # Uses the filtered variants from method_variants_dict\n",
    "        ngram_range=ngram_range,\n",
    "        min_df=min_df,\n",
    "        max_df=max_df,\n",
    "        binary=True,  # KEY CHANGE: Binary presence/absence\n",
    "        token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "    \n",
    "    count_matrix = count_vectorizer.fit_transform(processed_texts)\n",
    "    \n",
    "    # Step 2: Apply IDF weighting to binary counts\n",
    "    tfidf_transformer = TfidfTransformer(\n",
    "        norm='l2',           # Keep document length normalization\n",
    "        use_idf=True,        # Keep IDF weighting for specificity\n",
    "        smooth_idf=True,     # Prevents division by zero\n",
    "        sublinear_tf=False   # Not needed with binary weighting\n",
    "    )\n",
    "    \n",
    "    tfidf_matrix = tfidf_transformer.fit_transform(count_matrix)\n",
    "    \n",
    "    scores = tfidf_matrix.toarray()\n",
    "    feature_names = count_vectorizer.get_feature_names_out()\n",
    "    return scores, feature_names\n",
    "\n",
    "\n",
    "\n",
    "def compute_enhanced_lda_scores(processed_texts, method_variants_dict, ngram_range=(1, 4), n_topics=None, max_iter=20):\n",
    "    \"\"\"Compute LDA scores for method variants.\"\"\"\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "\n",
    "    if n_topics is None:\n",
    "        n_topics = min(len(all_variants), 100)\n",
    "\n",
    "    vectorizer = CountVectorizer(\n",
    "        vocabulary=all_variants,\n",
    "        ngram_range=ngram_range,\n",
    "        token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        doc_term_matrix = vectorizer.fit_transform(processed_texts)\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "        if n_topics >= 2 and doc_term_matrix.shape[1] > 0:\n",
    "            lda = LatentDirichletAllocation(\n",
    "                n_components=min(n_topics, doc_term_matrix.shape[1]),\n",
    "                learning_method='batch',\n",
    "                random_state=42,\n",
    "                max_iter=max_iter\n",
    "            )\n",
    "            lda_matrix = lda.fit_transform(doc_term_matrix)\n",
    "        else:\n",
    "            lda_matrix = np.zeros((doc_term_matrix.shape[0], len(all_variants)))\n",
    "\n",
    "        return lda_matrix, feature_names\n",
    "    except Exception as e:\n",
    "        logger.error(f\"LDA computation failed: {e}\")\n",
    "        return np.zeros((len(processed_texts), len(all_variants))), all_variants\n",
    "    \n",
    "def compute_enhanced_compound_scores(df, method_variants_dict, processed_col='processed_text', window=150):\n",
    "    \"\"\"Enhanced compound scoring with proximity matching and filtering common stop/context words\"\"\"\n",
    "    import re\n",
    "    from itertools import product\n",
    "    \n",
    "    n_docs = len(df)\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "    \n",
    "    n_methods = len(all_variants)\n",
    "    scores = np.zeros((n_docs, n_methods), dtype=np.float32)\n",
    "    docs = df[processed_col].fillna('').str.lower().tolist()\n",
    "    \n",
    "    # Common distracting words that indicate figure/table/diagram context\n",
    "    forbidden_context_words = {\n",
    "        \"figure\", \"table\", \"diagram\", \"plot\", \"chart\", \"graph\", \"section\", \n",
    "        \"appendix\", \"equation\", \"formula\", \"example\", \"case\", \"study\", \n",
    "        \"shown\", \"presented\", \"illustrated\", \"depicts\", \"shows\"\n",
    "    }\n",
    "    \n",
    "    for j, variant in enumerate(all_variants):\n",
    "        variant_l = variant.lower().strip()\n",
    "        variant_words = variant_l.split()\n",
    "        \n",
    "        for i, text in enumerate(docs):\n",
    "            # 1. Exact phrase match (highest priority)\n",
    "            pattern = r'\\b' + re.escape(variant_l) + r'\\b'\n",
    "            if re.search(pattern, text):\n",
    "                scores[i, j] = 1.0\n",
    "                continue\n",
    "            \n",
    "            # 2. Hyphenated form matching\n",
    "            hyphenated_pattern = r'\\b' + re.escape(variant_l.replace(' ', '-')) + r'\\b'\n",
    "            if re.search(hyphenated_pattern, text):\n",
    "                scores[i, j] = 1.0\n",
    "                continue\n",
    "            \n",
    "            # 3. Pure abbreviation matching (≤4 chars, single word)\n",
    "            if len(variant_l) <= 4 and variant_l.isalpha() and len(variant_words) == 1:\n",
    "                abbrev_pattern = r'\\b' + variant_l.upper() + r'\\b'\n",
    "                if re.search(abbrev_pattern, text.upper()):\n",
    "                    scores[i, j] = 0.9\n",
    "                continue\n",
    "            \n",
    "            # 4. Proximity matching for compound terms (2-5 words only)\n",
    "            if 2 <= len(variant_words) <= 5:\n",
    "                word_positions = []\n",
    "                \n",
    "                # Find positions of each word\n",
    "                for word in variant_words:\n",
    "                    # Skip very common words that might cause false positives\n",
    "                    if word in {\"of\", \"the\", \"a\", \"an\", \"and\", \"or\", \"in\", \"on\", \"at\", \"to\", \"for\"}:\n",
    "                        continue\n",
    "                        \n",
    "                    word_pattern = r'\\b' + re.escape(word) + r'\\b'\n",
    "                    matches = [m.start() for m in re.finditer(word_pattern, text)]\n",
    "                    if not matches:\n",
    "                        word_positions = []\n",
    "                        break\n",
    "                    word_positions.append(matches)\n",
    "                \n",
    "                # Check if all words found and proximity conditions met\n",
    "                if word_positions and len(word_positions) >= len(variant_words) - 1:  # Allow missing 1 stop word\n",
    "                    found_valid_match = False\n",
    "                    \n",
    "                    for pos_tuple in product(*word_positions):\n",
    "                        min_pos = min(pos_tuple)\n",
    "                        max_pos = max(pos_tuple)\n",
    "                        span = max_pos - min_pos\n",
    "                        \n",
    "                        # Check if within window and no forbidden context words nearby\n",
    "                        if span <= window:\n",
    "                            # Extract snippet around the match\n",
    "                            snippet_start = max(0, min_pos - 50)\n",
    "                            snippet_end = min(len(text), max_pos + 50)\n",
    "                            snippet = text[snippet_start:snippet_end]\n",
    "                            \n",
    "                            # Check for forbidden context words in the snippet\n",
    "                            has_forbidden_context = any(\n",
    "                                fw in snippet for fw in forbidden_context_words\n",
    "                            )\n",
    "                            \n",
    "                            if not has_forbidden_context:\n",
    "                                scores[i, j] = 0.7  # Lower score for proximity match\n",
    "                                found_valid_match = True\n",
    "                                break\n",
    "                    \n",
    "                    if found_valid_match:\n",
    "                        continue\n",
    "    \n",
    "    return scores, all_variants\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def aggregate_variant_scores_to_canonical(scores, variant_names, variant_to_canonical):\n",
    "    \"\"\"Aggregate variant scores back to canonical method names\"\"\"\n",
    "    canonical_methods = list(set(variant_to_canonical.values()))\n",
    "    canonical_scores = np.zeros((scores.shape[0], len(canonical_methods)))\n",
    "    \n",
    "    canonical_to_idx = {method: i for i, method in enumerate(canonical_methods)}\n",
    "    \n",
    "    for j, variant in enumerate(variant_names):\n",
    "        canonical = variant_to_canonical.get(variant.lower(), variant)\n",
    "        if canonical in canonical_to_idx:\n",
    "            canonical_idx = canonical_to_idx[canonical]\n",
    "            canonical_scores[:, canonical_idx] += scores[:, j]  # Sum scores for variants\n",
    "    \n",
    "    return canonical_scores, canonical_methods\n",
    "\n",
    "def prefilter_obvious_duplicates(method_list):\n",
    "    \"\"\"Clean CSV artifacts and normalize method names before LLM processing.\"\"\"\n",
    "    cleaned_methods = []\n",
    "    for method in method_list:\n",
    "        # Remove CSV artifacts (trailing quotes, commas, escaped characters)\n",
    "        cleaned = method.strip().strip('\"').strip(\"'\").rstrip(',').strip()\n",
    "        # Remove escaped quotes\n",
    "        cleaned = cleaned.replace('\\\\\"', '').replace(\"\\\\'\", '')\n",
    "        # Remove empty or very short entries\n",
    "        if len(cleaned) > 1:\n",
    "            cleaned_methods.append(cleaned)\n",
    "    \n",
    "    return list(set(cleaned_methods))  # Remove exact duplicates\n",
    "\n",
    "\n",
    "def assign_top_methods_enhanced(\n",
    "    df, canonical_scores, canonical_methods, variant_scores, variant_names,\n",
    "    top_n=5, min_score=0.005\n",
    "):\n",
    "    \"\"\"Enhanced method assignment with granular variant tracking\"\"\"\n",
    "    \n",
    "    # Assign top canonical methods\n",
    "    for rank in range(top_n):\n",
    "        top_method = []\n",
    "        top_score = []\n",
    "        top_variants = []\n",
    "        confidence = []\n",
    "\n",
    "        for i, row in enumerate(canonical_scores):\n",
    "            if np.allclose(row, row):  # All equal\n",
    "                top_method.append(\"\")\n",
    "                top_score.append(0.0)\n",
    "                top_variants.append(\"\")\n",
    "                confidence.append(\"\")\n",
    "                continue\n",
    "\n",
    "            idxs = np.argsort(row)[::-1]\n",
    "            if rank < len(idxs):\n",
    "                method_idx = idxs[rank]\n",
    "                method = canonical_methods[method_idx]\n",
    "                score = row[method_idx]\n",
    "                \n",
    "                if score >= min_score:\n",
    "                    # Find contributing variants\n",
    "                    variant_contributions = []\n",
    "                    for v_idx, variant in enumerate(variant_names):\n",
    "                        if variant_scores[i, v_idx] > 0:\n",
    "                            # Check if this variant belongs to the current canonical method\n",
    "                            variant_canonical = variant_to_canonical.get(variant.lower(), variant)\n",
    "                            if variant_canonical == method:\n",
    "                                variant_contributions.append(f\"{variant}({variant_scores[i, v_idx]:.2f})\")\n",
    "                    \n",
    "                    top_method.append(method)\n",
    "                    top_score.append(score)\n",
    "                    top_variants.append(\"; \".join(variant_contributions[:3]))  # Top 3 variants\n",
    "                    confidence.append(\"confident\" if score > min_score * 2 else \"low_confidence\")\n",
    "                else:\n",
    "                    top_method.append(\"\")\n",
    "                    top_score.append(0.0)\n",
    "                    top_variants.append(\"\")\n",
    "                    confidence.append(\"\")\n",
    "            else:\n",
    "                top_method.append(\"\")\n",
    "                top_score.append(0.0)\n",
    "                top_variants.append(\"\")\n",
    "                confidence.append(\"\")\n",
    "\n",
    "        df[f'Top_{rank+1}_Method'] = top_method\n",
    "        df[f'Top_{rank+1}_Score'] = top_score\n",
    "        df[f'Top_{rank+1}_Variants'] = top_variants\n",
    "        df[f'Top_{rank+1}_Confidence'] = confidence\n",
    "\n",
    "    # Set primary columns\n",
    "    df['Primary_Method'] = df['Top_1_Method']\n",
    "    df['Primary_Method_Score'] = df['Top_1_Score']\n",
    "    df['Primary_Method_Variants'] = df['Top_1_Variants']\n",
    "    df['Method_Confidence'] = df['Top_1_Confidence']\n",
    "\n",
    "    return df\n",
    "def save_method_phrases_to_csv(method_phrases, method_counts, filename=\"extracted_method_phrases.csv\"):\n",
    "    filename = os.path.join(SAVE_DIR, filename)\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Method Phrase\", \"Count\"])\n",
    "        # If method_counts is a Counter, convert to dict\n",
    "        if hasattr(method_counts, 'items'):\n",
    "            for phrase, count in method_counts.items():\n",
    "                clean_phrase = phrase.strip().replace('\\n', ' ')\n",
    "                writer.writerow([clean_phrase, count])\n",
    "        else:\n",
    "            # fallback: zipped lists\n",
    "            for phrase, count in zip(method_phrases, method_counts):\n",
    "                clean_phrase = phrase.strip().replace('\\n', ' ')\n",
    "                writer.writerow([clean_phrase, count])\n",
    "    print(f\"✓ Saved method phrases to {filename}\")\n",
    "    \n",
    "def assign_methods_improved(df, scores, method_names, top_n=5, min_score=0.005):\n",
    "    \"\"\"\n",
    "    Improved method assignment with better diagnostics.\n",
    "    \"\"\"\n",
    "    n_papers, n_methods = scores.shape\n",
    "    \n",
    "    # Initialize method columns\n",
    "    for i in range(top_n):\n",
    "        df[f'Method_{i+1}'] = ''\n",
    "        df[f'Method_{i+1}_Score'] = 0.0\n",
    "    \n",
    "    df['Primary_Method'] = ''\n",
    "    df['Primary_Method_Score'] = 0.0\n",
    "    df['Method_Confidence'] = 'None'\n",
    "    df['Total_Method_Score'] = 0.0\n",
    "    \n",
    "    assigned_count = 0\n",
    "    \n",
    "    for paper_idx in range(n_papers):\n",
    "        paper_scores = scores[paper_idx, :]\n",
    "        \n",
    "        # Get top methods for this paper\n",
    "        top_indices = np.argsort(paper_scores)[::-1][:top_n]\n",
    "        top_scores = paper_scores[top_indices]\n",
    "        \n",
    "        # Filter by minimum score\n",
    "        valid_mask = top_scores >= min_score\n",
    "        valid_indices = top_indices[valid_mask]\n",
    "        valid_scores = top_scores[valid_mask]\n",
    "        \n",
    "        if len(valid_indices) > 0:\n",
    "            assigned_count += 1\n",
    "            \n",
    "            # Assign primary method\n",
    "            df.loc[paper_idx, 'Primary_Method'] = method_names[valid_indices[0]]\n",
    "            df.loc[paper_idx, 'Primary_Method_Score'] = valid_scores[0]\n",
    "            df.loc[paper_idx, 'Total_Method_Score'] = valid_scores.sum()\n",
    "            \n",
    "            # Assign confidence based on top score\n",
    "            if valid_scores[0] > 0.7:\n",
    "                df.loc[paper_idx, 'Method_Confidence'] = 'Super-High'\n",
    "            elif valid_scores[0] > 0.5:\n",
    "                df.loc[paper_idx, 'Method_Confidence'] = 'High'\n",
    "            elif valid_scores[0] > 0.2:\n",
    "                df.loc[paper_idx, 'Method_Confidence'] = 'Medium'\n",
    "            elif valid_scores[0] > 0.05:\n",
    "                df.loc[paper_idx, 'Method_Confidence'] = 'Low'\n",
    "            \n",
    "            # Assign all valid methods\n",
    "            for i, (idx, score) in enumerate(zip(valid_indices, valid_scores)):\n",
    "                if i < top_n:\n",
    "                    df.loc[paper_idx, f'Method_{i+1}'] = method_names[idx]\n",
    "                    df.loc[paper_idx, f'Method_{i+1}_Score'] = score\n",
    "    \n",
    "    logger.info(f\"  Assigned methods to {assigned_count}/{n_papers} papers ({100*assigned_count/n_papers:.1f}%)\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a86210a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 7: Enhanced Topic Analysis Functions with Multi-N-gram Support\n",
    "\n",
    "def run_lda_topic_modeling(df, num_topics=10, num_words=25):\n",
    "    tokenized_texts = df['processed_text'].apply(lambda x: x.split()).tolist()\n",
    "    bigram = Phrases(tokenized_texts, min_count=10, threshold=50, delimiter='_')\n",
    "    trigram = Phrases(bigram[tokenized_texts], threshold=50, delimiter='_')\n",
    "    phrased = []\n",
    "    for doc in tokenized_texts:\n",
    "        bigrams_ = [w for w in bigram[doc] if '_' in w]\n",
    "        trigrams_ = [w for w in trigram[bigram[doc]] if '_' in w]\n",
    "        combined = doc + bigrams_ + trigrams_\n",
    "        phrased.append(' '.join(combined))\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 1), token_pattern=r'\\b[\\w_-]+\\b', max_df=0.95, min_df=2, max_features=10000)\n",
    "    doc_term_matrix = vectorizer.fit_transform(phrased)\n",
    "    lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "    topic_distributions = lda_model.fit_transform(doc_term_matrix)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    topic_keywords = {}\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        top_indices = topic.argsort()[:-num_words-1:-1]\n",
    "        top_words = [feature_names[i] for i in top_indices]\n",
    "        topic_keywords[topic_idx] = {'top_words': top_words}\n",
    "    return lda_model, vectorizer, topic_distributions, topic_keywords\n",
    "\n",
    "def assign_papers_to_topics(topic_distributions):\n",
    "    paper_classifications = []\n",
    "    for idx, dist in enumerate(topic_distributions):\n",
    "        top_2_topics = np.argsort(dist)[-2:][::-1]\n",
    "        primary_score = dist[top_2_topics]\n",
    "        other_topics_sum = sum(dist) - primary_score\n",
    "        dominance_ratio = primary_score / (other_topics_sum + 1e-10)\n",
    "        paper_classifications.append({\n",
    "            'paper_idx': idx,\n",
    "            'primary_topic': top_2_topics[0],\n",
    "            'secondary_topic': top_2_topics[1],\n",
    "            'primary_score': primary_score,\n",
    "            'dominance_ratio': dominance_ratio\n",
    "        })\n",
    "    return paper_classifications\n",
    "\n",
    "def string_similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def topic_name_llm_robust(\n",
    "    lda_keywords, tfidf_ngrams, top_titles,\n",
    "    client, model_type, credit_tracker,\n",
    "    initial_iterations=3, max_iterations=10, similarity_threshold=0.7,\n",
    "    temp=None, top_p=None \n",
    "):\n",
    "    prompt = (\n",
    "        \"Based on the following keywords and n-grams from LDA and TF-IDF, plus top paper titles, provide a concise topic name \"\n",
    "        \"(bigram or trigram, single word if very specific):\\n\"\n",
    "        f\"LDA: {', '.join(lda_keywords)}\\n\"\n",
    "        f\"TFIDF: {', '.join(tfidf_ngrams)}\\n\"\n",
    "        f\"TITLES: {', '.join(top_titles)}\\n\"\n",
    "        \"Return ONLY the topic name.\"\n",
    "    )\n",
    "    \n",
    "    iterations = initial_iterations\n",
    "    from collections import Counter\n",
    "    \n",
    "    while iterations <= max_iterations:\n",
    "        generated_names = []\n",
    "        for _ in range(iterations):\n",
    "            try:\n",
    "                # Build API parameters dictionary properly\n",
    "                api_params = {\n",
    "                    \"model\": model_type,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"You are a science topic-naming assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ]\n",
    "                }\n",
    "                \n",
    "                # Add parameters conditionally (FIXED SYNTAX)\n",
    "                if temp is not None:\n",
    "                    api_params[\"temperature\"] = temp\n",
    "                if top_p is not None:\n",
    "                    api_params[\"top_p\"] = top_p\n",
    "                \n",
    "                # Handle different model types\n",
    "                if model_type.startswith('gpt-5-nano'):\n",
    "                    api_params[\"max_completion_tokens\"] = 100\n",
    "                else:\n",
    "                    api_params[\"max_tokens\"] = 100\n",
    "                \n",
    "                response = client.chat.completions.create(**api_params)\n",
    "                content = response.choices[0].message.content.strip()\n",
    "                \n",
    "                # Track token usage\n",
    "                if hasattr(response, 'usage') and response.usage:\n",
    "                    credit_tracker.update(response.usage.total_tokens)\n",
    "                else:\n",
    "                    # Fallback token estimation\n",
    "                    credit_tracker.update(num_tokens_from_string(prompt + content, model_type))\n",
    "                \n",
    "                if content:\n",
    "                    generated_names.append(content)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error in LLM call: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Check for consensus (FIXED LOGIC)\n",
    "        if generated_names:  # Only proceed if we have generated names\n",
    "            for i, name in enumerate(generated_names):\n",
    "                matches = [other for j, other in enumerate(generated_names)\n",
    "                          if i != j and string_similarity(name, other) >= similarity_threshold]\n",
    "                if len(matches) >= len(generated_names) // 2:\n",
    "                    print(f\"Topic name stabilized after {iterations} iterations: {name}\")\n",
    "                    return name\n",
    "        \n",
    "        # Increase iterations and try again\n",
    "        iterations += 2\n",
    "        print(f\"No majority topic name found, increasing iterations to {iterations}.\")\n",
    "    \n",
    "    # Fallback: return most common name (FIXED RETURN LOGIC)\n",
    "    if generated_names:\n",
    "        most_common = Counter(generated_names).most_common(1)\n",
    "        if most_common:\n",
    "            best_name = most_common[0][0]  # Extract the actual name, not the tuple\n",
    "            print(f\"Returning most common topic name after {max_iterations} iterations: {best_name}\")\n",
    "            return best_name\n",
    "    \n",
    "    # Ultimate fallback\n",
    "    print(\"⚠️ Failed to generate any topic names, using fallback\")\n",
    "    return \"Unknown Topic\"\n",
    "\n",
    "def get_top_titles_for_topic(df, paper_classifications, topic_idx, n_titles=10):\n",
    "    dominant_papers = [p for p in paper_classifications if p['primary_topic'] == topic_idx]\n",
    "    paper_infos = [\n",
    "        (df.iloc[p['paper_idx']]['citationCount'] if 'citationCount' in df.columns else 0, df.iloc[p['paper_idx']]['title'])\n",
    "        for p in dominant_papers if not pd.isna(df.iloc[p['paper_idx']]['title'])\n",
    "    ]\n",
    "    # Correctly sort by citation count (descending)\n",
    "    top_titles = [title for _, title in sorted(paper_infos, key=lambda x: -x[0])[:n_titles]]\n",
    "    return top_titles\n",
    "\n",
    "def get_top_tfidf_ngrams_per_topic_enhanced(df, topic_col='Primary_Topic_Index', text_col='processed_text', \n",
    "                                          top_k=15, min_df=2, max_df=0.8):\n",
    "    \"\"\"\n",
    "    Enhanced function to extract top TF-IDF keywords, bigrams, and trigrams for each topic.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with topic assignments and text\n",
    "    - topic_col: Column name for topic indices\n",
    "    - text_col: Column name for processed text\n",
    "    - top_k: Number of top n-grams to extract per topic per type\n",
    "    - min_df: Minimum document frequency for TF-IDF\n",
    "    - max_df: Maximum document frequency for TF-IDF\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with structure: {topic_id: {'keywords': {...}, 'bigrams': {...}, 'trigrams': {...}}}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🔍 Extracting topic-specific n-grams...\")\n",
    "    \n",
    "    # Ensure text column exists and is not empty\n",
    "    if text_col not in df.columns:\n",
    "        print(f\"❌ Text column '{text_col}' not found in DataFrame\")\n",
    "        return {}\n",
    "    \n",
    "    # Remove rows with missing text or topic assignments\n",
    "    df_clean = df.dropna(subset=[text_col, topic_col]).copy()\n",
    "    print(f\"📊 Processing {len(df_clean)} documents across {df_clean[topic_col].nunique()} topics\")\n",
    "    \n",
    "    # Initialize result structure\n",
    "    topic_ngrams = {}\n",
    "    \n",
    "    # Get unique topics\n",
    "    unique_topics = sorted(df_clean[topic_col].dropna().unique())\n",
    "    \n",
    "    # Define n-gram configurations\n",
    "    ngram_configs = {\n",
    "        'keywords': (1, 1),    # Unigrams\n",
    "        'bigrams': (2, 2),     # Bigrams  \n",
    "        'trigrams': (3, 3)     # Trigrams\n",
    "    }\n",
    "    \n",
    "    for ngram_type, (min_n, max_n) in ngram_configs.items():\n",
    "        print(f\"📈 Processing {ngram_type} ({min_n}-{max_n} grams)...\")\n",
    "        \n",
    "        try:\n",
    "            # Create TF-IDF vectorizer for this n-gram type\n",
    "            vectorizer = TfidfVectorizer(\n",
    "                ngram_range=(min_n, max_n),\n",
    "                min_df=min_df,\n",
    "                max_df=max_df,\n",
    "                stop_words='english',\n",
    "                lowercase=True,\n",
    "                token_pattern=r'\\b[a-zA-Z][a-zA-Z0-9]*\\b'  # Only alphanumeric tokens starting with letter\n",
    "            )\n",
    "            \n",
    "            # Fit on all documents\n",
    "            tfidf_matrix = vectorizer.fit_transform(df_clean[text_col])\n",
    "            feature_names = vectorizer.get_feature_names_out()\n",
    "            \n",
    "            print(f\"  ✅ Created {len(feature_names)} {ngram_type} features\")\n",
    "            \n",
    "            # Extract top terms for each topic\n",
    "            for topic_idx in unique_topics:\n",
    "                topic_idx = int(topic_idx)\n",
    "                \n",
    "                # Initialize topic entry if not exists\n",
    "                if topic_idx not in topic_ngrams:\n",
    "                    topic_ngrams[topic_idx] = {}\n",
    "                \n",
    "                # Get documents for this topic\n",
    "                doc_indices = df_clean[df_clean[topic_col] == topic_idx].index\n",
    "                topic_doc_positions = [df_clean.index.get_loc(idx) for idx in doc_indices]\n",
    "                \n",
    "                if len(topic_doc_positions) == 0:\n",
    "                    topic_ngrams[topic_idx][ngram_type] = {}\n",
    "                    continue\n",
    "                \n",
    "                # Calculate mean TF-IDF scores for this topic\n",
    "                topic_tfidf = tfidf_matrix[topic_doc_positions].mean(axis=0).A1\n",
    "                \n",
    "                # Get top terms\n",
    "                top_indices = topic_tfidf.argsort()[-top_k:][::-1]\n",
    "                top_terms = {\n",
    "                    feature_names[i]: float(topic_tfidf[i]) \n",
    "                    for i in top_indices \n",
    "                    if topic_tfidf[i] > 0\n",
    "                }\n",
    "                \n",
    "                topic_ngrams[topic_idx][ngram_type] = top_terms\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error processing {ngram_type}: {e}\")\n",
    "            # Initialize empty entries for all topics for this n-gram type\n",
    "            for topic_idx in unique_topics:\n",
    "                topic_idx = int(topic_idx)\n",
    "                if topic_idx not in topic_ngrams:\n",
    "                    topic_ngrams[topic_idx] = {}\n",
    "                topic_ngrams[topic_idx][ngram_type] = {}\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n📊 N-gram Extraction Summary:\")\n",
    "    for topic_idx in sorted(topic_ngrams.keys()):\n",
    "        topic_data = topic_ngrams[topic_idx]\n",
    "        print(f\"  Topic {topic_idx}:\")\n",
    "        for ngram_type in ['keywords', 'bigrams', 'trigrams']:\n",
    "            count = len(topic_data.get(ngram_type, {}))\n",
    "            print(f\"    {ngram_type}: {count} terms\")\n",
    "    \n",
    "    return topic_ngrams\n",
    "\n",
    "# Legacy function for backward compatibility\n",
    "def get_top_tfidf_ngrams_per_topic(df, tfidf_matrix, feature_names, topic_col='Primary_Topic_Index', top_k=10):\n",
    "    \"\"\"\n",
    "    Legacy function - now calls the enhanced version for keywords only.\n",
    "    \"\"\"\n",
    "    print(\"⚠️  Using legacy function - consider switching to get_top_tfidf_ngrams_per_topic_enhanced\")\n",
    "    \n",
    "    result = get_top_tfidf_ngrams_per_topic_enhanced(\n",
    "        df, topic_col=topic_col, text_col='processed_text', top_k=top_k\n",
    "    )\n",
    "    \n",
    "    if not result:\n",
    "        return {}\n",
    "    \n",
    "    # Convert to legacy format (keywords only)\n",
    "    legacy_result = {}\n",
    "    for topic_idx, topic_data in result.items():\n",
    "        keywords = topic_data.get('keywords', {})\n",
    "        # Convert to list of tuples format\n",
    "        legacy_result[topic_idx] = [(term, score) for term, score in keywords.items()]\n",
    "    \n",
    "    return legacy_result\n",
    "\n",
    "def get_author_stats(paper_classifications, df_field, n_top=5):\n",
    "    top_papers = {}\n",
    "    author_topic_stats = {}\n",
    "    \n",
    "    for topic in set(p['primary_topic'] for p in paper_classifications):\n",
    "        topic_papers = [p for p in paper_classifications if p['primary_topic'] == topic]\n",
    "        \n",
    "        # Fix: Handle various numpy array cases for dominance_ratio\n",
    "        for p in topic_papers:\n",
    "            dominance_ratio = p['dominance_ratio']\n",
    "            \n",
    "            if isinstance(dominance_ratio, np.ndarray):\n",
    "                if dominance_ratio.size == 1:\n",
    "                    p['dominance_ratio'] = float(dominance_ratio.item())\n",
    "                else:\n",
    "                    # Take the first element if it's a multi-element array\n",
    "                    p['dominance_ratio'] = float(dominance_ratio.flat[0])\n",
    "            elif hasattr(dominance_ratio, 'item'):\n",
    "                p['dominance_ratio'] = float(dominance_ratio.item())\n",
    "            else:\n",
    "                p['dominance_ratio'] = float(dominance_ratio)\n",
    "            \n",
    "            # Also fix primary_score if needed\n",
    "            primary_score = p['primary_score']\n",
    "            if isinstance(primary_score, np.ndarray):\n",
    "                if primary_score.size == 1:\n",
    "                    p['primary_score'] = float(primary_score.item())\n",
    "                else:\n",
    "                    p['primary_score'] = float(primary_score.flat[0])\n",
    "            elif hasattr(primary_score, 'item'):\n",
    "                p['primary_score'] = float(primary_score.item())\n",
    "            else:\n",
    "                p['primary_score'] = float(primary_score)\n",
    "        \n",
    "        topic_papers.sort(key=lambda x: x['dominance_ratio'], reverse=True)\n",
    "        top_papers[topic] = []\n",
    "        \n",
    "        for p in topic_papers[:n_top]:\n",
    "            paper_idx = p['paper_idx']\n",
    "            try:\n",
    "                authors = df_field.iloc[paper_idx]['authors']\n",
    "                if isinstance(authors, str):\n",
    "                    try: \n",
    "                        authors = ast.literal_eval(authors)\n",
    "                    except (ValueError, SyntaxError): \n",
    "                        authors = []\n",
    "                if isinstance(authors, list):\n",
    "                    author_list = []\n",
    "                    for author in authors:\n",
    "                        if isinstance(author, dict):\n",
    "                            author_list.append({'name': author.get('name', 'Unknown'), 'id': author.get('authorId', 'Unknown')})\n",
    "                else: \n",
    "                    author_list = []\n",
    "                    \n",
    "                top_papers[topic].append({\n",
    "                    'paperId': df_field.iloc[paper_idx].get('paperId',''),\n",
    "                    'title': df_field.iloc[paper_idx].get('title',''),\n",
    "                    'authors': author_list,\n",
    "                    'score': float(p['primary_score']),\n",
    "                    'dominance_ratio': float(p['dominance_ratio'])\n",
    "                })\n",
    "            except Exception as e: \n",
    "                continue\n",
    "                \n",
    "    return top_papers, author_topic_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa79b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 8: Enhanced Utility Functions for Saving with Topic N-grams\n",
    "\n",
    "def save_term_frequencies(df, suffix_string, save_dir=SAVE_DIR, max_keywords=50000):\n",
    "    \"\"\"Save .json containing keywords, bigrams, trigrams with their counts for later visualization.\"\"\"\n",
    "    freq_data = {}\n",
    "    processed_text = df['processed_text'].fillna('').astype(str)\n",
    "    \n",
    "    for n in range(1, 4):\n",
    "        vectorizer = CountVectorizer(ngram_range=(n, n), stop_words='english', max_features=max_keywords)\n",
    "        matrix = vectorizer.fit_transform(processed_text)\n",
    "        terms = vectorizer.get_feature_names_out()\n",
    "        freqs = matrix.sum(axis=0).A1\n",
    "        \n",
    "        # Fix: Access the frequency (x[1]) for sorting, not the whole tuple (x)\n",
    "        freq_dict = {term: int(freq) for term, freq in sorted(zip(terms, freqs), key=lambda x: -x[1])}\n",
    "        \n",
    "        if n == 1: \n",
    "            freq_data['keywords'] = freq_dict\n",
    "        elif n == 2: \n",
    "            freq_data['bigrams'] = freq_dict\n",
    "        elif n == 3: \n",
    "            freq_data['trigrams'] = freq_dict\n",
    "    \n",
    "    out_fn = os.path.join(save_dir, f'term_frequencies_{suffix_string}.json')\n",
    "    with open(out_fn, 'w', encoding='utf-8') as f:\n",
    "        json.dump(freq_data, f, indent=2)\n",
    "    print(f\"✓ Saved term frequency summary to {out_fn}\")\n",
    "    return out_fn\n",
    "\n",
    "def save_author_and_venue_frequencies(df, suffix_string, save_dir=SAVE_DIR):\n",
    "    if 'authors' in df.columns:\n",
    "        authors_all = []\n",
    "        for item in df['authors']:\n",
    "            if isinstance(item, str) and item.strip():\n",
    "                try:\n",
    "                    obj = eval(item) if (item.strip().startswith(\"[\") or item.strip().startswith(\"{\")) else item.strip()\n",
    "                except Exception:\n",
    "                    obj = item.strip()\n",
    "            else:\n",
    "                obj = item\n",
    "            if isinstance(obj, list):\n",
    "                for author in obj:\n",
    "                    if isinstance(author, dict) and 'name' in author:\n",
    "                        authors_all.append(author['name'])\n",
    "                    elif isinstance(author, str):\n",
    "                        authors_all.append(author)\n",
    "            elif isinstance(obj, dict) and 'name' in obj:\n",
    "                authors_all.append(obj['name'])\n",
    "            elif isinstance(obj, str):\n",
    "                authors_all.append(obj)\n",
    "        author_counts = pd.Series(authors_all).value_counts().reset_index()\n",
    "        author_counts.columns = ['Author', 'Frequency']\n",
    "        author_fn = os.path.join(save_dir, f\"semantic_scholar_{suffix_string}_author_analysis.csv\")\n",
    "        author_counts.to_csv(author_fn, sep=';', encoding='utf-8', index=False)\n",
    "        print(f\"✓ Saved author frequencies: {author_fn}\")\n",
    "    else:\n",
    "        print(\"No 'authors' column found in DF: skipping author frequencies.\")\n",
    "        \n",
    "    if 'venue' in df.columns:\n",
    "        venue_counts = df['venue'].value_counts().reset_index()\n",
    "        venue_counts.columns = ['Venue', 'Frequency']\n",
    "        venue_fn = os.path.join(save_dir, f\"semantic_scholar_{suffix_string}_venue_frequencies.csv\")\n",
    "        venue_counts.to_csv(venue_fn, sep=';', encoding='utf-8', index=False)\n",
    "        print(f\"✓ Saved venue frequencies: {venue_fn}\")\n",
    "    else:\n",
    "        print(\"No 'venue' column found in DF: skipping venue frequencies.\")\n",
    "\n",
    "def save_topic_analysis_outputs(\n",
    "    df, lda_model, lda_vectorizer, topic_distributions, topic_keywords, topic_names, topic_ngrams,\n",
    "    author_stats, top_papers, tfidf_ngrams, suffix_string\n",
    "):\n",
    "    topic_metadata = {\n",
    "        \"topics\": {int(k): v for k,v in topic_keywords.items()},\n",
    "        \"topic_names\": {int(k): v for k,v in topic_names.items()},\n",
    "        \"topic_ngrams\": {int(k): v for k,v in topic_ngrams.items()},\n",
    "    }\n",
    "    with open(os.path.join(SAVE_DIR, f\"topics_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(topic_metadata, f, indent=2)\n",
    "    with open(os.path.join(SAVE_DIR, f\"topic_names_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({int(k):v for k,v in topic_names.items()}, f, indent=2)\n",
    "    np.save(os.path.join(SAVE_DIR, f\"topic_distributions_{suffix_string}.npy\"), topic_distributions)\n",
    "    import joblib\n",
    "    joblib.dump(lda_model, os.path.join(SAVE_DIR, f\"lda_model_{suffix_string}.joblib\"))\n",
    "    joblib.dump(lda_vectorizer, os.path.join(SAVE_DIR, f\"lda_vectorizer_{suffix_string}.joblib\"))\n",
    "    with open(os.path.join(SAVE_DIR, f\"top_papers_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({int(k): v for k, v in top_papers.items()}, f, ensure_ascii=False, indent=2, default=str)\n",
    "    pd.DataFrame.from_dict(author_stats, orient='index').to_csv(\n",
    "        os.path.join(SAVE_DIR, f\"author_stats_{suffix_string}.csv\"))\n",
    "    \n",
    "    # ENHANCED: Save topic-specific TF-IDF n-grams in the new format\n",
    "    if topic_ngrams and isinstance(list(topic_ngrams.values())[0], dict):\n",
    "        # New format with keywords/bigrams/trigrams structure\n",
    "        with open(os.path.join(SAVE_DIR, f\"topic_specific_tfidf_ngrams_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({int(k): v for k, v in topic_ngrams.items()}, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"✓ Saved enhanced topic-specific TF-IDF n-grams to topic_specific_tfidf_ngrams_{suffix_string}.json\")\n",
    "    else:\n",
    "        # Legacy format fallback\n",
    "        with open(os.path.join(SAVE_DIR, f\"topic_specific_tfidf_ngrams_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({int(k):[(term,float(score)) for term,score in v] for k,v in topic_ngrams.items()}, f, indent=2)\n",
    "        print(f\"✓ Saved legacy topic-specific TF-IDF n-grams to topic_specific_tfidf_ngrams_{suffix_string}.json\")\n",
    "\n",
    "def diagnostics_enhanced(df, canonical_scores, variant_scores, canonical_methods, variant_names):\n",
    "    n_docs, n_canonical = canonical_scores.shape\n",
    "    n_variants = variant_scores.shape[1]\n",
    "    \n",
    "    print(\"=== ENHANCED DIAGNOSTICS ===\")\n",
    "    print(f\"Total documents: {n_docs}\")\n",
    "    print(f\"Canonical methods: {n_canonical}\")\n",
    "    print(f\"Method variants: {n_variants}\")\n",
    "    print(f\"Canonical coverage: {(canonical_scores > 0).any(axis=1).sum()}/{n_docs} ({100*(canonical_scores>0).any(axis=1).mean():.1f}%)\")\n",
    "    print(f\"Variant coverage: {(variant_scores > 0).any(axis=1).sum()}/{n_docs} ({100*(variant_scores>0).any(axis=1).mean():.1f}%)\")\n",
    "    \n",
    "    if 'Primary_Method' in df.columns:\n",
    "        print(\"\\nMethod distribution (top 10):\")\n",
    "        method_dist = df['Primary_Method'].value_counts().head(10)\n",
    "        for method, count in method_dist.items():\n",
    "            if method:  # Skip empty strings\n",
    "                print(f\"  {method}: {count}\")\n",
    "    \n",
    "    if 'Method_Confidence' in df.columns:\n",
    "        print(\"\\nConfidence distribution:\")\n",
    "        conf_dist = df['Method_Confidence'].value_counts()\n",
    "        for conf, count in conf_dist.items():\n",
    "            if conf:  # Skip empty strings\n",
    "                print(f\"  {conf}: {count}\")\n",
    "    \n",
    "    print(f\"\\nCanonical methods sample: {canonical_methods[:5]}\")\n",
    "    print(f\"Variant methods sample: {variant_names[:10]}\")\n",
    "    print(f\"\\nCanonical scores stats: mean={canonical_scores.mean():.3f}, std={canonical_scores.std():.3f}\")\n",
    "    print(f\"Variant scores stats: mean={variant_scores.mean():.3f}, std={variant_scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "687dd62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_scores_robust(scores, current_features, target_features):\n",
    "    \n",
    "    #Enhanced alignment with dimension safety checks and detailed error handling.\n",
    "    \n",
    "    if not target_features:\n",
    "        return np.array([]).reshape(scores.shape[0], 0)\n",
    "    \n",
    "    # SAFETY CHECK: Verify dimensions match expectations\n",
    "    expected_cols = len(current_features)\n",
    "    actual_cols = scores.shape[1]\n",
    "    \n",
    "    if expected_cols != actual_cols:\n",
    "        print(f\"⚠️  DIMENSION MISMATCH DETECTED:\")\n",
    "        print(f\"    Expected columns: {expected_cols} (from feature names)\")\n",
    "        print(f\"    Actual columns: {actual_cols} (from score matrix)\")\n",
    "        print(f\"    Using actual matrix dimensions for safety\")\n",
    "        \n",
    "        # Use only the features that actually exist in the matrix\n",
    "        safe_current_features = current_features[:actual_cols]\n",
    "        print(f\"    Truncated feature list: {len(safe_current_features)} features\")\n",
    "    else:\n",
    "        safe_current_features = current_features\n",
    "    \n",
    "    # Initialize aligned matrix with zeros\n",
    "    aligned_scores = np.zeros((scores.shape[0], len(target_features)))\n",
    "    current_to_idx = {feat: i for i, feat in enumerate(safe_current_features)}\n",
    "    \n",
    "    # Map existing features to aligned positions with bounds checking\n",
    "    found_features = 0\n",
    "    skipped_features = 0\n",
    "    \n",
    "    for j, feat in enumerate(target_features):\n",
    "        if feat in current_to_idx:\n",
    "            source_idx = current_to_idx[feat]\n",
    "            \n",
    "            # BOUNDS CHECK: Ensure source index is valid\n",
    "            if source_idx < scores.shape[1]:\n",
    "                aligned_scores[:, j] = scores[:, source_idx]\n",
    "                found_features += 1\n",
    "            else:\n",
    "                print(f\"⚠️  Skipping feature '{feat}': index {source_idx} >= {scores.shape[1]}\")\n",
    "                skipped_features += 1\n",
    "    \n",
    "    print(f\"    ✓ Aligned {found_features}/{len(target_features)} features\")\n",
    "    if skipped_features > 0:\n",
    "        print(f\"    ⚠️  Skipped {skipped_features} features due to bounds issues\")\n",
    "    \n",
    "    return aligned_scores\n",
    "\n",
    "def normalize_scores(scores):\n",
    "    #Normalize scores to  range per matrix for fair weighting.[1]\n",
    "    if scores.max() == 0:\n",
    "        return scores\n",
    "    return scores / scores.max()\n",
    "def enhanced_method_diagnostics(df, scores, method_names, variant_groups):\n",
    "    \n",
    "    #Comprehensive diagnostics for method assignment quality and consolidation effectiveness.\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPREHENSIVE METHOD DETECTION DIAGNOSTICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Basic assignment statistics\n",
    "    n_papers = len(df)\n",
    "    assigned_papers = (df['Primary_Method'] != '').sum()\n",
    "    assignment_rate = 100 * assigned_papers / n_papers\n",
    "    \n",
    "    print(f\"\\n📊 ASSIGNMENT OVERVIEW:\")\n",
    "    print(f\"  Total papers processed: {n_papers:,}\")\n",
    "    print(f\"  Papers with methods assigned: {assigned_papers:,} ({assignment_rate:.1f}%)\")\n",
    "    print(f\"  Papers without methods: {n_papers - assigned_papers:,} ({100-assignment_rate:.1f}%)\")\n",
    "    \n",
    "    # Score distribution analysis\n",
    "    print(f\"\\n📈 SCORE DISTRIBUTION ANALYSIS:\")\n",
    "    print(f\"  Final score matrix shape: {scores.shape}\")\n",
    "    print(f\"  Total canonical methods: {len(method_names)}\")\n",
    "    print(f\"  Score range: [{scores.min():.4f}, {scores.max():.4f}]\")\n",
    "    print(f\"  Mean score: {scores.mean():.4f}\")\n",
    "    print(f\"  Standard deviation: {scores.std():.4f}\")\n",
    "    \n",
    "    # Score threshold analysis\n",
    "    thresholds = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "    for threshold in thresholds:\n",
    "        count = (scores > threshold).sum()\n",
    "        print(f\"  Scores > {threshold}: {count:,} ({100*count/scores.size:.2f}% of all scores)\")\n",
    "    \n",
    "    # Method popularity and assignment quality\n",
    "    if assigned_papers > 0:\n",
    "        print(f\"\\n🔥 TOP ASSIGNED METHODS:\")\n",
    "        method_counts = df['Primary_Method'].value_counts()\n",
    "        \n",
    "        for i, (method, count) in enumerate(method_counts.head(15).items()):\n",
    "            if method:  # Skip empty strings\n",
    "                percentage = 100 * count / assigned_papers\n",
    "                # Check if method was consolidated from variants\n",
    "                variants = variant_groups.get(method, [method])\n",
    "                variant_info = f\" (from {len(variants)} variants)\" if len(variants) > 1 else \"\"\n",
    "                print(f\"  {i+1:2d}. {method}: {count:,} papers ({percentage:.1f}%){variant_info}\")\n",
    "    \n",
    "    # Confidence distribution analysis\n",
    "    if 'Method_Confidence' in df.columns:\n",
    "        print(f\"\\n🎯 CONFIDENCE DISTRIBUTION:\")\n",
    "        conf_counts = df['Method_Confidence'].value_counts()\n",
    "        for conf, count in conf_counts.items():\n",
    "            percentage = 100 * count / n_papers\n",
    "            print(f\"  {conf}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Consolidation effectiveness analysis\n",
    "    print(f\"\\n🔧 CONSOLIDATION EFFECTIVENESS:\")\n",
    "    total_variants = sum(len(variants) for variants in variant_groups.values())\n",
    "    consolidated_groups = len([v for v in variant_groups.values() if len(v) > 1])\n",
    "    \n",
    "    print(f\"  Total method variants processed: {total_variants:,}\")\n",
    "    print(f\"  Final canonical methods: {len(variant_groups):,}\")\n",
    "    print(f\"  Groups with multiple variants: {consolidated_groups:,}\")\n",
    "    print(f\"  Consolidation ratio: {total_variants/len(variant_groups):.2f}:1\")\n",
    "    \n",
    "    # Quality assessment and recommendations\n",
    "    print(f\"\\n⚠️  QUALITY ASSESSMENT:\")\n",
    "    \n",
    "    if assignment_rate < 50:\n",
    "        print(f\"  ⚠️  Low assignment rate ({assignment_rate:.1f}%) - consider:\")\n",
    "        print(f\"      -  Lowering MIN_ASSIGN_SCORE (current: {MIN_ASSIGN_SCORE})\")\n",
    "        print(f\"      -  Reviewing method extraction quality\")\n",
    "        print(f\"      -  Checking text preprocessing effectiveness\")\n",
    "    else:\n",
    "        print(f\"  ✅ Good assignment rate ({assignment_rate:.1f}%)\")\n",
    "    \n",
    "    if scores.max() < 0.1:\n",
    "        print(f\"  ⚠️  Low maximum scores ({scores.max():.4f}) - scoring method may need adjustment\")\n",
    "    else:\n",
    "        print(f\"  ✅ Reasonable maximum scores ({scores.max():.4f})\")\n",
    "    \n",
    "    zero_score_methods = (scores.max(axis=0) == 0).sum()\n",
    "    if zero_score_methods > 0:\n",
    "        zero_percentage = 100 * zero_score_methods / len(method_names)\n",
    "        print(f\"  ⚠️  {zero_score_methods} methods ({zero_percentage:.1f}%) have zero scores across all papers\")\n",
    "        print(f\"      Consider reviewing method extraction or scoring parameters\")\n",
    "    else:\n",
    "        print(f\"  ✅ All methods have non-zero scores in at least some papers\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    return {\n",
    "        'assignment_rate': assignment_rate,\n",
    "        'total_papers': n_papers,\n",
    "        'assigned_papers': assigned_papers,\n",
    "        'score_stats': {\n",
    "            'min': scores.min(),\n",
    "            'max': scores.max(),\n",
    "            'mean': scores.mean(),\n",
    "            'std': scores.std()\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db56121",
   "metadata": {},
   "source": [
    "### Topic and author analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f31ba70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved term frequency summary to Saved_files_new\\term_frequencies_2025_09_30_reliability_resilience_power_systems.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 10:14:55,076 - INFO - Starting topic modeling workflow...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved author frequencies: Saved_files_new\\semantic_scholar_2025_09_30_reliability_resilience_power_systems_author_analysis.csv\n",
      "✓ Saved venue frequencies: Saved_files_new\\semantic_scholar_2025_09_30_reliability_resilience_power_systems_venue_frequencies.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 10:14:55,384 - INFO - collecting all words and their counts\n",
      "2025-09-30 10:14:55,384 - INFO - PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2025-09-30 10:14:56,881 - INFO - PROGRESS: at sentence #10000, processed 1525966 words and 864319 word types\n",
      "2025-09-30 10:14:58,315 - INFO - PROGRESS: at sentence #20000, processed 3006723 words and 1468449 word types\n",
      "2025-09-30 10:14:59,863 - INFO - PROGRESS: at sentence #30000, processed 4445145 words and 1949442 word types\n",
      "2025-09-30 10:15:00,001 - INFO - collected 1990025 token types (unigram + bigrams) from a corpus of 4575260 words and 30917 sentences\n",
      "2025-09-30 10:15:00,002 - INFO - merged Phrases<1990025 vocab, min_count=10, threshold=50, max_vocab_size=40000000>\n",
      "2025-09-30 10:15:00,005 - INFO - Phrases lifecycle event {'msg': 'built Phrases<1990025 vocab, min_count=10, threshold=50, max_vocab_size=40000000> in 4.62s', 'datetime': '2025-09-30T10:15:00.005445', 'gensim': '4.3.2', 'python': '3.11.13 (main, Jun 12 2025, 12:41:34) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "2025-09-30 10:15:00,005 - INFO - collecting all words and their counts\n",
      "2025-09-30 10:15:00,006 - INFO - PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2025-09-30 10:15:03,123 - INFO - PROGRESS: at sentence #10000, processed 1472158 words and 886563 word types\n",
      "2025-09-30 10:15:06,321 - INFO - PROGRESS: at sentence #20000, processed 2892069 words and 1519970 word types\n",
      "2025-09-30 10:15:09,489 - INFO - PROGRESS: at sentence #30000, processed 4263335 words and 2032513 word types\n",
      "2025-09-30 10:15:09,788 - INFO - collected 2075824 token types (unigram + bigrams) from a corpus of 4387743 words and 30917 sentences\n",
      "2025-09-30 10:15:09,789 - INFO - merged Phrases<2075824 vocab, min_count=5, threshold=50, max_vocab_size=40000000>\n",
      "2025-09-30 10:15:09,790 - INFO - Phrases lifecycle event {'msg': 'built Phrases<2075824 vocab, min_count=5, threshold=50, max_vocab_size=40000000> in 9.79s', 'datetime': '2025-09-30T10:15:09.790721', 'gensim': '4.3.2', 'python': '3.11.13 (main, Jun 12 2025, 12:41:34) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "2025-09-30 10:17:34,065 - INFO - ✓ LDA topic modeling completed.\n",
      "2025-09-30 10:17:34,324 - INFO - ✓ Papers assigned to topics based on LDA distributions.\n",
      "2025-09-30 10:17:34,325 - INFO - Extracting enhanced topic-specific TF-IDF n-grams...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Extracting topic-specific n-grams...\n",
      "📊 Processing 30917 documents across 10 topics\n",
      "📈 Processing keywords (1-1 grams)...\n",
      "  ✅ Created 32526 keywords features\n",
      "📈 Processing bigrams (2-2 grams)...\n",
      "  ✅ Created 436411 bigrams features\n",
      "📈 Processing trigrams (3-3 grams)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 10:17:50,657 - INFO - ✓ Extracted enhanced topic-specific TF-IDF n-grams for naming.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Created 264787 trigrams features\n",
      "\n",
      "📊 N-gram Extraction Summary:\n",
      "  Topic 0:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 1:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 2:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 3:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 4:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 5:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 6:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 7:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 8:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 9:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 10:17:52,918 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:17:54,663 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:17:55,975 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:17:55,978 - INFO - Topic 0: Wireless Communication Systems\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Wireless Communication Systems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 10:17:57,598 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:17:59,394 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:00,011 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:00,018 - INFO - Topic 1: Power System Reliability\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Power System Reliability\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 10:18:03,567 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:06,883 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:09,882 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:09,888 - INFO - Topic 2: Renewable Energy Systems\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Renewable Energy Systems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 10:18:11,020 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:12,365 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:13,152 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:13,156 - INFO - Topic 3: Electric Vehicle Battery Systems\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Electric Vehicle Battery Systems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 10:18:14,138 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:14,814 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:16,310 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:16,317 - INFO - Topic 4: Energy Resilience Management\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Energy Resilience Management\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 10:18:17,974 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:18,925 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:19,401 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:19,408 - INFO - Topic 5: Thermal Energy Systems\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Thermal Energy Systems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 10:18:20,412 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:21,298 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:21,976 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:21,992 - INFO - Topic 6: Renewable Energy Optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Renewable Energy Optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 10:18:23,305 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:24,415 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:25,450 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:25,458 - INFO - Topic 7: Water Energy Systems\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Water Energy Systems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 10:18:26,504 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:26,926 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:27,403 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:27,444 - INFO - Topic 8: Smart Network Reliability\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Smart Network Reliability\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 10:18:28,860 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:29,428 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:30,117 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 10:18:30,122 - INFO - Topic 9: Power System Control\n",
      "2025-09-30 10:18:30,131 - INFO - ✓ Topic naming and assignment completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Power System Control\n",
      "✓ Saved enhanced topic-specific TF-IDF n-grams to topic_specific_tfidf_ngrams_2025_09_30_reliability_resilience_power_systems.json\n",
      "\n",
      "Sample topics and names:\n",
      "{0: 'Wireless Communication Systems', 1: 'Power System Reliability', 2: 'Renewable Energy Systems', 3: 'Electric Vehicle Battery Systems', 4: 'Energy Resilience Management'}\n",
      "\n",
      "📊 Enhanced N-grams Structure Sample:\n",
      "Topic 0 (Wireless Communication Systems):\n",
      "  keywords: [('communication', 0.05952357402952956), ('channel', 0.05415651052964458), ('network', 0.05195755025204625), ('wireless', 0.043335504838006085), ('user', 0.03508300912112406)]\n",
      "  bigrams: [('power allocation', 0.014523518301132025), ('wireless communication', 0.012700154332130124), ('multiple access', 0.010141318320924015), ('data rate', 0.009929391975903307), ('base station', 0.009328527408284647)]\n",
      "  trigrams: [('bit error rate', 0.009837525248469871), ('input multiple output', 0.0097201250798645), ('multiple input multiple', 0.009572333694543017), ('wireless sensor network', 0.009292651261296513), ('multiple output mimo', 0.007125540767331956)]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 9: Enhanced Topic Analysis Workflow with Multi-N-gram Support\n",
    "\n",
    "NUM_TOPICS = 10\n",
    "NUM_TOPIC_WORDS = 20\n",
    "TOPIC_LLM_ITER_INIT = 3\n",
    "TOPIC_LLM_ITER_MAX = 9\n",
    "TOPIC_LLM_SIM_THRESH = 0.8\n",
    "TOPIC_LLM_TEMP = 0.2 #TOPIC_LLM_TOP_P = 0.2 # Adjust only one of these\n",
    "\n",
    "\n",
    "current_date = datetime.now().strftime(\"%Y_%m_%d\")\n",
    "keyword_str = '_'.join(extract_keywords_from_filename(filename)) if 'filename' in locals() else \"\"\n",
    "suffix_string = f\"{current_date}_{keyword_str}\"\n",
    "\n",
    "# Save basic term frequencies and author/venue analysis\n",
    "save_term_frequencies(df, suffix_string)\n",
    "save_author_and_venue_frequencies(df, suffix_string)\n",
    "\n",
    "logger.info(\"Starting topic modeling workflow...\")  \n",
    "lda_model, lda_vectorizer, topic_distributions, topic_keywords = run_lda_topic_modeling(\n",
    "    df, num_topics=NUM_TOPICS, num_words=NUM_TOPIC_WORDS)\n",
    "logger.info(\"✓ LDA topic modeling completed.\")\n",
    "\n",
    "paper_classifications = assign_papers_to_topics(topic_distributions)\n",
    "df['Primary_Topic_Index'] = [int(p['primary_topic']) for p in paper_classifications]\n",
    "df['Primary_Score'] = [p['primary_score'] for p in paper_classifications]\n",
    "df['Dominance_Ratio'] = [p['dominance_ratio'] for p in paper_classifications]\n",
    "\n",
    "logger.info(\"✓ Papers assigned to topics based on LDA distributions.\")\n",
    "\n",
    "# ENHANCED: Use the new multi-n-gram extraction function\n",
    "logger.info(\"Extracting enhanced topic-specific TF-IDF n-grams...\")\n",
    "topic_ngrams = get_top_tfidf_ngrams_per_topic_enhanced(\n",
    "    df, topic_col='Primary_Topic_Index', text_col='processed_text', top_k=15, min_df=2, max_df=0.8\n",
    ")\n",
    "logger.info(\"✓ Extracted enhanced topic-specific TF-IDF n-grams for naming.\")\n",
    "\n",
    "# Generate topic names using enhanced n-grams\n",
    "topic_names = {}\n",
    "for topic_idx, keywords in topic_keywords.items():\n",
    "    lda_ngrams = keywords['top_words'][:NUM_TOPIC_WORDS]\n",
    "    \n",
    "    # ENHANCED: Use keywords from the new structure\n",
    "    topic_data = topic_ngrams.get(topic_idx, {})\n",
    "    tfidf_keywords = list(topic_data.get('keywords', {}).keys())[:NUM_TOPIC_WORDS]\n",
    "    \n",
    "    top_titles = get_top_titles_for_topic(df, paper_classifications, topic_idx, n_titles=10)\n",
    "    topic_name = topic_name_llm_robust(\n",
    "        lda_ngrams, tfidf_keywords, top_titles,\n",
    "        client, model_type, credit_tracker,\n",
    "        initial_iterations=TOPIC_LLM_ITER_INIT,\n",
    "        max_iterations=TOPIC_LLM_ITER_MAX,\n",
    "        similarity_threshold=TOPIC_LLM_SIM_THRESH,\n",
    "        temp=TOPIC_LLM_TEMP#, top_p=TOPIC_LLM_TOP_P\n",
    "    )\n",
    "    topic_names[topic_idx] = topic_name\n",
    "    logger.info(f\"Topic {topic_idx}: {topic_name if topic_name else 'Unnamed'}\")\n",
    "\n",
    "df['Primary_Topic'] = df['Primary_Topic_Index'].map(lambda x: topic_names.get(x, f\"Topic_{x}\"))\n",
    "logger.info(\"✓ Topic naming and assignment completed.\")\n",
    "\n",
    "top_papers, author_stats = get_author_stats(paper_classifications, df, n_top=5)\n",
    "\n",
    "# ENHANCED: Save with the new n-grams structure\n",
    "save_topic_analysis_outputs(df, lda_model, lda_vectorizer, topic_distributions, \n",
    "                           topic_keywords, topic_names, topic_ngrams, author_stats, \n",
    "                           top_papers, topic_ngrams, suffix_string)\n",
    "\n",
    "print(\"\\nSample topics and names:\")\n",
    "print({k: topic_names[k] for k in list(topic_names)[:5]})\n",
    "\n",
    "# Show sample of enhanced n-grams structure\n",
    "if topic_ngrams:\n",
    "    print(f\"\\n📊 Enhanced N-grams Structure Sample:\")\n",
    "    sample_topic = list(topic_ngrams.keys())[0]\n",
    "    sample_data = topic_ngrams[sample_topic]\n",
    "    topic_name = topic_names.get(sample_topic, f\"Topic {sample_topic}\")\n",
    "    print(f\"Topic {sample_topic} ({topic_name}):\")\n",
    "    for ngram_type in ['keywords', 'bigrams', 'trigrams']:\n",
    "        terms = sample_data.get(ngram_type, {})\n",
    "        if terms:\n",
    "            top_terms = list(terms.items())[:5]\n",
    "            print(f\"  {ngram_type}: {top_terms}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddcaf9d",
   "metadata": {},
   "source": [
    "### Method analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbac9820",
   "metadata": {},
   "source": [
    "#### old prompt definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877ab3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are a comprehensive research methodology expert analyzing power systems literature.\\n\\nTASK: Extract ONLY, but ALL phrases that can be strictly defined as a specific research method, algorithm, and/or techniques from these candidate terms.\\nGOAL: Find all the qualified phrases in this batch. Be thorough and comprehensive. Generic terms or terms that are describing the objectiv or result of analysis does not qualify\\n\\nCandidate terms: {candidate_terms}\\n\\nCOMPREHENSIVE EXTRACTION CRITERIA:\\n✅ INCLUDE specific methods, algorithms and/or techniques in these categories:\\n1. Named algorithms: genetic algorithm, differential evolution...\\n2. Mathematical methods: monte carlo simulation, linear programming...\\n3. Machine learning: neural network, support vector machine...\\n4. Analysis techniques: fault tree analysis, load flow analysis...\\n5. Power system analysis methods: unit commitment, optimal power flow...\\n6. Power system indicator terms: LOLE, EENS, PTDF...\\n\\nDistinguish between actuall analysis-method, algorithms and/or technique phrases and objectives of an anlysis.\\nDiscard typicall generic phrases or phrases that describe the objective(goal) rather than the method, algoritm and/or technique, e.g.  'Risk assesment', 'Capacity utilization', 'Control Strategy' \\nKeep method, algorithm and/or technique phrases used in connection to such objectives\\n\\nTARGET: Extract only specific research methods, algorithm and/or techniques that are qualified by the above criteriasfrom this batch.\\nReview the list before finalizing to make sure it only contains qualified terms are \\nReturn as Python list with comprehensive coverage:\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#old prompt versions\n",
    "\"\"\"You are a comprehensive research methodology expert analyzing power systems literature.\n",
    "\n",
    "TASK: Extract ONLY, but ALL phrases that can be strictly defined as a specific research method, algorithm, and/or techniques from these candidate terms.\n",
    "GOAL: Find all the qualified phrases in this batch. Be thorough and comprehensive. Generic terms or terms that are describing the objectiv or result of analysis does not qualify\n",
    "\n",
    "Candidate terms: {candidate_terms}\n",
    "\n",
    "COMPREHENSIVE EXTRACTION CRITERIA:\n",
    "✅ INCLUDE specific methods, algorithms and/or techniques in these categories:\n",
    "1. Named algorithms: genetic algorithm, differential evolution...\n",
    "2. Mathematical methods: monte carlo simulation, linear programming...\n",
    "3. Machine learning: neural network, support vector machine...\n",
    "4. Analysis techniques: fault tree analysis, load flow analysis...\n",
    "5. Power system analysis methods: unit commitment, optimal power flow...\n",
    "6. Power system indicator terms: LOLE, EENS, PTDF...\n",
    "\n",
    "Distinguish between actuall analysis-method, algorithms and/or technique phrases and objectives of an anlysis.\n",
    "Discard typicall generic phrases or phrases that describe the objective(goal) rather than the method, algoritm and/or technique, e.g.  'Risk assesment', 'Capacity utilization', 'Control Strategy' \n",
    "Keep method, algorithm and/or technique phrases used in connection to such objectives\n",
    "\n",
    "TARGET: Extract only specific research methods, algorithm and/or techniques that are qualified by the above criteriasfrom this batch.\n",
    "Review the list before finalizing to make sure it only contains qualified terms are \n",
    "Return as Python list with comprehensive coverage:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c81908",
   "metadata": {},
   "source": [
    "#### Prompt definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ed7bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your extraction prompt\n",
    "extraction_prompt = improved_extraction_prompt = \"\"\"You are a research methodology extraction expert specializing in power systems literature history, seminal work and recend advances.\n",
    "\n",
    "TASK: From the candidate terms below, extract ALL terms that represent specific, named research methodologies, algorithms, or techniques.\n",
    "\n",
    "Candidate terms: {candidate_terms}\n",
    "\n",
    "QUALIFICATION CRITERIA - A term qualifies if it is:\n",
    "✅ A NAMED algorithm, method, or technique with specific definition\n",
    "✅ A SPECIFIC mathematical/computational approach \n",
    "✅ A WELL-DEFINED analysis technique with established procedure\n",
    "✅ A RECOGNIZED power systems methodology\n",
    "\n",
    "INCLUDE these categories:\n",
    "1. Named algorithms: \"genetic algorithm\", \"particle swarm optimization\", \"differential evolution\"\n",
    "2. Mathematical methods: \"monte carlo simulation\", \"linear programming\", \"quadratic programming\" \n",
    "3. Machine learning: \"neural network\", \"support vector machine\", \"random forest\", \"k-means clustering\"\n",
    "4. Analysis techniques: \"fault tree analysis\", \"load flow analysis\", \"modal analysis\", \"sensitivity analysis\"\n",
    "5. Power system methods: \"unit commitment\", \"optimal power flow\", \"economic dispatch\", \"state estimation\"\n",
    "6. Power system indicators: \"LOLE\", \"EENS\", \"PTDF\", \"LODF\" (specific technical acronyms)\n",
    "\n",
    "EXCLUDE these patterns:\n",
    "❌ Generic nouns: \"method\", \"analysis\", \"approach\", \"technique\", \"framework\", \"system\", \"procedure\"\n",
    "❌ Generic combinations: \"energy analysis\", \"power method\", \"system approach\", \"network optimization\"\n",
    "❌ Process descriptions: \"optimization process\", \"analysis procedure\", \"design methodology\" \n",
    "❌ Objective descriptions: \"performance improvement\", \"efficiency enhancement\", \"cost reduction\"\n",
    "❌ Research activities: \"literature review\", \"case study\", \"experimental analysis\", \"field research\"\n",
    "\n",
    "DECISION PROCESS:\n",
    "1. Scan each candidate term\n",
    "2. Ask: \"Is this a specific, named methodology that a researcher could implement?\"\n",
    "3. If yes and fits categories above → INCLUDE\n",
    "4. If generic or describes outcome/process → EXCLUDE\n",
    "\n",
    "EXAMPLES:\n",
    "✅ INCLUDE: \"monte carlo simulation\" (specific technique), \"unit commitment\" (specific power systems method)\n",
    "❌ EXCLUDE: \"energy analysis\" (generic), \"optimization approach\" (too broad), \"case study\" (research activity)\n",
    "\n",
    "Extract ALL qualifying terms from the candidate list. Be comprehensive within the qualification criteria, when in doubt, include the term.\n",
    "\n",
    "Return as a clean Python list: [\"term1\", \"term2\", \"term3\", ...]\"\"\"\n",
    "\n",
    "\n",
    "# Define your grouping prompt  \n",
    "grouping_prompt = \"\"\"You are an expert in power systems analysis methods. Your task is to group variants of the same core technique.\n",
    "\n",
    "Methods to analyze: {method_list}\n",
    "\n",
    "STRICT GROUPING RULES:\n",
    "\n",
    "✅ GROUP these cases (same core method):\n",
    "- Abbreviation + full form: e.g. opf\" with \"optimal power flow\" and \"copt\" with \"capacity outage probability table\"\n",
    "- Method + descriptor: \"neural network\" with \"artificial neural network\" \n",
    "- Acronym + full name: e.g. \"anfis\" with \"adaptive neuro fuzzy inference system\"\n",
    "- Slight variations: \"monte carlo\" with \"monte carlo simulation\"\n",
    "- Same indices: \"saifi\" with \"system average interruption frequency index\"\n",
    "\n",
    "❌ NEVER GROUP these cases (different methods):\n",
    "- Different algorithm types: \"linear programming\" ≠ \"nonlinear programming\"\n",
    "- Different orders/levels: \"first order\" ≠ \"second order reliability method\"  \n",
    "- Different shift factors: \"generation shift factors\" ≠ \"injection shift factors\"\n",
    "- Different optimization algorithms: \"genetic algorithm\" ≠ \"particle swarm\"\n",
    "- Different neural networks: \"lstm\" ≠ \"gru\"\n",
    "\n",
    "CANONICAL SELECTION:\n",
    "- Always use the FULL descriptive name as the canonical form\n",
    "- Never use abbreviations as canonical forms\n",
    "- Example: Use \"optimal power flow\" not \"opf\"\n",
    "\n",
    "Return a Python dictionary where:\n",
    "- Keys are FULL canonical method names (never abbreviations)\n",
    "- Values are lists of ALL variants including the canonical form itself\n",
    "\n",
    "Example format:\n",
    "{{\n",
    "  \"optimal power flow\": [\"optimal power flow\", \"opf\", \"power flow optimization\"],\n",
    "  \"monte carlo simulation\": [\"monte carlo simulation\", \"monte carlo\", \"monte-carlo\"]\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6a72660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:38:25,213 - INFO - === Starting Method Extraction and Grouping Phase ===\n",
      "2025-09-30 13:38:25,213 - INFO - Step 1: Loading or extracting method phrases...\n",
      "2025-09-30 13:38:25,218 - INFO -   ✓ Loaded 386 method phrases from existing CSV\n",
      "2025-09-30 13:38:25,218 - INFO - ✓ Method phrase extraction complete: 386 phrases\n",
      "2025-09-30 13:38:25,219 - INFO - Step 2: Building enhanced method variant groups with consolidation...\n",
      "2025-09-30 13:38:25,220 - INFO -  No existing variant groups found. Running LLM grouping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sample methods: ['deep learning approach', 'genetic programming', 'wavelet transform dwt', 'simulated annealing', 'multi-fidelity task', 'two-stage stochastic', 'hybrid system modeling', 'multi-agent', 'bayesian optimization', 'multi-fidelity activity']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:39:22,432 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-30 13:39:22,577 - INFO - LLM raw response: ChatCompletion(id='chatcmpl-CLSyUk0mjQIrH5v2vd2o19kQLlNvi', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\n{\\n    \"deep learning approach\": [\"deep learning approach\", \"deep learning algorithm\", \"deep learning model\", \"deep learning-based\", \"deep learning\"],\\n    \"genetic programming\": [\"genetic programming\", \"genetic algorithm\", \"genetic algorithm based\", \"non-dominated sorting genetic algorithm\", \"non-dominated sorting genetic\"],\\n    \"wavelet transform dwt\": [\"wavelet transform dwt\", \"discrete wavelet transform dwt\", \"discrete wavelet transform\"],\\n    \"simulated annealing\": [\"simulated annealing\"],\\n    \"multi-fidelity task\": [\"multi-fidelity task\", \"multi-fidelity activity\", \"multi-fidelity investigation\", \"multi-fidelity application\", \"multi-fidelity analysis\", \"multi-fidelity verification\", \"multi-fidelity study\", \"multi-fidelity endeavor\", \"multi-fidelity structure\", \"multi-fidelity project\", \"multi-fidelity design\", \"multi-fidelity operation\", \"multi-fidelity methodology\", \"multi-fidelity optimization\", \"multi-fidelity framework\", \"multi-fidelity technique\", \"multi-fidelity modeling\", \"multi-fidelity simulation\"],\\n    \"two-stage stochastic\": [\"two-stage stochastic\", \"two-stage robust\"],\\n    \"hybrid system modeling\": [\"hybrid system modeling\", \"hybrid optimization model\", \"hybrid energy storage\", \"hybrid acdc microgrid\", \"hybrid acdc microgrids\"],\\n    \"multi-agent\": [\"multi-agent\", \"multi-agent system\"],\\n    \"bayesian optimization\": [\"bayesian optimization\"],\\n    \"energy demand forecasting\": [\"energy demand forecasting\", \"short-term load forecasting\", \"load forecasting\", \"supply-demand forecasting\", \"energy production forecasting\", \"wind power prediction\"],\\n    \"big data analysis\": [\"big data analysis\", \"data-driven optimization\", \"data-driven method\", \"real-time data analysis\", \"data mining\"],\\n    \"fuzzy comprehensive evaluation\": [\"fuzzy comprehensive evaluation\", \"fuzzy logic\", \"fuzzy logic controller\", \"fuzzy logic controller flc\", \"fuzzy inference system\"],\\n    \"iterative methods\": [\"iterative methods\", \"iterative algorithm\"],\\n    \"alternating direction method multiplier\": [\"alternating direction method multiplier\", \"alternating direction method\"],\\n    \"probabilistic production simulation\": [\"probabilistic production simulation\", \"probabilistic model\"],\\n    \"k-nearest\": [\"k-nearest\", \"k-nearest neighbor\", \"k-nearest clustering\"],\\n    \"metaheuristics\": [\"metaheuristics\", \"heuristic optimization\"],\\n    \"energy resilience analysis\": [\"energy resilience analysis\"],\\n    \"numerical method\": [\"numerical method\"],\\n    \"support vector regression\": [\"support vector regression\", \"support vector regression svr\", \"support vector machine\"],\\n    \"anfis\": [\"anfis\", \"adaptive neuro-fuzzy inference\", \"adaptive neuro-fuzzy inference system\"],\\n    \"neural network based\": [\"neural network based\", \"neural network\", \"artificial neural network\", \"neural network model\", \"neural network anns\", \"neural network algorithm\"],\\n    \"energy efficiency modeling\": [\"energy efficiency modeling\"],\\n    \"optimal power flow\": [\"optimal power flow\", \"opf\"],\\n    \"stochastic model\": [\"stochastic model\", \"stochastic modeling\", \"stochastic programming\", \"stochastic unit commitment\"],\\n    \"short-term memory lstm network\": [\"short-term memory lstm network\"],\\n    \"linear programming\": [\"linear programming\"],\\n    \"mean absolute\": [\"mean absolute\", \"mean absolute error mae\", \"mean absolute percentage error\"],\\n    \"reactive power sharing\": [\"reactive power sharing\"],\\n    \"zero energy\": [\"zero energy\"],\\n    \"multi-user detection\": [\"multi-user detection\", \"multi-user mimo\"],\\n    \"maximum power point tracking\": [\"maximum power point tracking\"],\\n    \"feedback control\": [\"feedback control\"],\\n    \"modified ieee rts\": [\"modified ieee rts\"],\\n    \"monte-carlo simulation\": [\"monte-carlo simulation\", \"monte carlo\", \"monte-carlo\"],\\n    \"voltage control strategy\": [\"voltage control strategy\", \"voltage control\"],\\n    \"multi-fidelity\": [\"multi-fidelity\", \"multi-fidelity approach\"],\\n    \"principal component analysis pca\": [\"principal component analysis pca\", \"principal component analysis\"],\\n    \"optimal utilization\": [\"optimal utilization\"],\\n    \"adaptive neuro-fuzzy inference\": [\"adaptive neuro-fuzzy inference\"],\\n    \"resource allocation algorithm\": [\"resource allocation algorithm\", \"resource allocation scheme\", \"resource allocation\"],\\n    \"dynamic programming\": [\"dynamic programming\"],\\n    \"multi-objective optimization\": [\"multi-objective optimization\", \"multi-objective optimization method\", \"multi-objective optimization model\", \"multi-objective optimization problem\", \"multi-objective particle swarm optimization\"],\\n    \"bee colony\": [\"bee colony\", \"bee colony algorithm\", \"artificial bee colony algorithm\"],\\n    \"static var compensator svc\": [\"static var compensator svc\", \"static var compensator\"],\\n    \"power system stabilizer\": [\"power system stabilizer\"],\\n    \"supply-demand forecasting\": [\"supply-demand forecasting\"],\\n    \"dynamic voltage restorer dvr\": [\"dynamic voltage restorer dvr\", \"dynamic voltage restorer\"],\\n    \"global search\": [\"global search\"],\\n    \"fault detection diagnosis\": [\"fault detection diagnosis\", \"fault detection classification\", \"fault detection\"],\\n    \"energy consumption modeling\": [\"energy consumption modeling\"],\\n    \"multi-fidelity assessment\": [\"multi-fidelity assessment\"],\\n    \"multi-fidelity exploration\": [\"multi-fidelity exploration\"],\\n    \"multi-fidelity testing\": [\"multi-fidelity testing\"],\\n    \"multi-fidelity validation\": [\"multi-fidelity validation\"],\\n    \"multi-fidelity evaluation\": [\"multi-fidelity evaluation\"],\\n    \"demand side management dsm\": [\"demand side management dsm\", \"demand response dr\", \"demand response\"],\\n    \"k-means\": [\"k-means\", \"k-means clustering\"],\\n    \"load frequency control lfc\": [\"load frequency control lfc\", \"load frequency control\"],\\n    \"dynamic reactive power compensation\": [\"dynamic reactive power compensation\"],\\n    \"multi-fidelity initiative\": [\"multi-fidelity initiative\"],\\n    \"energy transition strategy\": [\"energy transition strategy\", \"energy transition modeling\"],\\n    \"multi-state model\": [\"multi-state model\"],\\n    \"multi-modal\": [\"multi-modal\"],\\n    \"multi-fidelity framework\": [\"multi-fidelity framework\"],\\n    \"multi-fidelity program\": [\"multi-fidelity program\"],\\n    \"multi-fidelity structure\": [\"multi-fidelity structure\"],\\n    \"multi-fidelity design\": [\"multi-fidelity design\"],\\n    \"multi-fidelity operation\": [\"multi-fidelity operation\"],\\n    \"multi-fidelity methodology\": [\"multi-fidelity methodology\"],\\n    \"multi-fidelity optimization\": [\"multi-fidelity optimization\"],\\n    \"multi-fidelity simulation\": [\"multi-fidelity simulation\"],\\n    \"multi-fidelity modeling\": [\"multi-fidelity modeling\"],\\n    \"multi-fidelity project\": [\"multi-fidelity project\"],\\n    \"multi-fidelity effort\": [\"multi-fidelity effort\"],\\n    \"multi-fidelity study\": [\"multi-fidelity study\"],\\n    \"multi-fidelity task\": [\"multi-fidelity task\"],\\n    \"multi-fidelity application\": [\"multi-fidelity application\"],\\n    \"multi-fidelity analysis\": [\"multi-fidelity analysis\"],\\n    \"multi-fidelity verification\": [\"multi-fidelity verification\"],\\n    \"multi-fidelity investigation\": [\"multi-fidelity investigation\"],\\n    \"multi-fidelity activity\": [\"multi-fidelity activity\"],\\n    \"multi-fidelity endeavor\": [\"multi-fidelity endeavor\"],\\n    \"multi-fidelity exploration\": [\"multi-fidelity exploration\"],\\n    \"multi-fidelity validation\": [\"multi-fidelity validation\"],\\n    \"multi-fidelity evaluation\": [\"multi-fidelity evaluation\"],\\n    \"multi-fidelity testing\": [\"multi-fidelity testing\"],\\n    \"multi-fidelity assessment\": [\"multi-fidelity assessment\"],\\n    \"multi-fidelity initiative\": [\"multi-fidelity initiative\"],\\n    \"multi-fidelity framework\": [\"multi-fidelity framework\"],\\n    \"multi-fidelity program\": [\"multi-fidelity program\"],\\n    \"multi-fidelity structure\": [\"multi-fidelity structure\"],\\n    \"multi-fidelity design\": [\"multi-fidelity design\"],\\n    \"multi-fidelity operation\": [\"multi-fidelity operation\"],\\n    \"multi-fidelity methodology\": [\"multi-fidelity methodology\"],\\n    \"multi-fidelity optimization\": [\"multi-fidelity optimization\"],\\n    \"multi-fidelity simulation\": [\"multi-fidelity simulation\"],\\n    \"multi-fidelity modeling\": [\"multi-fidelity modeling\"],\\n    \"multi-fidelity project\": [\"multi-fidelity project\"],\\n    \"multi-fidelity effort\": [\"multi-fidelity effort\"],\\n    \"multi-fidelity study\": [\"multi-fidelity study\"],\\n    \"multi-fidelity task\": [\"multi-fidelity task\"],\\n    \"multi-fidelity application\": [\"multi-fidelity application\"],\\n    \"multi-fidelity analysis\": [\"multi-fidelity analysis\"],\\n    \"multi-fidelity verification\": [\"multi-fidelity verification\"],\\n    \"multi-fidelity investigation\": [\"multi-fidelity investigation\"],\\n    \"multi-fidelity activity\": [\"multi-fidelity activity\"],\\n    \"multi-fidelity endeavor\": [\"multi-fidelity endeavor\"],\\n    \"multi-fidelity exploration\": [\"multi-fidelity exploration\"],\\n    \"multi-fidelity validation\": [\"multi-fidelity validation\"],\\n    \"multi-fidelity evaluation\": [\"multi-fidelity evaluation\"],\\n    \"multi-fidelity testing\": [\"multi-fidelity testing\"],\\n    \"multi-fidelity assessment\": [\"multi-fidelity assessment\"],\\n    \"multi-fidelity initiative\": [\"multi-fidelity initiative\"],\\n    \"multi-fidelity framework\": [\"multi-fidelity framework\"],\\n    \"multi-fidelity program\": [\"multi-fidelity program\"],\\n    \"multi-fidelity structure\": [\"multi-fidelity structure\"],\\n    \"multi-fidelity design\": [\"multi-fidelity design\"],\\n    \"multi-fidelity operation\": [\"multi-fidelity operation\"],\\n    \"multi-fidelity methodology\": [\"multi-fidelity methodology\"],\\n    \"multi-fidelity optimization\": [\"multi-fidelity optimization\"],\\n    \"multi-fidelity simulation\": [\"multi-fidelity simulation\"],\\n    \"multi-fidelity modeling\": [\"multi-fidelity modeling\"],\\n    \"multi-fidelity project\": [\"multi-fidelity project\"],\\n    \"multi-fidelity effort\": [\"multi-fidelity effort\"],\\n    \"multi-fidelity study\": [\"multi-fidelity study\"],\\n    \"multi-fidelity task\": [\"multi-fidelity task\"],\\n    \"multi-fidelity application\": [\"multi-fidelity application\"],\\n    \"multi-fidelity analysis\": [\"multi-fidelity analysis\"],\\n    \"multi-fidelity verification\": [\"multi-fidelity verification\"],\\n    \"multi-fidelity investigation\": [\"multi-fidelity investigation\"],\\n    \"multi-fidelity activity\": [\"multi-fidelity activity\"],\\n    \"multi-fidelity endeavor\": [\"multi-fidelity endeavor\"],\\n    \"multi-fidelity exploration\": [\"multi-fidelity exploration\"],\\n    \"multi-fidelity validation\": [\"multi-fidelity validation\"],\\n    \"multi-fidelity evaluation\": [\"multi-fidelity evaluation\"],\\n    \"multi-fidelity testing\": [\"multi-fidelity testing\"],\\n    \"multi-fidelity assessment\": [\"multi-fidelity assessment\"],\\n    \"multi-fidelity initiative\": [\"multi-fidelity initiative\"],\\n    \"multi-fidelity framework\": [\"multi-fidelity framework\"],\\n    \"multi-fidelity program\": [\"multi-fidelity program\"],\\n    \"multi-fidelity structure\": [\"multi-fidelity structure\"],\\n    \"multi-fidelity design\": [\"multi-fidelity design\"],\\n    \"multi-fidelity operation\": [\"multi-fidelity operation\"],\\n    \"multi-fidelity methodology\": [\"multi-fidelity methodology\"],\\n    \"multi-fidelity optimization\": [\"multi-fidelity optimization\"],\\n    \"multi-fidelity simulation\": [\"multi-fidelity simulation\"],\\n    \"multi-fidelity modeling\": [\"multi-fidelity modeling\"],\\n    \"multi-fidelity project\": [\"multi-fidelity project\"],\\n    \"multi-fidelity effort\": [\"multi-fidelity effort\"],\\n    \"multi-fidelity study\": [\"multi-fidelity study\"],\\n    \"multi-fidelity task\": [\"multi-fidelity task\"],\\n    \"multi-fidelity application\": [\"multi-fidelity application\"],\\n    \"multi-fidelity analysis\": [\"multi-fidelity analysis\"],\\n    \"multi-fidelity verification\": [\"multi-fidelity verification\"],\\n    \"multi-fidelity investigation\": [\"multi-fidelity investigation\"],\\n    \"multi-fidelity activity\": [\"multi-fidelity activity\"],\\n    \"multi-fidelity endeavor\": [\"multi-fidelity endeavor\"],\\n    \"multi-fidelity exploration\": [\"multi-fidelity exploration\"],\\n    \"multi-fidelity validation\": [\"multi-fidelity validation\"],\\n    \"multi-fidelity evaluation\": [\"multi-fidelity evaluation\"],\\n    \"multi-fidelity testing\": [\"multi-fidelity testing\"],\\n    \"multi-fidelity assessment\": [\"multi-fidelity assessment\"],\\n    \"multi-fidelity initiative\": [\"multi-fidelity initiative\"],\\n    \"multi-fidelity framework\": [\"multi-fidelity framework\"],\\n    \"multi-fidelity program\": [\"multi-fidelity program\"],\\n    \"multi-fidelity structure\": [\"multi-fidelity structure\"],\\n    \"multi-fidelity design\": [\"multi-fidelity design\"],\\n    \"multi-fidelity operation\": [\"multi-fidelity operation\"],\\n    \"multi-fidelity methodology\": [\"multi-fidelity methodology\"],\\n    \"multi-fidelity optimization\": [\"multi-fidelity optimization\"],\\n    \"multi-fidelity simulation\": [\"multi-fidelity simulation\"],\\n    \"multi-fidelity modeling\": [\"multi-fidelity modeling\"],\\n    \"multi-fidelity project\": [\"multi-fidelity project\"],\\n    \"multi-fidelity effort\": [\"multi-fidelity effort\"],\\n    \"multi-fidelity study\": [\"multi-fidelity study\"],\\n    \"multi-fidelity task\": [\"multi-fidelity task\"],\\n    \"multi-fidelity application\": [\"multi-fidelity application\"],\\n    \"multi-fidelity analysis\": [\"multi-fidelity analysis\"],\\n    \"multi-fidelity verification\": [\"multi-fidelity verification\"],\\n    \"multi-fidelity investigation\": [\"multi-fidelity investigation\"],\\n    \"multi-fidelity activity\": [\"multi-fidelity activity\"],\\n    \"multi-fidelity endeavor\": [\"multi-fidelity endeavor\"],\\n    \"multi-fidelity exploration\": [\"multi-fidelity exploration\"],\\n    \"multi-fidelity validation\": [\"multi-fidelity validation\"],\\n    \"multi-fidelity evaluation\": [\"multi-fidelity evaluation\"],\\n    \"multi-fidelity testing\": [\"multi-fidelity testing\"],\\n    \"multi-fidelity assessment\": [\"multi-fidelity assessment\"],\\n    \"multi-fidelity initiative\": [\"multi-fidelity initiative\"],\\n    \"multi-fidelity framework\": [\"multi-fidelity framework\"],\\n    \"multi-fidelity program\": [\"multi-fidelity program\"],\\n    \"multi-fidelity structure\": [\"multi-fidelity structure\"],\\n    \"multi-fidelity design\": [\"multi-fidelity design\"],\\n    \"multi-fidelity operation\": [\"multi-fidelity operation\"],\\n    \"multi-fidelity methodology\": [\"multi-fidelity methodology', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1759232302, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=3000, prompt_tokens=2487, total_tokens=5487, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2025-09-30 13:39:22,578 - INFO - LLM content: ```python\n",
      "{\n",
      "    \"deep learning approach\": [\"deep learning approach\", \"deep learning algorithm\", \"deep learning model\", \"deep learning-based\", \"deep learning\"],\n",
      "    \"genetic programming\": [\"genetic programming\", \"genetic algorithm\", \"genetic algorithm based\", \"non-dominated sorting genetic algorithm\", \"non-dominated sorting genetic\"],\n",
      "    \"wavelet transform dwt\": [\"wavelet transform dwt\", \"discrete wavelet transform dwt\", \"discrete wavelet transform\"],\n",
      "    \"simulated annealing\": [\"simulated annealing\"],\n",
      "    \"multi-fidelity task\": [\"multi-fidelity task\", \"multi-fidelity activity\", \"multi-fidelity investigation\", \"multi-fidelity application\", \"multi-fidelity analysis\", \"multi-fidelity verification\", \"multi-fidelity study\", \"multi-fidelity endeavor\", \"multi-fidelity structure\", \"multi-fidelity project\", \"multi-fidelity design\", \"multi-fidelity operation\", \"multi-fidelity methodology\", \"multi-fidelity optimization\", \"multi-fidelity framework\", \"multi-fidelity technique\", \"multi-fidelity modeling\", \"multi-fidelity simulation\"],\n",
      "    \"two-stage stochastic\": [\"two-stage stochastic\", \"two-stage robust\"],\n",
      "    \"hybrid system modeling\": [\"hybrid system modeling\", \"hybrid optimization model\", \"hybrid energy storage\", \"hybrid acdc microgrid\", \"hybrid acdc microgrids\"],\n",
      "    \"multi-agent\": [\"multi-agent\", \"multi-agent system\"],\n",
      "    \"bayesian optimization\": [\"bayesian optimization\"],\n",
      "    \"energy demand forecasting\": [\"energy demand forecasting\", \"short-term load forecasting\", \"load forecasting\", \"supply-demand forecasting\", \"energy production forecasting\", \"wind power prediction\"],\n",
      "    \"big data analysis\": [\"big data analysis\", \"data-driven optimization\", \"data-driven method\", \"real-time data analysis\", \"data mining\"],\n",
      "    \"fuzzy comprehensive evaluation\": [\"fuzzy comprehensive evaluation\", \"fuzzy logic\", \"fuzzy logic controller\", \"fuzzy logic controller flc\", \"fuzzy inference system\"],\n",
      "    \"iterative methods\": [\"iterative methods\", \"iterative algorithm\"],\n",
      "    \"alternating direction method multiplier\": [\"alternating direction method multiplier\", \"alternating direction method\"],\n",
      "    \"probabilistic production simulation\": [\"probabilistic production simulation\", \"probabilistic model\"],\n",
      "    \"k-nearest\": [\"k-nearest\", \"k-nearest neighbor\", \"k-nearest clustering\"],\n",
      "    \"metaheuristics\": [\"metaheuristics\", \"heuristic optimization\"],\n",
      "    \"energy resilience analysis\": [\"energy resilience analysis\"],\n",
      "    \"numerical method\": [\"numerical method\"],\n",
      "    \"support vector regression\": [\"support vector regression\", \"support vector regression svr\", \"support vector machine\"],\n",
      "    \"anfis\": [\"anfis\", \"adaptive neuro-fuzzy inference\", \"adaptive neuro-fuzzy inference system\"],\n",
      "    \"neural network based\": [\"neural network based\", \"neural network\", \"artificial neural network\", \"neural network model\", \"neural network anns\", \"neural network algorithm\"],\n",
      "    \"energy efficiency modeling\": [\"energy efficiency modeling\"],\n",
      "    \"optimal power flow\": [\"optimal power flow\", \"opf\"],\n",
      "    \"stochastic model\": [\"stochastic model\", \"stochastic modeling\", \"stochastic programming\", \"stochastic unit commitment\"],\n",
      "    \"short-term memory lstm network\": [\"short-term memory lstm network\"],\n",
      "    \"linear programming\": [\"linear programming\"],\n",
      "    \"mean absolute\": [\"mean absolute\", \"mean absolute error mae\", \"mean absolute percentage error\"],\n",
      "    \"reactive power sharing\": [\"reactive power sharing\"],\n",
      "    \"zero energy\": [\"zero energy\"],\n",
      "    \"multi-user detection\": [\"multi-user detection\", \"multi-user mimo\"],\n",
      "    \"maximum power point tracking\": [\"maximum power point tracking\"],\n",
      "    \"feedback control\": [\"feedback control\"],\n",
      "    \"modified ieee rts\": [\"modified ieee rts\"],\n",
      "    \"monte-carlo simulation\": [\"monte-carlo simulation\", \"monte carlo\", \"monte-carlo\"],\n",
      "    \"voltage control strategy\": [\"voltage control strategy\", \"voltage control\"],\n",
      "    \"multi-fidelity\": [\"multi-fidelity\", \"multi-fidelity approach\"],\n",
      "    \"principal component analysis pca\": [\"principal component analysis pca\", \"principal component analysis\"],\n",
      "    \"optimal utilization\": [\"optimal utilization\"],\n",
      "    \"adaptive neuro-fuzzy inference\": [\"adaptive neuro-fuzzy inference\"],\n",
      "    \"resource allocation algorithm\": [\"resource allocation algorithm\", \"resource allocation scheme\", \"resource allocation\"],\n",
      "    \"dynamic programming\": [\"dynamic programming\"],\n",
      "    \"multi-objective optimization\": [\"multi-objective optimization\", \"multi-objective optimization method\", \"multi-objective optimization model\", \"multi-objective optimization problem\", \"multi-objective particle swarm optimization\"],\n",
      "    \"bee colony\": [\"bee colony\", \"bee colony algorithm\", \"artificial bee colony algorithm\"],\n",
      "    \"static var compensator svc\": [\"static var compensator svc\", \"static var compensator\"],\n",
      "    \"power system stabilizer\": [\"power system stabilizer\"],\n",
      "    \"supply-demand forecasting\": [\"supply-demand forecasting\"],\n",
      "    \"dynamic voltage restorer dvr\": [\"dynamic voltage restorer dvr\", \"dynamic voltage restorer\"],\n",
      "    \"global search\": [\"global search\"],\n",
      "    \"fault detection diagnosis\": [\"fault detection diagnosis\", \"fault detection classification\", \"fault detection\"],\n",
      "    \"energy consumption modeling\": [\"energy consumption modeling\"],\n",
      "    \"multi-fidelity assessment\": [\"multi-fidelity assessment\"],\n",
      "    \"multi-fidelity exploration\": [\"multi-fidelity exploration\"],\n",
      "    \"multi-fidelity testing\": [\"multi-fidelity testing\"],\n",
      "    \"multi-fidelity validation\": [\"multi-fidelity validation\"],\n",
      "    \"multi-fidelity evaluation\": [\"multi-fidelity evaluation\"],\n",
      "    \"demand side management dsm\": [\"demand side management dsm\", \"demand response dr\", \"demand response\"],\n",
      "    \"k-means\": [\"k-means\", \"k-means clustering\"],\n",
      "    \"load frequency control lfc\": [\"load frequency control lfc\", \"load frequency control\"],\n",
      "    \"dynamic reactive power compensation\": [\"dynamic reactive power compensation\"],\n",
      "    \"multi-fidelity initiative\": [\"multi-fidelity initiative\"],\n",
      "    \"energy transition strategy\": [\"energy transition strategy\", \"energy transition modeling\"],\n",
      "    \"multi-state model\": [\"multi-state model\"],\n",
      "    \"multi-modal\": [\"multi-modal\"],\n",
      "    \"multi-fidelity framework\": [\"multi-fidelity framework\"],\n",
      "    \"multi-fidelity program\": [\"multi-fidelity program\"],\n",
      "    \"multi-fidelity structure\": [\"multi-fidelity structure\"],\n",
      "    \"multi-fidelity design\": [\"multi-fidelity design\"],\n",
      "    \"multi-fidelity operation\": [\"multi-fidelity operation\"],\n",
      "    \"multi-fidelity methodology\": [\"multi-fidelity methodology\"],\n",
      "    \"multi-fidelity optimization\": [\"multi-fidelity optimization\"],\n",
      "    \"multi-fidelity simulation\": [\"multi-fidelity simulation\"],\n",
      "    \"multi-fidelity modeling\": [\"multi-fidelity modeling\"],\n",
      "    \"multi-fidelity project\": [\"multi-fidelity project\"],\n",
      "    \"multi-fidelity effort\": [\"multi-fidelity effort\"],\n",
      "    \"multi-fidelity study\": [\"multi-fidelity study\"],\n",
      "    \"multi-fidelity task\": [\"multi-fidelity task\"],\n",
      "    \"multi-fidelity application\": [\"multi-fidelity application\"],\n",
      "    \"multi-fidelity analysis\": [\"multi-fidelity analysis\"],\n",
      "    \"multi-fidelity verification\": [\"multi-fidelity verification\"],\n",
      "    \"multi-fidelity investigation\": [\"multi-fidelity investigation\"],\n",
      "    \"multi-fidelity activity\": [\"multi-fidelity activity\"],\n",
      "    \"multi-fidelity endeavor\": [\"multi-fidelity endeavor\"],\n",
      "    \"multi-fidelity exploration\": [\"multi-fidelity exploration\"],\n",
      "    \"multi-fidelity validation\": [\"multi-fidelity validation\"],\n",
      "    \"multi-fidelity evaluation\": [\"multi-fidelity evaluation\"],\n",
      "    \"multi-fidelity testing\": [\"multi-fidelity testing\"],\n",
      "    \"multi-fidelity assessment\": [\"multi-fidelity assessment\"],\n",
      "    \"multi-fidelity initiative\": [\"multi-fidelity initiative\"],\n",
      "    \"multi-fidelity framework\": [\"multi-fidelity framework\"],\n",
      "    \"multi-fidelity program\": [\"multi-fidelity program\"],\n",
      "    \"multi-fidelity structure\": [\"multi-fidelity structure\"],\n",
      "    \"multi-fidelity design\": [\"multi-fidelity design\"],\n",
      "    \"multi-fidelity operation\": [\"multi-fidelity operation\"],\n",
      "    \"multi-fidelity methodology\": [\"multi-fidelity methodology\"],\n",
      "    \"multi-fidelity optimization\": [\"multi-fidelity optimization\"],\n",
      "    \"multi-fidelity simulation\": [\"multi-fidelity simulation\"],\n",
      "    \"multi-fidelity modeling\": [\"multi-fidelity modeling\"],\n",
      "    \"multi-fidelity project\": [\"multi-fidelity project\"],\n",
      "    \"multi-fidelity effort\": [\"multi-fidelity effort\"],\n",
      "    \"multi-fidelity study\": [\"multi-fidelity study\"],\n",
      "    \"multi-fidelity task\": [\"multi-fidelity task\"],\n",
      "    \"multi-fidelity application\": [\"multi-fidelity application\"],\n",
      "    \"multi-fidelity analysis\": [\"multi-fidelity analysis\"],\n",
      "    \"multi-fidelity verification\": [\"multi-fidelity verification\"],\n",
      "    \"multi-fidelity investigation\": [\"multi-fidelity investigation\"],\n",
      "    \"multi-fidelity activity\": [\"multi-fidelity activity\"],\n",
      "    \"multi-fidelity endeavor\": [\"multi-fidelity endeavor\"],\n",
      "    \"multi-fidelity exploration\": [\"multi-fidelity exploration\"],\n",
      "    \"multi-fidelity validation\": [\"multi-fidelity validation\"],\n",
      "    \"multi-fidelity evaluation\": [\"multi-fidelity evaluation\"],\n",
      "    \"multi-fidelity testing\": [\"multi-fidelity testing\"],\n",
      "    \"multi-fidelity assessment\": [\"multi-fidelity assessment\"],\n",
      "    \"multi-fidelity initiative\": [\"multi-fidelity initiative\"],\n",
      "    \"multi-fidelity framework\": [\"multi-fidelity framework\"],\n",
      "    \"multi-fidelity program\": [\"multi-fidelity program\"],\n",
      "    \"multi-fidelity structure\": [\"multi-fidelity structure\"],\n",
      "    \"multi-fidelity design\": [\"multi-fidelity design\"],\n",
      "    \"multi-fidelity operation\": [\"multi-fidelity operation\"],\n",
      "    \"multi-fidelity methodology\": [\"multi-fidelity methodology\"],\n",
      "    \"multi-fidelity optimization\": [\"multi-fidelity optimization\"],\n",
      "    \"multi-fidelity simulation\": [\"multi-fidelity simulation\"],\n",
      "    \"multi-fidelity modeling\": [\"multi-fidelity modeling\"],\n",
      "    \"multi-fidelity project\": [\"multi-fidelity project\"],\n",
      "    \"multi-fidelity effort\": [\"multi-fidelity effort\"],\n",
      "    \"multi-fidelity study\": [\"multi-fidelity study\"],\n",
      "    \"multi-fidelity task\": [\"multi-fidelity task\"],\n",
      "    \"multi-fidelity application\": [\"multi-fidelity application\"],\n",
      "    \"multi-fidelity analysis\": [\"multi-fidelity analysis\"],\n",
      "    \"multi-fidelity verification\": [\"multi-fidelity verification\"],\n",
      "    \"multi-fidelity investigation\": [\"multi-fidelity investigation\"],\n",
      "    \"multi-fidelity activity\": [\"multi-fidelity activity\"],\n",
      "    \"multi-fidelity endeavor\": [\"multi-fidelity endeavor\"],\n",
      "    \"multi-fidelity exploration\": [\"multi-fidelity exploration\"],\n",
      "    \"multi-fidelity validation\": [\"multi-fidelity validation\"],\n",
      "    \"multi-fidelity evaluation\": [\"multi-fidelity evaluation\"],\n",
      "    \"multi-fidelity testing\": [\"multi-fidelity testing\"],\n",
      "    \"multi-fidelity assessment\": [\"multi-fidelity assessment\"],\n",
      "    \"multi-fidelity initiative\": [\"multi-fidelity initiative\"],\n",
      "    \"multi-fidelity framework\": [\"multi-fidelity framework\"],\n",
      "    \"multi-fidelity program\": [\"multi-fidelity program\"],\n",
      "    \"multi-fidelity structure\": [\"multi-fidelity structure\"],\n",
      "    \"multi-fidelity design\": [\"multi-fidelity design\"],\n",
      "    \"multi-fidelity operation\": [\"multi-fidelity operation\"],\n",
      "    \"multi-fidelity methodology\": [\"multi-fidelity methodology\"],\n",
      "    \"multi-fidelity optimization\": [\"multi-fidelity optimization\"],\n",
      "    \"multi-fidelity simulation\": [\"multi-fidelity simulation\"],\n",
      "    \"multi-fidelity modeling\": [\"multi-fidelity modeling\"],\n",
      "    \"multi-fidelity project\": [\"multi-fidelity project\"],\n",
      "    \"multi-fidelity effort\": [\"multi-fidelity effort\"],\n",
      "    \"multi-fidelity study\": [\"multi-fidelity study\"],\n",
      "    \"multi-fidelity task\": [\"multi-fidelity task\"],\n",
      "    \"multi-fidelity application\": [\"multi-fidelity application\"],\n",
      "    \"multi-fidelity analysis\": [\"multi-fidelity analysis\"],\n",
      "    \"multi-fidelity verification\": [\"multi-fidelity verification\"],\n",
      "    \"multi-fidelity investigation\": [\"multi-fidelity investigation\"],\n",
      "    \"multi-fidelity activity\": [\"multi-fidelity activity\"],\n",
      "    \"multi-fidelity endeavor\": [\"multi-fidelity endeavor\"],\n",
      "    \"multi-fidelity exploration\": [\"multi-fidelity exploration\"],\n",
      "    \"multi-fidelity validation\": [\"multi-fidelity validation\"],\n",
      "    \"multi-fidelity evaluation\": [\"multi-fidelity evaluation\"],\n",
      "    \"multi-fidelity testing\": [\"multi-fidelity testing\"],\n",
      "    \"multi-fidelity assessment\": [\"multi-fidelity assessment\"],\n",
      "    \"multi-fidelity initiative\": [\"multi-fidelity initiative\"],\n",
      "    \"multi-fidelity framework\": [\"multi-fidelity framework\"],\n",
      "    \"multi-fidelity program\": [\"multi-fidelity program\"],\n",
      "    \"multi-fidelity structure\": [\"multi-fidelity structure\"],\n",
      "    \"multi-fidelity design\": [\"multi-fidelity design\"],\n",
      "    \"multi-fidelity operation\": [\"multi-fidelity operation\"],\n",
      "    \"multi-fidelity methodology\": [\"multi-fidelity methodology\"],\n",
      "    \"multi-fidelity optimization\": [\"multi-fidelity optimization\"],\n",
      "    \"multi-fidelity simulation\": [\"multi-fidelity simulation\"],\n",
      "    \"multi-fidelity modeling\": [\"multi-fidelity modeling\"],\n",
      "    \"multi-fidelity project\": [\"multi-fidelity project\"],\n",
      "    \"multi-fidelity effort\": [\"multi-fidelity effort\"],\n",
      "    \"multi-fidelity study\": [\"multi-fidelity study\"],\n",
      "    \"multi-fidelity task\": [\"multi-fidelity task\"],\n",
      "    \"multi-fidelity application\": [\"multi-fidelity application\"],\n",
      "    \"multi-fidelity analysis\": [\"multi-fidelity analysis\"],\n",
      "    \"multi-fidelity verification\": [\"multi-fidelity verification\"],\n",
      "    \"multi-fidelity investigation\": [\"multi-fidelity investigation\"],\n",
      "    \"multi-fidelity activity\": [\"multi-fidelity activity\"],\n",
      "    \"multi-fidelity endeavor\": [\"multi-fidelity endeavor\"],\n",
      "    \"multi-fidelity exploration\": [\"multi-fidelity exploration\"],\n",
      "    \"multi-fidelity validation\": [\"multi-fidelity validation\"],\n",
      "    \"multi-fidelity evaluation\": [\"multi-fidelity evaluation\"],\n",
      "    \"multi-fidelity testing\": [\"multi-fidelity testing\"],\n",
      "    \"multi-fidelity assessment\": [\"multi-fidelity assessment\"],\n",
      "    \"multi-fidelity initiative\": [\"multi-fidelity initiative\"],\n",
      "    \"multi-fidelity framework\": [\"multi-fidelity framework\"],\n",
      "    \"multi-fidelity program\": [\"multi-fidelity program\"],\n",
      "    \"multi-fidelity structure\": [\"multi-fidelity structure\"],\n",
      "    \"multi-fidelity design\": [\"multi-fidelity design\"],\n",
      "    \"multi-fidelity operation\": [\"multi-fidelity operation\"],\n",
      "    \"multi-fidelity methodology\": [\"multi-fidelity methodology\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Batch 1 LLM response received: 14146 characters\n",
      "⚠️ No dictionary found in LLM response for batch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 13:39:24,186 - INFO - Created 334 method variant groups from 386 original methods\n",
      "2025-09-30 13:39:24,187 - INFO - ✓ Created 334 canonical methods with 386 total variants\n",
      "2025-09-30 13:39:24,187 - INFO - Saving method phrases and groups for manual review and editing...\n",
      "2025-09-30 13:39:24,191 - INFO - ✅ Method extraction and grouping phase completed successfully!\n",
      "2025-09-30 13:39:24,193 - INFO - 💰 Credit usage so far: {'total_tokens': 139138, 'total_cost': 0.0209}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Post-processing preserved 334 groups\n",
      "\n",
      "📊 Method Extraction and Grouping Results:\n",
      "  Original methods: 386\n",
      "  Consolidated methods: 334\n",
      "  Reduction: 52 methods (13.5% reduction)\n",
      "\n",
      "⏸️  EDITING CHECKPOINT:\n",
      "  📝 Edit extracted_method_phrases.csv to add/remove/rename methods\n",
      "  📝 Edit method_variant_groups.json to adjust groupings\n",
      "  ✅ Files saved to: Saved_files_new\n",
      "  ➡️  Run Cell 10B when editing is complete\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 10A: Method Extraction and Grouping Phase (LLM-based)\n",
    "#Runs LLM calls for method extraction and grouping\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION PARAMETERS - Adjust these for optimal method detection\n",
    "# =============================================================================\n",
    "MAX_FEATURES = 30000                    # Maximum features for candidate term extraction\n",
    "BATCH_SIZE = 5000                       # Batch size for LLM processing\n",
    "METHOD_LLM_N_RUNS = 3                   # Number of LLM runs for method extraction\n",
    "VARIANT_GROUP_BATCH_SIZE = 5000         # Batch size for method variant grouping\n",
    "TEMP = 0.2 #TOP_P = 0.2 #Adjust only one of these, not both....\n",
    "logger.info(\"=== Starting Method Extraction and Grouping Phase ===\")\n",
    "save_method_phrases=False # initalizing setpoint for saving if new file is created\n",
    "save_method_groups= False # initalizing setpoint for saving if new file is created\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: LOAD OR EXTRACT METHOD PHRASES FROM CORPUS\n",
    "# =============================================================================\n",
    "logger.info(\"Step 1: Loading or extracting method phrases...\")\n",
    "\n",
    "# Try to load existing method phrases from previous runs\n",
    "try:\n",
    "    method_phrases, method_counts = load_method_phrases_from_csv(filename=\"extracted_method_phrases.csv\")\n",
    "except (FileNotFoundError, TypeError):\n",
    "    method_phrases, method_counts = None, None\n",
    "\n",
    "# If no existing phrases found or too few, extract new ones using LLM\n",
    "if (method_phrases is None) or (len(method_phrases) < 3):\n",
    "    logger.info(\"  1a: Extracting candidate terms from processed text...\")\n",
    "    \n",
    "    # Extract candidate n-grams (1-4 grams) from the corpus using CountVectorizer\n",
    "    candidate_terms = extract_candidate_terms(df, text_col='processed_text', max_features=MAX_FEATURES)\n",
    "    logger.info(f\"  ✓ Extracted {len(candidate_terms)} candidate terms\")\n",
    "    print(f\"  Sample candidate terms: {candidate_terms[:10]}\")\n",
    "    \n",
    "    logger.info(\"  1b: Using LLM to identify research methods from candidate terms...\")\n",
    "    \n",
    "    # Use LLM to intelligently identify research methods from candidate terms\n",
    "    method_phrases, method_counts = get_method_phrases_enhanced(\n",
    "        candidate_terms,\n",
    "        client,\n",
    "        model_type,\n",
    "        credit_tracker,\n",
    "        prompt=extraction_prompt,\n",
    "        n_runs=METHOD_LLM_N_RUNS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        #top_p=TOP_P, % use only one of TOP_P or TEMP\n",
    "        temp=TEMP\n",
    "    )\n",
    "    method_phrases = filter_generic_phrases(method_phrases)\n",
    "    save_method_phrases = True # enable saving of new file\n",
    "    #save_method_phrases_to_csv(method_phrases, method_counts)\n",
    "else:\n",
    "    logger.info(f\"  ✓ Loaded {len(method_phrases)} method phrases from existing CSV\")\n",
    "\n",
    "# Validate that method extraction was successful\n",
    "if not method_phrases:\n",
    "    logger.error(\"No method phrases extracted! Check your LLM configuration and prompts.\")\n",
    "    raise RuntimeError(\"Method extraction failed - no phrases found\")\n",
    "\n",
    "logger.info(f\"✓ Method phrase extraction complete: {len(method_phrases)} phrases\")\n",
    "print(f\"  Sample methods: {method_phrases[:10]}\")\n",
    "# Save method phrases (can be edited)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: ENHANCED METHOD VARIANT CONSOLIDATION\n",
    "# =============================================================================\n",
    "logger.info(\"Step 2: Building enhanced method variant groups with consolidation...\")\n",
    "\n",
    "# check if file exist\n",
    "variant_groups_path= os.path.join(SAVE_DIR,\"method_variant_groups.json\") \n",
    "if os.path.exists(variant_groups_path):\n",
    "    logger.info(f\"Found existing variant groups file: {variant_groups_path}\")\n",
    "    logger.info(\" Loading existing groups instead of regenerating...\")\n",
    "\n",
    "    with open(variant_groups_path, 'r', encoding='utf-8') as f:\n",
    "        canonical_to_variants=json.load(f)\n",
    "    variant_groups=canonical_to_variants\n",
    "\n",
    "    logger.info(f\"Loaded {len(canonical_to_variants)} existing method groups\")\n",
    "    logger.info(f\"Sample method groups{list(canonical_to_variants.items())[:10]}\")\n",
    "\n",
    "else: \n",
    "    logger.info(\" No existing variant groups found. Running LLM grouping\")\n",
    "    # Use enhanced LLM-based variant grouping to consolidate similar methods\n",
    "    variant_groups = build_method_variant_groups_enhanced(\n",
    "    method_phrases, \n",
    "    client, \n",
    "    model_type, \n",
    "    credit_tracker, \n",
    "    prompt=grouping_prompt, \n",
    "    #top_p=TOP_P,\n",
    "    temp=TEMP,\n",
    "    batch_size=VARIANT_GROUP_BATCH_SIZE\n",
    "    ) if method_phrases else {}\n",
    "    save_method_groups = True\n",
    "    # Create fallback mapping if LLM-based grouping fails completely\n",
    "    if not variant_groups and method_phrases:\n",
    "        logger.info(\"  LLM grouping failed completely - using enhanced aggressive fallback grouping...\")\n",
    "        variant_groups = aggressive_fallback_grouping(method_phrases, similarity_threshold=0.75)\n",
    "        logger.info(f\"  ✓ Aggressive fallback created {len(variant_groups)} groups from {len(method_phrases)} methods\")\n",
    "\n",
    "\n",
    "\n",
    "# Create bidirectional mappings for efficient lookup during scoring\n",
    "variant_to_canonical, canonical_to_variants = create_variant_mapping(variant_groups)\n",
    "logger.info(f\"✓ Created {len(canonical_to_variants)} canonical methods with {len(variant_to_canonical)} total variants\")\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE FOR MANUAL EDITING\n",
    "# =============================================================================\n",
    "logger.info(\"Saving method phrases and groups for manual review and editing...\")\n",
    "\n",
    "if save_method_phrases: # Save method phrases (can be edited)\n",
    "    save_method_phrases_to_csv(method_phrases, method_counts, filename=\"extracted_method_phrases.csv\")\n",
    "if save_method_groups: # Save variant groups (can be edited)\n",
    "    \n",
    "    with open(os.path.join(SAVE_DIR, \"method_variant_groups.json\"), 'w') as f:\n",
    "        json.dump(canonical_to_variants, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Display consolidation results\n",
    "print(f\"\\n📊 Method Extraction and Grouping Results:\")\n",
    "print(f\"  Original methods: {len(method_phrases) if method_phrases else 0}\")\n",
    "print(f\"  Consolidated methods: {len(canonical_to_variants)}\")\n",
    "reduction = len(method_phrases) - len(canonical_to_variants) if method_phrases else 0\n",
    "print(f\"  Reduction: {reduction} methods ({100*reduction/len(method_phrases):.1f}% reduction)\" if method_phrases and len(method_phrases) > 0 else \"\")\n",
    "\n",
    "print(f\"\\n⏸️  EDITING CHECKPOINT:\")\n",
    "print(f\"  📝 Edit extracted_method_phrases.csv to add/remove/rename methods\")\n",
    "print(f\"  📝 Edit method_variant_groups.json to adjust groupings\")\n",
    "print(f\"  ✅ Files saved to: {SAVE_DIR}\")\n",
    "print(f\"  ➡️  Run Cell 10B when editing is complete\")\n",
    "\n",
    "logger.info(\"✅ Method extraction and grouping phase completed successfully!\")\n",
    "logger.info(f\"💰 Credit usage so far: {credit_tracker.get_stats()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52a6bf1",
   "metadata": {},
   "source": [
    "#### added function to compare extracted terms and grouped terms after editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a467a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-time operation to compare groups and terms.clear\n",
    "#compare the terms in the json file \"method_variant_groups\" with the terms in the csv file \"extract_method_phrases\"\n",
    "# list all the terms that are not found in extracted_method_phrases and add them\n",
    "\n",
    "def compare_variant_groups_with_extracted_terms(variant_groups_file, extracted_phrases_file, output_file=None):\n",
    "    \"\"\"\n",
    "    Compare method variant groups with extracted method phrases to find missing terms\n",
    "    \n",
    "    Parameters:\n",
    "    - variant_groups_file: path to JSON file with method variant groups\n",
    "    - extracted_phrases_file: path to CSV file with extracted method phrases  \n",
    "    - output_file: optional path to save detailed analysis CSV\n",
    "    \n",
    "    Returns:\n",
    "    - dictionary with analysis results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    with open(variant_groups_file, 'r', encoding='utf-8') as f:\n",
    "        method_variant_groups = json.load(f)\n",
    "    \n",
    "    df_extracted = pd.read_csv(extracted_phrases_file)\n",
    "    \n",
    "    # Normalize terms for comparison (lowercase, strip whitespace)\n",
    "    def normalize_term(term):\n",
    "        if pd.isna(term):\n",
    "            return \"\"\n",
    "        return str(term).strip().lower()\n",
    "    \n",
    "    # Create sets for comparison\n",
    "    extracted_terms = set(df_extracted['Method Phrase'].apply(normalize_term))\n",
    "    extracted_terms.discard(\"\")  # Remove empty strings\n",
    "    \n",
    "    # Get all terms from variant groups\n",
    "    variant_terms = set()\n",
    "    term_to_group_mapping = {}  # Track which group each term belongs to\n",
    "    \n",
    "    for group_key, variants in method_variant_groups.items():\n",
    "        # Add the group key itself\n",
    "        normalized_key = normalize_term(group_key)\n",
    "        if normalized_key:\n",
    "            variant_terms.add(normalized_key)\n",
    "            term_to_group_mapping[normalized_key] = group_key\n",
    "        \n",
    "        # Add all variants in the group\n",
    "        for variant in variants:\n",
    "            normalized_variant = normalize_term(variant)\n",
    "            if normalized_variant:\n",
    "                variant_terms.add(normalized_variant)\n",
    "                term_to_group_mapping[normalized_variant] = group_key\n",
    "    \n",
    "    # Find differences\n",
    "    missing_from_extracted = sorted(variant_terms - extracted_terms)\n",
    "    missing_from_variants = sorted(extracted_terms - variant_terms)\n",
    "    common_terms = sorted(extracted_terms & variant_terms)\n",
    "    \n",
    "    # Summary statistics\n",
    "    results = {\n",
    "        'total_variant_groups': len(method_variant_groups),\n",
    "        'total_unique_variant_terms': len(variant_terms),\n",
    "        'total_extracted_terms': len(extracted_terms),\n",
    "        'common_terms_count': len(common_terms),\n",
    "        'missing_from_extracted_count': len(missing_from_extracted),\n",
    "        'missing_from_variants_count': len(missing_from_variants),\n",
    "        'missing_from_extracted': missing_from_extracted,\n",
    "        'missing_from_variants': missing_from_variants,\n",
    "        'common_terms': common_terms,\n",
    "        'coverage_percentage': (len(common_terms) / len(variant_terms) * 100) if len(variant_terms) > 0 else 0\n",
    "    }\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"COMPARISON RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total variant groups: {results['total_variant_groups']}\")\n",
    "    print(f\"Total unique terms in variant groups: {results['total_unique_variant_terms']}\")\n",
    "    print(f\"Total extracted terms: {results['total_extracted_terms']}\")\n",
    "    print(f\"Common terms: {results['common_terms_count']}\")\n",
    "    print(f\"Terms in variants but missing from extracted: {results['missing_from_extracted_count']}\")\n",
    "    print(f\"Terms in extracted but missing from variants: {results['missing_from_variants_count']}\")\n",
    "    print(f\"Coverage of variant terms in extracted: {results['coverage_percentage']:.1f}%\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def check_duplicates_in_json_groups(json_file):\n",
    "    \"\"\"\n",
    "    CORRECTED: Don't count group name as duplicate when it appears in its own variants\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        method_variant_groups = json.load(f)\n",
    "    \n",
    "    def normalize_term(term):\n",
    "        return str(term).strip().lower() if not pd.isna(term) else \"\"\n",
    "    \n",
    "    # Check for duplicate group keys\n",
    "    normalized_keys = [normalize_term(key) for key in method_variant_groups.keys()]\n",
    "    key_counts = Counter(normalized_keys)\n",
    "    duplicate_keys = {k: v for k, v in key_counts.items() if v > 1}\n",
    "    \n",
    "    # Check for terms appearing in multiple groups\n",
    "    # CORRECTED: Don't count group name appearing in its own variants\n",
    "    term_to_groups = defaultdict(set)\n",
    "    \n",
    "    for group_key, variants in method_variant_groups.items():\n",
    "        normalized_key = normalize_term(group_key)\n",
    "        normalized_variants = [normalize_term(v) for v in variants if normalize_term(v)]\n",
    "        \n",
    "        # Add all variants to the mapping\n",
    "        for variant in variants:\n",
    "            normalized_variant = normalize_term(variant)\n",
    "            if normalized_variant:\n",
    "                term_to_groups[normalized_variant].add(group_key)\n",
    "        \n",
    "        # Only add the group key if it's NOT already in its variants\n",
    "        if normalized_key and normalized_key not in normalized_variants:\n",
    "            term_to_groups[normalized_key].add(group_key)\n",
    "    \n",
    "    # Find terms that appear in multiple groups\n",
    "    cross_group_duplicates = {}\n",
    "    for term, groups in term_to_groups.items():\n",
    "        if len(groups) > 1:\n",
    "            cross_group_duplicates[term] = list(groups)\n",
    "    \n",
    "    return {\n",
    "        'duplicate_group_keys': duplicate_keys,\n",
    "        'cross_group_duplicates': cross_group_duplicates\n",
    "    }\n",
    "\n",
    "def comprehensive_duplicate_check(json_file, csv_file, output_file=None, clean_csv=False):\n",
    "    \"\"\"Complete duplicate analysis with corrected logic\"\"\"\n",
    "    \n",
    "    json_results = check_duplicates_in_json_groups(json_file)\n",
    "    csv_results = check_duplicates_in_csv_terms(csv_file)  # Previous function unchanged\n",
    "    \n",
    "    print(\"SUMMARY (CORRECTED):\")\n",
    "    print(f\"JSON - Duplicate group keys: {len(json_results['duplicate_group_keys'])}\")\n",
    "    print(f\"JSON - Terms in multiple groups: {len(json_results['cross_group_duplicates'])}\")\n",
    "    print(f\"CSV - Duplicate terms: {len(csv_results['duplicate_terms'])}\")\n",
    "    \n",
    "    return {'json_results': json_results, 'csv_results': csv_results}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5057b875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "\n",
      "============================================================\n",
      "COMPARISON RESULTS\n",
      "============================================================\n",
      "Total variant groups: 300\n",
      "Total unique terms in variant groups: 393\n",
      "Total extracted terms: 393\n",
      "Common terms: 393\n",
      "Terms in variants but missing from extracted: 0\n",
      "Terms in extracted but missing from variants: 0\n",
      "Coverage of variant terms in extracted: 100.0%\n",
      "\n",
      "MISSING TERMS (0):\n",
      "SUMMARY (CORRECTED):\n",
      "JSON - Duplicate group keys: 0\n",
      "JSON - Terms in multiple groups: 0\n",
      "CSV - Duplicate terms: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'json_results': {'duplicate_group_keys': {}, 'cross_group_duplicates': {}},\n",
       " 'csv_results': {'total_terms': 393,\n",
       "  'duplicate_terms': {},\n",
       "  'duplicate_details': {}}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups='Saved_files_new\\method_variant_groups.json'\n",
    "phrases='Saved_files_new\\extracted_method_phrases.csv'\n",
    "results = compare_variant_groups_with_extracted_terms(\n",
    "        groups, \n",
    "        phrases\n",
    "    )\n",
    "    \n",
    "    # Print missing terms\n",
    "print(f\"\\nMISSING TERMS ({len(results['missing_from_variants'])}):\")\n",
    "for i, term in enumerate(results['missing_from_extracted']):\n",
    "       print(f\"{i+1:3d}. {term}\")\n",
    "# controll for duplicates\n",
    "# Basic check: \n",
    "comprehensive_duplicate_check(groups, phrases)\n",
    "# With cleaning: comprehensive_duplicate_check('groups.json', 'terms.csv', clean_csv=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912b37cb",
   "metadata": {},
   "source": [
    "#### method detection and assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d8b289d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 15:41:45,367 - INFO - === Starting Scoring and Assignment Phase ===\n",
      "2025-09-30 15:41:45,368 - INFO - Loading method phrases and groups (potentially edited)...\n",
      "2025-09-30 15:41:45,375 - INFO - ✓ Loaded 402 method phrases\n",
      "2025-09-30 15:41:45,378 - INFO - ✓ Loaded 305 method groups\n",
      "2025-09-30 15:41:45,379 - INFO - Computing enhanced scoring matrices using multiple approaches...\n",
      "2025-09-30 15:41:45,390 - INFO -   Computing TF-IDF scores for method variants...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 364 variants that exist in corpus out of 399 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 15:43:14,757 - INFO -   ✓ TF-IDF: (30917, 364) with 364 features\n",
      "2025-09-30 15:43:14,758 - INFO -   Computing LDA scores for method variants...\n",
      "2025-09-30 15:44:22,737 - INFO -   ✓ LDA: (30917, 305) with 399 features\n",
      "2025-09-30 15:44:22,738 - INFO -   Computing compound scores for method variants...\n",
      "2025-09-30 15:58:02,546 - INFO -   ✓ Compound: (30917, 399) with 399 features\n",
      "2025-09-30 15:58:02,547 - INFO - Aligning and harmonizing features across scoring methods...\n",
      "2025-09-30 15:58:02,548 - INFO -   Feature alignment statistics:\n",
      "2025-09-30 15:58:02,549 - INFO -     Total unique features: 399\n",
      "2025-09-30 15:58:02,550 - INFO -     TF-IDF features: 364\n",
      "2025-09-30 15:58:02,550 - INFO -     LDA features: 399\n",
      "2025-09-30 15:58:02,550 - INFO -     Compound features: 399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Aligned 364/399 features\n",
      "⚠️  DIMENSION MISMATCH DETECTED:\n",
      "    Expected columns: 399 (from feature names)\n",
      "    Actual columns: 305 (from score matrix)\n",
      "    Using actual matrix dimensions for safety\n",
      "    Truncated feature list: 305 features\n",
      "    ✓ Aligned 305/399 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 15:58:03,172 - INFO - ✓ Feature alignment complete: (30917, 399)\n",
      "2025-09-30 15:58:03,173 - INFO - Normalizing scores and applying variant consolidation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Aligned 399/399 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 15:58:03,632 - INFO - ✓ Score combination complete: (30917, 399)\n",
      "2025-09-30 15:58:03,649 - INFO -   Combined score range: [0.0000, 0.9502]\n",
      "2025-09-30 15:58:03,651 - INFO -   Applying variant score consolidation to prevent double-counting...\n",
      "2025-09-30 15:58:03,891 - INFO -   ✓ Consolidated 399 methods to 305 canonical methods\n",
      "2025-09-30 15:58:03,892 - INFO - ✓ Final consolidated scores: (30917, 305)\n",
      "2025-09-30 15:58:03,905 - INFO -   Final score range: [0.0000, 0.9502]\n",
      "2025-09-30 15:58:03,906 - INFO - Assigning methods to papers using consolidated scores...\n",
      "2025-09-30 15:58:32,310 - INFO -   Assigned methods to 18465/30917 papers (59.7%)\n",
      "2025-09-30 15:58:32,445 - INFO - Saving results and metadata...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Final Assignment Verification:\n",
      "  Papers assigned methods: 18465\n",
      "  Unique methods assigned: 293\n",
      "  Top assigned methods:\n",
      "    energy storage system esss: 1281 papers (consolidated from: ['energy storage system', 'distributed energy storage system', 'ess'])\n",
      "    capacity factor: 640 papers\n",
      "    distributed generation: 570 papers\n",
      "    voltage control: 450 papers\n",
      "    neural network: 389 papers (consolidated from: ['neural network model', 'back propagation', 'neural network based', 'neural network anns', 'artificial neural network', 'anns', 'neural network ann', 'neural network', 'neural network algorithm'])\n",
      "    power system fault: 384 papers\n",
      "    voltage stability: 326 papers (consolidated from: ['voltage stability', 'voltage stability index'])\n",
      "    demand response: 307 papers (consolidated from: ['demand response', 'demand response dr'])\n",
      "    renewable energy paper: 286 papers\n",
      "    particle swarm optimization: 285 papers (consolidated from: ['particle swarm optimization pso', 'pso', 'particle swarm optimization', 'particle swarm optimization algorithm', 'binary particle swarm optimization'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 15:58:51,096 - INFO - ✓ Results saved:\n",
      "2025-09-30 15:58:51,098 - INFO -   Enhanced analysis: enhanced_method_analysis_2025_09_30_reliability_resilience_power_systems.csv\n",
      "2025-09-30 15:58:51,098 - INFO -   Method variant groups: method_variant_groups_2025_09_30_reliability_resilience_power_systems.json\n",
      "2025-09-30 15:58:51,100 - INFO -   Consolidated scores: consolidated_method_scores_2025_09_30_reliability_resilience_power_systems.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE METHOD DETECTION DIAGNOSTICS\n",
      "================================================================================\n",
      "\n",
      "📊 ASSIGNMENT OVERVIEW:\n",
      "  Total papers processed: 30,917\n",
      "  Papers with methods assigned: 18,465 (59.7%)\n",
      "  Papers without methods: 12,452 (40.3%)\n",
      "\n",
      "📈 SCORE DISTRIBUTION ANALYSIS:\n",
      "  Final score matrix shape: (30917, 305)\n",
      "  Total canonical methods: 305\n",
      "  Score range: [0.0000, 0.9502]\n",
      "  Mean score: 0.0025\n",
      "  Standard deviation: 0.0386\n",
      "  Scores > 0.001: 76,943 (0.82% of all scores)\n",
      "  Scores > 0.005: 66,931 (0.71% of all scores)\n",
      "  Scores > 0.01: 63,197 (0.67% of all scores)\n",
      "  Scores > 0.05: 47,557 (0.50% of all scores)\n",
      "  Scores > 0.1: 47,557 (0.50% of all scores)\n",
      "\n",
      "🔥 TOP ASSIGNED METHODS:\n",
      "   2. energy storage system esss: 1,281 papers (6.9%) (from 3 variants)\n",
      "   3. capacity factor: 640 papers (3.5%)\n",
      "   4. distributed generation: 570 papers (3.1%)\n",
      "   5. voltage control: 450 papers (2.4%)\n",
      "   6. neural network: 389 papers (2.1%) (from 9 variants)\n",
      "   7. power system fault: 384 papers (2.1%)\n",
      "   8. voltage stability: 326 papers (1.8%) (from 2 variants)\n",
      "   9. demand response: 307 papers (1.7%) (from 2 variants)\n",
      "  10. renewable energy paper: 286 papers (1.5%)\n",
      "  11. particle swarm optimization: 285 papers (1.5%) (from 5 variants)\n",
      "  12. distributed control: 277 papers (1.5%)\n",
      "  13. real-time monitoring: 264 papers (1.4%)\n",
      "  14. resource allocation: 263 papers (1.4%)\n",
      "  15. system performance analysis: 260 papers (1.4%)\n",
      "\n",
      "🎯 CONFIDENCE DISTRIBUTION:\n",
      "  None: 12,452 (40.3%)\n",
      "  Super-High: 10,820 (35.0%)\n",
      "  Medium: 6,051 (19.6%)\n",
      "  High: 1,594 (5.2%)\n",
      "\n",
      "🔧 CONSOLIDATION EFFECTIVENESS:\n",
      "  Total method variants processed: 399\n",
      "  Final canonical methods: 305\n",
      "  Groups with multiple variants: 63\n",
      "  Consolidation ratio: 1.31:1\n",
      "\n",
      "⚠️  QUALITY ASSESSMENT:\n",
      "  ✅ Good assignment rate (59.7%)\n",
      "  ✅ Reasonable maximum scores (0.9502)\n",
      "  ⚠️  1 methods (0.3%) have zero scores across all papers\n",
      "      Consider reviewing method extraction or scoring parameters\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 15:58:51,383 - INFO - Enhanced method detection pipeline with consolidation completed successfully!\n",
      "2025-09-30 15:58:51,385 - INFO - Credit usage: {'total_tokens': 139138, 'total_cost': 0.0209}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Enhanced Method Detection Pipeline Completed Successfully!\n",
      "📁 All results saved to: Saved_files_new\n",
      "📊 Assignment Rate: 59.7%\n",
      "🔧 Methods Consolidated: 402 → 305\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 10B: Scoring and Assignment Phase (Uses Edited Terms)\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION PARAMETERS FOR SCORING\n",
    "# =============================================================================\n",
    "TFIDF_WEIGHT = 0.65                      # Weight for TF-IDF scoring in final combination\n",
    "LDA_WEIGHT = 0.05                        # Weight for LDA scoring in final combination  \n",
    "COMPOUND_WEIGHT = 0.30                   # Weight for compound scoring in final combination\n",
    "TOP_METHODS_PER_PAPER = 10               # Number of top methods to assign per paper\n",
    "MIN_ASSIGN_SCORE = 0.01                  # Minimum score threshold for method assignment\n",
    "\n",
    "logger.info(\"=== Starting Scoring and Assignment Phase ===\")\n",
    "\n",
    "# =============================================================================\n",
    "# LOAD EDITED METHODS AND GROUPS\n",
    "# =============================================================================\n",
    "logger.info(\"Loading method phrases and groups (potentially edited)...\")\n",
    "\n",
    "# Load method phrases (potentially edited by user)\n",
    "method_phrases, method_counts = load_method_phrases_from_csv(filename=\"extracted_method_phrases.csv\")\n",
    "logger.info(f\"✓ Loaded {len(method_phrases)} method phrases\")\n",
    "\n",
    "# Load variant groups (potentially edited by user)\n",
    "with open(os.path.join(SAVE_DIR, \"method_variant_groups.json\"), 'r') as f:\n",
    "    canonical_to_variants = json.load(f)\n",
    "logger.info(f\"✓ Loaded {len(canonical_to_variants)} method groups\")\n",
    "\n",
    "# Recreate mappings\n",
    "variant_to_canonical, _ = create_variant_mapping(canonical_to_variants)\n",
    "\n",
    "# =============================================================================\n",
    "# COMPUTE MULTIPLE SCORING MATRICES FOR ROBUST METHOD DETECTION\n",
    "# =============================================================================\n",
    "logger.info(\"Computing enhanced scoring matrices using multiple approaches...\")\n",
    "\n",
    "# Convert DataFrame text to list for processing\n",
    "processed_texts = df['processed_text'].fillna('').tolist()\n",
    "\n",
    "# 3a: TF-IDF Scoring - Captures term frequency and document importance\n",
    "logger.info(\"  Computing TF-IDF scores for method variants...\")\n",
    "\n",
    "#standard (non-boolean) tfidf implementation\n",
    "#tfidf_scores, tfidf_feature_names = compute_enhanced_tfidf_scores(\n",
    "#    processed_texts, canonical_to_variants\n",
    "#)\n",
    "tfidf_scores, tfidf_feature_names = compute_enhanced_tfidf_scores_adapted(\n",
    "    processed_texts, canonical_to_variants, max_df=0.98,min_df=1\n",
    ")\n",
    "\n",
    "logger.info(f\"  ✓ TF-IDF: {tfidf_scores.shape} with {len(tfidf_feature_names)} features\")\n",
    "\n",
    "# 3b: LDA Scoring - Captures topic-based method associations\n",
    "logger.info(\"  Computing LDA scores for method variants...\")  \n",
    "method_vocab = list(canonical_to_variants.keys())\n",
    "lda_scores, lda_feature_names = compute_enhanced_lda_scores(\n",
    "    processed_texts, canonical_to_variants, n_topics=len(method_vocab)\n",
    ")\n",
    "logger.info(f\"  ✓ LDA: {lda_scores.shape} with {len(lda_feature_names)} features\")\n",
    "\n",
    "# 3c: Compound Scoring - Captures exact phrase matches and partial matches\n",
    "logger.info(\"  Computing compound scores for method variants...\")\n",
    "compound_scores, compound_feature_names = compute_enhanced_compound_scores(\n",
    "    df, canonical_to_variants\n",
    ")\n",
    "logger.info(f\"  ✓ Compound: {compound_scores.shape} with {len(compound_feature_names)} features\")\n",
    "\n",
    "# =============================================================================\n",
    "# FEATURE ALIGNMENT AND HARMONIZATION\n",
    "# =============================================================================\n",
    "logger.info(\"Aligning and harmonizing features across scoring methods...\")\n",
    "\n",
    "# Create union of all features to preserve maximum method coverage\n",
    "all_features = set(tfidf_feature_names) | set(lda_feature_names) | set(compound_feature_names)\n",
    "all_features = sorted(list(all_features))  # Sort for consistency\n",
    "\n",
    "logger.info(f\"  Feature alignment statistics:\")\n",
    "logger.info(f\"    Total unique features: {len(all_features)}\")\n",
    "logger.info(f\"    TF-IDF features: {len(tfidf_feature_names)}\")\n",
    "logger.info(f\"    LDA features: {len(lda_feature_names)}\")  \n",
    "logger.info(f\"    Compound features: {len(compound_feature_names)}\")\n",
    "\n",
    "# Use your existing align_scores_robust function\n",
    "tfidf_aligned = align_scores_robust(tfidf_scores, tfidf_feature_names, all_features)\n",
    "lda_aligned = align_scores_robust(lda_scores, lda_feature_names, all_features)\n",
    "compound_aligned = align_scores_robust(compound_scores, compound_feature_names, all_features)\n",
    "\n",
    "logger.info(f\"✓ Feature alignment complete: {tfidf_aligned.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SCORE NORMALIZATION AND CONSOLIDATION\n",
    "# =============================================================================\n",
    "logger.info(\"Normalizing scores and applying variant consolidation...\")\n",
    "\n",
    "\n",
    "\n",
    "# Normalize each scoring matrix to ensure fair contribution to final scores\n",
    "tfidf_normalized = normalize_scores(tfidf_aligned)\n",
    "lda_normalized = normalize_scores(lda_aligned)\n",
    "compound_normalized = normalize_scores(compound_aligned)\n",
    "\n",
    "# Combine normalized scores using weighted average\n",
    "combined_scores = (\n",
    "    TFIDF_WEIGHT * tfidf_normalized + \n",
    "    LDA_WEIGHT * lda_normalized + \n",
    "    COMPOUND_WEIGHT * compound_normalized\n",
    ")\n",
    "\n",
    "logger.info(f\"✓ Score combination complete: {combined_scores.shape}\")\n",
    "logger.info(f\"  Combined score range: [{combined_scores.min():.4f}, {combined_scores.max():.4f}]\")\n",
    "\n",
    "# Apply variant consolidation to prevent double-counting\n",
    "if variant_to_canonical:\n",
    "    logger.info(\"  Applying variant score consolidation to prevent double-counting...\")\n",
    "    \n",
    "    # Consolidate variant scores using maximum (not sum) to avoid inflating scores\n",
    "    final_scores, canonical_methods = consolidate_variant_scores(\n",
    "        combined_scores, all_features, variant_to_canonical\n",
    "    )\n",
    "    logger.info(f\"  ✓ Consolidated {len(all_features)} methods to {len(canonical_methods)} canonical methods\")\n",
    "else:\n",
    "    # No consolidation needed - use combined scores as-is\n",
    "    final_scores = combined_scores\n",
    "    canonical_methods = all_features\n",
    "    logger.info(\"  No variant consolidation applied (no variant mappings found)\")\n",
    "\n",
    "logger.info(f\"✓ Final consolidated scores: {final_scores.shape}\")\n",
    "logger.info(f\"  Final score range: [{final_scores.min():.4f}, {final_scores.max():.4f}]\")\n",
    "\n",
    "# =============================================================================\n",
    "# METHOD ASSIGNMENT TO PAPERS\n",
    "# =============================================================================\n",
    "logger.info(\"Assigning methods to papers using consolidated scores...\")\n",
    "\n",
    "# Assign top methods to each paper using the consolidated scores\n",
    "df = assign_methods_improved(\n",
    "    df, final_scores, canonical_methods, \n",
    "    top_n=TOP_METHODS_PER_PAPER, \n",
    "    min_score=MIN_ASSIGN_SCORE\n",
    ")\n",
    "\n",
    "# Additional diagnostic: Verify no double-counting occurred\n",
    "assigned_methods = df[df['Primary_Method'] != '']['Primary_Method'].tolist()\n",
    "method_assignment_counts = pd.Series(assigned_methods).value_counts()\n",
    "\n",
    "print(f\"\\n🔍 Final Assignment Verification:\")\n",
    "print(f\"  Papers assigned methods: {len(assigned_methods)}\")\n",
    "print(f\"  Unique methods assigned: {len(method_assignment_counts)}\")\n",
    "print(f\"  Top assigned methods:\")\n",
    "\n",
    "for method, count in method_assignment_counts.head(10).items():\n",
    "    # Check if this method has variants that were consolidated\n",
    "    variants = canonical_to_variants.get(method, [method])\n",
    "    if len(variants) > 1:\n",
    "        print(f\"    {method}: {count} papers (consolidated from: {variants})\")\n",
    "    else:\n",
    "        print(f\"    {method}: {count} papers\")\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE RESULTS AND METADATA\n",
    "# =============================================================================\n",
    "logger.info(\"Saving results and metadata...\")\n",
    "\n",
    "# Save method variant mappings for future reference and transparency\n",
    "with open(os.path.join(SAVE_DIR, f\"method_variant_groups_{suffix_string}.json\"), 'w') as f:\n",
    "    json.dump(canonical_to_variants, f, indent=2)\n",
    "\n",
    "# Save consolidated score matrix for analysis and debugging\n",
    "pd.DataFrame(final_scores, columns=canonical_methods).to_csv(\n",
    "    os.path.join(SAVE_DIR, f\"consolidated_method_scores_{suffix_string}.csv\")\n",
    ")\n",
    "\n",
    "# Save final enhanced dataframe with method assignments\n",
    "enhanced_analysis_filename = f\"enhanced_method_analysis_{suffix_string}.csv\"\n",
    "df.to_csv(os.path.join(SAVE_DIR, enhanced_analysis_filename), index=False)\n",
    "\n",
    "logger.info(f\"✓ Results saved:\")\n",
    "logger.info(f\"  Enhanced analysis: {enhanced_analysis_filename}\")\n",
    "logger.info(f\"  Method variant groups: method_variant_groups_{suffix_string}.json\")\n",
    "logger.info(f\"  Consolidated scores: consolidated_method_scores_{suffix_string}.csv\")\n",
    "\n",
    "# Run diagnostics\n",
    "diagnostic_results = enhanced_method_diagnostics(df, final_scores, canonical_methods, canonical_to_variants)\n",
    "\n",
    "print(f\"\\n✅ Enhanced Method Detection Pipeline Completed Successfully!\")\n",
    "print(f\"📁 All results saved to: {SAVE_DIR}\")\n",
    "print(f\"📊 Assignment Rate: {diagnostic_results['assignment_rate']:.1f}%\")\n",
    "print(f\"🔧 Methods Consolidated: {len(method_phrases) if method_phrases else 0} → {len(canonical_methods)}\")\n",
    "\n",
    "logger.info(\"Enhanced method detection pipeline with consolidation completed successfully!\")\n",
    "logger.info(f\"Credit usage: {credit_tracker.get_stats()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb61ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# %%\\n# Cell 10: Complete Enhanced Method Extraction and Assignment Workflow - REFACTORED\\n\\n# =============================================================================\\n# CONFIGURATION PARAMETERS - Adjust these for optimal method detection\\n# =============================================================================\\nMAX_FEATURES = 10000                    # Maximum features for candidate term extraction\\nTFIDF_WEIGHT = 0.45                      # Weight for TF-IDF scoring in final combination\\nLDA_WEIGHT = 0.25                        # Weight for LDA scoring in final combination  \\nCOMPOUND_WEIGHT = 0.30                   # Weight for compound scoring in final combination\\nTOP_METHODS_PER_PAPER = 10              # Number of top methods to assign per paper\\nMIN_ASSIGN_SCORE = 0.02                # Minimum score threshold for method assignment\\nBATCH_SIZE = 5000                       # Batch size for LLM processing\\nMETHOD_LLM_N_RUNS = 3                   # Number of LLM runs for method extraction\\nVARIANT_GROUP_BATCH_SIZE = 5000           # Batch size for method variant grouping\\nTOP_P=0.92\\nTEMP=0.15\\n\\nlogger.info(\"=== Starting Enhanced Method Detection Pipeline with Consolidation ===\")\\n\\n# =============================================================================\\n# STEP 1: LOAD OR EXTRACT METHOD PHRASES FROM CORPUS\\n# =============================================================================\\nlogger.info(\"Step 1: Loading or extracting method phrases...\")\\n\\n# Try to load existing method phrases from previous runs\\ntry:\\n    method_phrases, method_counts = load_method_phrases_from_csv(filename=\"extracted_method_phrases.csv\")\\nexcept (FileNotFoundError, TypeError):\\n    method_phrases, method_counts = None, None\\n\\n# If no existing phrases found or too few, extract new ones using LLM\\nif (method_phrases is None) or (len(method_phrases) < 3):\\n    logger.info(\"  1a: Extracting candidate terms from processed text...\")\\n    \\n    # Extract candidate n-grams (1-4 grams) from the corpus using CountVectorizer\\n    candidate_terms = extract_candidate_terms(df, text_col=\\'processed_text\\', max_features=MAX_FEATURES)\\n    logger.info(f\"  ✓ Extracted {len(candidate_terms)} candidate terms\")\\n    print(f\"  Sample candidate terms: {candidate_terms[:10]}\")\\n    \\n    logger.info(\"  1b: Using LLM to identify research methods from candidate terms...\")\\n    \\n    # Use LLM to intelligently identify research methods from candidate terms\\n    # This filters out generic terms and focuses on actual research methodologies\\n    # Call the functions with your prompts\\n    \\n    method_phrases, method_counts = get_method_phrases_enhanced(\\n        candidate_terms,\\n        client,\\n        model_type,\\n        credit_tracker,\\n        prompt=extraction_prompt,\\n        n_runs=METHOD_LLM_N_RUNS,\\n        batch_size=BATCH_SIZE,\\n        top_p=TOP_P,\\n        temp=TEMP\\n    )\\n    method_phrases = filter_generic_phrases(method_phrases)\\n    # Save extracted phrases for future use\\n    save_method_phrases_to_csv(method_phrases, method_counts)\\nelse:\\n    logger.info(f\"  ✓ Loaded {len(method_phrases)} method phrases from existing CSV\")\\n\\n# Validate that method extraction was successful\\nif not method_phrases:\\n    logger.error(\"No method phrases extracted! Check your LLM configuration and prompts.\")\\n    raise RuntimeError(\"Method extraction failed - no phrases found\")\\n\\nlogger.info(f\"✓ Method phrase extraction complete: {len(method_phrases)} phrases\")\\nprint(f\"  Sample methods: {method_phrases[:10]}\")\\n# Apply after LLM extraction:\\n\\n\\n# =============================================================================\\n# STEP 2: ENHANCED METHOD VARIANT CONSOLIDATION\\n# =============================================================================\\nlogger.info(\"Step 2: Building enhanced method variant groups with consolidation...\")\\n\\n# Use enhanced LLM-based variant grouping to consolidate similar methods\\nvariant_groups = build_method_variant_groups_enhanced(\\n    method_phrases, \\n    client, \\n    model_type, \\n    credit_tracker, \\n    prompt=grouping_prompt, \\n    top_p=TOP_P,\\n    temp=TEMP,\\n    batch_size=VARIANT_GROUP_BATCH_SIZE\\n) if method_phrases else {}\\n\\n# Create fallback mapping if LLM-based grouping fails completely\\nif not variant_groups and method_phrases:\\n    logger.info(\"  LLM grouping failed completely - using enhanced aggressive fallback grouping...\")\\n    variant_groups = aggressive_fallback_grouping(method_phrases, similarity_threshold=0.75)\\n    logger.info(f\"  ✓ Aggressive fallback created {len(variant_groups)} groups from {len(method_phrases)} methods\")\\n\\n# Create bidirectional mappings for efficient lookup during scoring\\nvariant_to_canonical, canonical_to_variants = create_variant_mapping(variant_groups)\\nlogger.info(f\"✓ Created {len(canonical_to_variants)} canonical methods with {len(variant_to_canonical)} total variants\")\\n\\n\\n# Display consolidation results\\nprint(f\"\\n📊 Method Consolidation Results:\")\\nprint(f\"  Original methods: {len(method_phrases) if method_phrases else 0}\")\\nprint(f\"  Consolidated methods: {len(canonical_to_variants)}\")\\nreduction = len(method_phrases) - len(canonical_to_variants) if method_phrases else 0\\nprint(f\"  Reduction: {reduction} methods ({100*reduction/len(method_phrases):.1f}% reduction)\" if method_phrases and len(method_phrases) > 0 else \"\")\\n\\nprint(\"\\nSample variant groups (showing groups with multiple variants):\")\\nsample_count = 0\\nfor canonical, variants in canonical_to_variants.items():\\n    if len(variants) > 1 and sample_count < 5:  # Only show groups with multiple variants\\n        print(f\"  {canonical}: {variants}\")\\n        sample_count += 1\\n\\n# =============================================================================\\n# STEP 3: COMPUTE MULTIPLE SCORING MATRICES FOR ROBUST METHOD DETECTION\\n# =============================================================================\\nlogger.info(\"Step 3: Computing enhanced scoring matrices using multiple approaches...\")\\n\\n# Convert DataFrame text to list for processing\\nprocessed_texts = df[\\'processed_text\\'].fillna(\\'\\').tolist()\\n\\n# 3a: TF-IDF Scoring - Captures term frequency and document importance\\nlogger.info(\"  3a: Computing TF-IDF scores for method variants...\")\\ntfidf_scores, tfidf_feature_names = compute_enhanced_tfidf_scores(\\n    processed_texts, canonical_to_variants\\n)\\nlogger.info(f\"  ✓ TF-IDF: {tfidf_scores.shape} with {len(tfidf_feature_names)} features\")\\n\\n# 3b: LDA Scoring - Captures topic-based method associations\\nlogger.info(\"  3b: Computing LDA scores for method variants...\")  \\nmethod_vocab = list(canonical_to_variants.keys())\\nlda_scores, lda_feature_names = compute_enhanced_lda_scores(\\n    processed_texts, canonical_to_variants, n_topics=len(method_vocab)\\n)\\nlogger.info(f\"  ✓ LDA: {lda_scores.shape} with {len(lda_feature_names)} features\")\\n\\n# 3c: Compound Scoring - Captures exact phrase matches and partial matches\\nlogger.info(\"  3c: Computing compound scores for method variants...\")\\ncompound_scores, compound_feature_names = compute_enhanced_compound_scores(\\n    df, canonical_to_variants\\n)\\nlogger.info(f\"  ✓ Compound: {compound_scores.shape} with {len(compound_feature_names)} features\")\\n\\n# =============================================================================\\n# STEP 4: FEATURE ALIGNMENT AND HARMONIZATION\\n# =============================================================================\\nlogger.info(\"Step 4: Aligning and harmonizing features across scoring methods...\")\\n\\n# Create union of all features to preserve maximum method coverage\\n# This ensures we don\\'t lose methods that appear in only one scoring approach\\nall_features = set(tfidf_feature_names) | set(lda_feature_names) | set(compound_feature_names)\\nall_features = sorted(list(all_features))  # Sort for consistency\\n\\nlogger.info(f\"  Feature alignment statistics:\")\\nlogger.info(f\"    Total unique features: {len(all_features)}\")\\nlogger.info(f\"    TF-IDF features: {len(tfidf_feature_names)}\")\\nlogger.info(f\"    LDA features: {len(lda_feature_names)}\")  \\nlogger.info(f\"    Compound features: {len(compound_feature_names)}\")\\n\\ndef align_scores_robust(scores, current_features, target_features):\\n    \\n    #Enhanced alignment with dimension safety checks and detailed error handling.\\n    \\n    if not target_features:\\n        return np.array([]).reshape(scores.shape[0], 0)\\n    \\n    # SAFETY CHECK: Verify dimensions match expectations\\n    expected_cols = len(current_features)\\n    actual_cols = scores.shape[1]\\n    \\n    if expected_cols != actual_cols:\\n        print(f\"⚠️  DIMENSION MISMATCH DETECTED:\")\\n        print(f\"    Expected columns: {expected_cols} (from feature names)\")\\n        print(f\"    Actual columns: {actual_cols} (from score matrix)\")\\n        print(f\"    Using actual matrix dimensions for safety\")\\n        \\n        # Use only the features that actually exist in the matrix\\n        safe_current_features = current_features[:actual_cols]\\n        print(f\"    Truncated feature list: {len(safe_current_features)} features\")\\n    else:\\n        safe_current_features = current_features\\n    \\n    # Initialize aligned matrix with zeros\\n    aligned_scores = np.zeros((scores.shape[0], len(target_features)))\\n    current_to_idx = {feat: i for i, feat in enumerate(safe_current_features)}\\n    \\n    # Map existing features to aligned positions with bounds checking\\n    found_features = 0\\n    skipped_features = 0\\n    \\n    for j, feat in enumerate(target_features):\\n        if feat in current_to_idx:\\n            source_idx = current_to_idx[feat]\\n            \\n            # BOUNDS CHECK: Ensure source index is valid\\n            if source_idx < scores.shape[1]:\\n                aligned_scores[:, j] = scores[:, source_idx]\\n                found_features += 1\\n            else:\\n                print(f\"⚠️  Skipping feature \\'{feat}\\': index {source_idx} >= {scores.shape[1]}\")\\n                skipped_features += 1\\n    \\n    print(f\"    ✓ Aligned {found_features}/{len(target_features)} features\")\\n    if skipped_features > 0:\\n        print(f\"    ⚠️  Skipped {skipped_features} features due to bounds issues\")\\n    \\n    return aligned_scores\\n\\n\\n# Align all scoring matrices to the unified feature space\\ntfidf_aligned = align_scores_robust(tfidf_scores, tfidf_feature_names, all_features)\\nlda_aligned = align_scores_robust(lda_scores, lda_feature_names, all_features)\\ncompound_aligned = align_scores_robust(compound_scores, compound_feature_names, all_features)\\n\\nlogger.info(f\"✓ Feature alignment complete: {tfidf_aligned.shape}\")\\n\\n# =============================================================================\\n# STEP 5: SCORE NORMALIZATION AND CONSOLIDATION\\n# =============================================================================\\nlogger.info(\"Step 5: Normalizing scores and applying variant consolidation...\")\\n\\ndef normalize_scores(scores):\\n    #Normalize scores to  range per matrix for fair weighting.[1]\\n    if scores.max() == 0:\\n        return scores\\n    return scores / scores.max()\\n\\n# Normalize each scoring matrix to ensure fair contribution to final scores\\ntfidf_normalized = normalize_scores(tfidf_aligned)\\nlda_normalized = normalize_scores(lda_aligned)\\ncompound_normalized = normalize_scores(compound_aligned)\\n\\n# Combine normalized scores using weighted average\\ncombined_scores = (\\n    TFIDF_WEIGHT * tfidf_normalized + \\n    LDA_WEIGHT * lda_normalized + \\n    COMPOUND_WEIGHT * compound_normalized\\n)\\n\\nlogger.info(f\"✓ Score combination complete: {combined_scores.shape}\")\\nlogger.info(f\"  Combined score range: [{combined_scores.min():.4f}, {combined_scores.max():.4f}]\")\\n\\n# Apply variant consolidation to prevent double-counting\\nif variant_to_canonical:\\n    logger.info(\"  Applying variant score consolidation to prevent double-counting...\")\\n    \\n    # Consolidate variant scores using maximum (not sum) to avoid inflating scores\\n    final_scores, canonical_methods = consolidate_variant_scores(\\n        combined_scores, all_features, variant_to_canonical\\n    )\\n    logger.info(f\"  ✓ Consolidated {len(all_features)} methods to {len(canonical_methods)} canonical methods\")\\n    \\n    # Display consolidation statistics\\n    print(f\"\\n🔍 Score Consolidation Check:\")\\n    print(f\"  Methods before consolidation: {len(all_features)}\")\\n    print(f\"  Methods after consolidation: {len(canonical_methods)}\")\\n    print(f\"  Consolidation prevented potential double-counting of {len(all_features) - len(canonical_methods)} method variants\")\\n    \\nelse:\\n    # No consolidation needed - use combined scores as-is\\n    final_scores = combined_scores\\n    canonical_methods = all_features\\n    logger.info(\"  No variant consolidation applied (no variant mappings found)\")\\n\\nlogger.info(f\"✓ Final consolidated scores: {final_scores.shape}\")\\nlogger.info(f\"  Final score range: [{final_scores.min():.4f}, {final_scores.max():.4f}]\")\\n\\n# =============================================================================\\n# STEP 6: METHOD ASSIGNMENT TO PAPERS\\n# =============================================================================\\nlogger.info(\"Step 6: Assigning methods to papers using consolidated scores...\")\\n\\n# Assign top methods to each paper using the consolidated scores\\n# This creates columns Method_1, Method_2, etc. plus Primary_Method\\ndf = assign_methods_improved(\\n    df, final_scores, canonical_methods, \\n    top_n=TOP_METHODS_PER_PAPER, \\n    min_score=MIN_ASSIGN_SCORE\\n)\\n\\n# Additional diagnostic: Verify no double-counting occurred\\nassigned_methods = df[df[\\'Primary_Method\\'] != \\'\\'][\\'Primary_Method\\'].tolist()\\nmethod_assignment_counts = pd.Series(assigned_methods).value_counts()\\n\\nprint(f\"\\n🔍 Final Assignment Verification:\")\\nprint(f\"  Papers assigned methods: {len(assigned_methods)}\")\\nprint(f\"  Unique methods assigned: {len(method_assignment_counts)}\")\\nprint(f\"  Top assigned methods:\")\\n\\nfor method, count in method_assignment_counts.head(10).items():\\n    # Check if this method has variants that were consolidated\\n    variants = canonical_to_variants.get(method, [method])\\n    if len(variants) > 1:\\n        print(f\"    {method}: {count} papers (consolidated from: {variants})\")\\n    else:\\n        print(f\"    {method}: {count} papers\")\\n\\n# =============================================================================\\n# STEP 7: SAVE RESULTS AND METADATA\\n# =============================================================================\\nlogger.info(\"Step 7: Saving results and metadata...\")\\n\\n# Save method variant mappings for future reference and transparency\\nwith open(os.path.join(SAVE_DIR, f\"method_variant_groups_{suffix_string}.json\"), \\'w\\') as f:\\n    json.dump(canonical_to_variants, f, indent=2)\\n\\n# Save consolidated score matrix for analysis and debugging\\npd.DataFrame(final_scores, columns=canonical_methods).to_csv(\\n    os.path.join(SAVE_DIR, f\"consolidated_method_scores_{suffix_string}.csv\")\\n)\\n\\n# Save final enhanced dataframe with method assignments\\nenhanced_analysis_filename = f\"enhanced_method_analysis_{suffix_string}.csv\"\\ndf.to_csv(os.path.join(SAVE_DIR, enhanced_analysis_filename), index=False)\\n\\nlogger.info(f\"✓ Results saved:\")\\nlogger.info(f\"  Enhanced analysis: {enhanced_analysis_filename}\")\\nlogger.info(f\"  Method variant groups: method_variant_groups_{suffix_string}.json\")\\nlogger.info(f\"  Consolidated scores: consolidated_method_scores_{suffix_string}.csv\")\\n\\n# =============================================================================\\n# STEP 8: COMPREHENSIVE DIAGNOSTICS AND QUALITY ASSESSMENT\\n# =============================================================================\\nlogger.info(\"Step 8: Running comprehensive diagnostics...\")\\n\\ndef enhanced_method_diagnostics(df, scores, method_names, variant_groups):\\n    \\n    #Comprehensive diagnostics for method assignment quality and consolidation effectiveness.\\n    \\n    print(\"\\n\" + \"=\"*80)\\n    print(\"COMPREHENSIVE METHOD DETECTION DIAGNOSTICS\")\\n    print(\"=\"*80)\\n    \\n    # Basic assignment statistics\\n    n_papers = len(df)\\n    assigned_papers = (df[\\'Primary_Method\\'] != \\'\\').sum()\\n    assignment_rate = 100 * assigned_papers / n_papers\\n    \\n    print(f\"\\n📊 ASSIGNMENT OVERVIEW:\")\\n    print(f\"  Total papers processed: {n_papers:,}\")\\n    print(f\"  Papers with methods assigned: {assigned_papers:,} ({assignment_rate:.1f}%)\")\\n    print(f\"  Papers without methods: {n_papers - assigned_papers:,} ({100-assignment_rate:.1f}%)\")\\n    \\n    # Score distribution analysis\\n    print(f\"\\n📈 SCORE DISTRIBUTION ANALYSIS:\")\\n    print(f\"  Final score matrix shape: {scores.shape}\")\\n    print(f\"  Total canonical methods: {len(method_names)}\")\\n    print(f\"  Score range: [{scores.min():.4f}, {scores.max():.4f}]\")\\n    print(f\"  Mean score: {scores.mean():.4f}\")\\n    print(f\"  Standard deviation: {scores.std():.4f}\")\\n    \\n    # Score threshold analysis\\n    thresholds = [0.001, 0.005, 0.01, 0.05, 0.1]\\n    for threshold in thresholds:\\n        count = (scores > threshold).sum()\\n        print(f\"  Scores > {threshold}: {count:,} ({100*count/scores.size:.2f}% of all scores)\")\\n    \\n    # Method popularity and assignment quality\\n    if assigned_papers > 0:\\n        print(f\"\\n🔥 TOP ASSIGNED METHODS:\")\\n        method_counts = df[\\'Primary_Method\\'].value_counts()\\n        \\n        for i, (method, count) in enumerate(method_counts.head(15).items()):\\n            if method:  # Skip empty strings\\n                percentage = 100 * count / assigned_papers\\n                # Check if method was consolidated from variants\\n                variants = variant_groups.get(method, [method])\\n                variant_info = f\" (from {len(variants)} variants)\" if len(variants) > 1 else \"\"\\n                print(f\"  {i+1:2d}. {method}: {count:,} papers ({percentage:.1f}%){variant_info}\")\\n    \\n    # Confidence distribution analysis\\n    if \\'Method_Confidence\\' in df.columns:\\n        print(f\"\\n🎯 CONFIDENCE DISTRIBUTION:\")\\n        conf_counts = df[\\'Method_Confidence\\'].value_counts()\\n        for conf, count in conf_counts.items():\\n            percentage = 100 * count / n_papers\\n            print(f\"  {conf}: {count:,} ({percentage:.1f}%)\")\\n    \\n    # Consolidation effectiveness analysis\\n    print(f\"\\n🔧 CONSOLIDATION EFFECTIVENESS:\")\\n    total_variants = sum(len(variants) for variants in variant_groups.values())\\n    consolidated_groups = len([v for v in variant_groups.values() if len(v) > 1])\\n    \\n    print(f\"  Total method variants processed: {total_variants:,}\")\\n    print(f\"  Final canonical methods: {len(variant_groups):,}\")\\n    print(f\"  Groups with multiple variants: {consolidated_groups:,}\")\\n    print(f\"  Consolidation ratio: {total_variants/len(variant_groups):.2f}:1\")\\n    \\n    # Quality assessment and recommendations\\n    print(f\"\\n⚠️  QUALITY ASSESSMENT:\")\\n    \\n    if assignment_rate < 50:\\n        print(f\"  ⚠️  Low assignment rate ({assignment_rate:.1f}%) - consider:\")\\n        print(f\"      -  Lowering MIN_ASSIGN_SCORE (current: {MIN_ASSIGN_SCORE})\")\\n        print(f\"      -  Reviewing method extraction quality\")\\n        print(f\"      -  Checking text preprocessing effectiveness\")\\n    else:\\n        print(f\"  ✅ Good assignment rate ({assignment_rate:.1f}%)\")\\n    \\n    if scores.max() < 0.1:\\n        print(f\"  ⚠️  Low maximum scores ({scores.max():.4f}) - scoring method may need adjustment\")\\n    else:\\n        print(f\"  ✅ Reasonable maximum scores ({scores.max():.4f})\")\\n    \\n    zero_score_methods = (scores.max(axis=0) == 0).sum()\\n    if zero_score_methods > 0:\\n        zero_percentage = 100 * zero_score_methods / len(method_names)\\n        print(f\"  ⚠️  {zero_score_methods} methods ({zero_percentage:.1f}%) have zero scores across all papers\")\\n        print(f\"      Consider reviewing method extraction or scoring parameters\")\\n    else:\\n        print(f\"  ✅ All methods have non-zero scores in at least some papers\")\\n    \\n    print(\"\\n\" + \"=\"*80)\\n    return {\\n        \\'assignment_rate\\': assignment_rate,\\n        \\'total_papers\\': n_papers,\\n        \\'assigned_papers\\': assigned_papers,\\n        \\'score_stats\\': {\\n            \\'min\\': scores.min(),\\n            \\'max\\': scores.max(),\\n            \\'mean\\': scores.mean(),\\n            \\'std\\': scores.std()\\n        }\\n    }\\n\\n# Run comprehensive diagnostics\\ndiagnostic_results = enhanced_method_diagnostics(df, final_scores, canonical_methods, canonical_to_variants)\\n\\n# =============================================================================\\n# STEP 9: DISPLAY SAMPLE RESULTS FOR VERIFICATION\\n# =============================================================================\\nprint(\"\\n\" + \"=\"*80)\\nprint(\"SAMPLE RESULTS FOR VERIFICATION\")\\nprint(\"=\"*80)\\n\\n# Define columns to display in sample results\\nsample_cols = [\\'Primary_Method\\', \\'Primary_Method_Score\\', \\'Method_Confidence\\', \\'Total_Method_Score\\']\\navailable_cols = [col for col in sample_cols if col in df.columns]\\n\\n# Show sample of papers WITH methods assigned\\nassigned_mask = df[\\'Primary_Method\\'] != \\'\\'\\nif assigned_mask.sum() > 0:\\n    print(f\"\\n📄 SAMPLE PAPERS WITH METHODS ASSIGNED (first 10):\")\\n    sample_assigned = df[assigned_mask][available_cols].head(10)\\n    print(sample_assigned.to_string(index=False))\\n    \\n    # Show distribution of assigned methods\\n    print(f\"\\n📊 METHOD ASSIGNMENT DISTRIBUTION:\")\\n    for i in range(1, min(4, TOP_METHODS_PER_PAPER + 1)):  # Show top 3 method columns\\n        col_name = f\\'Method_{i}\\'\\n        if col_name in df.columns:\\n            non_empty = df[df[col_name] != \\'\\'][col_name].value_counts()\\n            print(f\"  {col_name} - {len(non_empty)} unique methods assigned to {non_empty.sum()} papers\")\\n\\n# Show sample of papers WITHOUT methods for diagnostic purposes\\nunassigned_mask = df[\\'Primary_Method\\'] == \\'\\'\\nif unassigned_mask.sum() > 0:\\n    print(f\"\\n❌ SAMPLE PAPERS WITHOUT METHODS (first 5 for diagnostic):\")\\n    unassigned_sample = df[unassigned_mask].head(5)\\n    \\n    if \\'processed_text\\' in df.columns:\\n        for idx, row in unassigned_sample.iterrows():\\n            text_preview = row.get(\\'processed_text\\', \\'\\')[:150] + \"...\" if len(str(row.get(\\'processed_text\\', \\'\\'))) > 150 else row.get(\\'processed_text\\', \\'\\')\\n            print(f\"  Paper {idx}: {text_preview}\")\\n\\n# Final completion message\\nprint(f\"\\n✅ Enhanced Method Detection Pipeline Completed Successfully!\")\\nprint(f\"📁 All results saved to: {SAVE_DIR}\")\\nprint(f\"📊 Assignment Rate: {diagnostic_results[\\'assignment_rate\\']:.1f}%\")\\nprint(f\"🔧 Methods Consolidated: {len(method_phrases) if method_phrases else 0} → {len(canonical_methods)}\")\\n\\nlogger.info(\"Enhanced method detection pipeline with consolidation completed successfully!\")\\nlogger.info(f\"Credit usage: {credit_tracker.get_stats()}\")\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# old \"one-fell swoup\"executing of method assignment\n",
    "\"\"\"\n",
    "# %%\n",
    "# Cell 10: Complete Enhanced Method Extraction and Assignment Workflow - REFACTORED\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION PARAMETERS - Adjust these for optimal method detection\n",
    "# =============================================================================\n",
    "MAX_FEATURES = 10000                    # Maximum features for candidate term extraction\n",
    "TFIDF_WEIGHT = 0.45                      # Weight for TF-IDF scoring in final combination\n",
    "LDA_WEIGHT = 0.25                        # Weight for LDA scoring in final combination  \n",
    "COMPOUND_WEIGHT = 0.30                   # Weight for compound scoring in final combination\n",
    "TOP_METHODS_PER_PAPER = 10              # Number of top methods to assign per paper\n",
    "MIN_ASSIGN_SCORE = 0.02                # Minimum score threshold for method assignment\n",
    "BATCH_SIZE = 5000                       # Batch size for LLM processing\n",
    "METHOD_LLM_N_RUNS = 3                   # Number of LLM runs for method extraction\n",
    "VARIANT_GROUP_BATCH_SIZE = 5000           # Batch size for method variant grouping\n",
    "TOP_P=0.92\n",
    "TEMP=0.15\n",
    "\n",
    "logger.info(\"=== Starting Enhanced Method Detection Pipeline with Consolidation ===\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: LOAD OR EXTRACT METHOD PHRASES FROM CORPUS\n",
    "# =============================================================================\n",
    "logger.info(\"Step 1: Loading or extracting method phrases...\")\n",
    "\n",
    "# Try to load existing method phrases from previous runs\n",
    "try:\n",
    "    method_phrases, method_counts = load_method_phrases_from_csv(filename=\"extracted_method_phrases.csv\")\n",
    "except (FileNotFoundError, TypeError):\n",
    "    method_phrases, method_counts = None, None\n",
    "\n",
    "# If no existing phrases found or too few, extract new ones using LLM\n",
    "if (method_phrases is None) or (len(method_phrases) < 3):\n",
    "    logger.info(\"  1a: Extracting candidate terms from processed text...\")\n",
    "    \n",
    "    # Extract candidate n-grams (1-4 grams) from the corpus using CountVectorizer\n",
    "    candidate_terms = extract_candidate_terms(df, text_col='processed_text', max_features=MAX_FEATURES)\n",
    "    logger.info(f\"  ✓ Extracted {len(candidate_terms)} candidate terms\")\n",
    "    print(f\"  Sample candidate terms: {candidate_terms[:10]}\")\n",
    "    \n",
    "    logger.info(\"  1b: Using LLM to identify research methods from candidate terms...\")\n",
    "    \n",
    "    # Use LLM to intelligently identify research methods from candidate terms\n",
    "    # This filters out generic terms and focuses on actual research methodologies\n",
    "    # Call the functions with your prompts\n",
    "    \n",
    "    method_phrases, method_counts = get_method_phrases_enhanced(\n",
    "        candidate_terms,\n",
    "        client,\n",
    "        model_type,\n",
    "        credit_tracker,\n",
    "        prompt=extraction_prompt,\n",
    "        n_runs=METHOD_LLM_N_RUNS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        top_p=TOP_P,\n",
    "        temp=TEMP\n",
    "    )\n",
    "    method_phrases = filter_generic_phrases(method_phrases)\n",
    "    # Save extracted phrases for future use\n",
    "    save_method_phrases_to_csv(method_phrases, method_counts)\n",
    "else:\n",
    "    logger.info(f\"  ✓ Loaded {len(method_phrases)} method phrases from existing CSV\")\n",
    "\n",
    "# Validate that method extraction was successful\n",
    "if not method_phrases:\n",
    "    logger.error(\"No method phrases extracted! Check your LLM configuration and prompts.\")\n",
    "    raise RuntimeError(\"Method extraction failed - no phrases found\")\n",
    "\n",
    "logger.info(f\"✓ Method phrase extraction complete: {len(method_phrases)} phrases\")\n",
    "print(f\"  Sample methods: {method_phrases[:10]}\")\n",
    "# Apply after LLM extraction:\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: ENHANCED METHOD VARIANT CONSOLIDATION\n",
    "# =============================================================================\n",
    "logger.info(\"Step 2: Building enhanced method variant groups with consolidation...\")\n",
    "\n",
    "# Use enhanced LLM-based variant grouping to consolidate similar methods\n",
    "variant_groups = build_method_variant_groups_enhanced(\n",
    "    method_phrases, \n",
    "    client, \n",
    "    model_type, \n",
    "    credit_tracker, \n",
    "    prompt=grouping_prompt, \n",
    "    top_p=TOP_P,\n",
    "    temp=TEMP,\n",
    "    batch_size=VARIANT_GROUP_BATCH_SIZE\n",
    ") if method_phrases else {}\n",
    "\n",
    "# Create fallback mapping if LLM-based grouping fails completely\n",
    "if not variant_groups and method_phrases:\n",
    "    logger.info(\"  LLM grouping failed completely - using enhanced aggressive fallback grouping...\")\n",
    "    variant_groups = aggressive_fallback_grouping(method_phrases, similarity_threshold=0.75)\n",
    "    logger.info(f\"  ✓ Aggressive fallback created {len(variant_groups)} groups from {len(method_phrases)} methods\")\n",
    "\n",
    "# Create bidirectional mappings for efficient lookup during scoring\n",
    "variant_to_canonical, canonical_to_variants = create_variant_mapping(variant_groups)\n",
    "logger.info(f\"✓ Created {len(canonical_to_variants)} canonical methods with {len(variant_to_canonical)} total variants\")\n",
    "\n",
    "\n",
    "# Display consolidation results\n",
    "print(f\"\\n📊 Method Consolidation Results:\")\n",
    "print(f\"  Original methods: {len(method_phrases) if method_phrases else 0}\")\n",
    "print(f\"  Consolidated methods: {len(canonical_to_variants)}\")\n",
    "reduction = len(method_phrases) - len(canonical_to_variants) if method_phrases else 0\n",
    "print(f\"  Reduction: {reduction} methods ({100*reduction/len(method_phrases):.1f}% reduction)\" if method_phrases and len(method_phrases) > 0 else \"\")\n",
    "\n",
    "print(\"\\nSample variant groups (showing groups with multiple variants):\")\n",
    "sample_count = 0\n",
    "for canonical, variants in canonical_to_variants.items():\n",
    "    if len(variants) > 1 and sample_count < 5:  # Only show groups with multiple variants\n",
    "        print(f\"  {canonical}: {variants}\")\n",
    "        sample_count += 1\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: COMPUTE MULTIPLE SCORING MATRICES FOR ROBUST METHOD DETECTION\n",
    "# =============================================================================\n",
    "logger.info(\"Step 3: Computing enhanced scoring matrices using multiple approaches...\")\n",
    "\n",
    "# Convert DataFrame text to list for processing\n",
    "processed_texts = df['processed_text'].fillna('').tolist()\n",
    "\n",
    "# 3a: TF-IDF Scoring - Captures term frequency and document importance\n",
    "logger.info(\"  3a: Computing TF-IDF scores for method variants...\")\n",
    "tfidf_scores, tfidf_feature_names = compute_enhanced_tfidf_scores(\n",
    "    processed_texts, canonical_to_variants\n",
    ")\n",
    "logger.info(f\"  ✓ TF-IDF: {tfidf_scores.shape} with {len(tfidf_feature_names)} features\")\n",
    "\n",
    "# 3b: LDA Scoring - Captures topic-based method associations\n",
    "logger.info(\"  3b: Computing LDA scores for method variants...\")  \n",
    "method_vocab = list(canonical_to_variants.keys())\n",
    "lda_scores, lda_feature_names = compute_enhanced_lda_scores(\n",
    "    processed_texts, canonical_to_variants, n_topics=len(method_vocab)\n",
    ")\n",
    "logger.info(f\"  ✓ LDA: {lda_scores.shape} with {len(lda_feature_names)} features\")\n",
    "\n",
    "# 3c: Compound Scoring - Captures exact phrase matches and partial matches\n",
    "logger.info(\"  3c: Computing compound scores for method variants...\")\n",
    "compound_scores, compound_feature_names = compute_enhanced_compound_scores(\n",
    "    df, canonical_to_variants\n",
    ")\n",
    "logger.info(f\"  ✓ Compound: {compound_scores.shape} with {len(compound_feature_names)} features\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 4: FEATURE ALIGNMENT AND HARMONIZATION\n",
    "# =============================================================================\n",
    "logger.info(\"Step 4: Aligning and harmonizing features across scoring methods...\")\n",
    "\n",
    "# Create union of all features to preserve maximum method coverage\n",
    "# This ensures we don't lose methods that appear in only one scoring approach\n",
    "all_features = set(tfidf_feature_names) | set(lda_feature_names) | set(compound_feature_names)\n",
    "all_features = sorted(list(all_features))  # Sort for consistency\n",
    "\n",
    "logger.info(f\"  Feature alignment statistics:\")\n",
    "logger.info(f\"    Total unique features: {len(all_features)}\")\n",
    "logger.info(f\"    TF-IDF features: {len(tfidf_feature_names)}\")\n",
    "logger.info(f\"    LDA features: {len(lda_feature_names)}\")  \n",
    "logger.info(f\"    Compound features: {len(compound_feature_names)}\")\n",
    "\n",
    "def align_scores_robust(scores, current_features, target_features):\n",
    "    \n",
    "    #Enhanced alignment with dimension safety checks and detailed error handling.\n",
    "    \n",
    "    if not target_features:\n",
    "        return np.array([]).reshape(scores.shape[0], 0)\n",
    "    \n",
    "    # SAFETY CHECK: Verify dimensions match expectations\n",
    "    expected_cols = len(current_features)\n",
    "    actual_cols = scores.shape[1]\n",
    "    \n",
    "    if expected_cols != actual_cols:\n",
    "        print(f\"⚠️  DIMENSION MISMATCH DETECTED:\")\n",
    "        print(f\"    Expected columns: {expected_cols} (from feature names)\")\n",
    "        print(f\"    Actual columns: {actual_cols} (from score matrix)\")\n",
    "        print(f\"    Using actual matrix dimensions for safety\")\n",
    "        \n",
    "        # Use only the features that actually exist in the matrix\n",
    "        safe_current_features = current_features[:actual_cols]\n",
    "        print(f\"    Truncated feature list: {len(safe_current_features)} features\")\n",
    "    else:\n",
    "        safe_current_features = current_features\n",
    "    \n",
    "    # Initialize aligned matrix with zeros\n",
    "    aligned_scores = np.zeros((scores.shape[0], len(target_features)))\n",
    "    current_to_idx = {feat: i for i, feat in enumerate(safe_current_features)}\n",
    "    \n",
    "    # Map existing features to aligned positions with bounds checking\n",
    "    found_features = 0\n",
    "    skipped_features = 0\n",
    "    \n",
    "    for j, feat in enumerate(target_features):\n",
    "        if feat in current_to_idx:\n",
    "            source_idx = current_to_idx[feat]\n",
    "            \n",
    "            # BOUNDS CHECK: Ensure source index is valid\n",
    "            if source_idx < scores.shape[1]:\n",
    "                aligned_scores[:, j] = scores[:, source_idx]\n",
    "                found_features += 1\n",
    "            else:\n",
    "                print(f\"⚠️  Skipping feature '{feat}': index {source_idx} >= {scores.shape[1]}\")\n",
    "                skipped_features += 1\n",
    "    \n",
    "    print(f\"    ✓ Aligned {found_features}/{len(target_features)} features\")\n",
    "    if skipped_features > 0:\n",
    "        print(f\"    ⚠️  Skipped {skipped_features} features due to bounds issues\")\n",
    "    \n",
    "    return aligned_scores\n",
    "\n",
    "\n",
    "# Align all scoring matrices to the unified feature space\n",
    "tfidf_aligned = align_scores_robust(tfidf_scores, tfidf_feature_names, all_features)\n",
    "lda_aligned = align_scores_robust(lda_scores, lda_feature_names, all_features)\n",
    "compound_aligned = align_scores_robust(compound_scores, compound_feature_names, all_features)\n",
    "\n",
    "logger.info(f\"✓ Feature alignment complete: {tfidf_aligned.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 5: SCORE NORMALIZATION AND CONSOLIDATION\n",
    "# =============================================================================\n",
    "logger.info(\"Step 5: Normalizing scores and applying variant consolidation...\")\n",
    "\n",
    "def normalize_scores(scores):\n",
    "    #Normalize scores to  range per matrix for fair weighting.[1]\n",
    "    if scores.max() == 0:\n",
    "        return scores\n",
    "    return scores / scores.max()\n",
    "\n",
    "# Normalize each scoring matrix to ensure fair contribution to final scores\n",
    "tfidf_normalized = normalize_scores(tfidf_aligned)\n",
    "lda_normalized = normalize_scores(lda_aligned)\n",
    "compound_normalized = normalize_scores(compound_aligned)\n",
    "\n",
    "# Combine normalized scores using weighted average\n",
    "combined_scores = (\n",
    "    TFIDF_WEIGHT * tfidf_normalized + \n",
    "    LDA_WEIGHT * lda_normalized + \n",
    "    COMPOUND_WEIGHT * compound_normalized\n",
    ")\n",
    "\n",
    "logger.info(f\"✓ Score combination complete: {combined_scores.shape}\")\n",
    "logger.info(f\"  Combined score range: [{combined_scores.min():.4f}, {combined_scores.max():.4f}]\")\n",
    "\n",
    "# Apply variant consolidation to prevent double-counting\n",
    "if variant_to_canonical:\n",
    "    logger.info(\"  Applying variant score consolidation to prevent double-counting...\")\n",
    "    \n",
    "    # Consolidate variant scores using maximum (not sum) to avoid inflating scores\n",
    "    final_scores, canonical_methods = consolidate_variant_scores(\n",
    "        combined_scores, all_features, variant_to_canonical\n",
    "    )\n",
    "    logger.info(f\"  ✓ Consolidated {len(all_features)} methods to {len(canonical_methods)} canonical methods\")\n",
    "    \n",
    "    # Display consolidation statistics\n",
    "    print(f\"\\n🔍 Score Consolidation Check:\")\n",
    "    print(f\"  Methods before consolidation: {len(all_features)}\")\n",
    "    print(f\"  Methods after consolidation: {len(canonical_methods)}\")\n",
    "    print(f\"  Consolidation prevented potential double-counting of {len(all_features) - len(canonical_methods)} method variants\")\n",
    "    \n",
    "else:\n",
    "    # No consolidation needed - use combined scores as-is\n",
    "    final_scores = combined_scores\n",
    "    canonical_methods = all_features\n",
    "    logger.info(\"  No variant consolidation applied (no variant mappings found)\")\n",
    "\n",
    "logger.info(f\"✓ Final consolidated scores: {final_scores.shape}\")\n",
    "logger.info(f\"  Final score range: [{final_scores.min():.4f}, {final_scores.max():.4f}]\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 6: METHOD ASSIGNMENT TO PAPERS\n",
    "# =============================================================================\n",
    "logger.info(\"Step 6: Assigning methods to papers using consolidated scores...\")\n",
    "\n",
    "# Assign top methods to each paper using the consolidated scores\n",
    "# This creates columns Method_1, Method_2, etc. plus Primary_Method\n",
    "df = assign_methods_improved(\n",
    "    df, final_scores, canonical_methods, \n",
    "    top_n=TOP_METHODS_PER_PAPER, \n",
    "    min_score=MIN_ASSIGN_SCORE\n",
    ")\n",
    "\n",
    "# Additional diagnostic: Verify no double-counting occurred\n",
    "assigned_methods = df[df['Primary_Method'] != '']['Primary_Method'].tolist()\n",
    "method_assignment_counts = pd.Series(assigned_methods).value_counts()\n",
    "\n",
    "print(f\"\\n🔍 Final Assignment Verification:\")\n",
    "print(f\"  Papers assigned methods: {len(assigned_methods)}\")\n",
    "print(f\"  Unique methods assigned: {len(method_assignment_counts)}\")\n",
    "print(f\"  Top assigned methods:\")\n",
    "\n",
    "for method, count in method_assignment_counts.head(10).items():\n",
    "    # Check if this method has variants that were consolidated\n",
    "    variants = canonical_to_variants.get(method, [method])\n",
    "    if len(variants) > 1:\n",
    "        print(f\"    {method}: {count} papers (consolidated from: {variants})\")\n",
    "    else:\n",
    "        print(f\"    {method}: {count} papers\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 7: SAVE RESULTS AND METADATA\n",
    "# =============================================================================\n",
    "logger.info(\"Step 7: Saving results and metadata...\")\n",
    "\n",
    "# Save method variant mappings for future reference and transparency\n",
    "with open(os.path.join(SAVE_DIR, f\"method_variant_groups_{suffix_string}.json\"), 'w') as f:\n",
    "    json.dump(canonical_to_variants, f, indent=2)\n",
    "\n",
    "# Save consolidated score matrix for analysis and debugging\n",
    "pd.DataFrame(final_scores, columns=canonical_methods).to_csv(\n",
    "    os.path.join(SAVE_DIR, f\"consolidated_method_scores_{suffix_string}.csv\")\n",
    ")\n",
    "\n",
    "# Save final enhanced dataframe with method assignments\n",
    "enhanced_analysis_filename = f\"enhanced_method_analysis_{suffix_string}.csv\"\n",
    "df.to_csv(os.path.join(SAVE_DIR, enhanced_analysis_filename), index=False)\n",
    "\n",
    "logger.info(f\"✓ Results saved:\")\n",
    "logger.info(f\"  Enhanced analysis: {enhanced_analysis_filename}\")\n",
    "logger.info(f\"  Method variant groups: method_variant_groups_{suffix_string}.json\")\n",
    "logger.info(f\"  Consolidated scores: consolidated_method_scores_{suffix_string}.csv\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 8: COMPREHENSIVE DIAGNOSTICS AND QUALITY ASSESSMENT\n",
    "# =============================================================================\n",
    "logger.info(\"Step 8: Running comprehensive diagnostics...\")\n",
    "\n",
    "def enhanced_method_diagnostics(df, scores, method_names, variant_groups):\n",
    "    \n",
    "    #Comprehensive diagnostics for method assignment quality and consolidation effectiveness.\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPREHENSIVE METHOD DETECTION DIAGNOSTICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Basic assignment statistics\n",
    "    n_papers = len(df)\n",
    "    assigned_papers = (df['Primary_Method'] != '').sum()\n",
    "    assignment_rate = 100 * assigned_papers / n_papers\n",
    "    \n",
    "    print(f\"\\n📊 ASSIGNMENT OVERVIEW:\")\n",
    "    print(f\"  Total papers processed: {n_papers:,}\")\n",
    "    print(f\"  Papers with methods assigned: {assigned_papers:,} ({assignment_rate:.1f}%)\")\n",
    "    print(f\"  Papers without methods: {n_papers - assigned_papers:,} ({100-assignment_rate:.1f}%)\")\n",
    "    \n",
    "    # Score distribution analysis\n",
    "    print(f\"\\n📈 SCORE DISTRIBUTION ANALYSIS:\")\n",
    "    print(f\"  Final score matrix shape: {scores.shape}\")\n",
    "    print(f\"  Total canonical methods: {len(method_names)}\")\n",
    "    print(f\"  Score range: [{scores.min():.4f}, {scores.max():.4f}]\")\n",
    "    print(f\"  Mean score: {scores.mean():.4f}\")\n",
    "    print(f\"  Standard deviation: {scores.std():.4f}\")\n",
    "    \n",
    "    # Score threshold analysis\n",
    "    thresholds = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "    for threshold in thresholds:\n",
    "        count = (scores > threshold).sum()\n",
    "        print(f\"  Scores > {threshold}: {count:,} ({100*count/scores.size:.2f}% of all scores)\")\n",
    "    \n",
    "    # Method popularity and assignment quality\n",
    "    if assigned_papers > 0:\n",
    "        print(f\"\\n🔥 TOP ASSIGNED METHODS:\")\n",
    "        method_counts = df['Primary_Method'].value_counts()\n",
    "        \n",
    "        for i, (method, count) in enumerate(method_counts.head(15).items()):\n",
    "            if method:  # Skip empty strings\n",
    "                percentage = 100 * count / assigned_papers\n",
    "                # Check if method was consolidated from variants\n",
    "                variants = variant_groups.get(method, [method])\n",
    "                variant_info = f\" (from {len(variants)} variants)\" if len(variants) > 1 else \"\"\n",
    "                print(f\"  {i+1:2d}. {method}: {count:,} papers ({percentage:.1f}%){variant_info}\")\n",
    "    \n",
    "    # Confidence distribution analysis\n",
    "    if 'Method_Confidence' in df.columns:\n",
    "        print(f\"\\n🎯 CONFIDENCE DISTRIBUTION:\")\n",
    "        conf_counts = df['Method_Confidence'].value_counts()\n",
    "        for conf, count in conf_counts.items():\n",
    "            percentage = 100 * count / n_papers\n",
    "            print(f\"  {conf}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Consolidation effectiveness analysis\n",
    "    print(f\"\\n🔧 CONSOLIDATION EFFECTIVENESS:\")\n",
    "    total_variants = sum(len(variants) for variants in variant_groups.values())\n",
    "    consolidated_groups = len([v for v in variant_groups.values() if len(v) > 1])\n",
    "    \n",
    "    print(f\"  Total method variants processed: {total_variants:,}\")\n",
    "    print(f\"  Final canonical methods: {len(variant_groups):,}\")\n",
    "    print(f\"  Groups with multiple variants: {consolidated_groups:,}\")\n",
    "    print(f\"  Consolidation ratio: {total_variants/len(variant_groups):.2f}:1\")\n",
    "    \n",
    "    # Quality assessment and recommendations\n",
    "    print(f\"\\n⚠️  QUALITY ASSESSMENT:\")\n",
    "    \n",
    "    if assignment_rate < 50:\n",
    "        print(f\"  ⚠️  Low assignment rate ({assignment_rate:.1f}%) - consider:\")\n",
    "        print(f\"      -  Lowering MIN_ASSIGN_SCORE (current: {MIN_ASSIGN_SCORE})\")\n",
    "        print(f\"      -  Reviewing method extraction quality\")\n",
    "        print(f\"      -  Checking text preprocessing effectiveness\")\n",
    "    else:\n",
    "        print(f\"  ✅ Good assignment rate ({assignment_rate:.1f}%)\")\n",
    "    \n",
    "    if scores.max() < 0.1:\n",
    "        print(f\"  ⚠️  Low maximum scores ({scores.max():.4f}) - scoring method may need adjustment\")\n",
    "    else:\n",
    "        print(f\"  ✅ Reasonable maximum scores ({scores.max():.4f})\")\n",
    "    \n",
    "    zero_score_methods = (scores.max(axis=0) == 0).sum()\n",
    "    if zero_score_methods > 0:\n",
    "        zero_percentage = 100 * zero_score_methods / len(method_names)\n",
    "        print(f\"  ⚠️  {zero_score_methods} methods ({zero_percentage:.1f}%) have zero scores across all papers\")\n",
    "        print(f\"      Consider reviewing method extraction or scoring parameters\")\n",
    "    else:\n",
    "        print(f\"  ✅ All methods have non-zero scores in at least some papers\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    return {\n",
    "        'assignment_rate': assignment_rate,\n",
    "        'total_papers': n_papers,\n",
    "        'assigned_papers': assigned_papers,\n",
    "        'score_stats': {\n",
    "            'min': scores.min(),\n",
    "            'max': scores.max(),\n",
    "            'mean': scores.mean(),\n",
    "            'std': scores.std()\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Run comprehensive diagnostics\n",
    "diagnostic_results = enhanced_method_diagnostics(df, final_scores, canonical_methods, canonical_to_variants)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 9: DISPLAY SAMPLE RESULTS FOR VERIFICATION\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE RESULTS FOR VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define columns to display in sample results\n",
    "sample_cols = ['Primary_Method', 'Primary_Method_Score', 'Method_Confidence', 'Total_Method_Score']\n",
    "available_cols = [col for col in sample_cols if col in df.columns]\n",
    "\n",
    "# Show sample of papers WITH methods assigned\n",
    "assigned_mask = df['Primary_Method'] != ''\n",
    "if assigned_mask.sum() > 0:\n",
    "    print(f\"\\n📄 SAMPLE PAPERS WITH METHODS ASSIGNED (first 10):\")\n",
    "    sample_assigned = df[assigned_mask][available_cols].head(10)\n",
    "    print(sample_assigned.to_string(index=False))\n",
    "    \n",
    "    # Show distribution of assigned methods\n",
    "    print(f\"\\n📊 METHOD ASSIGNMENT DISTRIBUTION:\")\n",
    "    for i in range(1, min(4, TOP_METHODS_PER_PAPER + 1)):  # Show top 3 method columns\n",
    "        col_name = f'Method_{i}'\n",
    "        if col_name in df.columns:\n",
    "            non_empty = df[df[col_name] != ''][col_name].value_counts()\n",
    "            print(f\"  {col_name} - {len(non_empty)} unique methods assigned to {non_empty.sum()} papers\")\n",
    "\n",
    "# Show sample of papers WITHOUT methods for diagnostic purposes\n",
    "unassigned_mask = df['Primary_Method'] == ''\n",
    "if unassigned_mask.sum() > 0:\n",
    "    print(f\"\\n❌ SAMPLE PAPERS WITHOUT METHODS (first 5 for diagnostic):\")\n",
    "    unassigned_sample = df[unassigned_mask].head(5)\n",
    "    \n",
    "    if 'processed_text' in df.columns:\n",
    "        for idx, row in unassigned_sample.iterrows():\n",
    "            text_preview = row.get('processed_text', '')[:150] + \"...\" if len(str(row.get('processed_text', ''))) > 150 else row.get('processed_text', '')\n",
    "            print(f\"  Paper {idx}: {text_preview}\")\n",
    "\n",
    "# Final completion message\n",
    "print(f\"\\n✅ Enhanced Method Detection Pipeline Completed Successfully!\")\n",
    "print(f\"📁 All results saved to: {SAVE_DIR}\")\n",
    "print(f\"📊 Assignment Rate: {diagnostic_results['assignment_rate']:.1f}%\")\n",
    "print(f\"🔧 Methods Consolidated: {len(method_phrases) if method_phrases else 0} → {len(canonical_methods)}\")\n",
    "\n",
    "logger.info(\"Enhanced method detection pipeline with consolidation completed successfully!\")\n",
    "logger.info(f\"Credit usage: {credit_tracker.get_stats()}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9db32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🔍 METHOD CONSOLIDATION VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "📊 COUNTS:\n",
      "  Original methods: 165\n",
      "  Canonical groups: 91\n",
      "  Assigned methods: 86\n",
      "\n",
      "✅ SUCCESS: All assigned methods are canonical groups\n",
      "\n",
      "✅ SUCCESS: No redundant methods in assignments\n",
      "\n",
      "🔍 CONSOLIDATION EXAMPLES:\n",
      "  'total harmonic distortion thd' consolidated: ['total harmonic distortion thd', 'total harmonic distortion']\n",
      "  'deep reinforcement learning drl' consolidated: ['reinforcement learning drl', 'deep reinforcement learning drl']\n",
      "  'loss of load probability' consolidated: ['lolp', 'loss of load probability']\n",
      "  'system average interruption duration index' consolidated: ['system average interruption duration index', 'caidi']\n",
      "  'monte carlo simulation' consolidated: ['monte carlo simulation', 'monte-carlo simulation']\n",
      "\n",
      "📈 TOP ASSIGNED METHODS (canonical):\n",
      "   1. artificial neural network: 566 papers (from 4 variants)\n",
      "   2. monte carlo simulation: 439 papers (from 2 variants)\n",
      "   3. particle swarm optimization: 433 papers (from 4 variants)\n",
      "   4. genetic algorithm ga: 377 papers (from 2 variants)\n",
      "   5. optimal utilization: 356 papers\n",
      "   6. sensitivity analysis: 255 papers\n",
      "   7. optimal power flow opf: 200 papers (from 3 variants)\n",
      "   8. optimal power allocation: 199 papers\n",
      "   9. probabilistic reliability: 192 papers\n",
      "  10. mixed integer linear programming: 186 papers (from 2 variants)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def verify_method_consolidation(df, canonical_to_variants, original_method_list):\n",
    "    \"\"\"\n",
    "    Comprehensive verification that consolidation worked properly.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"🔍 METHOD CONSOLIDATION VERIFICATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Extract assigned methods from DataFrame\n",
    "    assigned_methods = set(df[df['Primary_Method'] != '']['Primary_Method'].unique())\n",
    "    \n",
    "    # Extract canonical methods from groups\n",
    "    canonical_methods = set(canonical_to_variants.keys()) \n",
    "    \n",
    "    # Extract all original methods (for comparison)\n",
    "    original_methods = set(original_method_list)\n",
    "    \n",
    "    print(f\"\\n📊 COUNTS:\")\n",
    "    print(f\"  Original methods: {len(original_methods)}\")\n",
    "    print(f\"  Canonical groups: {len(canonical_methods)}\")\n",
    "    print(f\"  Assigned methods: {len(assigned_methods)}\")\n",
    "    \n",
    "    # Check 1: Are assigned methods from canonical set?\n",
    "    non_canonical_assigned = assigned_methods - canonical_methods\n",
    "    if non_canonical_assigned:\n",
    "        print(f\"\\n❌ PROBLEM: {len(non_canonical_assigned)} assigned methods are NOT canonical:\")\n",
    "        for method in list(non_canonical_assigned)[:10]:\n",
    "            print(f\"    '{method}'\")\n",
    "    else:\n",
    "        print(f\"\\n✅ SUCCESS: All assigned methods are canonical groups\")\n",
    "    \n",
    "    # Check 2: Are any original redundant methods still assigned?\n",
    "    all_variants = set()\n",
    "    for variants in canonical_to_variants.values():\n",
    "        all_variants.update(variants)\n",
    "    \n",
    "    redundant_assigned = assigned_methods & (original_methods - canonical_methods)\n",
    "    if redundant_assigned:\n",
    "        print(f\"\\n❌ PROBLEM: {len(redundant_assigned)} redundant methods still assigned:\")\n",
    "        for method in list(redundant_assigned)[:10]:\n",
    "            print(f\"    '{method}' (should be consolidated)\")\n",
    "    else:\n",
    "        print(f\"\\n✅ SUCCESS: No redundant methods in assignments\")\n",
    "    \n",
    "    # Check 3: Show consolidation examples\n",
    "    print(f\"\\n🔍 CONSOLIDATION EXAMPLES:\")\n",
    "    consolidation_examples = 0\n",
    "    for canonical, variants in canonical_to_variants.items():\n",
    "        if len(variants) > 1 and canonical in assigned_methods:\n",
    "            print(f\"  '{canonical}' consolidated: {variants}\")\n",
    "            consolidation_examples += 1\n",
    "            if consolidation_examples >= 5:\n",
    "                break\n",
    "    \n",
    "    # Check 4: Show assignment distribution\n",
    "    print(f\"\\n📈 TOP ASSIGNED METHODS (canonical):\")\n",
    "    method_counts = df[df['Primary_Method'] != '']['Primary_Method'].value_counts()\n",
    "    for i, (method, count) in enumerate(method_counts.head(10).items()):\n",
    "        variants = canonical_to_variants.get(method, [method])\n",
    "        variant_info = f\" (from {len(variants)} variants)\" if len(variants) > 1 else \"\"\n",
    "        print(f\"  {i+1:2d}. {method}: {count} papers{variant_info}\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    return len(non_canonical_assigned) == 0 and len(redundant_assigned) == 0\n",
    "\n",
    "# Run verification\n",
    "verification_passed = verify_method_consolidation(df, canonical_to_variants, method_phrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd873c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 SPOT CHECK: Sample Paper Method Assignments\n",
      "------------------------------------------------------------\n",
      "\n",
      "Paper 45:\n",
      "  Assigned Method: 'load frequency control'\n",
      "  Score: 0.14345188046100252\n",
      "  Variants in Group: ['load frequency control']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 54:\n",
      "  Assigned Method: 'optimal utilization'\n",
      "  Score: 0.14345188046100252\n",
      "  Variants in Group: ['optimal utilization']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 57:\n",
      "  Assigned Method: 'probabilistic reliability'\n",
      "  Score: 0.14345188046100252\n",
      "  Variants in Group: ['probabilistic reliability']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 121:\n",
      "  Assigned Method: 'mean time between failures'\n",
      "  Score: 0.5855398034893327\n",
      "  Variants in Group: ['mtbf', 'mean time between failures']\n",
      "  Group Size: 2 methods\n",
      "  ✅ CONSOLIDATED: 1 variants merged\n",
      "\n",
      "Paper 127:\n",
      "  Assigned Method: 'probabilistic reliability'\n",
      "  Score: 0.14345188046100252\n",
      "  Variants in Group: ['probabilistic reliability']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 142:\n",
      "  Assigned Method: 'optimal utilization'\n",
      "  Score: 0.14345188046100252\n",
      "  Variants in Group: ['optimal utilization']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 175:\n",
      "  Assigned Method: 'mean time between failures'\n",
      "  Score: 0.7017259414225943\n",
      "  Variants in Group: ['mtbf', 'mean time between failures']\n",
      "  Group Size: 2 methods\n",
      "  ✅ CONSOLIDATED: 1 variants merged\n",
      "\n",
      "Paper 187:\n",
      "  Assigned Method: 'monte carlo simulation'\n",
      "  Score: 0.7017259414225943\n",
      "  Variants in Group: ['monte carlo simulation', 'monte-carlo simulation']\n",
      "  Group Size: 2 methods\n",
      "  ✅ CONSOLIDATED: 1 variants merged\n",
      "\n",
      "Paper 193:\n",
      "  Assigned Method: 'mean time between failures'\n",
      "  Score: 0.7017259414225943\n",
      "  Variants in Group: ['mtbf', 'mean time between failures']\n",
      "  Group Size: 2 methods\n",
      "  ✅ CONSOLIDATED: 1 variants merged\n",
      "\n",
      "Paper 199:\n",
      "  Assigned Method: 'probabilistic reliability'\n",
      "  Score: 0.14345188046100252\n",
      "  Variants in Group: ['probabilistic reliability']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n"
     ]
    }
   ],
   "source": [
    "def spot_check_paper_assignments(df, canonical_to_variants, n_samples=10):\n",
    "    \"\"\"\n",
    "    Show sample paper assignments with their consolidated method info.\n",
    "    \"\"\"\n",
    "    print(\"🔍 SPOT CHECK: Sample Paper Method Assignments\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Get papers with assigned methods\n",
    "    assigned_papers = df[df['Primary_Method'] != ''].head(n_samples)\n",
    "    \n",
    "    for idx, row in assigned_papers.iterrows():\n",
    "        primary_method = row['Primary_Method']\n",
    "        score = row.get('Primary_Method_Score', 'N/A')\n",
    "        \n",
    "        # Check if this method has variants\n",
    "        variants = canonical_to_variants.get(primary_method, [primary_method])\n",
    "        \n",
    "        print(f\"\\nPaper {idx}:\")\n",
    "        print(f\"  Assigned Method: '{primary_method}'\")\n",
    "        print(f\"  Score: {score}\")\n",
    "        print(f\"  Variants in Group: {variants}\")\n",
    "        print(f\"  Group Size: {len(variants)} methods\")\n",
    "        \n",
    "        # Show if consolidation occurred\n",
    "        if len(variants) > 1:\n",
    "            print(f\"  ✅ CONSOLIDATED: {len(variants)-1} variants merged\")\n",
    "        else:\n",
    "            print(f\"  ℹ️  INDIVIDUAL: No variants to consolidate\")\n",
    "\n",
    "# Run spot check\n",
    "spot_check_paper_assignments(df, canonical_to_variants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145252da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 SCORE MATRIX VERIFICATION\n",
      "----------------------------------------\n",
      "Score matrix shape: (28934, 91)\n",
      "Canonical methods count: 91\n",
      "✅ Score matrix columns match canonical method count\n",
      "\n",
      "First 10 canonical methods in score matrix:\n",
      "   0. stochastic optimization\n",
      "   1. N-1\n",
      "   2. interior point method\n",
      "   3. wavelet transform\n",
      "   4. injection shift factors\n",
      "   5. multi-input multiple output\n",
      "   6. first order reliability method\n",
      "   7. optimal utilization\n",
      "   8. optimal dispatch\n",
      "   9. optimal power allocation\n"
     ]
    }
   ],
   "source": [
    "def verify_score_matrix_methods(canonical_methods, final_scores):\n",
    "    \"\"\"\n",
    "    Check that the final score matrix columns correspond to canonical methods.\n",
    "    \"\"\"\n",
    "    print(\"🔍 SCORE MATRIX VERIFICATION\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    print(f\"Score matrix shape: {final_scores.shape}\")\n",
    "    print(f\"Canonical methods count: {len(canonical_methods)}\")\n",
    "    \n",
    "    if final_scores.shape[1] == len(canonical_methods):\n",
    "        print(\"✅ Score matrix columns match canonical method count\")\n",
    "    else:\n",
    "        print(\"❌ Dimension mismatch between scores and canonical methods\")\n",
    "    \n",
    "    print(f\"\\nFirst 10 canonical methods in score matrix:\")\n",
    "    for i, method in enumerate(canonical_methods[:10]):\n",
    "        print(f\"  {i:2d}. {method}\")\n",
    "\n",
    "# Run verification  \n",
    "verify_score_matrix_methods(canonical_methods, final_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad7acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 BEFORE/AFTER CONSOLIDATION COMPARISON\n",
      "================================================================================\n",
      "BEFORE: 165 original methods\n",
      "AFTER:  91 canonical groups\n",
      "REDUCTION: 74 methods (44.8%)\n",
      "\n",
      "📋 CONSOLIDATION EXAMPLES:\n",
      "\n",
      "  GROUP: 'total harmonic distortion thd'\n",
      "    Consolidated: ['total harmonic distortion thd', 'total harmonic distortion']\n",
      "\n",
      "  GROUP: 'deep reinforcement learning drl'\n",
      "    Consolidated: ['reinforcement learning drl', 'deep reinforcement learning drl']\n",
      "\n",
      "  GROUP: 'loss of load probability'\n",
      "    Consolidated: ['lolp', 'loss of load probability']\n",
      "\n",
      "  GROUP: 'system average interruption duration index'\n",
      "    Consolidated: ['system average interruption duration index', 'caidi']\n",
      "\n",
      "  GROUP: 'monte carlo simulation'\n",
      "    Consolidated: ['monte carlo simulation', 'monte-carlo simulation']\n",
      "\n",
      "  GROUP: 'system average interruption frequency index'\n",
      "    Consolidated: ['saifi', 'system average interruption frequency index']\n",
      "\n",
      "  GROUP: 'particle swarm optimization'\n",
      "    Consolidated: ['particle swarm optimization', 'pso algorithm', 'optimization pso algorithm', 'particle swarm algorithm']\n",
      "\n",
      "  GROUP: 'mixed integer linear programming'\n",
      "    Consolidated: ['mixed-integer linear', 'mixed integer linear programming']\n",
      "\n",
      "📊 SUMMARY:\n",
      "  Groups with multiple variants: 26\n",
      "  Single-method groups: 65\n"
     ]
    }
   ],
   "source": [
    "def show_before_after_comparison(original_methods, canonical_to_variants):\n",
    "    \"\"\"\n",
    "    Show before/after consolidation comparison.\n",
    "    \"\"\"\n",
    "    print(\"🔄 BEFORE/AFTER CONSOLIDATION COMPARISON\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"BEFORE: {len(original_methods)} original methods\")\n",
    "    print(f\"AFTER:  {len(canonical_to_variants)} canonical groups\")\n",
    "    reduction = len(original_methods) - len(canonical_to_variants)\n",
    "    reduction_pct = 100 * reduction / len(original_methods)\n",
    "    print(f\"REDUCTION: {reduction} methods ({reduction_pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n📋 CONSOLIDATION EXAMPLES:\")\n",
    "    consolidation_count = 0\n",
    "    for canonical, variants in canonical_to_variants.items():\n",
    "        if len(variants) > 1:\n",
    "            print(f\"\\n  GROUP: '{canonical}'\")\n",
    "            print(f\"    Consolidated: {variants}\")\n",
    "            consolidation_count += 1\n",
    "            if consolidation_count >= 8:\n",
    "                break\n",
    "    \n",
    "    print(f\"\\n📊 SUMMARY:\")\n",
    "    multi_variant_groups = sum(1 for v in canonical_to_variants.values() if len(v) > 1)\n",
    "    print(f\"  Groups with multiple variants: {multi_variant_groups}\")\n",
    "    print(f\"  Single-method groups: {len(canonical_to_variants) - multi_variant_groups}\")\n",
    "\n",
    "# Run comparison\n",
    "show_before_after_comparison(method_phrases, canonical_to_variants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7de75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stochastic optimization\n",
      "N-1\n",
      "interior point method\n",
      "wavelet transform\n",
      "N-2\n",
      "fault tree\n",
      "multi-input multi-output\n",
      "principal component analysis\n",
      "injection shift factors\n",
      "multi-input multiple output\n",
      "first order reliability method\n",
      "scopf\n",
      "optimal utilization\n",
      "wams\n",
      "optimal dispatch\n",
      "optimal power allocation\n",
      "anfis\n",
      "successive interference cancellation\n",
      "tabu search\n",
      "caidi\n",
      "lole\n",
      "two-step stochastic\n",
      "unit commitment\n",
      "kalman filter\n",
      "mttf\n",
      "particle swarm optimization\n",
      "fast decoupled power flow\n",
      "fault tree analysis\n",
      "cost-benefit analysis\n",
      "lodf\n",
      "quadratic programming\n",
      "regression model\n",
      "hosting capacity assesment\n",
      "arima\n",
      "sequential quadratic programming\n",
      "time-dependent\n",
      "dynamic line rating\n",
      "pem\n",
      "support vector machine\n",
      "genetic algorithm ga\n",
      "q-learning\n",
      "mean time to repair\n",
      "neural network ann\n",
      "hierarchical level ii\n",
      "time-domain\n",
      "load flow analysis\n",
      "sliding mode control\n",
      "differential evolution\n",
      "sensitivity analysis\n",
      "state estimation\n",
      "vector autoregression\n",
      "point estimate method\n",
      "pmu\n",
      "adaptive neuro-fuzzy\n",
      "saidi\n",
      "dynamic voltage\n",
      "neural network\n",
      "mixed integer linear\n",
      "mean time between failures\n",
      "otdf\n",
      "firefly algorithm\n",
      "support vector regression\n",
      "semidefinite programming\n",
      "optimal transmission\n",
      "mean time to failure\n",
      "incremental conductance\n",
      "monte-carlo\n",
      "garch\n",
      "multi-hop\n",
      "saifi\n",
      "total harmonic distortion\n",
      "contingency analysis\n",
      "capacity outage probability table\n",
      "wide area measurement system\n",
      "pso algorithm\n",
      "customer average interruption duration index\n",
      "N-x\n",
      "support vector machine svm\n",
      "optimal power flow opf\n",
      "economic dispatch\n",
      "short-term load forecasting\n",
      "svr\n",
      "non-orthogonal multiple access noma\n",
      "line outage distribution factor\n",
      "linear programming\n",
      "autoregressive integrated moving average\n",
      "discrete wavelet\n",
      "dynamic programming\n",
      "mpp\n",
      "particle swarm algorithm\n",
      "state-of-charge\n",
      "dynamic voltage restorer\n",
      "reinforcement learning drl\n",
      "load shifting\n",
      "minlp\n",
      "simulated annealing\n",
      "differential protection\n",
      "optimal power flow\n",
      "dynamic reactive power\n",
      "swarm optimization pso algorithm\n",
      "N-3\n",
      "multiobjective optimization\n",
      "latin hypercube sampling\n",
      "linear regression\n",
      "system average interruption duration index\n",
      "gated recurrent unit\n",
      "probabilistic reliability\n",
      "multi-objective optimization model\n",
      "long short-term memory\n",
      "hierarchical level iii\n",
      "neural network cnn\n",
      "monte-carlo simulation\n",
      "capacity outage probability density\n",
      "mcmc\n",
      "demand response dr\n",
      "particle swarm optimization algorithm\n",
      "mtbf\n",
      "generation shift factors\n",
      "model predictive control mpc\n",
      "stochastic programming\n",
      "security-constrained unit commitment\n",
      "load frequency control\n",
      "total harmonic distortion thd\n",
      "deep reinforcement learning drl\n",
      "copt\n",
      "lolp\n",
      "rate of occurrence of failures\n",
      "generalized autoregressive conditional heteroskedasticity\n",
      "second order cone programming\n",
      "optimization pso algorithm\n",
      "system average interruption frequency index\n",
      "integer linear programming\n",
      "forecasting method\n",
      "ptdf\n",
      "model synthesis\n",
      "markov chain monte carlo\n",
      "phasor measurement unit\n",
      "time series analysis\n",
      "security-constrained economic dispatch\n",
      "mixed-integer linear\n",
      "capacity outage probability\n",
      "phasor measurement\n",
      "eens\n",
      "mixed integer nonlinear programming\n",
      "sdn\n",
      "random forest\n",
      "N-k\n",
      "newton-raphson load flow\n",
      "ant colony optimization\n",
      "fuzzy control\n",
      "monte carlo simulation\n",
      "mttr\n",
      "security-constrained optimal power flow\n",
      "alternating direction method of multipliers\n",
      "genetic algorithm\n",
      "loss of load probability\n",
      "nonlinear programming\n",
      "deep reinforcement learning\n",
      "scuc\n",
      "gauss-seidel load flow\n",
      "decision tree\n",
      "k-means\n",
      "second order reliability method\n",
      "sced\n",
      "outage transfer distribution factors\n"
     ]
    }
   ],
   "source": [
    "for n in method_phrases:\n",
    "    print(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "literature-search-and-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
