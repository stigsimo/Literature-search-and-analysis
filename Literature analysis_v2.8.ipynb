{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33fc68ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 1: Imports and Setup\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import configparser\n",
    "import tiktoken\n",
    "import logging\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Phrases\n",
    "import openai\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "SAVE_DIR = \"Saved_files_new\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "156bf246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Cell 2: OpenAI Setup and Utility (Updated for gpt-5-nano)\n",
    "class CreditTracker:\n",
    "    def __init__(self):\n",
    "        self.total_tokens = 0\n",
    "        self.total_cost = 0\n",
    "        self.cost_per_1k_tokens = 0.00015\n",
    "    def update(self, tokens):\n",
    "        self.total_tokens += tokens\n",
    "        self.total_cost += (tokens / 1000) * self.cost_per_1k_tokens\n",
    "    def get_stats(self):\n",
    "        return {\"total_tokens\": self.total_tokens, \"total_cost\": round(self.total_cost, 4)}\n",
    "\n",
    "def initialize_openai():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config_LLM.txt')\n",
    "    api_key = config['LLM'].get('OPENAI_API_KEY')\n",
    "    model_type = config['LLM'].get('MODEL_TYPE')\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    return client, model_type\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"Get token count with fallback for unsupported models like gpt-5-nano\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model_name)\n",
    "        return len(encoding.encode(string))\n",
    "    except KeyError:\n",
    "        # Fallback for unsupported models like gpt-5-nano\n",
    "        if model_name.startswith('gpt-5-nano'):\n",
    "            # Use o200k_base encoding as fallback for gpt-5-nano\n",
    "            encoding = tiktoken.get_encoding(\"o200k_base\")\n",
    "            return len(encoding.encode(string))\n",
    "        else:\n",
    "            # For other unsupported models, use a reasonable approximation\n",
    "            return len(string) // 4  # Rough approximation: 4 chars per token\n",
    "\n",
    "client, model_type = initialize_openai()\n",
    "credit_tracker = CreditTracker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "145755ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Cell 3: Data Preprocessing Utilities\n",
    "\n",
    "def extract_keywords_from_filename(filename):\n",
    "    base = os.path.splitext(os.path.basename(filename))[0]\n",
    "    parts = base.split('_')\n",
    "    return [part for i, part in enumerate(parts) if i > 2 and part != 'results' and not part.isdigit()]\n",
    "\n",
    "def get_custom_stop_words(search_keywords=None):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words_to_keep = set()\n",
    "    if search_keywords:\n",
    "        for keyword in search_keywords:\n",
    "            keyword = keyword.lower()\n",
    "            words_to_keep.add(keyword)\n",
    "            for word in keyword.split():\n",
    "                words_to_keep.add(word)\n",
    "    stop_words = stop_words - words_to_keep\n",
    "    scientific_terms = {'et', 'al', 'ref', 'reference', 'references', 'cited', 'cite',\n",
    "        'fig', 'figure', 'figures', 'table', 'tables', 'chart', 'charts',\n",
    "        'published', 'journal', 'conference', 'proceedings', 'vol', 'volume', 'pp', 'page', 'pages', 'doi'}\n",
    "    return stop_words.union(scientific_terms)\n",
    "\n",
    "def preprocess_text(text, search_keywords=None, min_word_length=2, remove_numbers=True):\n",
    "    if not isinstance(text, (str, int, float)):\n",
    "        return ''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    if remove_numbers:\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "    text = re.sub(r'--+', ' ', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = get_custom_stop_words(search_keywords)\n",
    "    tokens = [t for t in tokens if len(t) >= min_word_length and t not in stop_words and len(t) > 1 and not t.isdigit()]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    try:\n",
    "        tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    except:\n",
    "        pass\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_dataframe(df, text_col, search_keywords, processed_col='processed_text'):\n",
    "    df[text_col] = df[text_col].fillna('').astype(str)\n",
    "    df[processed_col] = df[text_col].apply(lambda x: preprocess_text(x, search_keywords))\n",
    "    return df[df[processed_col].str.strip() != '']\n",
    "\n",
    "def clean_fields_of_study(s):\n",
    "    valid_fields = ['Computer Science', 'Economics', 'Engineering', 'Physics', 'Mathematics',\n",
    "        'Medicine','Business','Environmental Science','Chemistry','Materials Science',\n",
    "        'Geography','Biology','Geology','Political Science','Psychology','Com']\n",
    "    if pd.isna(s) or s == '[]':\n",
    "        return [\"Unknown\"]\n",
    "    if isinstance(s, str):\n",
    "        fields = [field.strip().strip(\"'\\\"\") for field in s.strip('[]').split(',')]\n",
    "        return [f if f in valid_fields else \"Unknown\" for f in fields] or [\"Unknown\"]\n",
    "    return [\"Unknown\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a22896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 10:35:18,672 - INFO - Loaded and preprocessed 28934 papers\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Cell 4: Data Loading & Cleaning\n",
    "\n",
    "filename = \"semantic_scholar_2025_02_14_reliability_resilience_power_systems_results.csv\"\n",
    "filepath = os.path.join(\"Saved_files\", filename)\n",
    "df = pd.read_csv(filepath, sep=\";\")\n",
    "df['text'] = df['title'].fillna('') + ' ' + df['abstract'].fillna('')\n",
    "search_keywords = extract_keywords_from_filename(filename)\n",
    "df = preprocess_dataframe(df, text_col='text', search_keywords=search_keywords)\n",
    "df['fieldsOfStudy'] = df['fieldsOfStudy'].apply(clean_fields_of_study)\n",
    "logger.info(f\"Loaded and preprocessed {len(df)} papers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feef6bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 5: Enhanced Method Detection Functions (COMPLETE CORRECTED VERSION)\n",
    "\n",
    "def extract_candidate_terms(df, text_col='processed_text', max_features=20000):\n",
    "    \"\"\"Extract candidate terms from processed text using CountVectorizer.\"\"\"\n",
    "    vectorizer = CountVectorizer(\n",
    "        ngram_range=(1, 4), max_df=0.95, min_df=2, max_features=max_features, token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "    matrix = vectorizer.fit_transform(df[text_col].fillna(''))\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    freqs = matrix.sum(axis=0).A1\n",
    "    return [term for term, freq in sorted(zip(terms, freqs), key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "def parse_llm_python_list(output_text):\n",
    "    \"\"\"Improved parsing function for LLM outputs\"\"\"\n",
    "    import re\n",
    "    import ast\n",
    "    \n",
    "    content = output_text.strip()\n",
    "    content = re.sub(r'```(?:python|json)?\\n?', '', content)\n",
    "    content = re.sub(r'```', '', content)\n",
    "    \n",
    "    list_patterns = [\n",
    "        r'\\[([^\\]]+)\\]',  # Standard list format\n",
    "        r'List:\\s*\\[([^\\]]+)\\]',  # List: [items]\n",
    "        r'Result:\\s*\\[([^\\]]+)\\]'  # Result: [items]\n",
    "    ]\n",
    "    \n",
    "    for pattern in list_patterns:\n",
    "        match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)\n",
    "        if match:\n",
    "            try:\n",
    "                return ast.literal_eval('[' + match.group(1) + ']')\n",
    "            except:\n",
    "                items = [item.strip().strip(\"'\\\"\") for item in match.group(1).split(',')]\n",
    "                return [item for item in items if item.strip()]\n",
    "    \n",
    "    lines = content.split('\\n')\n",
    "    items = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line and not line.startswith('#') and not line.startswith('//'):\n",
    "            line = re.sub(r'^\\d+\\.?\\s*[-*]?\\s*', '', line)\n",
    "            line = line.strip(\"'\\\"\")\n",
    "            if line:\n",
    "                items.append(line)\n",
    "    \n",
    "    return items[:1500]\n",
    "\n",
    "def get_method_phrases_enhanced(\n",
    "    corpus_terms, client, model_type, credit_tracker,\n",
    "    n_runs=3, temp=0.1, top_p=0.9, show_progress=True, batch_size=500 \n",
    "):\n",
    "    \"\"\"Enhanced method extraction with batching, for gpt-5-nano and others.\"\"\"\n",
    "    import collections\n",
    "    from math import ceil\n",
    "\n",
    "    all_phrases_sets = []\n",
    "    n_batches = ceil(len(corpus_terms) / batch_size)\n",
    "    \n",
    "    for batch_idx in range(n_batches):\n",
    "        batch_terms = corpus_terms[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "\n",
    "        prompt = f\"\"\"You are analyzing scientific papers about power systems reliability and resilience.\n",
    "\n",
    "From these terms: {batch_terms}\n",
    "\n",
    "Extract ALL terms that represent:\n",
    "1. Specific algorithms (e.g., genetic algorithm, particle swarm optimization)\n",
    "2. Mathematical methods (e.g., monte carlo simulation, linear programming)\n",
    "3. Analysis techniques (e.g., fault tree analysis, load flow analysis)\n",
    "4. Optimization methods (e.g., unit commitment, optimal power flow)\n",
    "5. Modeling approaches (e.g., neural network, markov chain)\n",
    "6. Simulation methods (e.g., time series analysis, stochastic programming)\n",
    "\n",
    "DO include: e.g. 'monte carlo simulation', 'unit commitment', 'load flow analysis', 'genetic algorithm', 'neural network', 'stochastic optimization', 'reinforcement learning', 'fault tree analysis'.\n",
    "DO NOT include generic terms like 'framework', 'analysis', 'system', 'method', 'procedure', 'approach', 'application', 'performance', 'review', 'assessment', by themselves or in combination with only other generic terms\n",
    "INCLUDE abbreviations, variants (e.g., OPF/optimal power flow) and compounds.\n",
    "\n",
    "Return as a Python list, one method per item.\"\"\"\n",
    "\n",
    "        for i in range(n_runs):\n",
    "            try:\n",
    "                api_params = {\n",
    "                    \"model\": model_type,\n",
    "                    \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                }\n",
    "                if model_type.startswith('gpt-5-nano'):\n",
    "                    api_params[\"max_completion_tokens\"] = 5000\n",
    "                else:\n",
    "                    api_params[\"temperature\"] = temp\n",
    "                    api_params[\"top_p\"] = top_p\n",
    "                    api_params[\"max_tokens\"] = 5000\n",
    "\n",
    "                response = client.chat.completions.create(**api_params)\n",
    "                content = response.choices[0].message.content\n",
    "                phrases = parse_llm_python_list(content)\n",
    "                phrases = [p.lower().strip() for p in phrases if p.strip() and len(p.strip()) > 2]\n",
    "                all_phrases_sets.append(set(phrases))\n",
    "                credit_tracker.update(num_tokens_from_string(content, model_type))\n",
    "                if show_progress:\n",
    "                    print(f\"BATCH {batch_idx+1}/{n_batches}, run {i+1}: found {len(phrases)}\")\n",
    "                    print(f\"  Sample: {phrases[:10]}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in LLM call for batch {batch_idx+1}, run {i+1}: {e}\")\n",
    "                all_phrases_sets.append(set())\n",
    "\n",
    "    all_flat = [p for s in all_phrases_sets for p in s]\n",
    "    counts = collections.Counter(all_flat)\n",
    "    sorted_methods = sorted(counts.keys(), key=lambda x: (-counts[x], x))\n",
    "    print(f\"\\nTotal unique phrases: {len(counts)}\")\n",
    "    print(f\"Most frequent (top 10): {sorted_methods[:10]}\")\n",
    "    return sorted_methods, counts\n",
    "\n",
    "def load_method_phrases_from_csv(filename=\"extracted_method_phrases.csv\"):\n",
    "    \"\"\"Load method phrases from CSV file.\"\"\"\n",
    "    path = os.path.join(SAVE_DIR, filename)\n",
    "    if os.path.exists(path):\n",
    "        with open(path, encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            method_phrases = []\n",
    "            method_counts = []\n",
    "            for row in reader:\n",
    "                method_phrases.append(row[\"Method Phrase\"])\n",
    "                method_counts.append(int(row[\"Count\"]))\n",
    "            print(f\"✓ Loaded {len(method_phrases)} method phrases from {path}\")\n",
    "            return method_phrases, method_counts\n",
    "    else:\n",
    "        logger.warning(f\"File {path} not found.\")\n",
    "        return None, None\n",
    "\n",
    "def save_method_phrases_to_csv(method_phrases, method_counts, filename=\"extracted_method_phrases.csv\"):\n",
    "    \"\"\"Save method phrases to CSV file.\"\"\"\n",
    "    filename = os.path.join(SAVE_DIR, filename)\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Method Phrase\", \"Count\"])\n",
    "        if hasattr(method_counts, 'items'):\n",
    "            for phrase, count in method_counts.items():\n",
    "                clean_phrase = phrase.strip().replace('\\n', ' ')\n",
    "                writer.writerow([clean_phrase, count])\n",
    "        else:\n",
    "            for phrase, count in zip(method_phrases, method_counts):\n",
    "                clean_phrase = phrase.strip().replace('\\n', ' ')\n",
    "                writer.writerow([clean_phrase, count])\n",
    "    print(f\"✓ Saved method phrases to {filename}\")\n",
    "\n",
    "# ================================================================\n",
    "# ENHANCED METHOD CONSOLIDATION FUNCTIONS - ALL MISSING FUNCTIONS\n",
    "# ================================================================\n",
    "\n",
    "def prefilter_obvious_duplicates(method_list, similarity_threshold=0.95):\n",
    "    \"\"\"Remove obvious near-duplicates before LLM processing to improve efficiency.\"\"\"\n",
    "    from difflib import SequenceMatcher\n",
    "    \n",
    "    filtered_methods = []\n",
    "    seen_methods = set()\n",
    "    \n",
    "    for method in sorted(method_list, key=len):  # Process shorter methods first\n",
    "        method_lower = method.lower().strip()\n",
    "        \n",
    "        is_duplicate = False\n",
    "        for seen in seen_methods:\n",
    "            similarity = SequenceMatcher(None, method_lower, seen).ratio()\n",
    "            if similarity >= similarity_threshold:\n",
    "                is_duplicate = True\n",
    "                break\n",
    "        \n",
    "        if not is_duplicate:\n",
    "            filtered_methods.append(method)\n",
    "            seen_methods.add(method_lower)\n",
    "    \n",
    "    print(f\"Pre-filtering: {len(method_list)} → {len(filtered_methods)} methods ({len(method_list) - len(filtered_methods)} obvious duplicates removed)\")\n",
    "    return filtered_methods\n",
    "\n",
    "def are_methods_truly_similar(method_variants):\n",
    "    \"\"\"Check if methods in a group are truly the same technique by analyzing core words.\"\"\"\n",
    "    if len(method_variants) <= 1:\n",
    "        return True\n",
    "    \n",
    "    # Extract core words (remove common qualifiers that indicate different techniques)\n",
    "    qualifiers = {'improved', 'enhanced', 'adaptive', 'advanced', 'modified', 'sequential', 'parallel', \n",
    "                 'distributed', 'hybrid', 'multi', 'bi', 'tri', 'optimal', 'sub', 'quasi'}\n",
    "    \n",
    "    core_words_sets = []\n",
    "    for method in method_variants:\n",
    "        words = set(method.lower().split())\n",
    "        core_words = words - qualifiers\n",
    "        core_words_sets.append(core_words)\n",
    "    \n",
    "    # Check if core words overlap significantly across all variants\n",
    "    if len(core_words_sets) < 2:\n",
    "        return True\n",
    "    \n",
    "    base_core = core_words_sets[0]  # FIXED: was incorrectly `core_words_sets`\n",
    "    for other_core in core_words_sets[1:]:\n",
    "        if not base_core or not other_core:  # Handle empty sets\n",
    "            continue\n",
    "        overlap = len(base_core & other_core) / len(base_core | other_core) if (base_core | other_core) else 0\n",
    "        if overlap < 0.7:  # Less than 70% overlap in core words\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def validate_method_groups(groups, original_batch):\n",
    "    \"\"\"SIMPLIFIED validation that preserves LLM groupings\"\"\"\n",
    "    validated = {}\n",
    "    original_batch_lower = [m.lower() for m in original_batch]\n",
    "    \n",
    "    for canonical, variants in groups.items():\n",
    "        if not isinstance(variants, list):\n",
    "            variants = [variants]\n",
    "        \n",
    "        # Keep variants that exist in original batch (case insensitive)\n",
    "        clean_variants = []\n",
    "        for variant in variants:\n",
    "            variant_lower = str(variant).strip().lower()\n",
    "            if variant_lower in original_batch_lower:\n",
    "                # FIXED: Keep original casing from original_batch\n",
    "                original_idx = original_batch_lower.index(variant_lower)\n",
    "                clean_variants.append(original_batch[original_idx])\n",
    "        \n",
    "        if clean_variants:\n",
    "            # Use provided canonical name (don't change it)\n",
    "            canonical_clean = canonical.lower()  # Normalize casing only\n",
    "            validated[canonical_clean] = clean_variants\n",
    "    \n",
    "    print(f\"  Validation preserved {len(validated)} groups from LLM\")\n",
    "    return validated\n",
    "\n",
    "\n",
    "def have_common_core_terms(method1, method2):\n",
    "    \"\"\"Check if two methods share meaningful core terms beyond stop words.\"\"\"\n",
    "    stop_words = {'and', 'or', 'the', 'a', 'an', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}\n",
    "    \n",
    "    words1 = set(method1.split()) - stop_words\n",
    "    words2 = set(method2.split()) - stop_words\n",
    "    \n",
    "    if len(words1) == 0 or len(words2) == 0:\n",
    "        return False\n",
    "    \n",
    "    # Require at least 50% overlap in core terms\n",
    "    overlap = len(words1 & words2) / min(len(words1), len(words2))\n",
    "    return overlap >= 0.5\n",
    "\n",
    "def fallback_similarity_grouping(method_batch, similarity_threshold=0.85):\n",
    "    \"\"\"Fallback grouping using string similarity when LLM fails.\"\"\"\n",
    "    from difflib import SequenceMatcher\n",
    "    \n",
    "    groups = {}\n",
    "    processed = set()\n",
    "    \n",
    "    for method in sorted(method_batch, key=len):\n",
    "        if method in processed:\n",
    "            continue\n",
    "        \n",
    "        # Find similar methods using both string similarity and semantic checks\n",
    "        similar_methods = [method]\n",
    "        method_lower = method.lower()\n",
    "        \n",
    "        for other_method in method_batch:\n",
    "            if other_method != method and other_method not in processed:\n",
    "                other_lower = other_method.lower()\n",
    "                similarity = SequenceMatcher(None, method_lower, other_lower).ratio()\n",
    "                \n",
    "                if similarity >= similarity_threshold:\n",
    "                    # Additional check: ensure they're not just coincidentally similar\n",
    "                    if have_common_core_terms(method_lower, other_lower):\n",
    "                        similar_methods.append(other_method)\n",
    "                        processed.add(other_method)\n",
    "        \n",
    "        canonical = min(similar_methods, key=len)  # Use shortest as canonical\n",
    "        groups[canonical] = similar_methods\n",
    "        processed.add(method)\n",
    "    \n",
    "    return groups\n",
    "\n",
    "def post_process_method_groups(variant_groups):\n",
    "    \"\"\"MINIMAL post-processing that preserves LLM consolidation work\"\"\"\n",
    "    final_groups = {}\n",
    "    \n",
    "    for canonical, variants in variant_groups.items():\n",
    "        # Remove duplicates but keep groups intact\n",
    "        clean_variants = list(set(variants))\n",
    "        \n",
    "        # Only split if canonical name is obviously generic (very restrictive)\n",
    "        truly_generic = ['method', 'analysis', 'approach', 'technique'] \n",
    "        if any(canonical.lower() == generic for generic in truly_generic):\n",
    "            # Only split if canonical is EXACTLY one of these generic terms\n",
    "            for variant in clean_variants:\n",
    "                final_groups[variant] = [variant]\n",
    "        else:\n",
    "            # PRESERVE the group as-is\n",
    "            final_groups[canonical] = clean_variants\n",
    "    \n",
    "    print(f\"  Post-processing preserved {len(final_groups)} groups\")\n",
    "    return final_groups\n",
    "\n",
    "\n",
    "def build_method_variant_groups_enhanced(method_list, client, model_type, credit_tracker, batch_size=30, top_p=0.9,temp=0.1):\n",
    "    \"\"\"\n",
    "    Enhanced method grouping that distinguishes between identical variants and similar-but-distinct methods.\n",
    "    \"\"\"\n",
    "    variant_groups = {}\n",
    "    processed_methods = set()\n",
    "    \n",
    "    # Step 1: Pre-filter obvious duplicates to improve LLM efficiency\n",
    "    method_list = prefilter_obvious_duplicates(method_list)\n",
    "    \n",
    "    # Step 2: Process methods in batches using enhanced LLM prompting\n",
    "    for i in range(0, len(method_list), batch_size):\n",
    "        batch = method_list[i:i + batch_size]\n",
    "        batch = [m for m in batch if m not in processed_methods]\n",
    "        \n",
    "        if not batch:\n",
    "            continue\n",
    "            \n",
    "        # Enhanced prompt with clear distinction rules and examples\n",
    "        prompt = f\"\"\"Consolidate these power systems methods. Group ONLY direct variants of the same specific technique. Be very conservative.\n",
    "\n",
    "Methods: {batch}\n",
    "\n",
    "STRICT CONSOLIDATION RULES:\n",
    "✅ GROUP only these exact cases:\n",
    "- Same method + abbreviation: \"genetic algorithm\" + \"ga\"  \n",
    "- Same method + minor descriptor: \"neural network\" + \"bp neural network\"\n",
    "- Same method + implementation variant: \"kalman filter\" + \"extended kalman\"\n",
    "- Same method + different wording: \"monte carlo simulation\" + \"monte carlo + \"monte carlo based\"\n",
    "\n",
    "❌ NEVER GROUP these types:\n",
    "- Different algorithm families (e.g., \"neural network\" ≠ \"reinforcement learning\")\n",
    "- Broad categories with specific methods (e.g., \"machine learning\" ≠ \"support vector machine\") \n",
    "- Different mathematical approaches (e.g., \"supervised\" ≠ \"unsupervised\" ≠ \"reinforcement\")\n",
    "- Different analysis types (e.g., \"time series\" ≠ \"fault analysis\" ≠ \"regression\")\n",
    "\n",
    "EXAMPLES OF VALID GROUPINGS:\n",
    "{{\n",
    "  \"genetic algorithm\": [\"genetic algorithm\", \"ga\"],\n",
    "  \"neural network\": [\"neural network\", \"bp neural network\", \"artificial neural network\"],\n",
    "  \"particle swarm optimization\": [\"particle swarm optimization\", \"pso\"],\n",
    "  \"monte carlo simulation\": [\"monte carlo simulation\", \"monte carlo\"]\n",
    "}}\n",
    "\n",
    "EXAMPLES TO AVOID:\n",
    "{{\n",
    "  \"machine learning\": [\"machine learning\", \"support vector machine\"],  // NO - SVM is specific algorithm\n",
    "  \"deep learning\": [\"neural network\", \"reinforcement learning\"],       // NO - different paradigms  \n",
    "  \"optimization\": [\"genetic algorithm\", \"particle swarm\"]              // NO - too broad\n",
    "}}\n",
    "\n",
    "Group if methods are nearly identical.\n",
    "Return Python dictionary:\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            # Configure API parameters for different model types\n",
    "            api_params = {\n",
    "                \"model\": model_type,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a scientific method classification expert specializing in power systems analysis.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            if model_type.startswith('gpt-5-nano'):\n",
    "                api_params[\"max_completion_tokens\"] = 2000\n",
    "            else:\n",
    "                api_params[\"temperature\"] = temp\n",
    "                api_params[\"top_p\"] = top_p\n",
    "                api_params[\"max_tokens\"] = 2000\n",
    "            \n",
    "            # Make LLM call and process response\n",
    "            response = client.chat.completions.create(**api_params)\n",
    "            logger.info(f\"LLM raw response: {response}\")\n",
    "            content = response.choices[0].message.content\n",
    "            logger.info(f\"LLM content: {content}\")\n",
    "            credit_tracker.update(num_tokens_from_string(content, model_type))\n",
    "            \n",
    "            print(f\"✓ Batch {i//batch_size + 1} LLM response received: {len(content)} characters\")\n",
    "            \n",
    "            # Parse the dictionary response with error handling\n",
    "            try:\n",
    "                content = content.strip()\n",
    "                if content.startswith('```'):\n",
    "                    content = re.sub(r'```(?:python|json)?\\n?', '', content)\n",
    "                    content = re.sub(r'```$', '', content)\n",
    "                \n",
    "                dict_match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
    "                if dict_match:\n",
    "                    groups = ast.literal_eval(dict_match.group(0))\n",
    "                    \n",
    "                    # Validate and clean the groups using enhanced validation\n",
    "                    validated_groups = validate_method_groups(groups, batch)\n",
    "                    variant_groups.update(validated_groups)\n",
    "                    processed_methods.update(batch)\n",
    "                    \n",
    "                    print(f\"✓ Processed batch {i//batch_size + 1}: {len(validated_groups)} groups created\")\n",
    "                else:\n",
    "                    print(f\"⚠️ No dictionary found in LLM response for batch {i//batch_size + 1}\")\n",
    "                    fallback_groups = fallback_similarity_grouping(batch)\n",
    "                    variant_groups.update(fallback_groups)\n",
    "                    processed_methods.update(batch)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to parse LLM response, using fallback similarity grouping: {e}\")\n",
    "                fallback_groups = fallback_similarity_grouping(batch)\n",
    "                variant_groups.update(fallback_groups)\n",
    "                processed_methods.update(batch)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"LLM call failed, using fallback: {e}\")\n",
    "            fallback_groups = fallback_similarity_grouping(batch)\n",
    "            variant_groups.update(fallback_groups)\n",
    "            processed_methods.update(batch)\n",
    "        # Add this right after LLM response parsing:\n",
    "\n",
    "\n",
    "    # Step 3: Post-process to ensure quality and remove inappropriate groupings\n",
    "    final_groups = post_process_method_groups(variant_groups)\n",
    "    \n",
    "    logger.info(f\"Created {len(final_groups)} method variant groups from {len(method_list)} original methods\")\n",
    "    return final_groups\n",
    "\n",
    "def create_variant_mapping(variant_groups):\n",
    "    \"\"\"Create mapping from any variant to its canonical form for method consolidation.\"\"\"\n",
    "    variant_to_canonical = {}\n",
    "    canonical_to_variants = {}\n",
    "    \n",
    "    for canonical, variants in variant_groups.items():\n",
    "        canonical_to_variants[canonical] = variants\n",
    "        for variant in variants:\n",
    "            variant_to_canonical[variant.lower()] = canonical\n",
    "    \n",
    "    return variant_to_canonical, canonical_to_variants\n",
    "\n",
    "def consolidate_variant_scores(scores, method_names, variant_to_canonical):\n",
    "    \"\"\"\n",
    "    Consolidate method scores to prevent double-counting of variants.\n",
    "    Uses MAXIMUM score among variants (not sum) to avoid inflating scores.\n",
    "    \"\"\"\n",
    "    canonical_methods = list(set(variant_to_canonical.values()))\n",
    "    canonical_scores = np.zeros((scores.shape[0], len(canonical_methods)))  # FIXED: was scores.shape\n",
    "    \n",
    "    canonical_to_idx = {method: i for i, method in enumerate(canonical_methods)}\n",
    "    \n",
    "    for j, method_name in enumerate(method_names):\n",
    "        method_lower = method_name.lower()\n",
    "        canonical = variant_to_canonical.get(method_lower, method_name)\n",
    "        \n",
    "        if canonical in canonical_to_idx:\n",
    "            canonical_idx = canonical_to_idx[canonical]\n",
    "            # Use MAXIMUM score among variants (not sum) to prevent double-counting\n",
    "            canonical_scores[:, canonical_idx] = np.maximum(\n",
    "                canonical_scores[:, canonical_idx], \n",
    "                scores[:, j]\n",
    "            )\n",
    "    \n",
    "    return canonical_scores, canonical_methods\n",
    "\n",
    "# ================================================================\n",
    "# METHOD SCORING FUNCTIONS\n",
    "# ================================================================\n",
    "\n",
    "def compute_enhanced_tfidf_scores(processed_texts, method_variants_dict, ngram_range=(1, 4), min_df=1, max_df=0.95):\n",
    "    \"\"\"Compute TF-IDF scores for all method variants\"\"\"\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "    \n",
    "    existing_variants = []\n",
    "    for variant in all_variants:\n",
    "        variant_pattern = r'\\b' + re.escape(variant.lower()) + r'\\b'\n",
    "        found = False\n",
    "        for text in processed_texts[:1000]:  # Sample check for efficiency\n",
    "            if re.search(variant_pattern, text.lower()):\n",
    "                existing_variants.append(variant)\n",
    "                found = True\n",
    "                break\n",
    "        if not found and len(existing_variants) < 5000:\n",
    "            for text in processed_texts:\n",
    "                if re.search(variant_pattern, text.lower()):\n",
    "                    existing_variants.append(variant)\n",
    "                    break\n",
    "    \n",
    "    print(f\"Found {len(existing_variants)} variants that exist in corpus out of {len(all_variants)} total\")\n",
    "    \n",
    "    if not existing_variants:\n",
    "        logger.warning(\"No method variants found in corpus!\")\n",
    "        return np.zeros((len(processed_texts), 1)), ['no_methods_found']\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        vocabulary=existing_variants,\n",
    "        ngram_range=ngram_range,\n",
    "        min_df=min_df,\n",
    "        max_df=max_df,\n",
    "        norm='l2',\n",
    "        token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(processed_texts)\n",
    "        scores = tfidf_matrix.toarray()\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        return scores, feature_names\n",
    "    except Exception as e:\n",
    "        logger.error(f\"TF-IDF computation failed: {e}\")\n",
    "        return np.zeros((len(processed_texts), len(existing_variants))), existing_variants\n",
    "\n",
    "def compute_enhanced_lda_scores(processed_texts, method_variants_dict, ngram_range=(1, 4), n_topics=None, max_iter=20):\n",
    "    \"\"\"Compute LDA scores for method variants. FIXED VERSION\"\"\"\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "\n",
    "    if n_topics is None:\n",
    "        n_topics = min(len(all_variants), 100)\n",
    "\n",
    "    vectorizer = CountVectorizer(\n",
    "        vocabulary=all_variants,\n",
    "        ngram_range=ngram_range,\n",
    "        token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        doc_term_matrix = vectorizer.fit_transform(processed_texts)\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        \n",
    "        print(f\"  LDA Debug: doc_term_matrix.shape = {doc_term_matrix.shape}\")\n",
    "        print(f\"  LDA Debug: len(all_variants) = {len(all_variants)}\")\n",
    "        print(f\"  LDA Debug: len(feature_names) = {len(feature_names)}\")\n",
    "        \n",
    "        if n_topics >= 2 and doc_term_matrix.shape[1] > 0:\n",
    "            # FIXED: Use min to prevent n_topics > n_features\n",
    "            actual_topics = min(n_topics, doc_term_matrix.shape[1], len(all_variants))\n",
    "            \n",
    "            lda = LatentDirichletAllocation(\n",
    "                n_components=actual_topics,\n",
    "                learning_method='batch',\n",
    "                random_state=42,\n",
    "                max_iter=max_iter\n",
    "            )\n",
    "            \n",
    "            # Fit LDA and get topic distributions\n",
    "            doc_topic_matrix = lda.fit_transform(doc_term_matrix)\n",
    "            topic_term_matrix = lda.components_  # Shape: (n_topics, n_features)\n",
    "            \n",
    "            print(f\"  LDA Debug: doc_topic_matrix.shape = {doc_topic_matrix.shape}\")\n",
    "            print(f\"  LDA Debug: topic_term_matrix.shape = {topic_term_matrix.shape}\")\n",
    "            \n",
    "            # FIXED: Convert topic-document matrix back to document-term space\n",
    "            # We want scores for each method variant in each document\n",
    "            # Method: multiply doc-topic scores by topic-term weights\n",
    "            lda_scores = np.dot(doc_topic_matrix, topic_term_matrix)\n",
    "            \n",
    "            print(f\"  LDA Debug: final lda_scores.shape = {lda_scores.shape}\")\n",
    "            \n",
    "            # Ensure correct dimensions\n",
    "            if lda_scores.shape[1] != len(all_variants):\n",
    "                print(f\"  LDA Warning: Score matrix columns ({lda_scores.shape[1]}) != variants ({len(all_variants)})\")\n",
    "                # Pad or truncate to match expected dimensions\n",
    "                if lda_scores.shape[1] < len(all_variants):\n",
    "                    padding = np.zeros((lda_scores.shape[0], len(all_variants) - lda_scores.shape[1]))\n",
    "                    lda_scores = np.hstack([lda_scores, padding])\n",
    "                else:\n",
    "                    lda_scores = lda_scores[:, :len(all_variants)]\n",
    "                    \n",
    "                print(f\"  LDA Debug: adjusted lda_scores.shape = {lda_scores.shape}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"  LDA: Creating zero matrix due to insufficient topics/features\")\n",
    "            lda_scores = np.zeros((len(processed_texts), len(all_variants)))\n",
    "\n",
    "        return lda_scores, feature_names\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"LDA computation failed: {e}\")\n",
    "        print(f\"LDA Error details: {e}\")\n",
    "        return np.zeros((len(processed_texts), len(all_variants))), all_variants\n",
    "\n",
    "    \n",
    "def compute_enhanced_compound_scores(df, method_variants_dict, processed_col='processed_text', window=150):\n",
    "    \"\"\"Enhanced compound scoring that handles variants\"\"\"\n",
    "    n_docs = len(df)\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "    \n",
    "    n_methods = len(all_variants)\n",
    "    scores = np.zeros((n_docs, n_methods), dtype=np.float32)\n",
    "    docs = df[processed_col].fillna('').str.lower().tolist()\n",
    "    \n",
    "    for j, variant in enumerate(all_variants):\n",
    "        variant_l = variant.lower()\n",
    "        \n",
    "        for i, text in enumerate(docs):\n",
    "            if variant_l in text:\n",
    "                scores[i, j] = 1.0\n",
    "            elif len(variant_l.split()) > 1:\n",
    "                words = variant_l.split()\n",
    "                if all(word in text for word in words):\n",
    "                    scores[i, j] = 0.7\n",
    "            elif len(variant_l) <= 5 and variant_l.upper() in text.upper():\n",
    "                scores[i, j] = 0.8\n",
    "    \n",
    "    return scores, all_variants\n",
    "\n",
    "def assign_methods_improved(df, scores, method_names, top_n=5, min_score=0.005):\n",
    "    \"\"\"Improved method assignment with better diagnostics.\"\"\"\n",
    "    n_papers, n_methods = scores.shape\n",
    "    \n",
    "    # Initialize method columns\n",
    "    for i in range(top_n):\n",
    "        df[f'Method_{i+1}'] = ''\n",
    "        df[f'Method_{i+1}_Score'] = 0.0\n",
    "    \n",
    "    df['Primary_Method'] = ''\n",
    "    df['Primary_Method_Score'] = 0.0\n",
    "    df['Method_Confidence'] = 'Low'\n",
    "    df['Total_Method_Score'] = 0.0\n",
    "    \n",
    "    assigned_count = 0\n",
    "    \n",
    "    for paper_idx in range(n_papers):\n",
    "        paper_scores = scores[paper_idx, :]\n",
    "        \n",
    "        top_indices = np.argsort(paper_scores)[::-1][:top_n]\n",
    "        top_scores = paper_scores[top_indices]\n",
    "        \n",
    "        valid_mask = top_scores >= min_score\n",
    "        valid_indices = top_indices[valid_mask]\n",
    "        valid_scores = top_scores[valid_mask]\n",
    "        \n",
    "        if len(valid_indices) > 0:\n",
    "            assigned_count += 1\n",
    "            \n",
    "            # FIXED: Use [0] to get first element, not entire array\n",
    "            df.loc[paper_idx, 'Primary_Method'] = method_names[valid_indices[0]]\n",
    "            df.loc[paper_idx, 'Primary_Method_Score'] = valid_scores[0]\n",
    "            df.loc[paper_idx, 'Total_Method_Score'] = valid_scores.sum()\n",
    "            \n",
    "            if valid_scores[0] > 0.1:\n",
    "                df.loc[paper_idx, 'Method_Confidence'] = 'High'\n",
    "            elif valid_scores[0] > 0.05:\n",
    "                df.loc[paper_idx, 'Method_Confidence'] = 'Medium'\n",
    "            \n",
    "            for i, (idx, score) in enumerate(zip(valid_indices, valid_scores)):\n",
    "                if i < top_n:\n",
    "                    df.loc[paper_idx, f'Method_{i+1}'] = method_names[idx]\n",
    "                    df.loc[paper_idx, f'Method_{i+1}_Score'] = score\n",
    "    \n",
    "    logger.info(f\"  Assigned methods to {assigned_count}/{n_papers} papers ({100*assigned_count/n_papers:.1f}%)\")\n",
    "    return df\n",
    "\n",
    "def aggressive_fallback_grouping(method_list, similarity_threshold=0.75):\n",
    "    \"\"\"\n",
    "    Enhanced fallback grouping with aggressive similarity matching and pattern recognition.\n",
    "    This will handle cases where LLM API fails.\n",
    "    \"\"\"\n",
    "    from difflib import SequenceMatcher\n",
    "    \n",
    "    groups = {}\n",
    "    processed = set()\n",
    "    \n",
    "    # First pass: Handle obvious patterns\n",
    "    pattern_groups = handle_common_patterns(method_list)\n",
    "    for canonical, variants in pattern_groups.items():\n",
    "        groups[canonical] = variants\n",
    "        processed.update(variants)\n",
    "    \n",
    "    # Second pass: Similarity-based grouping for remaining methods\n",
    "    remaining_methods = [m for m in method_list if m not in processed]\n",
    "    \n",
    "    for method in sorted(remaining_methods, key=len):\n",
    "        if method in processed:\n",
    "            continue\n",
    "            \n",
    "        group = [method]\n",
    "        method_lower = method.lower()\n",
    "        method_tokens = set(method_lower.split())\n",
    "        \n",
    "        for other_method in remaining_methods:\n",
    "            if other_method == method or other_method in processed:\n",
    "                continue\n",
    "                \n",
    "            other_lower = other_method.lower()\n",
    "            other_tokens = set(other_lower.split())\n",
    "            \n",
    "            # Multiple similarity checks\n",
    "            string_sim = SequenceMatcher(None, method_lower, other_lower).ratio()\n",
    "            token_overlap = len(method_tokens & other_tokens) / len(method_tokens | other_tokens) if (method_tokens | other_tokens) else 0\n",
    "            \n",
    "            # Check for containment (one is substring of other)\n",
    "            containment = method_lower in other_lower or other_lower in method_lower\n",
    "            \n",
    "            # Group if any condition met\n",
    "            if (string_sim >= similarity_threshold or \n",
    "                token_overlap >= 0.6 or \n",
    "                containment):\n",
    "                group.append(other_method)\n",
    "                processed.add(other_method)\n",
    "        \n",
    "        # Use shortest name as canonical\n",
    "        canonical = min(group, key=lambda x: (len(x), x))\n",
    "        groups[canonical] = group\n",
    "        processed.add(method)\n",
    "    \n",
    "    return groups\n",
    "\n",
    "def handle_common_patterns(method_list):\n",
    "    \"\"\"Handle common method name patterns that should be grouped together.\"\"\"\n",
    "    import re\n",
    "    \n",
    "    pattern_groups = {}\n",
    "    processed = set()\n",
    "    \n",
    "    # Common abbreviation patterns\n",
    "    abbreviation_patterns = [\n",
    "        (r'^ga$', r'genetic algorithm.*'),\n",
    "        (r'^pso$', r'particle swarm optimization.*'),\n",
    "        (r'^abc$', r'.*bee colony.*'),\n",
    "        (r'^gwo$', r'grey wolf.*'),\n",
    "        (r'^opf$', r'optimal power flow.*'),\n",
    "        (r'^milp$', r'.*integer.*linear.*programming.*'),\n",
    "        (r'^dnn.*', r'.*neural network.*'),\n",
    "        (r'^cnn$', r'convolutional neural network.*'),\n",
    "        (r'^rnn$', r'.*neural network rnn.*'),\n",
    "        (r'^svm$', r'support vector machine.*'),\n",
    "        (r'^pca$', r'principal component analysis.*'),\n",
    "    ]\n",
    "    \n",
    "    # Method variant patterns\n",
    "    variant_patterns = [\n",
    "        # Neural network variants\n",
    "        (r'.*neural network.*', ['neural network', 'bp neural network', 'neural network algorithm', 'artificial neural network']),\n",
    "        # Genetic algorithm variants  \n",
    "        (r'.*genetic algorithm.*', ['genetic algorithm', 'genetic algorithm ga', 'adaptive genetic algorithm']),\n",
    "        # Monte Carlo variants\n",
    "        (r'.*monte carlo.*', ['monte carlo simulation', 'sequential monte carlo', 'carlo simulation result']),\n",
    "        # Particle swarm variants\n",
    "        (r'.*particle swarm.*', ['particle swarm optimization', 'binary particle swarm', 'improved particle swarm optimization']),\n",
    "        # Random forest variants\n",
    "        (r'.*random forest.*', ['random forest', 'random forest rf', 'random forest algorithm']),\n",
    "        # Machine learning variants\n",
    "        (r'.*machine learning.*', ['machine learning', 'ensemble learning']),\n",
    "    ]\n",
    "    \n",
    "    # Group by abbreviation patterns\n",
    "    for abbrev_pattern, full_pattern in abbreviation_patterns:\n",
    "        abbrev_matches = []\n",
    "        full_matches = []\n",
    "        \n",
    "        for method in method_list:\n",
    "            if method in processed:\n",
    "                continue\n",
    "            if re.search(abbrev_pattern, method.lower()):\n",
    "                abbrev_matches.append(method)\n",
    "            elif re.search(full_pattern, method.lower()):\n",
    "                full_matches.append(method)\n",
    "        \n",
    "        if abbrev_matches and full_matches:\n",
    "            all_matches = abbrev_matches + full_matches\n",
    "            canonical = min(full_matches, key=len) if full_matches else min(abbrev_matches, key=len)\n",
    "            pattern_groups[canonical] = all_matches\n",
    "            processed.update(all_matches)\n",
    "    \n",
    "    # Group by variant patterns\n",
    "    for base_pattern, known_variants in variant_patterns:\n",
    "        matches = []\n",
    "        for method in method_list:\n",
    "            if method in processed:\n",
    "                continue\n",
    "            if (re.search(base_pattern, method.lower()) or \n",
    "                method.lower() in [v.lower() for v in known_variants]):\n",
    "                matches.append(method)\n",
    "        \n",
    "        if len(matches) > 1:\n",
    "            canonical = min(matches, key=len)\n",
    "            pattern_groups[canonical] = matches\n",
    "            processed.update(matches)\n",
    "    \n",
    "    return pattern_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35425ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Cell 6: Method Scoring Functions (Enhanced)\n",
    "\n",
    "def compute_enhanced_tfidf_scores(processed_texts, method_variants_dict, ngram_range=(1, 4), min_df=1, max_df=0.95):\n",
    "    \"\"\"Compute TF-IDF scores for all method variants\"\"\"\n",
    "    # Get all variants\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "    \n",
    "    # Create vocabulary from actual variants that exist in corpus\n",
    "    existing_variants = []\n",
    "    for variant in all_variants:\n",
    "        # Check if variant appears in any document\n",
    "        variant_pattern = r'\\b' + re.escape(variant.lower()) + r'\\b'\n",
    "        found = False\n",
    "        for text in processed_texts:  # Sample check for efficiency\n",
    "            if re.search(variant_pattern, text.lower()):\n",
    "                existing_variants.append(variant)\n",
    "                found = True\n",
    "                break\n",
    "        if not found and len(existing_variants) < 5000:  # Keep checking if we don't have too many\n",
    "            for text in processed_texts:\n",
    "                if re.search(variant_pattern, text.lower()):\n",
    "                    existing_variants.append(variant)\n",
    "                    break\n",
    "    \n",
    "    print(f\"Found {len(existing_variants)} variants that exist in corpus out of {len(all_variants)} total\")\n",
    "    \n",
    "    if not existing_variants:\n",
    "        logger.warning(\"No method variants found in corpus!\")\n",
    "        return np.zeros((len(processed_texts), 1)), ['no_methods_found']\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        vocabulary=existing_variants,\n",
    "        ngram_range=ngram_range,\n",
    "        min_df=min_df,\n",
    "        max_df=max_df,\n",
    "        norm='l2',\n",
    "        token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(processed_texts)\n",
    "        scores = tfidf_matrix.toarray()\n",
    "        feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "        return scores, feature_names\n",
    "    except Exception as e:\n",
    "        logger.error(f\"TF-IDF computation failed: {e}\")\n",
    "        return np.zeros((len(processed_texts), len(existing_variants))), existing_variants\n",
    "\n",
    "def compute_enhanced_lda_scores(processed_texts, method_variants_dict, ngram_range=(1, 4), n_topics=None, max_iter=20):\n",
    "    \"\"\"Compute LDA scores for method variants.\"\"\"\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "\n",
    "    if n_topics is None:\n",
    "        n_topics = min(len(all_variants), 100)\n",
    "\n",
    "    vectorizer = CountVectorizer(\n",
    "        vocabulary=all_variants,\n",
    "        ngram_range=ngram_range,\n",
    "        token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        doc_term_matrix = vectorizer.fit_transform(processed_texts)\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "        if n_topics >= 2 and doc_term_matrix.shape[1] > 0:\n",
    "            lda = LatentDirichletAllocation(\n",
    "                n_components=min(n_topics, doc_term_matrix.shape[1]),\n",
    "                learning_method='batch',\n",
    "                random_state=42,\n",
    "                max_iter=max_iter\n",
    "            )\n",
    "            lda_matrix = lda.fit_transform(doc_term_matrix)\n",
    "        else:\n",
    "            lda_matrix = np.zeros((doc_term_matrix.shape[0], len(all_variants)))\n",
    "\n",
    "        return lda_matrix, feature_names\n",
    "    except Exception as e:\n",
    "        logger.error(f\"LDA computation failed: {e}\")\n",
    "        return np.zeros((len(processed_texts), len(all_variants))), all_variants\n",
    "    \n",
    "def compute_enhanced_compound_scores(df, method_variants_dict, processed_col='processed_text', window=150):\n",
    "    \"\"\"Enhanced compound scoring that handles variants\"\"\"\n",
    "    n_docs = len(df)\n",
    "    all_variants = []\n",
    "    for variants in method_variants_dict.values():\n",
    "        all_variants.extend(variants)\n",
    "    \n",
    "    n_methods = len(all_variants)\n",
    "    scores = np.zeros((n_docs, n_methods), dtype=np.float32)\n",
    "    docs = df[processed_col].fillna('').str.lower().tolist()\n",
    "    \n",
    "    for j, variant in enumerate(all_variants):\n",
    "        variant_l = variant.lower()\n",
    "        \n",
    "        for i, text in enumerate(docs):\n",
    "            # Full phrase match\n",
    "            if variant_l in text:\n",
    "                scores[i, j] = 1.0\n",
    "            # Partial word match for compound terms\n",
    "            elif len(variant_l.split()) > 1:\n",
    "                words = variant_l.split()\n",
    "                if all(word in text for word in words):\n",
    "                    scores[i, j] = 0.7\n",
    "            # Abbreviation handling\n",
    "            elif len(variant_l) <= 5 and variant_l.upper() in text.upper():\n",
    "                scores[i, j] = 0.8\n",
    "    \n",
    "    return scores, all_variants\n",
    "\n",
    "def aggregate_variant_scores_to_canonical(scores, variant_names, variant_to_canonical):\n",
    "    \"\"\"Aggregate variant scores back to canonical method names\"\"\"\n",
    "    canonical_methods = list(set(variant_to_canonical.values()))\n",
    "    canonical_scores = np.zeros((scores.shape[0], len(canonical_methods)))\n",
    "    \n",
    "    canonical_to_idx = {method: i for i, method in enumerate(canonical_methods)}\n",
    "    \n",
    "    for j, variant in enumerate(variant_names):\n",
    "        canonical = variant_to_canonical.get(variant.lower(), variant)\n",
    "        if canonical in canonical_to_idx:\n",
    "            canonical_idx = canonical_to_idx[canonical]\n",
    "            canonical_scores[:, canonical_idx] += scores[:, j]  # Sum scores for variants\n",
    "    \n",
    "    return canonical_scores, canonical_methods\n",
    "\n",
    "def assign_top_methods_enhanced(\n",
    "    df, canonical_scores, canonical_methods, variant_scores, variant_names,\n",
    "    top_n=5, min_score=0.005\n",
    "):\n",
    "    \"\"\"Enhanced method assignment with granular variant tracking\"\"\"\n",
    "    \n",
    "    # Assign top canonical methods\n",
    "    for rank in range(top_n):\n",
    "        top_method = []\n",
    "        top_score = []\n",
    "        top_variants = []\n",
    "        confidence = []\n",
    "\n",
    "        for i, row in enumerate(canonical_scores):\n",
    "            if np.allclose(row, row):  # All equal\n",
    "                top_method.append(\"\")\n",
    "                top_score.append(0.0)\n",
    "                top_variants.append(\"\")\n",
    "                confidence.append(\"\")\n",
    "                continue\n",
    "\n",
    "            idxs = np.argsort(row)[::-1]\n",
    "            if rank < len(idxs):\n",
    "                method_idx = idxs[rank]\n",
    "                method = canonical_methods[method_idx]\n",
    "                score = row[method_idx]\n",
    "                \n",
    "                if score >= min_score:\n",
    "                    # Find contributing variants\n",
    "                    variant_contributions = []\n",
    "                    for v_idx, variant in enumerate(variant_names):\n",
    "                        if variant_scores[i, v_idx] > 0:\n",
    "                            # Check if this variant belongs to the current canonical method\n",
    "                            variant_canonical = variant_to_canonical.get(variant.lower(), variant)\n",
    "                            if variant_canonical == method:\n",
    "                                variant_contributions.append(f\"{variant}({variant_scores[i, v_idx]:.2f})\")\n",
    "                    \n",
    "                    top_method.append(method)\n",
    "                    top_score.append(score)\n",
    "                    top_variants.append(\"; \".join(variant_contributions[:3]))  # Top 3 variants\n",
    "                    confidence.append(\"confident\" if score > min_score * 2 else \"low_confidence\")\n",
    "                else:\n",
    "                    top_method.append(\"\")\n",
    "                    top_score.append(0.0)\n",
    "                    top_variants.append(\"\")\n",
    "                    confidence.append(\"\")\n",
    "            else:\n",
    "                top_method.append(\"\")\n",
    "                top_score.append(0.0)\n",
    "                top_variants.append(\"\")\n",
    "                confidence.append(\"\")\n",
    "\n",
    "        df[f'Top_{rank+1}_Method'] = top_method\n",
    "        df[f'Top_{rank+1}_Score'] = top_score\n",
    "        df[f'Top_{rank+1}_Variants'] = top_variants\n",
    "        df[f'Top_{rank+1}_Confidence'] = confidence\n",
    "\n",
    "    # Set primary columns\n",
    "    df['Primary_Method'] = df['Top_1_Method']\n",
    "    df['Primary_Method_Score'] = df['Top_1_Score']\n",
    "    df['Primary_Method_Variants'] = df['Top_1_Variants']\n",
    "    df['Method_Confidence'] = df['Top_1_Confidence']\n",
    "\n",
    "    return df\n",
    "def save_method_phrases_to_csv(method_phrases, method_counts, filename=\"extracted_method_phrases.csv\"):\n",
    "    filename = os.path.join(SAVE_DIR, filename)\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Method Phrase\", \"Count\"])\n",
    "        # If method_counts is a Counter, convert to dict\n",
    "        if hasattr(method_counts, 'items'):\n",
    "            for phrase, count in method_counts.items():\n",
    "                clean_phrase = phrase.strip().replace('\\n', ' ')\n",
    "                writer.writerow([clean_phrase, count])\n",
    "        else:\n",
    "            # fallback: zipped lists\n",
    "            for phrase, count in zip(method_phrases, method_counts):\n",
    "                clean_phrase = phrase.strip().replace('\\n', ' ')\n",
    "                writer.writerow([clean_phrase, count])\n",
    "    print(f\"✓ Saved method phrases to {filename}\")\n",
    "    \n",
    "def assign_methods_improved(df, scores, method_names, top_n=5, min_score=0.005):\n",
    "    \"\"\"\n",
    "    Improved method assignment with better diagnostics.\n",
    "    \"\"\"\n",
    "    n_papers, n_methods = scores.shape\n",
    "    \n",
    "    # Initialize method columns\n",
    "    for i in range(top_n):\n",
    "        df[f'Method_{i+1}'] = ''\n",
    "        df[f'Method_{i+1}_Score'] = 0.0\n",
    "    \n",
    "    df['Primary_Method'] = ''\n",
    "    df['Primary_Method_Score'] = 0.0\n",
    "    df['Method_Confidence'] = 'Low'\n",
    "    df['Total_Method_Score'] = 0.0\n",
    "    \n",
    "    assigned_count = 0\n",
    "    \n",
    "    for paper_idx in range(n_papers):\n",
    "        paper_scores = scores[paper_idx, :]\n",
    "        \n",
    "        # Get top methods for this paper\n",
    "        top_indices = np.argsort(paper_scores)[::-1][:top_n]\n",
    "        top_scores = paper_scores[top_indices]\n",
    "        \n",
    "        # Filter by minimum score\n",
    "        valid_mask = top_scores >= min_score\n",
    "        valid_indices = top_indices[valid_mask]\n",
    "        valid_scores = top_scores[valid_mask]\n",
    "        \n",
    "        if len(valid_indices) > 0:\n",
    "            assigned_count += 1\n",
    "            \n",
    "            # Assign primary method\n",
    "            df.loc[paper_idx, 'Primary_Method'] = method_names[valid_indices[0]]\n",
    "            df.loc[paper_idx, 'Primary_Method_Score'] = valid_scores[0]\n",
    "            df.loc[paper_idx, 'Total_Method_Score'] = valid_scores.sum()\n",
    "            \n",
    "            # Assign confidence based on top score\n",
    "            if valid_scores[0] > 0.1:\n",
    "                df.loc[paper_idx, 'Method_Confidence'] = 'High'\n",
    "            elif valid_scores[0] > 0.05:\n",
    "                df.loc[paper_idx, 'Method_Confidence'] = 'Medium'\n",
    "            \n",
    "            # Assign all valid methods\n",
    "            for i, (idx, score) in enumerate(zip(valid_indices, valid_scores)):\n",
    "                if i < top_n:\n",
    "                    df.loc[paper_idx, f'Method_{i+1}'] = method_names[idx]\n",
    "                    df.loc[paper_idx, f'Method_{i+1}_Score'] = score\n",
    "    \n",
    "    logger.info(f\"  Assigned methods to {assigned_count}/{n_papers} papers ({100*assigned_count/n_papers:.1f}%)\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a86210a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 7: Enhanced Topic Analysis Functions with Multi-N-gram Support\n",
    "\n",
    "def run_lda_topic_modeling(df, num_topics=10, num_words=25):\n",
    "    tokenized_texts = df['processed_text'].apply(lambda x: x.split()).tolist()\n",
    "    bigram = Phrases(tokenized_texts, min_count=10, threshold=50, delimiter='_')\n",
    "    trigram = Phrases(bigram[tokenized_texts], threshold=50, delimiter='_')\n",
    "    phrased = []\n",
    "    for doc in tokenized_texts:\n",
    "        bigrams_ = [w for w in bigram[doc] if '_' in w]\n",
    "        trigrams_ = [w for w in trigram[bigram[doc]] if '_' in w]\n",
    "        combined = doc + bigrams_ + trigrams_\n",
    "        phrased.append(' '.join(combined))\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 1), token_pattern=r'\\b[\\w_-]+\\b', max_df=0.95, min_df=2, max_features=10000)\n",
    "    doc_term_matrix = vectorizer.fit_transform(phrased)\n",
    "    lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "    topic_distributions = lda_model.fit_transform(doc_term_matrix)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    topic_keywords = {}\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        top_indices = topic.argsort()[:-num_words-1:-1]\n",
    "        top_words = [feature_names[i] for i in top_indices]\n",
    "        topic_keywords[topic_idx] = {'top_words': top_words}\n",
    "    return lda_model, vectorizer, topic_distributions, topic_keywords\n",
    "\n",
    "def assign_papers_to_topics(topic_distributions):\n",
    "    paper_classifications = []\n",
    "    for idx, dist in enumerate(topic_distributions):\n",
    "        top_2_topics = np.argsort(dist)[-2:][::-1]\n",
    "        primary_score = dist[top_2_topics]\n",
    "        other_topics_sum = sum(dist) - primary_score\n",
    "        dominance_ratio = primary_score / (other_topics_sum + 1e-10)\n",
    "        paper_classifications.append({\n",
    "            'paper_idx': idx,\n",
    "            'primary_topic': top_2_topics[0],\n",
    "            'secondary_topic': top_2_topics[1],\n",
    "            'primary_score': primary_score,\n",
    "            'dominance_ratio': dominance_ratio\n",
    "        })\n",
    "    return paper_classifications\n",
    "\n",
    "def string_similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def topic_name_llm_robust(\n",
    "    lda_keywords, tfidf_ngrams, top_titles,\n",
    "    client, model_type, credit_tracker,\n",
    "    initial_iterations=3, max_iterations=10, similarity_threshold=0.7,\n",
    "    temp=0, top_p=1.0\n",
    "):\n",
    "    prompt = (\n",
    "        \"Based on the following keywords and n-grams from LDA and TF-IDF, plus top paper titles, provide a concise topic name \"\n",
    "        \"(bigram or trigram, single word if very specific):\\n\"\n",
    "        f\"LDA: {', '.join(lda_keywords)}\\n\"\n",
    "        f\"TFIDF: {', '.join(tfidf_ngrams)}\\n\"\n",
    "        f\"TITLES: {', '.join(top_titles)}\\n\"\n",
    "        \"Return ONLY the topic name.\"\n",
    "    )\n",
    "    iterations = initial_iterations\n",
    "    from collections import Counter\n",
    "    while iterations <= max_iterations:\n",
    "        generated_names = []\n",
    "        for _ in range(iterations):\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_type,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a science topic-naming assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=temp,\n",
    "                top_p=top_p\n",
    "            )\n",
    "            content = response.choices[0].message.content.strip()\n",
    "            if content:\n",
    "                generated_names.append(content)\n",
    "        for i, name in enumerate(generated_names):\n",
    "            matches = [other for j, other in enumerate(generated_names)\n",
    "                       if i != j and string_similarity(name, other) >= similarity_threshold]\n",
    "            if len(matches) >= len(generated_names)//2:\n",
    "                print(f\"Topic name stabilized after {iterations} iterations: {name}\")\n",
    "                return name\n",
    "        iterations += 2\n",
    "        print(f\"No majority topic name found, increasing iterations to {iterations}.\")\n",
    "    most_common = Counter(generated_names).most_common(1)\n",
    "    print(f\"Returning most common topic name after {max_iterations} iterations: {most_common}\")\n",
    "    return most_common\n",
    "\n",
    "def get_top_titles_for_topic(df, paper_classifications, topic_idx, n_titles=10):\n",
    "    dominant_papers = [p for p in paper_classifications if p['primary_topic'] == topic_idx]\n",
    "    paper_infos = [\n",
    "        (df.iloc[p['paper_idx']]['citationCount'] if 'citationCount' in df.columns else 0, df.iloc[p['paper_idx']]['title'])\n",
    "        for p in dominant_papers if not pd.isna(df.iloc[p['paper_idx']]['title'])\n",
    "    ]\n",
    "    # Correctly sort by citation count (descending)\n",
    "    top_titles = [title for _, title in sorted(paper_infos, key=lambda x: -x[0])[:n_titles]]\n",
    "    return top_titles\n",
    "\n",
    "def get_top_tfidf_ngrams_per_topic_enhanced(df, topic_col='Primary_Topic_Index', text_col='processed_text', \n",
    "                                          top_k=15, min_df=2, max_df=0.8):\n",
    "    \"\"\"\n",
    "    Enhanced function to extract top TF-IDF keywords, bigrams, and trigrams for each topic.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with topic assignments and text\n",
    "    - topic_col: Column name for topic indices\n",
    "    - text_col: Column name for processed text\n",
    "    - top_k: Number of top n-grams to extract per topic per type\n",
    "    - min_df: Minimum document frequency for TF-IDF\n",
    "    - max_df: Maximum document frequency for TF-IDF\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with structure: {topic_id: {'keywords': {...}, 'bigrams': {...}, 'trigrams': {...}}}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"🔍 Extracting topic-specific n-grams...\")\n",
    "    \n",
    "    # Ensure text column exists and is not empty\n",
    "    if text_col not in df.columns:\n",
    "        print(f\"❌ Text column '{text_col}' not found in DataFrame\")\n",
    "        return {}\n",
    "    \n",
    "    # Remove rows with missing text or topic assignments\n",
    "    df_clean = df.dropna(subset=[text_col, topic_col]).copy()\n",
    "    print(f\"📊 Processing {len(df_clean)} documents across {df_clean[topic_col].nunique()} topics\")\n",
    "    \n",
    "    # Initialize result structure\n",
    "    topic_ngrams = {}\n",
    "    \n",
    "    # Get unique topics\n",
    "    unique_topics = sorted(df_clean[topic_col].dropna().unique())\n",
    "    \n",
    "    # Define n-gram configurations\n",
    "    ngram_configs = {\n",
    "        'keywords': (1, 1),    # Unigrams\n",
    "        'bigrams': (2, 2),     # Bigrams  \n",
    "        'trigrams': (3, 3)     # Trigrams\n",
    "    }\n",
    "    \n",
    "    for ngram_type, (min_n, max_n) in ngram_configs.items():\n",
    "        print(f\"📈 Processing {ngram_type} ({min_n}-{max_n} grams)...\")\n",
    "        \n",
    "        try:\n",
    "            # Create TF-IDF vectorizer for this n-gram type\n",
    "            vectorizer = TfidfVectorizer(\n",
    "                ngram_range=(min_n, max_n),\n",
    "                min_df=min_df,\n",
    "                max_df=max_df,\n",
    "                stop_words='english',\n",
    "                lowercase=True,\n",
    "                token_pattern=r'\\b[a-zA-Z][a-zA-Z0-9]*\\b'  # Only alphanumeric tokens starting with letter\n",
    "            )\n",
    "            \n",
    "            # Fit on all documents\n",
    "            tfidf_matrix = vectorizer.fit_transform(df_clean[text_col])\n",
    "            feature_names = vectorizer.get_feature_names_out()\n",
    "            \n",
    "            print(f\"  ✅ Created {len(feature_names)} {ngram_type} features\")\n",
    "            \n",
    "            # Extract top terms for each topic\n",
    "            for topic_idx in unique_topics:\n",
    "                topic_idx = int(topic_idx)\n",
    "                \n",
    "                # Initialize topic entry if not exists\n",
    "                if topic_idx not in topic_ngrams:\n",
    "                    topic_ngrams[topic_idx] = {}\n",
    "                \n",
    "                # Get documents for this topic\n",
    "                doc_indices = df_clean[df_clean[topic_col] == topic_idx].index\n",
    "                topic_doc_positions = [df_clean.index.get_loc(idx) for idx in doc_indices]\n",
    "                \n",
    "                if len(topic_doc_positions) == 0:\n",
    "                    topic_ngrams[topic_idx][ngram_type] = {}\n",
    "                    continue\n",
    "                \n",
    "                # Calculate mean TF-IDF scores for this topic\n",
    "                topic_tfidf = tfidf_matrix[topic_doc_positions].mean(axis=0).A1\n",
    "                \n",
    "                # Get top terms\n",
    "                top_indices = topic_tfidf.argsort()[-top_k:][::-1]\n",
    "                top_terms = {\n",
    "                    feature_names[i]: float(topic_tfidf[i]) \n",
    "                    for i in top_indices \n",
    "                    if topic_tfidf[i] > 0\n",
    "                }\n",
    "                \n",
    "                topic_ngrams[topic_idx][ngram_type] = top_terms\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error processing {ngram_type}: {e}\")\n",
    "            # Initialize empty entries for all topics for this n-gram type\n",
    "            for topic_idx in unique_topics:\n",
    "                topic_idx = int(topic_idx)\n",
    "                if topic_idx not in topic_ngrams:\n",
    "                    topic_ngrams[topic_idx] = {}\n",
    "                topic_ngrams[topic_idx][ngram_type] = {}\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n📊 N-gram Extraction Summary:\")\n",
    "    for topic_idx in sorted(topic_ngrams.keys()):\n",
    "        topic_data = topic_ngrams[topic_idx]\n",
    "        print(f\"  Topic {topic_idx}:\")\n",
    "        for ngram_type in ['keywords', 'bigrams', 'trigrams']:\n",
    "            count = len(topic_data.get(ngram_type, {}))\n",
    "            print(f\"    {ngram_type}: {count} terms\")\n",
    "    \n",
    "    return topic_ngrams\n",
    "\n",
    "# Legacy function for backward compatibility\n",
    "def get_top_tfidf_ngrams_per_topic(df, tfidf_matrix, feature_names, topic_col='Primary_Topic_Index', top_k=10):\n",
    "    \"\"\"\n",
    "    Legacy function - now calls the enhanced version for keywords only.\n",
    "    \"\"\"\n",
    "    print(\"⚠️  Using legacy function - consider switching to get_top_tfidf_ngrams_per_topic_enhanced\")\n",
    "    \n",
    "    result = get_top_tfidf_ngrams_per_topic_enhanced(\n",
    "        df, topic_col=topic_col, text_col='processed_text', top_k=top_k\n",
    "    )\n",
    "    \n",
    "    if not result:\n",
    "        return {}\n",
    "    \n",
    "    # Convert to legacy format (keywords only)\n",
    "    legacy_result = {}\n",
    "    for topic_idx, topic_data in result.items():\n",
    "        keywords = topic_data.get('keywords', {})\n",
    "        # Convert to list of tuples format\n",
    "        legacy_result[topic_idx] = [(term, score) for term, score in keywords.items()]\n",
    "    \n",
    "    return legacy_result\n",
    "\n",
    "def get_author_stats(paper_classifications, df_field, n_top=5):\n",
    "    top_papers = {}\n",
    "    author_topic_stats = {}\n",
    "    \n",
    "    for topic in set(p['primary_topic'] for p in paper_classifications):\n",
    "        topic_papers = [p for p in paper_classifications if p['primary_topic'] == topic]\n",
    "        \n",
    "        # Fix: Handle various numpy array cases for dominance_ratio\n",
    "        for p in topic_papers:\n",
    "            dominance_ratio = p['dominance_ratio']\n",
    "            \n",
    "            if isinstance(dominance_ratio, np.ndarray):\n",
    "                if dominance_ratio.size == 1:\n",
    "                    p['dominance_ratio'] = float(dominance_ratio.item())\n",
    "                else:\n",
    "                    # Take the first element if it's a multi-element array\n",
    "                    p['dominance_ratio'] = float(dominance_ratio.flat[0])\n",
    "            elif hasattr(dominance_ratio, 'item'):\n",
    "                p['dominance_ratio'] = float(dominance_ratio.item())\n",
    "            else:\n",
    "                p['dominance_ratio'] = float(dominance_ratio)\n",
    "            \n",
    "            # Also fix primary_score if needed\n",
    "            primary_score = p['primary_score']\n",
    "            if isinstance(primary_score, np.ndarray):\n",
    "                if primary_score.size == 1:\n",
    "                    p['primary_score'] = float(primary_score.item())\n",
    "                else:\n",
    "                    p['primary_score'] = float(primary_score.flat[0])\n",
    "            elif hasattr(primary_score, 'item'):\n",
    "                p['primary_score'] = float(primary_score.item())\n",
    "            else:\n",
    "                p['primary_score'] = float(primary_score)\n",
    "        \n",
    "        topic_papers.sort(key=lambda x: x['dominance_ratio'], reverse=True)\n",
    "        top_papers[topic] = []\n",
    "        \n",
    "        for p in topic_papers[:n_top]:\n",
    "            paper_idx = p['paper_idx']\n",
    "            try:\n",
    "                authors = df_field.iloc[paper_idx]['authors']\n",
    "                if isinstance(authors, str):\n",
    "                    try: \n",
    "                        authors = ast.literal_eval(authors)\n",
    "                    except (ValueError, SyntaxError): \n",
    "                        authors = []\n",
    "                if isinstance(authors, list):\n",
    "                    author_list = []\n",
    "                    for author in authors:\n",
    "                        if isinstance(author, dict):\n",
    "                            author_list.append({'name': author.get('name', 'Unknown'), 'id': author.get('authorId', 'Unknown')})\n",
    "                else: \n",
    "                    author_list = []\n",
    "                    \n",
    "                top_papers[topic].append({\n",
    "                    'paperId': df_field.iloc[paper_idx].get('paperId',''),\n",
    "                    'title': df_field.iloc[paper_idx].get('title',''),\n",
    "                    'authors': author_list,\n",
    "                    'score': float(p['primary_score']),\n",
    "                    'dominance_ratio': float(p['dominance_ratio'])\n",
    "                })\n",
    "            except Exception as e: \n",
    "                continue\n",
    "                \n",
    "    return top_papers, author_topic_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfa79b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 8: Enhanced Utility Functions for Saving with Topic N-grams\n",
    "\n",
    "def save_term_frequencies(df, suffix_string, save_dir=SAVE_DIR, max_keywords=5000):\n",
    "    \"\"\"Save .json containing keywords, bigrams, trigrams with their counts for later visualization.\"\"\"\n",
    "    freq_data = {}\n",
    "    processed_text = df['processed_text'].fillna('').astype(str)\n",
    "    \n",
    "    for n in range(1, 4):\n",
    "        vectorizer = CountVectorizer(ngram_range=(n, n), stop_words='english', max_features=max_keywords)\n",
    "        matrix = vectorizer.fit_transform(processed_text)\n",
    "        terms = vectorizer.get_feature_names_out()\n",
    "        freqs = matrix.sum(axis=0).A1\n",
    "        \n",
    "        # Fix: Access the frequency (x[1]) for sorting, not the whole tuple (x)\n",
    "        freq_dict = {term: int(freq) for term, freq in sorted(zip(terms, freqs), key=lambda x: -x[1])}\n",
    "        \n",
    "        if n == 1: \n",
    "            freq_data['keywords'] = freq_dict\n",
    "        elif n == 2: \n",
    "            freq_data['bigrams'] = freq_dict\n",
    "        elif n == 3: \n",
    "            freq_data['trigrams'] = freq_dict\n",
    "    \n",
    "    out_fn = os.path.join(save_dir, f'term_frequencies_{suffix_string}.json')\n",
    "    with open(out_fn, 'w', encoding='utf-8') as f:\n",
    "        json.dump(freq_data, f, indent=2)\n",
    "    print(f\"✓ Saved term frequency summary to {out_fn}\")\n",
    "    return out_fn\n",
    "\n",
    "def save_author_and_venue_frequencies(df, suffix_string, save_dir=SAVE_DIR):\n",
    "    if 'authors' in df.columns:\n",
    "        authors_all = []\n",
    "        for item in df['authors']:\n",
    "            if isinstance(item, str) and item.strip():\n",
    "                try:\n",
    "                    obj = eval(item) if (item.strip().startswith(\"[\") or item.strip().startswith(\"{\")) else item.strip()\n",
    "                except Exception:\n",
    "                    obj = item.strip()\n",
    "            else:\n",
    "                obj = item\n",
    "            if isinstance(obj, list):\n",
    "                for author in obj:\n",
    "                    if isinstance(author, dict) and 'name' in author:\n",
    "                        authors_all.append(author['name'])\n",
    "                    elif isinstance(author, str):\n",
    "                        authors_all.append(author)\n",
    "            elif isinstance(obj, dict) and 'name' in obj:\n",
    "                authors_all.append(obj['name'])\n",
    "            elif isinstance(obj, str):\n",
    "                authors_all.append(obj)\n",
    "        author_counts = pd.Series(authors_all).value_counts().reset_index()\n",
    "        author_counts.columns = ['Author', 'Frequency']\n",
    "        author_fn = os.path.join(save_dir, f\"semantic_scholar_{suffix_string}_author_analysis.csv\")\n",
    "        author_counts.to_csv(author_fn, sep=';', encoding='utf-8', index=False)\n",
    "        print(f\"✓ Saved author frequencies: {author_fn}\")\n",
    "    else:\n",
    "        print(\"No 'authors' column found in DF: skipping author frequencies.\")\n",
    "        \n",
    "    if 'venue' in df.columns:\n",
    "        venue_counts = df['venue'].value_counts().reset_index()\n",
    "        venue_counts.columns = ['Venue', 'Frequency']\n",
    "        venue_fn = os.path.join(save_dir, f\"semantic_scholar_{suffix_string}_venue_frequencies.csv\")\n",
    "        venue_counts.to_csv(venue_fn, sep=';', encoding='utf-8', index=False)\n",
    "        print(f\"✓ Saved venue frequencies: {venue_fn}\")\n",
    "    else:\n",
    "        print(\"No 'venue' column found in DF: skipping venue frequencies.\")\n",
    "\n",
    "def save_topic_analysis_outputs(\n",
    "    df, lda_model, lda_vectorizer, topic_distributions, topic_keywords, topic_names, topic_ngrams,\n",
    "    author_stats, top_papers, tfidf_ngrams, suffix_string\n",
    "):\n",
    "    topic_metadata = {\n",
    "        \"topics\": {int(k): v for k,v in topic_keywords.items()},\n",
    "        \"topic_names\": {int(k): v for k,v in topic_names.items()},\n",
    "        \"topic_ngrams\": {int(k): v for k,v in topic_ngrams.items()},\n",
    "    }\n",
    "    with open(os.path.join(SAVE_DIR, f\"topics_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(topic_metadata, f, indent=2)\n",
    "    with open(os.path.join(SAVE_DIR, f\"topic_names_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({int(k):v for k,v in topic_names.items()}, f, indent=2)\n",
    "    np.save(os.path.join(SAVE_DIR, f\"topic_distributions_{suffix_string}.npy\"), topic_distributions)\n",
    "    import joblib\n",
    "    joblib.dump(lda_model, os.path.join(SAVE_DIR, f\"lda_model_{suffix_string}.joblib\"))\n",
    "    joblib.dump(lda_vectorizer, os.path.join(SAVE_DIR, f\"lda_vectorizer_{suffix_string}.joblib\"))\n",
    "    with open(os.path.join(SAVE_DIR, f\"top_papers_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({int(k): v for k, v in top_papers.items()}, f, ensure_ascii=False, indent=2, default=str)\n",
    "    pd.DataFrame.from_dict(author_stats, orient='index').to_csv(\n",
    "        os.path.join(SAVE_DIR, f\"author_stats_{suffix_string}.csv\"))\n",
    "    \n",
    "    # ENHANCED: Save topic-specific TF-IDF n-grams in the new format\n",
    "    if topic_ngrams and isinstance(list(topic_ngrams.values())[0], dict):\n",
    "        # New format with keywords/bigrams/trigrams structure\n",
    "        with open(os.path.join(SAVE_DIR, f\"topic_specific_tfidf_ngrams_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({int(k): v for k, v in topic_ngrams.items()}, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"✓ Saved enhanced topic-specific TF-IDF n-grams to topic_specific_tfidf_ngrams_{suffix_string}.json\")\n",
    "    else:\n",
    "        # Legacy format fallback\n",
    "        with open(os.path.join(SAVE_DIR, f\"topic_specific_tfidf_ngrams_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({int(k):[(term,float(score)) for term,score in v] for k,v in topic_ngrams.items()}, f, indent=2)\n",
    "        print(f\"✓ Saved legacy topic-specific TF-IDF n-grams to topic_specific_tfidf_ngrams_{suffix_string}.json\")\n",
    "\n",
    "def diagnostics_enhanced(df, canonical_scores, variant_scores, canonical_methods, variant_names):\n",
    "    n_docs, n_canonical = canonical_scores.shape\n",
    "    n_variants = variant_scores.shape[1]\n",
    "    \n",
    "    print(\"=== ENHANCED DIAGNOSTICS ===\")\n",
    "    print(f\"Total documents: {n_docs}\")\n",
    "    print(f\"Canonical methods: {n_canonical}\")\n",
    "    print(f\"Method variants: {n_variants}\")\n",
    "    print(f\"Canonical coverage: {(canonical_scores > 0).any(axis=1).sum()}/{n_docs} ({100*(canonical_scores>0).any(axis=1).mean():.1f}%)\")\n",
    "    print(f\"Variant coverage: {(variant_scores > 0).any(axis=1).sum()}/{n_docs} ({100*(variant_scores>0).any(axis=1).mean():.1f}%)\")\n",
    "    \n",
    "    if 'Primary_Method' in df.columns:\n",
    "        print(\"\\nMethod distribution (top 10):\")\n",
    "        method_dist = df['Primary_Method'].value_counts().head(10)\n",
    "        for method, count in method_dist.items():\n",
    "            if method:  # Skip empty strings\n",
    "                print(f\"  {method}: {count}\")\n",
    "    \n",
    "    if 'Method_Confidence' in df.columns:\n",
    "        print(\"\\nConfidence distribution:\")\n",
    "        conf_dist = df['Method_Confidence'].value_counts()\n",
    "        for conf, count in conf_dist.items():\n",
    "            if conf:  # Skip empty strings\n",
    "                print(f\"  {conf}: {count}\")\n",
    "    \n",
    "    print(f\"\\nCanonical methods sample: {canonical_methods[:5]}\")\n",
    "    print(f\"Variant methods sample: {variant_names[:10]}\")\n",
    "    print(f\"\\nCanonical scores stats: mean={canonical_scores.mean():.3f}, std={canonical_scores.std():.3f}\")\n",
    "    print(f\"Variant scores stats: mean={variant_scores.mean():.3f}, std={variant_scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db56121",
   "metadata": {},
   "source": [
    "### Topic and author analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f31ba70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved term frequency summary to Saved_files_new\\term_frequencies_2025_08_28_reliability_resilience_power_systems.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 10:35:48,223 - INFO - Starting topic modeling workflow...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved author frequencies: Saved_files_new\\semantic_scholar_2025_08_28_reliability_resilience_power_systems_author_analysis.csv\n",
      "✓ Saved venue frequencies: Saved_files_new\\semantic_scholar_2025_08_28_reliability_resilience_power_systems_venue_frequencies.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 10:35:48,506 - INFO - collecting all words and their counts\n",
      "2025-08-28 10:35:48,507 - INFO - PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2025-08-28 10:35:49,948 - INFO - PROGRESS: at sentence #10000, processed 1524957 words and 863761 word types\n",
      "2025-08-28 10:35:51,493 - INFO - PROGRESS: at sentence #20000, processed 3004878 words and 1467564 word types\n",
      "2025-08-28 10:35:52,972 - INFO - collected 1902495 token types (unigram + bigrams) from a corpus of 4290297 words and 28934 sentences\n",
      "2025-08-28 10:35:52,973 - INFO - merged Phrases<1902495 vocab, min_count=10, threshold=50, max_vocab_size=40000000>\n",
      "2025-08-28 10:35:52,974 - INFO - Phrases lifecycle event {'msg': 'built Phrases<1902495 vocab, min_count=10, threshold=50, max_vocab_size=40000000> in 4.47s', 'datetime': '2025-08-28T10:35:52.974550', 'gensim': '4.3.2', 'python': '3.11.13 (main, Jun 12 2025, 12:41:34) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "2025-08-28 10:35:52,975 - INFO - collecting all words and their counts\n",
      "2025-08-28 10:35:52,976 - INFO - PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2025-08-28 10:35:57,576 - INFO - PROGRESS: at sentence #10000, processed 1471162 words and 886074 word types\n",
      "2025-08-28 10:36:01,827 - INFO - PROGRESS: at sentence #20000, processed 2890563 words and 1519087 word types\n",
      "2025-08-28 10:36:05,190 - INFO - collected 1981629 token types (unigram + bigrams) from a corpus of 4117577 words and 28934 sentences\n",
      "2025-08-28 10:36:05,191 - INFO - merged Phrases<1981629 vocab, min_count=5, threshold=50, max_vocab_size=40000000>\n",
      "2025-08-28 10:36:05,192 - INFO - Phrases lifecycle event {'msg': 'built Phrases<1981629 vocab, min_count=5, threshold=50, max_vocab_size=40000000> in 12.22s', 'datetime': '2025-08-28T10:36:05.192344', 'gensim': '4.3.2', 'python': '3.11.13 (main, Jun 12 2025, 12:41:34) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "2025-08-28 10:38:33,439 - INFO - ✓ LDA topic modeling completed.\n",
      "2025-08-28 10:38:33,616 - INFO - ✓ Papers assigned to topics based on LDA distributions.\n",
      "2025-08-28 10:38:33,617 - INFO - Extracting enhanced topic-specific TF-IDF n-grams...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Extracting topic-specific n-grams...\n",
      "📊 Processing 28934 documents across 10 topics\n",
      "📈 Processing keywords (1-1 grams)...\n",
      "  ✅ Created 31701 keywords features\n",
      "📈 Processing bigrams (2-2 grams)...\n",
      "  ✅ Created 411874 bigrams features\n",
      "📈 Processing trigrams (3-3 grams)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 10:38:49,432 - INFO - ✓ Extracted enhanced topic-specific TF-IDF n-grams for naming.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✅ Created 244770 trigrams features\n",
      "\n",
      "📊 N-gram Extraction Summary:\n",
      "  Topic 0:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 1:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 2:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 3:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 4:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 5:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 6:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 7:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 8:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n",
      "  Topic 9:\n",
      "    keywords: 15 terms\n",
      "    bigrams: 15 terms\n",
      "    trigrams: 15 terms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 10:38:50,239 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:38:50,823 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:38:51,519 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:38:51,525 - INFO - Topic 0: Thermal Energy Systems\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Thermal Energy Systems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 10:38:52,533 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:38:53,131 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:38:53,625 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:38:53,630 - INFO - Topic 1: Wireless Communication Systems\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Wireless Communication Systems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 10:38:54,547 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:38:55,385 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:38:56,014 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:38:56,019 - INFO - Topic 2: Wireless Sensor Networks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Wireless Sensor Networks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 10:38:57,023 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:38:57,505 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:38:58,014 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:38:58,018 - INFO - Topic 3: Smart Energy Management\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Smart Energy Management\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 10:38:59,098 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:38:59,642 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:00,193 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:00,204 - INFO - Topic 4: Power System Control\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Power System Control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 10:39:01,395 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:01,958 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:02,510 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:02,512 - INFO - Topic 5: Wind Energy Optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Wind Energy Optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 10:39:03,436 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:04,217 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:04,786 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:04,788 - INFO - Topic 6: Renewable Energy Storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Renewable Energy Storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 10:39:05,671 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:06,422 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:07,202 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:07,207 - INFO - Topic 7: Resilience and Reliability Assessment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Resilience and Reliability Assessment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 10:39:08,131 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:08,860 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:09,551 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:09,558 - INFO - Topic 8: High-Performance Battery Materials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: High-Performance Battery Materials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 10:39:10,279 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:10,822 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:11,364 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 10:39:11,372 - INFO - Topic 9: Renewable Energy Systems\n",
      "2025-08-28 10:39:11,395 - INFO - ✓ Topic naming and assignment completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic name stabilized after 3 iterations: Renewable Energy Systems\n",
      "✓ Saved enhanced topic-specific TF-IDF n-grams to topic_specific_tfidf_ngrams_2025_08_28_reliability_resilience_power_systems.json\n",
      "\n",
      "Sample topics and names:\n",
      "{0: 'Thermal Energy Systems', 1: 'Wireless Communication Systems', 2: 'Wireless Sensor Networks', 3: 'Smart Energy Management', 4: 'Power System Control'}\n",
      "\n",
      "📊 Enhanced N-grams Structure Sample:\n",
      "Topic 0 (Thermal Energy Systems):\n",
      "  keywords: [('heat', 0.08320521744256197), ('cooling', 0.046850935226352065), ('temperature', 0.04088639765946179), ('plant', 0.040525551834016675), ('gas', 0.03979704864835042)]\n",
      "  bigrams: [('power plant', 0.019979301691567784), ('fuel cell', 0.015297183506756053), ('gas turbine', 0.01448446007269745), ('waste heat', 0.013601408575671874), ('power generation', 0.012452353028140536)]\n",
      "  trigrams: [('thermal energy storage', 0.00752598208271986), ('organic rankine cycle', 0.006598230500100499), ('nuclear power plant', 0.006214901675069471), ('waste heat recovery', 0.006048844127119306), ('thermal power plant', 0.006016461973114782)]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 9: Enhanced Topic Analysis Workflow with Multi-N-gram Support\n",
    "\n",
    "NUM_TOPICS = 10\n",
    "NUM_TOPIC_WORDS = 15\n",
    "TOPIC_LLM_ITER_INIT = 3\n",
    "TOPIC_LLM_ITER_MAX = 9\n",
    "TOPIC_LLM_SIM_THRESH = 0.72\n",
    "TOPIC_LLM_TEMP = 1\n",
    "TOPIC_LLM_TOP_P = 1.0\n",
    "\n",
    "current_date = datetime.now().strftime(\"%Y_%m_%d\")\n",
    "keyword_str = '_'.join(extract_keywords_from_filename(filename)) if 'filename' in locals() else \"\"\n",
    "suffix_string = f\"{current_date}_{keyword_str}\"\n",
    "\n",
    "# Save basic term frequencies and author/venue analysis\n",
    "save_term_frequencies(df, suffix_string)\n",
    "save_author_and_venue_frequencies(df, suffix_string)\n",
    "\n",
    "logger.info(\"Starting topic modeling workflow...\")  \n",
    "lda_model, lda_vectorizer, topic_distributions, topic_keywords = run_lda_topic_modeling(\n",
    "    df, num_topics=NUM_TOPICS, num_words=NUM_TOPIC_WORDS)\n",
    "logger.info(\"✓ LDA topic modeling completed.\")\n",
    "\n",
    "paper_classifications = assign_papers_to_topics(topic_distributions)\n",
    "df['Primary_Topic_Index'] = [int(p['primary_topic']) for p in paper_classifications]\n",
    "df['Primary_Score'] = [p['primary_score'] for p in paper_classifications]\n",
    "df['Dominance_Ratio'] = [p['dominance_ratio'] for p in paper_classifications]\n",
    "\n",
    "logger.info(\"✓ Papers assigned to topics based on LDA distributions.\")\n",
    "\n",
    "# ENHANCED: Use the new multi-n-gram extraction function\n",
    "logger.info(\"Extracting enhanced topic-specific TF-IDF n-grams...\")\n",
    "topic_ngrams = get_top_tfidf_ngrams_per_topic_enhanced(\n",
    "    df, topic_col='Primary_Topic_Index', text_col='processed_text', top_k=15, min_df=2, max_df=0.8\n",
    ")\n",
    "logger.info(\"✓ Extracted enhanced topic-specific TF-IDF n-grams for naming.\")\n",
    "\n",
    "# Generate topic names using enhanced n-grams\n",
    "topic_names = {}\n",
    "for topic_idx, keywords in topic_keywords.items():\n",
    "    lda_ngrams = keywords['top_words'][:NUM_TOPIC_WORDS]\n",
    "    \n",
    "    # ENHANCED: Use keywords from the new structure\n",
    "    topic_data = topic_ngrams.get(topic_idx, {})\n",
    "    tfidf_keywords = list(topic_data.get('keywords', {}).keys())[:NUM_TOPIC_WORDS]\n",
    "    \n",
    "    top_titles = get_top_titles_for_topic(df, paper_classifications, topic_idx, n_titles=10)\n",
    "    topic_name = topic_name_llm_robust(\n",
    "        lda_ngrams, tfidf_keywords, top_titles,\n",
    "        client, model_type, credit_tracker,\n",
    "        initial_iterations=TOPIC_LLM_ITER_INIT,\n",
    "        max_iterations=TOPIC_LLM_ITER_MAX,\n",
    "        similarity_threshold=TOPIC_LLM_SIM_THRESH,\n",
    "        temp=TOPIC_LLM_TEMP, top_p=TOPIC_LLM_TOP_P\n",
    "    )\n",
    "    topic_names[topic_idx] = topic_name\n",
    "    logger.info(f\"Topic {topic_idx}: {topic_name if topic_name else 'Unnamed'}\")\n",
    "\n",
    "df['Primary_Topic'] = df['Primary_Topic_Index'].map(lambda x: topic_names.get(x, f\"Topic_{x}\"))\n",
    "logger.info(\"✓ Topic naming and assignment completed.\")\n",
    "\n",
    "top_papers, author_stats = get_author_stats(paper_classifications, df, n_top=5)\n",
    "\n",
    "# ENHANCED: Save with the new n-grams structure\n",
    "save_topic_analysis_outputs(df, lda_model, lda_vectorizer, topic_distributions, \n",
    "                           topic_keywords, topic_names, topic_ngrams, author_stats, \n",
    "                           top_papers, topic_ngrams, suffix_string)\n",
    "\n",
    "print(\"\\nSample topics and names:\")\n",
    "print({k: topic_names[k] for k in list(topic_names)[:5]})\n",
    "\n",
    "# Show sample of enhanced n-grams structure\n",
    "if topic_ngrams:\n",
    "    print(f\"\\n📊 Enhanced N-grams Structure Sample:\")\n",
    "    sample_topic = list(topic_ngrams.keys())[0]\n",
    "    sample_data = topic_ngrams[sample_topic]\n",
    "    topic_name = topic_names.get(sample_topic, f\"Topic {sample_topic}\")\n",
    "    print(f\"Topic {sample_topic} ({topic_name}):\")\n",
    "    for ngram_type in ['keywords', 'bigrams', 'trigrams']:\n",
    "        terms = sample_data.get(ngram_type, {})\n",
    "        if terms:\n",
    "            top_terms = list(terms.items())[:5]\n",
    "            print(f\"  {ngram_type}: {top_terms}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddcaf9d",
   "metadata": {},
   "source": [
    "### Method analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bb61ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 11:32:33,176 - INFO - === Starting Enhanced Method Detection Pipeline with Consolidation ===\n",
      "2025-08-28 11:32:33,177 - INFO - Step 1: Loading or extracting method phrases...\n",
      "2025-08-28 11:32:33,191 - INFO -   ✓ Loaded 108 method phrases from existing CSV\n",
      "2025-08-28 11:32:33,193 - INFO - ✓ Method phrase extraction complete: 108 phrases\n",
      "2025-08-28 11:32:33,193 - INFO - Step 2: Building enhanced method variant groups with consolidation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 108 method phrases from Saved_files_new\\extracted_method_phrases.csv\n",
      "  Sample methods: ['genetic algorithm', 'artificial intelligence', 'particle swarm optimization', 'deep learning', 'neural network', 'machine learning', 'monte carlo simulation', 'genetic algorithm ga', 'opf', 'model predictive control']\n",
      "Pre-filtering: 108 → 108 methods (0 obvious duplicates removed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 11:32:44,727 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-28 11:32:44,727 - INFO - LLM raw response: ChatCompletion(id='chatcmpl-C9THd1dFWy9EKEvy1lLShv8QBQfso', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```python\\n{\\n    \"genetic algorithm\": [\"genetic algorithm\", \"ga\", \"algorithm genetic algorithm\", \"genetic algorithm ga\"],\\n    \"neural network\": [\"neural network\", \"bp neural network\", \"neural network rnn\", \"neural network anns\", \"neural network used\", \"neural network algorithm\"],\\n    \"kalman filter\": [\"kalman filter\", \"extended kalman\"],\\n    \"monte carlo simulation\": [\"monte carlo simulation\", \"based monte carlo simulation\", \"carlo simulation result\"],\\n    \"random forest\": [\"random forest\", \"random forest rf\", \"random forest algorithm\"],\\n    \"deep learning\": [\"dnn model\", \"deep learning\", \"dnn inference\", \"convolutional neural network\"],\\n    \"particle swarm optimization\": [\"particle swarm optimization\", \"particle swarm optimization algorithm\", \"improved particle swarm optimization\", \"binary particle swarm\"],\\n    \"fuzzy logic\": [\"fuzzy c-means\", \"fuzzy logic-based\", \"fuzzy neural network\"],\\n    \"time series\": [\"time series model\", \"time series analysis\", \"auto-regressive\", \"autoregressive integrated\"],\\n    \"artificial bee colony\": [\"abc algorithm\", \"bee colony abc\", \"artificial bee colony abc\"],\\n    \"stochastic simulation\": [\"stochastic simulation\", \"sequential monte carlo\", \"stochastic unit commitment\"],\\n    \"fault analysis\": [\"fault isolation\", \"fault detection diagnosis\", \"fault simulation\", \"fault tree analysis\"],\\n    \"reinforcement learning\": [\"reinforcement learning rl\", \"deep reinforcement learning\", \"reinforcement learning-based\"],\\n    \"linear programming\": [\"linear program\", \"linear programming model\", \"formulated mixed-integer linear\"],\\n    \"mixed-integer programming\": [\"milp\", \"mixed-integer nonlinear\"],\\n    \"support vector machine\": [\"support vector machine\", \"logistic regression\"],\\n    \"ensemble learning\": [\"ensemble learning\"],\\n    \"graph-based\": [\"graph-based\", \"graph neural network\"],\\n    \"numerical simulation\": [\"numerical simulation\", \"analytical simulation\"],\\n    \"global optimization\": [\"global optimization\", \"multi-objective optimization problem\"],\\n    \"economic dispatch\": [\"economic dispatch ed\"],\\n    \"unit commitment\": [\"unit commitment model\", \"unit commitment problem\"],\\n    \"probabilistic forecasting\": [\"probabilistic forecasting\", \"probabilistic risk assessment\", \"probabilistic reliability evaluation\", \"probabilistic production simulation\"],\\n    \"optimization\": [\"two-stage robust\", \"bi-level optimization\", \"chance constrained programming\", \"global optimization\"],\\n    \"data envelopment analysis\": [\"data envelopment analysis\"]\\n}\\n```', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1756373553, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_51db84afab', usage=CompletionUsage(completion_tokens=538, prompt_tokens=998, total_tokens=1536, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "2025-08-28 11:32:44,737 - INFO - LLM content: ```python\n",
      "{\n",
      "    \"genetic algorithm\": [\"genetic algorithm\", \"ga\", \"algorithm genetic algorithm\", \"genetic algorithm ga\"],\n",
      "    \"neural network\": [\"neural network\", \"bp neural network\", \"neural network rnn\", \"neural network anns\", \"neural network used\", \"neural network algorithm\"],\n",
      "    \"kalman filter\": [\"kalman filter\", \"extended kalman\"],\n",
      "    \"monte carlo simulation\": [\"monte carlo simulation\", \"based monte carlo simulation\", \"carlo simulation result\"],\n",
      "    \"random forest\": [\"random forest\", \"random forest rf\", \"random forest algorithm\"],\n",
      "    \"deep learning\": [\"dnn model\", \"deep learning\", \"dnn inference\", \"convolutional neural network\"],\n",
      "    \"particle swarm optimization\": [\"particle swarm optimization\", \"particle swarm optimization algorithm\", \"improved particle swarm optimization\", \"binary particle swarm\"],\n",
      "    \"fuzzy logic\": [\"fuzzy c-means\", \"fuzzy logic-based\", \"fuzzy neural network\"],\n",
      "    \"time series\": [\"time series model\", \"time series analysis\", \"auto-regressive\", \"autoregressive integrated\"],\n",
      "    \"artificial bee colony\": [\"abc algorithm\", \"bee colony abc\", \"artificial bee colony abc\"],\n",
      "    \"stochastic simulation\": [\"stochastic simulation\", \"sequential monte carlo\", \"stochastic unit commitment\"],\n",
      "    \"fault analysis\": [\"fault isolation\", \"fault detection diagnosis\", \"fault simulation\", \"fault tree analysis\"],\n",
      "    \"reinforcement learning\": [\"reinforcement learning rl\", \"deep reinforcement learning\", \"reinforcement learning-based\"],\n",
      "    \"linear programming\": [\"linear program\", \"linear programming model\", \"formulated mixed-integer linear\"],\n",
      "    \"mixed-integer programming\": [\"milp\", \"mixed-integer nonlinear\"],\n",
      "    \"support vector machine\": [\"support vector machine\", \"logistic regression\"],\n",
      "    \"ensemble learning\": [\"ensemble learning\"],\n",
      "    \"graph-based\": [\"graph-based\", \"graph neural network\"],\n",
      "    \"numerical simulation\": [\"numerical simulation\", \"analytical simulation\"],\n",
      "    \"global optimization\": [\"global optimization\", \"multi-objective optimization problem\"],\n",
      "    \"economic dispatch\": [\"economic dispatch ed\"],\n",
      "    \"unit commitment\": [\"unit commitment model\", \"unit commitment problem\"],\n",
      "    \"probabilistic forecasting\": [\"probabilistic forecasting\", \"probabilistic risk assessment\", \"probabilistic reliability evaluation\", \"probabilistic production simulation\"],\n",
      "    \"optimization\": [\"two-stage robust\", \"bi-level optimization\", \"chance constrained programming\", \"global optimization\"],\n",
      "    \"data envelopment analysis\": [\"data envelopment analysis\"]\n",
      "}\n",
      "```\n",
      "2025-08-28 11:32:44,746 - INFO - Created 25 method variant groups from 108 original methods\n",
      "2025-08-28 11:32:44,746 - INFO - ✓ Created 25 canonical methods with 70 total variants\n",
      "2025-08-28 11:32:44,746 - INFO - Step 3: Computing enhanced scoring matrices using multiple approaches...\n",
      "2025-08-28 11:32:44,758 - INFO -   3a: Computing TF-IDF scores for method variants...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Batch 1 LLM response received: 2497 characters\n",
      "  Validation preserved 25 groups from LLM\n",
      "✓ Processed batch 1: 25 groups created\n",
      "  🔍 LLM returned 25 groups:\n",
      "    genetic algorithm: ['genetic algorithm', 'ga', 'algorithm genetic algorithm', 'genetic algorithm ga']\n",
      "    neural network: ['neural network', 'bp neural network', 'neural network rnn', 'neural network anns', 'neural network used', 'neural network algorithm']\n",
      "    kalman filter: ['kalman filter', 'extended kalman']\n",
      "    monte carlo simulation: ['monte carlo simulation', 'based monte carlo simulation', 'carlo simulation result']\n",
      "    random forest: ['random forest', 'random forest rf', 'random forest algorithm']\n",
      "  Validation preserved 25 groups from LLM\n",
      "  🔍 After validation: 25 groups:\n",
      "    genetic algorithm: ['genetic algorithm', 'algorithm genetic algorithm', 'genetic algorithm ga']\n",
      "    neural network: ['neural network', 'bp neural network', 'neural network rnn', 'neural network anns', 'neural network used', 'neural network algorithm']\n",
      "    kalman filter: ['kalman filter', 'extended kalman']\n",
      "    monte carlo simulation: ['monte carlo simulation', 'based monte carlo simulation', 'carlo simulation result']\n",
      "    random forest: ['random forest', 'random forest rf', 'random forest algorithm']\n",
      "  Post-processing preserved 25 groups\n",
      "\n",
      "📊 Method Consolidation Results:\n",
      "  Original methods: 108\n",
      "  Consolidated methods: 25\n",
      "  Reduction: 83 methods (76.9% reduction)\n",
      "\n",
      "Sample variant groups (showing groups with multiple variants):\n",
      "  genetic algorithm: ['genetic algorithm ga', 'genetic algorithm', 'algorithm genetic algorithm']\n",
      "  neural network: ['neural network used', 'neural network algorithm', 'neural network', 'bp neural network', 'neural network rnn', 'neural network anns']\n",
      "  kalman filter: ['kalman filter', 'extended kalman']\n",
      "  monte carlo simulation: ['based monte carlo simulation', 'carlo simulation result', 'monte carlo simulation']\n",
      "  random forest: ['random forest', 'random forest rf', 'random forest algorithm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 11:32:52,722 - ERROR - TF-IDF computation failed: Duplicate term in vocabulary: 'global optimization'\n",
      "2025-08-28 11:32:52,722 - INFO -   ✓ TF-IDF: (28934, 71) with 71 features\n",
      "2025-08-28 11:32:52,722 - INFO -   3b: Computing LDA scores for method variants...\n",
      "2025-08-28 11:32:52,727 - ERROR - LDA computation failed: Duplicate term in vocabulary: 'global optimization'\n",
      "2025-08-28 11:32:52,727 - INFO -   ✓ LDA: (28934, 71) with 71 features\n",
      "2025-08-28 11:32:52,729 - INFO -   3c: Computing compound scores for method variants...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 71 variants that exist in corpus out of 71 total\n",
      "LDA Error details: Duplicate term in vocabulary: 'global optimization'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 11:32:57,617 - INFO -   ✓ Compound: (28934, 71) with 71 features\n",
      "2025-08-28 11:32:57,617 - INFO - Step 4: Aligning and harmonizing features across scoring methods...\n",
      "2025-08-28 11:32:57,617 - INFO -   Feature alignment statistics:\n",
      "2025-08-28 11:32:57,620 - INFO -     Total unique features: 70\n",
      "2025-08-28 11:32:57,620 - INFO -     TF-IDF features: 71\n",
      "2025-08-28 11:32:57,620 - INFO -     LDA features: 71\n",
      "2025-08-28 11:32:57,620 - INFO -     Compound features: 71\n",
      "2025-08-28 11:32:57,682 - INFO - ✓ Feature alignment complete: (28934, 70)\n",
      "2025-08-28 11:32:57,682 - INFO - Step 5: Normalizing scores and applying variant consolidation...\n",
      "2025-08-28 11:32:57,717 - INFO - ✓ Score combination complete: (28934, 70)\n",
      "2025-08-28 11:32:57,720 - INFO -   Combined score range: [0.0000, 0.3000]\n",
      "2025-08-28 11:32:57,720 - INFO -   Applying variant score consolidation to prevent double-counting...\n",
      "2025-08-28 11:32:57,740 - INFO -   ✓ Consolidated 70 methods to 25 canonical methods\n",
      "2025-08-28 11:32:57,740 - INFO - ✓ Final consolidated scores: (28934, 25)\n",
      "2025-08-28 11:32:57,740 - INFO -   Final score range: [0.0000, 0.3000]\n",
      "2025-08-28 11:32:57,740 - INFO - Step 6: Assigning methods to papers using consolidated scores...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Aligned 70/70 features\n",
      "    ✓ Aligned 70/70 features\n",
      "    ✓ Aligned 70/70 features\n",
      "\n",
      "🔍 Score Consolidation Check:\n",
      "  Methods before consolidation: 70\n",
      "  Methods after consolidation: 25\n",
      "  Consolidation prevented potential double-counting of 45 method variants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 11:33:01,980 - INFO -   Assigned methods to 6045/28934 papers (20.9%)\n",
      "2025-08-28 11:33:01,991 - INFO - Step 7: Saving results and metadata...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Final Assignment Verification:\n",
      "  Papers assigned methods: 6045\n",
      "  Unique methods assigned: 25\n",
      "  Top assigned methods:\n",
      "    neural network: 814 papers (consolidated from: ['neural network used', 'neural network algorithm', 'neural network', 'bp neural network', 'neural network rnn', 'neural network anns'])\n",
      "    fault analysis: 666 papers (consolidated from: ['fault detection diagnosis', 'fault tree analysis', 'fault simulation', 'fault isolation'])\n",
      "    numerical simulation: 576 papers (consolidated from: ['analytical simulation', 'numerical simulation'])\n",
      "    linear programming: 524 papers (consolidated from: ['formulated mixed-integer linear', 'linear programming model', 'linear program'])\n",
      "    particle swarm optimization: 473 papers (consolidated from: ['particle swarm optimization algorithm', 'particle swarm optimization', 'binary particle swarm', 'improved particle swarm optimization'])\n",
      "    monte carlo simulation: 448 papers (consolidated from: ['based monte carlo simulation', 'carlo simulation result', 'monte carlo simulation'])\n",
      "    genetic algorithm: 423 papers (consolidated from: ['genetic algorithm ga', 'genetic algorithm', 'algorithm genetic algorithm'])\n",
      "    optimization: 314 papers (consolidated from: ['bi-level optimization', 'two-stage robust', 'chance constrained programming', 'global optimization'])\n",
      "    economic dispatch: 263 papers\n",
      "    time series: 251 papers (consolidated from: ['time series model', 'time series analysis', 'auto-regressive', 'autoregressive integrated'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-28 11:33:07,503 - INFO - ✓ Results saved:\n",
      "2025-08-28 11:33:07,503 - INFO -   Enhanced analysis: enhanced_method_analysis_2025_08_28_reliability_resilience_power_systems.csv\n",
      "2025-08-28 11:33:07,507 - INFO -   Method variant groups: method_variant_groups_2025_08_28_reliability_resilience_power_systems.json\n",
      "2025-08-28 11:33:07,508 - INFO -   Consolidated scores: consolidated_method_scores_2025_08_28_reliability_resilience_power_systems.csv\n",
      "2025-08-28 11:33:07,508 - INFO - Step 8: Running comprehensive diagnostics...\n",
      "2025-08-28 11:33:07,553 - INFO - Enhanced method detection pipeline with consolidation completed successfully!\n",
      "2025-08-28 11:33:07,553 - INFO - Credit usage: {'total_tokens': 1070, 'total_cost': 0.0002}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE METHOD DETECTION DIAGNOSTICS\n",
      "================================================================================\n",
      "\n",
      "📊 ASSIGNMENT OVERVIEW:\n",
      "  Total papers processed: 28,934\n",
      "  Papers with methods assigned: 6,045 (20.9%)\n",
      "  Papers without methods: 22,889 (79.1%)\n",
      "\n",
      "📈 SCORE DISTRIBUTION ANALYSIS:\n",
      "  Final score matrix shape: (28934, 25)\n",
      "  Total canonical methods: 25\n",
      "  Score range: [0.0000, 0.3000]\n",
      "  Mean score: 0.0031\n",
      "  Standard deviation: 0.0288\n",
      "  Scores > 0.001: 8,756 (1.21% of all scores)\n",
      "  Scores > 0.005: 8,756 (1.21% of all scores)\n",
      "  Scores > 0.01: 8,756 (1.21% of all scores)\n",
      "  Scores > 0.05: 8,756 (1.21% of all scores)\n",
      "  Scores > 0.1: 8,756 (1.21% of all scores)\n",
      "\n",
      "🔥 TOP ASSIGNED METHODS:\n",
      "   2. neural network: 814 papers (13.5%) (from 6 variants)\n",
      "   3. fault analysis: 666 papers (11.0%) (from 4 variants)\n",
      "   4. numerical simulation: 576 papers (9.5%) (from 2 variants)\n",
      "   5. linear programming: 524 papers (8.7%) (from 3 variants)\n",
      "   6. particle swarm optimization: 473 papers (7.8%) (from 4 variants)\n",
      "   7. monte carlo simulation: 448 papers (7.4%) (from 3 variants)\n",
      "   8. genetic algorithm: 423 papers (7.0%) (from 3 variants)\n",
      "   9. optimization: 314 papers (5.2%) (from 4 variants)\n",
      "  10. economic dispatch: 263 papers (4.4%)\n",
      "  11. time series: 251 papers (4.2%) (from 4 variants)\n",
      "  12. deep learning: 229 papers (3.8%) (from 4 variants)\n",
      "  13. probabilistic forecasting: 206 papers (3.4%) (from 4 variants)\n",
      "  14. stochastic simulation: 154 papers (2.5%) (from 3 variants)\n",
      "  15. reinforcement learning: 126 papers (2.1%) (from 3 variants)\n",
      "\n",
      "🎯 CONFIDENCE DISTRIBUTION:\n",
      "  Low: 22,889 (79.1%)\n",
      "  High: 6,045 (20.9%)\n",
      "\n",
      "🔧 CONSOLIDATION EFFECTIVENESS:\n",
      "  Total method variants processed: 71\n",
      "  Final canonical methods: 25\n",
      "  Groups with multiple variants: 22\n",
      "  Consolidation ratio: 2.84:1\n",
      "\n",
      "⚠️  QUALITY ASSESSMENT:\n",
      "  ⚠️  Low assignment rate (20.9%) - consider:\n",
      "      -  Lowering MIN_ASSIGN_SCORE (current: 0.02)\n",
      "      -  Reviewing method extraction quality\n",
      "      -  Checking text preprocessing effectiveness\n",
      "  ✅ Reasonable maximum scores (0.3000)\n",
      "  ✅ All methods have non-zero scores in at least some papers\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "SAMPLE RESULTS FOR VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "📄 SAMPLE PAPERS WITH METHODS ASSIGNED (first 10):\n",
      "           Primary_Method  Primary_Method_Score Method_Confidence  Total_Method_Score\n",
      "       linear programming                  0.21              High                0.21\n",
      "probabilistic forecasting                  0.21              High                0.21\n",
      "           fault analysis                  0.21              High                0.42\n",
      "probabilistic forecasting                  0.21              High                0.21\n",
      "              time series                  0.21              High                0.21\n",
      "     numerical simulation                  0.30              High                0.30\n",
      "           fault analysis                  0.21              High                0.42\n",
      "   monte carlo simulation                  0.30              High                0.51\n",
      "probabilistic forecasting                  0.21              High                0.21\n",
      "probabilistic forecasting                  0.21              High                0.21\n",
      "\n",
      "📊 METHOD ASSIGNMENT DISTRIBUTION:\n",
      "  Method_1 - 25 unique methods assigned to 6045 papers\n",
      "  Method_2 - 25 unique methods assigned to 1990 papers\n",
      "  Method_3 - 23 unique methods assigned to 544 papers\n",
      "\n",
      "❌ SAMPLE PAPERS WITHOUT METHODS (first 5 for diagnostic):\n",
      "  Paper 0: new electric locomotive pennsylvania railroad simplicity reliability keynote design new single-phase a-c electric locomotive pennsylvania railroad lat...\n",
      "  Paper 1: digital computer manchester university new universal high-speed digital computing machine working computing machine laboratory manchester university d...\n",
      "  Paper 2: reliability research coding circuitry abstract study indicated amplitude signal noise gaussian distribution threshold effect discounted always increas...\n",
      "  Paper 3: safeguarding mineral-dependent economy american economy built around manufacturing construction industry turn dependent mineral supply economy flouris...\n",
      "  Paper 4: engineering feature union oil-shale retort retorting shale requires operation combining good heat fuel economy low capital investment order meet deman...\n",
      "\n",
      "✅ Enhanced Method Detection Pipeline Completed Successfully!\n",
      "📁 All results saved to: Saved_files_new\n",
      "📊 Assignment Rate: 20.9%\n",
      "🔧 Methods Consolidated: 108 → 25\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# %%\n",
    "# Cell 10: Complete Enhanced Method Extraction and Assignment Workflow - REFACTORED\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION PARAMETERS - Adjust these for optimal method detection\n",
    "# =============================================================================\n",
    "MAX_FEATURES = 50000                    # Maximum features for candidate term extraction\n",
    "TFIDF_WEIGHT = 0.5                      # Weight for TF-IDF scoring in final combination\n",
    "LDA_WEIGHT = 0.2                        # Weight for LDA scoring in final combination  \n",
    "COMPOUND_WEIGHT = 0.3                   # Weight for compound scoring in final combination\n",
    "TOP_METHODS_PER_PAPER = 5               # Number of top methods to assign per paper\n",
    "MIN_ASSIGN_SCORE = 0.02                # Minimum score threshold for method assignment\n",
    "BATCH_SIZE = 2000                       # Batch size for LLM processing\n",
    "METHOD_LLM_N_RUNS = 3                   # Number of LLM runs for method extraction\n",
    "VARIANT_GROUP_BATCH_SIZE = 2000           # Batch size for method variant grouping\n",
    "\n",
    "logger.info(\"=== Starting Enhanced Method Detection Pipeline with Consolidation ===\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: LOAD OR EXTRACT METHOD PHRASES FROM CORPUS\n",
    "# =============================================================================\n",
    "logger.info(\"Step 1: Loading or extracting method phrases...\")\n",
    "\n",
    "# Try to load existing method phrases from previous runs\n",
    "try:\n",
    "    method_phrases, method_counts = load_method_phrases_from_csv(filename=\"extracted_method_phrases.csv\")\n",
    "except (FileNotFoundError, TypeError):\n",
    "    method_phrases, method_counts = None, None\n",
    "\n",
    "# If no existing phrases found or too few, extract new ones using LLM\n",
    "if (method_phrases is None) or (len(method_phrases) < 3):\n",
    "    logger.info(\"  1a: Extracting candidate terms from processed text...\")\n",
    "    \n",
    "    # Extract candidate n-grams (1-4 grams) from the corpus using CountVectorizer\n",
    "    candidate_terms = extract_candidate_terms(df, text_col='processed_text', max_features=MAX_FEATURES)\n",
    "    logger.info(f\"  ✓ Extracted {len(candidate_terms)} candidate terms\")\n",
    "    print(f\"  Sample candidate terms: {candidate_terms[:10]}\")\n",
    "    \n",
    "    logger.info(\"  1b: Using LLM to identify research methods from candidate terms...\")\n",
    "    \n",
    "    # Use LLM to intelligently identify research methods from candidate terms\n",
    "    # This filters out generic terms and focuses on actual research methodologies\n",
    "    method_phrases, method_counts = get_method_phrases_enhanced(\n",
    "        candidate_terms,\n",
    "        client,\n",
    "        model_type,\n",
    "        credit_tracker,\n",
    "        n_runs=METHOD_LLM_N_RUNS,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    # Save extracted phrases for future use\n",
    "    save_method_phrases_to_csv(method_phrases, method_counts)\n",
    "else:\n",
    "    logger.info(f\"  ✓ Loaded {len(method_phrases)} method phrases from existing CSV\")\n",
    "\n",
    "# Validate that method extraction was successful\n",
    "if not method_phrases:\n",
    "    logger.error(\"No method phrases extracted! Check your LLM configuration and prompts.\")\n",
    "    raise RuntimeError(\"Method extraction failed - no phrases found\")\n",
    "\n",
    "logger.info(f\"✓ Method phrase extraction complete: {len(method_phrases)} phrases\")\n",
    "print(f\"  Sample methods: {method_phrases[:10]}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: ENHANCED METHOD VARIANT CONSOLIDATION\n",
    "# =============================================================================\n",
    "logger.info(\"Step 2: Building enhanced method variant groups with consolidation...\")\n",
    "\n",
    "# Use enhanced LLM-based variant grouping to consolidate similar methods\n",
    "variant_groups = build_method_variant_groups_enhanced(\n",
    "    method_phrases, \n",
    "    client, \n",
    "    model_type, \n",
    "    credit_tracker, \n",
    "    batch_size=VARIANT_GROUP_BATCH_SIZE\n",
    ") if method_phrases else {}\n",
    "\n",
    "# Create fallback mapping if LLM-based grouping fails completely\n",
    "if not variant_groups and method_phrases:\n",
    "    logger.info(\"  LLM grouping failed completely - using enhanced aggressive fallback grouping...\")\n",
    "    variant_groups = aggressive_fallback_grouping(method_phrases, similarity_threshold=0.75)\n",
    "    logger.info(f\"  ✓ Aggressive fallback created {len(variant_groups)} groups from {len(method_phrases)} methods\")\n",
    "\n",
    "# Create bidirectional mappings for efficient lookup during scoring\n",
    "variant_to_canonical, canonical_to_variants = create_variant_mapping(variant_groups)\n",
    "logger.info(f\"✓ Created {len(canonical_to_variants)} canonical methods with {len(variant_to_canonical)} total variants\")\n",
    "\n",
    "\n",
    "# Display consolidation results\n",
    "print(f\"\\n📊 Method Consolidation Results:\")\n",
    "print(f\"  Original methods: {len(method_phrases) if method_phrases else 0}\")\n",
    "print(f\"  Consolidated methods: {len(canonical_to_variants)}\")\n",
    "reduction = len(method_phrases) - len(canonical_to_variants) if method_phrases else 0\n",
    "print(f\"  Reduction: {reduction} methods ({100*reduction/len(method_phrases):.1f}% reduction)\" if method_phrases and len(method_phrases) > 0 else \"\")\n",
    "\n",
    "print(\"\\nSample variant groups (showing groups with multiple variants):\")\n",
    "sample_count = 0\n",
    "for canonical, variants in canonical_to_variants.items():\n",
    "    if len(variants) > 1 and sample_count < 5:  # Only show groups with multiple variants\n",
    "        print(f\"  {canonical}: {variants}\")\n",
    "        sample_count += 1\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: COMPUTE MULTIPLE SCORING MATRICES FOR ROBUST METHOD DETECTION\n",
    "# =============================================================================\n",
    "logger.info(\"Step 3: Computing enhanced scoring matrices using multiple approaches...\")\n",
    "\n",
    "# Convert DataFrame text to list for processing\n",
    "processed_texts = df['processed_text'].fillna('').tolist()\n",
    "\n",
    "# 3a: TF-IDF Scoring - Captures term frequency and document importance\n",
    "logger.info(\"  3a: Computing TF-IDF scores for method variants...\")\n",
    "tfidf_scores, tfidf_feature_names = compute_enhanced_tfidf_scores(\n",
    "    processed_texts, canonical_to_variants\n",
    ")\n",
    "logger.info(f\"  ✓ TF-IDF: {tfidf_scores.shape} with {len(tfidf_feature_names)} features\")\n",
    "\n",
    "# 3b: LDA Scoring - Captures topic-based method associations\n",
    "logger.info(\"  3b: Computing LDA scores for method variants...\")  \n",
    "method_vocab = list(canonical_to_variants.keys())\n",
    "lda_scores, lda_feature_names = compute_enhanced_lda_scores(\n",
    "    processed_texts, canonical_to_variants, n_topics=len(method_vocab)\n",
    ")\n",
    "logger.info(f\"  ✓ LDA: {lda_scores.shape} with {len(lda_feature_names)} features\")\n",
    "\n",
    "# 3c: Compound Scoring - Captures exact phrase matches and partial matches\n",
    "logger.info(\"  3c: Computing compound scores for method variants...\")\n",
    "compound_scores, compound_feature_names = compute_enhanced_compound_scores(\n",
    "    df, canonical_to_variants\n",
    ")\n",
    "logger.info(f\"  ✓ Compound: {compound_scores.shape} with {len(compound_feature_names)} features\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 4: FEATURE ALIGNMENT AND HARMONIZATION\n",
    "# =============================================================================\n",
    "logger.info(\"Step 4: Aligning and harmonizing features across scoring methods...\")\n",
    "\n",
    "# Create union of all features to preserve maximum method coverage\n",
    "# This ensures we don't lose methods that appear in only one scoring approach\n",
    "all_features = set(tfidf_feature_names) | set(lda_feature_names) | set(compound_feature_names)\n",
    "all_features = sorted(list(all_features))  # Sort for consistency\n",
    "\n",
    "logger.info(f\"  Feature alignment statistics:\")\n",
    "logger.info(f\"    Total unique features: {len(all_features)}\")\n",
    "logger.info(f\"    TF-IDF features: {len(tfidf_feature_names)}\")\n",
    "logger.info(f\"    LDA features: {len(lda_feature_names)}\")  \n",
    "logger.info(f\"    Compound features: {len(compound_feature_names)}\")\n",
    "\n",
    "def align_scores_robust(scores, current_features, target_features):\n",
    "    \"\"\"\n",
    "    Enhanced alignment with dimension safety checks and detailed error handling.\n",
    "    \"\"\"\n",
    "    if not target_features:\n",
    "        return np.array([]).reshape(scores.shape[0], 0)\n",
    "    \n",
    "    # SAFETY CHECK: Verify dimensions match expectations\n",
    "    expected_cols = len(current_features)\n",
    "    actual_cols = scores.shape[1]\n",
    "    \n",
    "    if expected_cols != actual_cols:\n",
    "        print(f\"⚠️  DIMENSION MISMATCH DETECTED:\")\n",
    "        print(f\"    Expected columns: {expected_cols} (from feature names)\")\n",
    "        print(f\"    Actual columns: {actual_cols} (from score matrix)\")\n",
    "        print(f\"    Using actual matrix dimensions for safety\")\n",
    "        \n",
    "        # Use only the features that actually exist in the matrix\n",
    "        safe_current_features = current_features[:actual_cols]\n",
    "        print(f\"    Truncated feature list: {len(safe_current_features)} features\")\n",
    "    else:\n",
    "        safe_current_features = current_features\n",
    "    \n",
    "    # Initialize aligned matrix with zeros\n",
    "    aligned_scores = np.zeros((scores.shape[0], len(target_features)))\n",
    "    current_to_idx = {feat: i for i, feat in enumerate(safe_current_features)}\n",
    "    \n",
    "    # Map existing features to aligned positions with bounds checking\n",
    "    found_features = 0\n",
    "    skipped_features = 0\n",
    "    \n",
    "    for j, feat in enumerate(target_features):\n",
    "        if feat in current_to_idx:\n",
    "            source_idx = current_to_idx[feat]\n",
    "            \n",
    "            # BOUNDS CHECK: Ensure source index is valid\n",
    "            if source_idx < scores.shape[1]:\n",
    "                aligned_scores[:, j] = scores[:, source_idx]\n",
    "                found_features += 1\n",
    "            else:\n",
    "                print(f\"⚠️  Skipping feature '{feat}': index {source_idx} >= {scores.shape[1]}\")\n",
    "                skipped_features += 1\n",
    "    \n",
    "    print(f\"    ✓ Aligned {found_features}/{len(target_features)} features\")\n",
    "    if skipped_features > 0:\n",
    "        print(f\"    ⚠️  Skipped {skipped_features} features due to bounds issues\")\n",
    "    \n",
    "    return aligned_scores\n",
    "\n",
    "\n",
    "# Align all scoring matrices to the unified feature space\n",
    "tfidf_aligned = align_scores_robust(tfidf_scores, tfidf_feature_names, all_features)\n",
    "lda_aligned = align_scores_robust(lda_scores, lda_feature_names, all_features)\n",
    "compound_aligned = align_scores_robust(compound_scores, compound_feature_names, all_features)\n",
    "\n",
    "logger.info(f\"✓ Feature alignment complete: {tfidf_aligned.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 5: SCORE NORMALIZATION AND CONSOLIDATION\n",
    "# =============================================================================\n",
    "logger.info(\"Step 5: Normalizing scores and applying variant consolidation...\")\n",
    "\n",
    "def normalize_scores(scores):\n",
    "    \"\"\"Normalize scores to  range per matrix for fair weighting.\"\"\"[1]\n",
    "    if scores.max() == 0:\n",
    "        return scores\n",
    "    return scores / scores.max()\n",
    "\n",
    "# Normalize each scoring matrix to ensure fair contribution to final scores\n",
    "tfidf_normalized = normalize_scores(tfidf_aligned)\n",
    "lda_normalized = normalize_scores(lda_aligned)\n",
    "compound_normalized = normalize_scores(compound_aligned)\n",
    "\n",
    "# Combine normalized scores using weighted average\n",
    "combined_scores = (\n",
    "    TFIDF_WEIGHT * tfidf_normalized + \n",
    "    LDA_WEIGHT * lda_normalized + \n",
    "    COMPOUND_WEIGHT * compound_normalized\n",
    ")\n",
    "\n",
    "logger.info(f\"✓ Score combination complete: {combined_scores.shape}\")\n",
    "logger.info(f\"  Combined score range: [{combined_scores.min():.4f}, {combined_scores.max():.4f}]\")\n",
    "\n",
    "# Apply variant consolidation to prevent double-counting\n",
    "if variant_to_canonical:\n",
    "    logger.info(\"  Applying variant score consolidation to prevent double-counting...\")\n",
    "    \n",
    "    # Consolidate variant scores using maximum (not sum) to avoid inflating scores\n",
    "    final_scores, canonical_methods = consolidate_variant_scores(\n",
    "        combined_scores, all_features, variant_to_canonical\n",
    "    )\n",
    "    logger.info(f\"  ✓ Consolidated {len(all_features)} methods to {len(canonical_methods)} canonical methods\")\n",
    "    \n",
    "    # Display consolidation statistics\n",
    "    print(f\"\\n🔍 Score Consolidation Check:\")\n",
    "    print(f\"  Methods before consolidation: {len(all_features)}\")\n",
    "    print(f\"  Methods after consolidation: {len(canonical_methods)}\")\n",
    "    print(f\"  Consolidation prevented potential double-counting of {len(all_features) - len(canonical_methods)} method variants\")\n",
    "    \n",
    "else:\n",
    "    # No consolidation needed - use combined scores as-is\n",
    "    final_scores = combined_scores\n",
    "    canonical_methods = all_features\n",
    "    logger.info(\"  No variant consolidation applied (no variant mappings found)\")\n",
    "\n",
    "logger.info(f\"✓ Final consolidated scores: {final_scores.shape}\")\n",
    "logger.info(f\"  Final score range: [{final_scores.min():.4f}, {final_scores.max():.4f}]\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 6: METHOD ASSIGNMENT TO PAPERS\n",
    "# =============================================================================\n",
    "logger.info(\"Step 6: Assigning methods to papers using consolidated scores...\")\n",
    "\n",
    "# Assign top methods to each paper using the consolidated scores\n",
    "# This creates columns Method_1, Method_2, etc. plus Primary_Method\n",
    "df = assign_methods_improved(\n",
    "    df, final_scores, canonical_methods, \n",
    "    top_n=TOP_METHODS_PER_PAPER, \n",
    "    min_score=MIN_ASSIGN_SCORE\n",
    ")\n",
    "\n",
    "# Additional diagnostic: Verify no double-counting occurred\n",
    "assigned_methods = df[df['Primary_Method'] != '']['Primary_Method'].tolist()\n",
    "method_assignment_counts = pd.Series(assigned_methods).value_counts()\n",
    "\n",
    "print(f\"\\n🔍 Final Assignment Verification:\")\n",
    "print(f\"  Papers assigned methods: {len(assigned_methods)}\")\n",
    "print(f\"  Unique methods assigned: {len(method_assignment_counts)}\")\n",
    "print(f\"  Top assigned methods:\")\n",
    "\n",
    "for method, count in method_assignment_counts.head(10).items():\n",
    "    # Check if this method has variants that were consolidated\n",
    "    variants = canonical_to_variants.get(method, [method])\n",
    "    if len(variants) > 1:\n",
    "        print(f\"    {method}: {count} papers (consolidated from: {variants})\")\n",
    "    else:\n",
    "        print(f\"    {method}: {count} papers\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 7: SAVE RESULTS AND METADATA\n",
    "# =============================================================================\n",
    "logger.info(\"Step 7: Saving results and metadata...\")\n",
    "\n",
    "# Save method variant mappings for future reference and transparency\n",
    "with open(os.path.join(SAVE_DIR, f\"method_variant_groups_{suffix_string}.json\"), 'w') as f:\n",
    "    json.dump(canonical_to_variants, f, indent=2)\n",
    "\n",
    "# Save consolidated score matrix for analysis and debugging\n",
    "pd.DataFrame(final_scores, columns=canonical_methods).to_csv(\n",
    "    os.path.join(SAVE_DIR, f\"consolidated_method_scores_{suffix_string}.csv\")\n",
    ")\n",
    "\n",
    "# Save final enhanced dataframe with method assignments\n",
    "enhanced_analysis_filename = f\"enhanced_method_analysis_{suffix_string}.csv\"\n",
    "df.to_csv(os.path.join(SAVE_DIR, enhanced_analysis_filename), index=False)\n",
    "\n",
    "logger.info(f\"✓ Results saved:\")\n",
    "logger.info(f\"  Enhanced analysis: {enhanced_analysis_filename}\")\n",
    "logger.info(f\"  Method variant groups: method_variant_groups_{suffix_string}.json\")\n",
    "logger.info(f\"  Consolidated scores: consolidated_method_scores_{suffix_string}.csv\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 8: COMPREHENSIVE DIAGNOSTICS AND QUALITY ASSESSMENT\n",
    "# =============================================================================\n",
    "logger.info(\"Step 8: Running comprehensive diagnostics...\")\n",
    "\n",
    "def enhanced_method_diagnostics(df, scores, method_names, variant_groups):\n",
    "    \"\"\"\n",
    "    Comprehensive diagnostics for method assignment quality and consolidation effectiveness.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPREHENSIVE METHOD DETECTION DIAGNOSTICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Basic assignment statistics\n",
    "    n_papers = len(df)\n",
    "    assigned_papers = (df['Primary_Method'] != '').sum()\n",
    "    assignment_rate = 100 * assigned_papers / n_papers\n",
    "    \n",
    "    print(f\"\\n📊 ASSIGNMENT OVERVIEW:\")\n",
    "    print(f\"  Total papers processed: {n_papers:,}\")\n",
    "    print(f\"  Papers with methods assigned: {assigned_papers:,} ({assignment_rate:.1f}%)\")\n",
    "    print(f\"  Papers without methods: {n_papers - assigned_papers:,} ({100-assignment_rate:.1f}%)\")\n",
    "    \n",
    "    # Score distribution analysis\n",
    "    print(f\"\\n📈 SCORE DISTRIBUTION ANALYSIS:\")\n",
    "    print(f\"  Final score matrix shape: {scores.shape}\")\n",
    "    print(f\"  Total canonical methods: {len(method_names)}\")\n",
    "    print(f\"  Score range: [{scores.min():.4f}, {scores.max():.4f}]\")\n",
    "    print(f\"  Mean score: {scores.mean():.4f}\")\n",
    "    print(f\"  Standard deviation: {scores.std():.4f}\")\n",
    "    \n",
    "    # Score threshold analysis\n",
    "    thresholds = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "    for threshold in thresholds:\n",
    "        count = (scores > threshold).sum()\n",
    "        print(f\"  Scores > {threshold}: {count:,} ({100*count/scores.size:.2f}% of all scores)\")\n",
    "    \n",
    "    # Method popularity and assignment quality\n",
    "    if assigned_papers > 0:\n",
    "        print(f\"\\n🔥 TOP ASSIGNED METHODS:\")\n",
    "        method_counts = df['Primary_Method'].value_counts()\n",
    "        \n",
    "        for i, (method, count) in enumerate(method_counts.head(15).items()):\n",
    "            if method:  # Skip empty strings\n",
    "                percentage = 100 * count / assigned_papers\n",
    "                # Check if method was consolidated from variants\n",
    "                variants = variant_groups.get(method, [method])\n",
    "                variant_info = f\" (from {len(variants)} variants)\" if len(variants) > 1 else \"\"\n",
    "                print(f\"  {i+1:2d}. {method}: {count:,} papers ({percentage:.1f}%){variant_info}\")\n",
    "    \n",
    "    # Confidence distribution analysis\n",
    "    if 'Method_Confidence' in df.columns:\n",
    "        print(f\"\\n🎯 CONFIDENCE DISTRIBUTION:\")\n",
    "        conf_counts = df['Method_Confidence'].value_counts()\n",
    "        for conf, count in conf_counts.items():\n",
    "            percentage = 100 * count / n_papers\n",
    "            print(f\"  {conf}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Consolidation effectiveness analysis\n",
    "    print(f\"\\n🔧 CONSOLIDATION EFFECTIVENESS:\")\n",
    "    total_variants = sum(len(variants) for variants in variant_groups.values())\n",
    "    consolidated_groups = len([v for v in variant_groups.values() if len(v) > 1])\n",
    "    \n",
    "    print(f\"  Total method variants processed: {total_variants:,}\")\n",
    "    print(f\"  Final canonical methods: {len(variant_groups):,}\")\n",
    "    print(f\"  Groups with multiple variants: {consolidated_groups:,}\")\n",
    "    print(f\"  Consolidation ratio: {total_variants/len(variant_groups):.2f}:1\")\n",
    "    \n",
    "    # Quality assessment and recommendations\n",
    "    print(f\"\\n⚠️  QUALITY ASSESSMENT:\")\n",
    "    \n",
    "    if assignment_rate < 50:\n",
    "        print(f\"  ⚠️  Low assignment rate ({assignment_rate:.1f}%) - consider:\")\n",
    "        print(f\"      -  Lowering MIN_ASSIGN_SCORE (current: {MIN_ASSIGN_SCORE})\")\n",
    "        print(f\"      -  Reviewing method extraction quality\")\n",
    "        print(f\"      -  Checking text preprocessing effectiveness\")\n",
    "    else:\n",
    "        print(f\"  ✅ Good assignment rate ({assignment_rate:.1f}%)\")\n",
    "    \n",
    "    if scores.max() < 0.1:\n",
    "        print(f\"  ⚠️  Low maximum scores ({scores.max():.4f}) - scoring method may need adjustment\")\n",
    "    else:\n",
    "        print(f\"  ✅ Reasonable maximum scores ({scores.max():.4f})\")\n",
    "    \n",
    "    zero_score_methods = (scores.max(axis=0) == 0).sum()\n",
    "    if zero_score_methods > 0:\n",
    "        zero_percentage = 100 * zero_score_methods / len(method_names)\n",
    "        print(f\"  ⚠️  {zero_score_methods} methods ({zero_percentage:.1f}%) have zero scores across all papers\")\n",
    "        print(f\"      Consider reviewing method extraction or scoring parameters\")\n",
    "    else:\n",
    "        print(f\"  ✅ All methods have non-zero scores in at least some papers\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    return {\n",
    "        'assignment_rate': assignment_rate,\n",
    "        'total_papers': n_papers,\n",
    "        'assigned_papers': assigned_papers,\n",
    "        'score_stats': {\n",
    "            'min': scores.min(),\n",
    "            'max': scores.max(),\n",
    "            'mean': scores.mean(),\n",
    "            'std': scores.std()\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Run comprehensive diagnostics\n",
    "diagnostic_results = enhanced_method_diagnostics(df, final_scores, canonical_methods, canonical_to_variants)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 9: DISPLAY SAMPLE RESULTS FOR VERIFICATION\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE RESULTS FOR VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define columns to display in sample results\n",
    "sample_cols = ['Primary_Method', 'Primary_Method_Score', 'Method_Confidence', 'Total_Method_Score']\n",
    "available_cols = [col for col in sample_cols if col in df.columns]\n",
    "\n",
    "# Show sample of papers WITH methods assigned\n",
    "assigned_mask = df['Primary_Method'] != ''\n",
    "if assigned_mask.sum() > 0:\n",
    "    print(f\"\\n📄 SAMPLE PAPERS WITH METHODS ASSIGNED (first 10):\")\n",
    "    sample_assigned = df[assigned_mask][available_cols].head(10)\n",
    "    print(sample_assigned.to_string(index=False))\n",
    "    \n",
    "    # Show distribution of assigned methods\n",
    "    print(f\"\\n📊 METHOD ASSIGNMENT DISTRIBUTION:\")\n",
    "    for i in range(1, min(4, TOP_METHODS_PER_PAPER + 1)):  # Show top 3 method columns\n",
    "        col_name = f'Method_{i}'\n",
    "        if col_name in df.columns:\n",
    "            non_empty = df[df[col_name] != ''][col_name].value_counts()\n",
    "            print(f\"  {col_name} - {len(non_empty)} unique methods assigned to {non_empty.sum()} papers\")\n",
    "\n",
    "# Show sample of papers WITHOUT methods for diagnostic purposes\n",
    "unassigned_mask = df['Primary_Method'] == ''\n",
    "if unassigned_mask.sum() > 0:\n",
    "    print(f\"\\n❌ SAMPLE PAPERS WITHOUT METHODS (first 5 for diagnostic):\")\n",
    "    unassigned_sample = df[unassigned_mask].head(5)\n",
    "    \n",
    "    if 'processed_text' in df.columns:\n",
    "        for idx, row in unassigned_sample.iterrows():\n",
    "            text_preview = row.get('processed_text', '')[:150] + \"...\" if len(str(row.get('processed_text', ''))) > 150 else row.get('processed_text', '')\n",
    "            print(f\"  Paper {idx}: {text_preview}\")\n",
    "\n",
    "# Final completion message\n",
    "print(f\"\\n✅ Enhanced Method Detection Pipeline Completed Successfully!\")\n",
    "print(f\"📁 All results saved to: {SAVE_DIR}\")\n",
    "print(f\"📊 Assignment Rate: {diagnostic_results['assignment_rate']:.1f}%\")\n",
    "print(f\"🔧 Methods Consolidated: {len(method_phrases) if method_phrases else 0} → {len(canonical_methods)}\")\n",
    "\n",
    "logger.info(\"Enhanced method detection pipeline with consolidation completed successfully!\")\n",
    "logger.info(f\"Credit usage: {credit_tracker.get_stats()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94e9db32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🔍 METHOD CONSOLIDATION VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "📊 COUNTS:\n",
      "  Original methods: 108\n",
      "  Canonical groups: 67\n",
      "  Assigned methods: 67\n",
      "\n",
      "✅ SUCCESS: All assigned methods are canonical groups\n",
      "\n",
      "✅ SUCCESS: No redundant methods in assignments\n",
      "\n",
      "🔍 CONSOLIDATION EXAMPLES:\n",
      "  'genetic algorithm' consolidated: ['genetic algorithm', 'algorithm genetic algorithm']\n",
      "\n",
      "📈 TOP ASSIGNED METHODS (canonical):\n",
      "   1. fault simulation: 502 papers\n",
      "   2. neural network: 491 papers\n",
      "   3. genetic algorithm: 436 papers (from 2 variants)\n",
      "   4. linear program: 395 papers\n",
      "   5. numerical simulation: 369 papers\n",
      "   6. particle swarm optimization: 368 papers\n",
      "   7. monte carlo simulation: 329 papers\n",
      "   8. deep learning: 321 papers\n",
      "   9. economic dispatch ed: 277 papers\n",
      "  10. system transient stability: 228 papers\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def verify_method_consolidation(df, canonical_to_variants, original_method_list):\n",
    "    \"\"\"\n",
    "    Comprehensive verification that consolidation worked properly.\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"🔍 METHOD CONSOLIDATION VERIFICATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Extract assigned methods from DataFrame\n",
    "    assigned_methods = set(df[df['Primary_Method'] != '']['Primary_Method'].unique())\n",
    "    \n",
    "    # Extract canonical methods from groups\n",
    "    canonical_methods = set(canonical_to_variants.keys()) \n",
    "    \n",
    "    # Extract all original methods (for comparison)\n",
    "    original_methods = set(original_method_list)\n",
    "    \n",
    "    print(f\"\\n📊 COUNTS:\")\n",
    "    print(f\"  Original methods: {len(original_methods)}\")\n",
    "    print(f\"  Canonical groups: {len(canonical_methods)}\")\n",
    "    print(f\"  Assigned methods: {len(assigned_methods)}\")\n",
    "    \n",
    "    # Check 1: Are assigned methods from canonical set?\n",
    "    non_canonical_assigned = assigned_methods - canonical_methods\n",
    "    if non_canonical_assigned:\n",
    "        print(f\"\\n❌ PROBLEM: {len(non_canonical_assigned)} assigned methods are NOT canonical:\")\n",
    "        for method in list(non_canonical_assigned)[:10]:\n",
    "            print(f\"    '{method}'\")\n",
    "    else:\n",
    "        print(f\"\\n✅ SUCCESS: All assigned methods are canonical groups\")\n",
    "    \n",
    "    # Check 2: Are any original redundant methods still assigned?\n",
    "    all_variants = set()\n",
    "    for variants in canonical_to_variants.values():\n",
    "        all_variants.update(variants)\n",
    "    \n",
    "    redundant_assigned = assigned_methods & (original_methods - canonical_methods)\n",
    "    if redundant_assigned:\n",
    "        print(f\"\\n❌ PROBLEM: {len(redundant_assigned)} redundant methods still assigned:\")\n",
    "        for method in list(redundant_assigned)[:10]:\n",
    "            print(f\"    '{method}' (should be consolidated)\")\n",
    "    else:\n",
    "        print(f\"\\n✅ SUCCESS: No redundant methods in assignments\")\n",
    "    \n",
    "    # Check 3: Show consolidation examples\n",
    "    print(f\"\\n🔍 CONSOLIDATION EXAMPLES:\")\n",
    "    consolidation_examples = 0\n",
    "    for canonical, variants in canonical_to_variants.items():\n",
    "        if len(variants) > 1 and canonical in assigned_methods:\n",
    "            print(f\"  '{canonical}' consolidated: {variants}\")\n",
    "            consolidation_examples += 1\n",
    "            if consolidation_examples >= 5:\n",
    "                break\n",
    "    \n",
    "    # Check 4: Show assignment distribution\n",
    "    print(f\"\\n📈 TOP ASSIGNED METHODS (canonical):\")\n",
    "    method_counts = df[df['Primary_Method'] != '']['Primary_Method'].value_counts()\n",
    "    for i, (method, count) in enumerate(method_counts.head(10).items()):\n",
    "        variants = canonical_to_variants.get(method, [method])\n",
    "        variant_info = f\" (from {len(variants)} variants)\" if len(variants) > 1 else \"\"\n",
    "        print(f\"  {i+1:2d}. {method}: {count} papers{variant_info}\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    return len(non_canonical_assigned) == 0 and len(redundant_assigned) == 0\n",
    "\n",
    "# Run verification\n",
    "verification_passed = verify_method_consolidation(df, canonical_to_variants, method_phrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbbd873c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 SPOT CHECK: Sample Paper Method Assignments\n",
      "------------------------------------------------------------\n",
      "\n",
      "Paper 17:\n",
      "  Assigned Method: 'linear program'\n",
      "  Score: 0.21325202894404652\n",
      "  Variants in Group: ['linear program']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 57:\n",
      "  Assigned Method: 'probabilistic reliability evaluation'\n",
      "  Score: 0.21325202894404652\n",
      "  Variants in Group: ['probabilistic reliability evaluation']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 101:\n",
      "  Assigned Method: 'fault simulation'\n",
      "  Score: 0.21325202894404652\n",
      "  Variants in Group: ['fault simulation']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 127:\n",
      "  Assigned Method: 'probabilistic forecasting'\n",
      "  Score: 0.21325202894404652\n",
      "  Variants in Group: ['probabilistic forecasting']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 153:\n",
      "  Assigned Method: 'time series analysis'\n",
      "  Score: 0.21325202894404652\n",
      "  Variants in Group: ['time series analysis']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 185:\n",
      "  Assigned Method: 'numerical simulation'\n",
      "  Score: 0.8016260162601625\n",
      "  Variants in Group: ['numerical simulation']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 186:\n",
      "  Assigned Method: 'fault simulation'\n",
      "  Score: 0.21325202894404652\n",
      "  Variants in Group: ['fault simulation']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 187:\n",
      "  Assigned Method: 'monte carlo simulation'\n",
      "  Score: 0.8016260162601625\n",
      "  Variants in Group: ['monte carlo simulation']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 199:\n",
      "  Assigned Method: 'probabilistic reliability evaluation'\n",
      "  Score: 0.21325202894404652\n",
      "  Variants in Group: ['probabilistic reliability evaluation']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n",
      "\n",
      "Paper 218:\n",
      "  Assigned Method: 'probabilistic reliability evaluation'\n",
      "  Score: 0.21325202894404652\n",
      "  Variants in Group: ['probabilistic reliability evaluation']\n",
      "  Group Size: 1 methods\n",
      "  ℹ️  INDIVIDUAL: No variants to consolidate\n"
     ]
    }
   ],
   "source": [
    "def spot_check_paper_assignments(df, canonical_to_variants, n_samples=10):\n",
    "    \"\"\"\n",
    "    Show sample paper assignments with their consolidated method info.\n",
    "    \"\"\"\n",
    "    print(\"🔍 SPOT CHECK: Sample Paper Method Assignments\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Get papers with assigned methods\n",
    "    assigned_papers = df[df['Primary_Method'] != ''].head(n_samples)\n",
    "    \n",
    "    for idx, row in assigned_papers.iterrows():\n",
    "        primary_method = row['Primary_Method']\n",
    "        score = row.get('Primary_Method_Score', 'N/A')\n",
    "        \n",
    "        # Check if this method has variants\n",
    "        variants = canonical_to_variants.get(primary_method, [primary_method])\n",
    "        \n",
    "        print(f\"\\nPaper {idx}:\")\n",
    "        print(f\"  Assigned Method: '{primary_method}'\")\n",
    "        print(f\"  Score: {score}\")\n",
    "        print(f\"  Variants in Group: {variants}\")\n",
    "        print(f\"  Group Size: {len(variants)} methods\")\n",
    "        \n",
    "        # Show if consolidation occurred\n",
    "        if len(variants) > 1:\n",
    "            print(f\"  ✅ CONSOLIDATED: {len(variants)-1} variants merged\")\n",
    "        else:\n",
    "            print(f\"  ℹ️  INDIVIDUAL: No variants to consolidate\")\n",
    "\n",
    "# Run spot check\n",
    "spot_check_paper_assignments(df, canonical_to_variants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "145252da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 SCORE MATRIX VERIFICATION\n",
      "----------------------------------------\n",
      "Score matrix shape: (28934, 67)\n",
      "Canonical methods count: 67\n",
      "✅ Score matrix columns match canonical method count\n",
      "\n",
      "First 10 canonical methods in score matrix:\n",
      "   0. random forest algorithm\n",
      "   1. dnn inference\n",
      "   2. fuzzy c-means\n",
      "   3. neural network used\n",
      "   4. formulated mixed-integer\n",
      "   5. linear programming model\n",
      "   6. improved particle swarm optimization\n",
      "   7. mixed-integer nonlinear\n",
      "   8. multi-objective optimization problem\n",
      "   9. sequential monte carlo\n"
     ]
    }
   ],
   "source": [
    "def verify_score_matrix_methods(canonical_methods, final_scores):\n",
    "    \"\"\"\n",
    "    Check that the final score matrix columns correspond to canonical methods.\n",
    "    \"\"\"\n",
    "    print(\"🔍 SCORE MATRIX VERIFICATION\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    print(f\"Score matrix shape: {final_scores.shape}\")\n",
    "    print(f\"Canonical methods count: {len(canonical_methods)}\")\n",
    "    \n",
    "    if final_scores.shape[1] == len(canonical_methods):\n",
    "        print(\"✅ Score matrix columns match canonical method count\")\n",
    "    else:\n",
    "        print(\"❌ Dimension mismatch between scores and canonical methods\")\n",
    "    \n",
    "    print(f\"\\nFirst 10 canonical methods in score matrix:\")\n",
    "    for i, method in enumerate(canonical_methods[:10]):\n",
    "        print(f\"  {i:2d}. {method}\")\n",
    "\n",
    "# Run verification  \n",
    "verify_score_matrix_methods(canonical_methods, final_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0ad7acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 BEFORE/AFTER CONSOLIDATION COMPARISON\n",
      "================================================================================\n",
      "BEFORE: 108 original methods\n",
      "AFTER:  67 canonical groups\n",
      "REDUCTION: 41 methods (38.0%)\n",
      "\n",
      "📋 CONSOLIDATION EXAMPLES:\n",
      "\n",
      "  GROUP: 'genetic algorithm'\n",
      "    Consolidated: ['genetic algorithm', 'algorithm genetic algorithm']\n",
      "\n",
      "📊 SUMMARY:\n",
      "  Groups with multiple variants: 1\n",
      "  Single-method groups: 66\n"
     ]
    }
   ],
   "source": [
    "def show_before_after_comparison(original_methods, canonical_to_variants):\n",
    "    \"\"\"\n",
    "    Show before/after consolidation comparison.\n",
    "    \"\"\"\n",
    "    print(\"🔄 BEFORE/AFTER CONSOLIDATION COMPARISON\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"BEFORE: {len(original_methods)} original methods\")\n",
    "    print(f\"AFTER:  {len(canonical_to_variants)} canonical groups\")\n",
    "    reduction = len(original_methods) - len(canonical_to_variants)\n",
    "    reduction_pct = 100 * reduction / len(original_methods)\n",
    "    print(f\"REDUCTION: {reduction} methods ({reduction_pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n📋 CONSOLIDATION EXAMPLES:\")\n",
    "    consolidation_count = 0\n",
    "    for canonical, variants in canonical_to_variants.items():\n",
    "        if len(variants) > 1:\n",
    "            print(f\"\\n  GROUP: '{canonical}'\")\n",
    "            print(f\"    Consolidated: {variants}\")\n",
    "            consolidation_count += 1\n",
    "            if consolidation_count >= 8:\n",
    "                break\n",
    "    \n",
    "    print(f\"\\n📊 SUMMARY:\")\n",
    "    multi_variant_groups = sum(1 for v in canonical_to_variants.values() if len(v) > 1)\n",
    "    print(f\"  Groups with multiple variants: {multi_variant_groups}\")\n",
    "    print(f\"  Single-method groups: {len(canonical_to_variants) - multi_variant_groups}\")\n",
    "\n",
    "# Run comparison\n",
    "show_before_after_comparison(method_phrases, canonical_to_variants)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b7de75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genetic algorithm\n",
      "artificial intelligence\n",
      "particle swarm optimization\n",
      "deep learning\n",
      "neural network\n",
      "machine learning\n",
      "monte carlo simulation\n",
      "genetic algorithm ga\n",
      "opf\n",
      "model predictive control\n",
      "kalman filter\n",
      "milp\n",
      "particle swarm optimization algorithm\n",
      "deep reinforcement learning\n",
      "random forest\n",
      "support vector machine\n",
      "sequential monte carlo\n",
      "convolutional neural network\n",
      "multi-objective optimization problem\n",
      "logistic regression\n",
      "fault tree analysis\n",
      "reinforcement learning-based\n",
      "extended kalman\n",
      "bp neural network\n",
      "improved particle swarm optimization\n",
      "linear program\n",
      "linear programming model\n",
      "abc algorithm\n",
      "binary particle swarm\n",
      "cuckoo search\n",
      "k-means clustering\n",
      "two-stage robust\n",
      "stochastic optimization model\n",
      "ensemble learning\n",
      "adaptive algorithm\n",
      "using finite element\n",
      "evolution algorithm\n",
      "ac optimal power flow\n",
      "bi-level optimization\n",
      "mixed-integer nonlinear\n",
      "time series model\n",
      "back propagation\n",
      "formulated mixed-integer\n",
      "principal component analysis pca\n",
      "reinforcement learning rl\n",
      "sequential simulation\n",
      "arima\n",
      "fault isolation\n",
      "fuzzy logic-based\n",
      "neural network algorithm\n",
      "fault detection diagnosis\n",
      "probabilistic production simulation\n",
      "graph neural network\n",
      "unit commitment model\n",
      "unit commitment problem\n",
      "probabilistic risk assessment\n",
      "stochastic unit commitment\n",
      "gravitational search algorithm\n",
      "stochastic simulation\n",
      "probabilistic reliability evaluation\n",
      "based monte carlo simulation\n",
      "swarm optimization pso technique\n",
      "time series analysis\n",
      "neural network anns\n",
      "random forest rf\n",
      "based deep reinforcement learning\n",
      "load flow study\n",
      "neural network used\n",
      "global optimization\n",
      "grey wolf optimizer\n",
      "graph-based\n",
      "system transient stability\n",
      "fuzzy neural network\n",
      "markov state\n",
      "numerical simulation\n",
      "probabilistic forecasting\n",
      "linear regression model\n",
      "bee colony abc\n",
      "fault simulation\n",
      "fuzzy c-means\n",
      "neural network rnn\n",
      "analytical simulation\n",
      "random forest algorithm\n",
      "grey wolf optimization gwo\n",
      "optimal transmission switching\n",
      "artificial bee colony abc\n",
      "nonlinear programming\n",
      "hidden markov\n",
      "chance constrained programming\n",
      "poisson point process\n",
      "integer linear programming problem\n",
      "gaussian mixture\n",
      "data envelopment analysis\n",
      "carlo simulation result\n",
      "autoregressive integrated\n",
      "dnn model\n",
      "grasshopper optimization algorithm\n",
      "auto-regressive\n",
      "back propagation neural network\n",
      "karush-kuhn-tucker kkt\n",
      "adaptive genetic algorithm\n",
      "algorithm genetic algorithm\n",
      "annealing sa\n",
      "formulated mixed-integer linear\n",
      "basis function neural network\n",
      "decision tree algorithm\n",
      "economic dispatch ed\n",
      "dnn inference\n"
     ]
    }
   ],
   "source": [
    "for n in method_phrases:\n",
    "    print(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "literature-search-and-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
