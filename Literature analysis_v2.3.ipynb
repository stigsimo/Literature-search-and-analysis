{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9d9c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Imports and Setup\n",
    "# %%\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import configparser\n",
    "import tiktoken\n",
    "import logging\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Phrases\n",
    "import openai\n",
    "import random\n",
    "from difflib import SequenceMatcher\n",
    "import joblib\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "SAVE_DIR = \"Saved_files_new\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1186794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenAI Setup and Credit Tracking\n",
    "# %%\n",
    "class CreditTracker:\n",
    "    def __init__(self):\n",
    "        self.total_tokens = 0\n",
    "        self.total_cost = 0\n",
    "        self.cost_per_1k_tokens = 0.00015\n",
    "    \n",
    "    def update(self, tokens):\n",
    "        self.total_tokens += tokens\n",
    "        self.total_cost += (tokens / 1000) * self.cost_per_1k_tokens\n",
    "    \n",
    "    def get_stats(self):\n",
    "        return {\"total_tokens\": self.total_tokens, \"total_cost\": round(self.total_cost, 4)}\n",
    "\n",
    "def initialize_openai():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config_LLM.txt')\n",
    "    api_key = config['LLM'].get('OPENAI_API_KEY')\n",
    "    model_type = config['LLM'].get('MODEL_TYPE')\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    return client, model_type\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    return len(encoding.encode(string))\n",
    "\n",
    "client, model_type = initialize_openai()\n",
    "credit_tracker = CreditTracker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "199ea517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility Functions\n",
    "# %%\n",
    "def extract_keywords_from_filename(filename):\n",
    "    base = os.path.splitext(os.path.basename(filename))[0]\n",
    "    parts = base.split('_')\n",
    "    keywords = []\n",
    "    for i, part in enumerate(parts):\n",
    "        if i > 2 and part != 'results':\n",
    "            keywords.append(part)\n",
    "    keywords = [kw for kw in keywords if not kw.isdigit()]\n",
    "    return keywords\n",
    "\n",
    "def keywords_to_filename_part(keywords):\n",
    "    return '_'.join([kw.lower().replace(' ', '_') for kw in keywords])\n",
    "\n",
    "def get_custom_stop_words(search_keywords=None):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words_to_keep = set()\n",
    "    if search_keywords:\n",
    "        for keyword in search_keywords:\n",
    "            keyword = keyword.lower()\n",
    "            words_to_keep.add(keyword)\n",
    "            for word in keyword.split():\n",
    "                words_to_keep.add(word)\n",
    "    stop_words = stop_words - words_to_keep\n",
    "    scientific_terms = {'et', 'al','ref','reference','references','cited','cite',\n",
    "        'fig','figure','figures','table','tables','chart','charts',\n",
    "        'published','journal','conference','proceedings','vol','volume','pp','page','pages','doi'}\n",
    "    return stop_words.union(scientific_terms)\n",
    "\n",
    "def string_similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b97c341",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Text Processing Functions\n",
    "# %%\n",
    "def preprocess_text(text, search_keywords, min_word_length=2, remove_numbers=False):\n",
    "    if not isinstance(text, (str, int, float)):\n",
    "        return ''\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    if remove_numbers:\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "    text = re.sub(r'--+', ' ', text)\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) >= min_word_length]\n",
    "    \n",
    "    stop_words = get_custom_stop_words(search_keywords)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    tokens = [token for token in tokens if len(token) > 1 and not token.isdigit()]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def get_wordnet_pos(word):\n",
    "        tag = nltk.pos_tag([word])[0][1].upper()\n",
    "        tag_dict = {\"J\": nltk.corpus.wordnet.ADJ,\n",
    "                   \"N\": nltk.corpus.wordnet.NOUN,\n",
    "                   \"V\": nltk.corpus.wordnet.VERB,\n",
    "                   \"R\": nltk.corpus.wordnet.ADV}\n",
    "        return tag_dict.get(tag, nltk.corpus.wordnet.NOUN)\n",
    "    \n",
    "    try:\n",
    "        tokens = [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens]\n",
    "    except:\n",
    "        tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    tokens = [token for token in tokens if token.strip()]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_dataframe(df, text_col, search_keywords, processed_col='processed_text'):\n",
    "    df[text_col] = df[text_col].fillna('').astype(str)\n",
    "    df[processed_col] = df[text_col].apply(lambda x: preprocess_text(x, search_keywords))\n",
    "    return df[df[processed_col].str.strip() != '']\n",
    "\n",
    "def detect_phrases(df, text_col='processed_text'):\n",
    "    tokenized_texts = df[text_col].apply(lambda x: x.split()).tolist()\n",
    "    bigram = Phrases(tokenized_texts, min_count=10, threshold=50, delimiter='_')\n",
    "    trigram = Phrases(bigram[tokenized_texts], threshold=50, delimiter='_')\n",
    "    \n",
    "    phrased_texts = []\n",
    "    for doc in tokenized_texts:\n",
    "        bigrams_ = [w for w in bigram[doc] if '_' in w]\n",
    "        trigrams_ = [w for w in trigram[bigram[doc]] if '_' in w]\n",
    "        combined = doc + bigrams_ + trigrams_\n",
    "        phrased_texts.append(' '.join(combined))\n",
    "    \n",
    "    return phrased_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55ba30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 10:08:46,034 - INFO - Loaded and preprocessed 28934 papers\n"
     ]
    }
   ],
   "source": [
    "# Data Loading and Preprocessing\n",
    "filename = \"semantic_scholar_2025_02_14_reliability_resilience_power_systems_results.csv\"\n",
    "filepath = os.path.join(\"Saved_files\", filename)\n",
    "df = pd.read_csv(filepath, sep=\";\")\n",
    "df['text'] = df['title'].fillna('') + ' ' + df['abstract'].fillna('')\n",
    "search_keywords = extract_keywords_from_filename(filename)\n",
    "df = preprocess_dataframe(df, text_col='text', search_keywords=search_keywords)\n",
    "\n",
    "def clean_fields_of_study(s):\n",
    "    valid_fields = ['Computer Science', 'Economics', 'Engineering', 'Physics', 'Mathematics',\n",
    "                    'Medicine','Business','Environmental Science','Chemistry','Materials Science',\n",
    "                    'Geography','Biology','Geology','Political Science','Psychology','Com']\n",
    "    if pd.isna(s) or s == '[]':\n",
    "        return [\"Unknown\"]\n",
    "    if isinstance(s, str):\n",
    "        fields = [field.strip().strip(\"'\\\"\") for field in s.strip('[]').split(',')]\n",
    "        cleaned_fields = []\n",
    "        for field in fields:\n",
    "            if field in valid_fields:\n",
    "                cleaned_fields.append(field)\n",
    "            else:\n",
    "                cleaned_fields.append(\"Unknown\")\n",
    "        return cleaned_fields if cleaned_fields else [\"Unknown\"]\n",
    "    return [\"Unknown\"]\n",
    "\n",
    "df['fieldsOfStudy'] = df['fieldsOfStudy'].apply(clean_fields_of_study)\n",
    "logger.info(f\"Loaded and preprocessed {len(df)} papers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85552132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 10:08:46,422 - INFO - collecting all words and their counts\n",
      "2025-08-20 10:08:46,424 - INFO - PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2025-08-20 10:08:47,993 - INFO - PROGRESS: at sentence #10000, processed 1528760 words and 873903 word types\n",
      "2025-08-20 10:08:49,703 - INFO - PROGRESS: at sentence #20000, processed 3012255 words and 1486274 word types\n",
      "2025-08-20 10:08:51,086 - INFO - collected 1928697 token types (unigram + bigrams) from a corpus of 4300658 words and 28934 sentences\n",
      "2025-08-20 10:08:51,086 - INFO - merged Phrases<1928697 vocab, min_count=10, threshold=50, max_vocab_size=40000000>\n",
      "2025-08-20 10:08:51,086 - INFO - Phrases lifecycle event {'msg': 'built Phrases<1928697 vocab, min_count=10, threshold=50, max_vocab_size=40000000> in 4.66s', 'datetime': '2025-08-20T10:08:51.086440', 'gensim': '4.3.2', 'python': '3.11.13 (main, Jun 12 2025, 12:41:34) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "2025-08-20 10:08:51,101 - INFO - collecting all words and their counts\n",
      "2025-08-20 10:08:51,101 - INFO - PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2025-08-20 10:08:54,494 - INFO - PROGRESS: at sentence #10000, processed 1474857 words and 896239 word types\n",
      "2025-08-20 10:08:58,366 - INFO - PROGRESS: at sentence #20000, processed 2897746 words and 1537900 word types\n",
      "2025-08-20 10:09:01,508 - INFO - collected 2008055 token types (unigram + bigrams) from a corpus of 4127557 words and 28934 sentences\n",
      "2025-08-20 10:09:01,508 - INFO - merged Phrases<2008055 vocab, min_count=5, threshold=50, max_vocab_size=40000000>\n",
      "2025-08-20 10:09:01,508 - INFO - Phrases lifecycle event {'msg': 'built Phrases<2008055 vocab, min_count=5, threshold=50, max_vocab_size=40000000> in 10.41s', 'datetime': '2025-08-20T10:09:01.508316', 'gensim': '4.3.2', 'python': '3.11.13 (main, Jun 12 2025, 12:41:34) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "2025-08-20 10:09:22,987 - INFO - Fitting LDA model with 10 topics\n",
      "2025-08-20 10:11:34,923 - INFO - ✓ Topic modeling and paper classification completed\n"
     ]
    }
   ],
   "source": [
    "# Topic Modeling with LDA\n",
    "def extract_topic_keywords(lda_model, feature_names, num_words=10):\n",
    "    topic_keywords = {}\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        top_indices = topic.argsort()[:-num_words-1:-1]\n",
    "        top_words = [feature_names[i] for i in top_indices]\n",
    "        word_weights = [(feature_names[i], topic[i]) for i in top_indices]\n",
    "        topic_keywords[topic_idx] = {\n",
    "            'top_words': top_words,\n",
    "            'word_weights': word_weights\n",
    "        }\n",
    "    return topic_keywords\n",
    "\n",
    "def model_topics(df, num_topics=10, num_words=100):\n",
    "    \"\"\"LDA analysis with unigrams + phrases\"\"\"\n",
    "    phrased_texts = detect_phrases(df)\n",
    "    \n",
    "    vectorizer = CountVectorizer(\n",
    "        ngram_range=(1, 1),\n",
    "        token_pattern=r'\\b[\\w_-]+\\b',\n",
    "        max_df=0.95,\n",
    "        min_df=2,\n",
    "        max_features=10000\n",
    "    )\n",
    "    \n",
    "    doc_term_matrix = vectorizer.fit_transform(phrased_texts)\n",
    "    \n",
    "    logger.info(f\"Fitting LDA model with {num_topics} topics\")\n",
    "    lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "    topic_distributions = lda_model.fit_transform(doc_term_matrix)\n",
    "    \n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    topic_keywords = extract_topic_keywords(lda_model, feature_names, num_words)\n",
    "    \n",
    "    return lda_model, vectorizer, topic_distributions, df, topic_keywords\n",
    "\n",
    "def classify_papers(topic_distributions, df_field):\n",
    "    paper_classifications = []\n",
    "    \n",
    "    for idx, dist in enumerate(topic_distributions):\n",
    "        top_2_topics = np.argsort(dist)[-2:][::-1]\n",
    "        \n",
    "        primary_score = dist[top_2_topics[0]]\n",
    "        other_topics_sum = sum(dist) - primary_score\n",
    "        dominance_ratio = primary_score / (other_topics_sum + 1e-10)\n",
    "        \n",
    "        paper_classifications.append({\n",
    "            'paper_idx': idx,\n",
    "            'primary_topic': top_2_topics[0],\n",
    "            'secondary_topic': top_2_topics[1],\n",
    "            'primary_score': primary_score,\n",
    "            'dominance_ratio': dominance_ratio\n",
    "        })\n",
    "    \n",
    "    return paper_classifications\n",
    "\n",
    "lda_model, vectorizer, topic_distributions, df_topic, topic_keywords = model_topics(df, num_topics=10, num_words=25)\n",
    "paper_classifications = classify_papers(topic_distributions, df)\n",
    "\n",
    "# Add topic assignments to dataframe\n",
    "df['Primary_Topic_Index'] = [int(p['primary_topic']) for p in paper_classifications]\n",
    "df['Primary_Score'] = [p['primary_score'] for p in paper_classifications]\n",
    "df['Dominance_Ratio'] = [p['dominance_ratio'] for p in paper_classifications]\n",
    "\n",
    "logger.info(\"✓ Topic modeling and paper classification completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94cb21e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 10:11:50,843 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:11:51,811 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:11:52,542 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:11:52,550 - INFO - Topic 0: Smart Grid Communication Systems\n",
      "2025-08-20 10:11:53,503 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:11:54,569 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:11:55,749 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:11:55,756 - INFO - Topic 1: Renewable Energy Storage Systems\n",
      "2025-08-20 10:11:57,013 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:11:57,906 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:11:59,036 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:11:59,040 - INFO - Topic 2: Wind Power System Reliability\n",
      "2025-08-20 10:11:59,905 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:00,670 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:01,799 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:01,800 - INFO - Topic 3: Wireless Communication Systems\n",
      "2025-08-20 10:12:02,515 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:03,212 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:03,943 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:03,948 - INFO - Topic 4: Resilience Management Systems\n",
      "2025-08-20 10:12:04,526 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:05,375 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:05,889 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:05,899 - INFO - Topic 5: Resilient Thermal Systems\n",
      "2025-08-20 10:12:06,521 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:06,920 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:07,634 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:07,637 - INFO - Topic 6: \"Fault Detection Systems\"\n",
      "2025-08-20 10:12:08,763 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:09,263 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:09,887 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:09,891 - INFO - Topic 7: Power Converter Systems\n",
      "2025-08-20 10:12:10,626 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:11,217 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:11,938 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:11,942 - INFO - Topic 8: Energy Generation Technologies\n",
      "2025-08-20 10:12:12,754 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:13,368 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:14,582 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:12:14,587 - INFO - Topic 9: Memory System Performance\n",
      "2025-08-20 10:12:14,598 - INFO - ✓ Topic naming completed\n"
     ]
    }
   ],
   "source": [
    "# Topic Naming with LLM\n",
    "def generate_topic_name_multiple_advanced(lda_keywords, tfidf_ngrams, top_titles, client, model_type, credit_tracker, search_keywords=None, initial_iterations=3, max_iterations=10, similarity_threshold=0.7):\n",
    "    iterations = initial_iterations\n",
    "    while iterations <= max_iterations:\n",
    "        generated_names = []\n",
    "        for _ in range(iterations):\n",
    "            name = generate_topic_name_advanced(lda_keywords, tfidf_ngrams, top_titles, client, model_type, credit_tracker, search_keywords=search_keywords)\n",
    "            if name:\n",
    "                generated_names.append(name)\n",
    "        \n",
    "        # Check for dominant topic\n",
    "        for i, name in enumerate(generated_names):\n",
    "            similar_names = [other_name for j, other_name in enumerate(generated_names) \n",
    "                             if i != j and string_similarity(name, other_name) >= similarity_threshold]\n",
    "            if len(similar_names) >= len(generated_names) // 2:\n",
    "                return name\n",
    "        \n",
    "        iterations += 2\n",
    "        print(f\"No clear common topic name found. Increasing iterations to {iterations}.\")\n",
    "    \n",
    "    from collections import Counter\n",
    "    return Counter(generated_names).most_common(1)[0][0]\n",
    "\n",
    "def generate_topic_name_advanced(lda_keywords, tfidf_ngrams, top_titles, client, model_type, credit_tracker, search_keywords=None):\n",
    "    prompt = f\"\"\"Based on the following keywords and n-grams from LDA and TF-IDF analysis and the titles of the most cited papers with this topic as dominant, provide a concise, specific, and descriptive topic name (preferably a bigram or trigram, but a single word is allowed if most fitting):\n",
    "\n",
    "LDA keywords and n-grams:\n",
    "{', '.join(lda_keywords)}\n",
    "\n",
    "TF-IDF n-grams:\n",
    "{', '.join(tfidf_ngrams)}\n",
    "\n",
    "Most cited paper titles:\n",
    "{'; '.join(top_titles)}\n",
    "\n",
    "Concise topic name:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        tokens = num_tokens_from_string(prompt, model_type)\n",
    "        credit_tracker.update(tokens)\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_type,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful scientific assistant that generates concise topic names based on keywords and paper titles.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        credit_tracker.update(num_tokens_from_string(content, model_type))\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_top_titles_for_topic(df, paper_classifications, topic_idx, n_titles=20):\n",
    "    dominant_papers = [p for p in paper_classifications if p['primary_topic'] == topic_idx]\n",
    "    paper_infos = [\n",
    "        (df.iloc[p['paper_idx']]['citationCount'], df.iloc[p['paper_idx']]['title'])\n",
    "        for p in dominant_papers\n",
    "        if not pd.isna(df.iloc[p['paper_idx']]['title'])\n",
    "    ]\n",
    "    top_titles = [title for _, title in sorted(paper_infos, key=lambda x: -x[0])[:n_titles]]\n",
    "    return top_titles\n",
    "\n",
    "def get_top_tfidf_ngrams_per_topic(df, tfidf_matrix, feature_names, topic_col='Primary_Topic_Index', top_k=10):\n",
    "    tfidf_ngrams = {}\n",
    "    for topic_idx in df[topic_col].dropna().unique():\n",
    "        topic_idx = int(topic_idx)\n",
    "        doc_indices = df[df[topic_col] == topic_idx].index\n",
    "        if len(doc_indices) == 0:\n",
    "            continue\n",
    "        topic_tfidf = np.asarray(tfidf_matrix[doc_indices].mean(axis=0)).ravel()\n",
    "        top_indices = topic_tfidf.argsort()[-top_k:][::-1]\n",
    "        top_terms = [(feature_names[i], topic_tfidf[i]) for i in top_indices if topic_tfidf[i] > 0]\n",
    "        tfidf_ngrams[topic_idx] = top_terms\n",
    "    return tfidf_ngrams\n",
    "\n",
    "# Generate TF-IDF n-grams for topic naming\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    token_pattern=r'\\b[\\w_-]+\\b'\n",
    ")\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['processed_text'])\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "tfidf_ngrams = get_top_tfidf_ngrams_per_topic(\n",
    "    df, tfidf_matrix, feature_names,\n",
    "    topic_col='Primary_Topic_Index', top_k=10\n",
    ")\n",
    "\n",
    "# Generate topic names using LLM\n",
    "topic_names = {}\n",
    "for topic_idx, keywords in topic_keywords.items():\n",
    "    lda_ngrams = keywords['top_words'][:20]\n",
    "    tfidf_ng = [ngram for ngram, _ in tfidf_ngrams.get(topic_idx, [])][:20]\n",
    "    top_titles = get_top_titles_for_topic(df, paper_classifications, topic_idx, n_titles=10)\n",
    "    \n",
    "    topic_name = generate_topic_name_multiple_advanced(\n",
    "        lda_ngrams, tfidf_ng, top_titles, client, model_type, credit_tracker, search_keywords=search_keywords\n",
    "    )\n",
    "    if topic_name:\n",
    "        topic_names[topic_idx] = topic_name\n",
    "    logger.info(f\"Topic {topic_idx}: {topic_name if topic_name else 'Unnamed'}\")\n",
    "\n",
    "# Add topic names to dataframe\n",
    "df['Primary_Topic'] = df['Primary_Topic_Index'].map(lambda x: topic_names.get(x, f\"Topic_{x}\"))\n",
    "\n",
    "logger.info(\"✓ Topic naming completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d06007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def extract_candidate_terms(df, text_col='processed_text', max_features=1000):\n",
    "    \"\"\"Extract candidate keywords and n-grams from processed text for LLM prompt testing\"\"\"\n",
    "    vectorizer = CountVectorizer(\n",
    "        ngram_range=(1, 3),\n",
    "        max_df=0.95,\n",
    "        min_df=2,\n",
    "        max_features=max_features,\n",
    "        token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "    matrix = vectorizer.fit_transform(df[text_col].fillna(''))\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    freqs = matrix.sum(axis=0).A1\n",
    "    # Sort terms by frequency descending\n",
    "    sorted_terms = sorted(zip(terms, freqs), key=lambda x: x[1], reverse=True)\n",
    "    return [term for term, freq in sorted_terms]\n",
    "\n",
    "def extract_candidate_terms_enhanced(df, text_col='processed_text', max_features=100000):\n",
    "    \"\"\"Enhanced candidate term extraction with 1-5 word n-grams and specificity filters\"\"\"\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "    vectorizer = CountVectorizer(\n",
    "        ngram_range=(1, 5),\n",
    "        max_df=0.98,\n",
    "        min_df=2,\n",
    "        max_features=max_features,\n",
    "        token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "    matrix = vectorizer.fit_transform(df[text_col].fillna(''))\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    freqs = matrix.sum(axis=0).A1\n",
    "\n",
    "    sorted_terms = sorted(zip(terms, freqs), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    generic_words = {\n",
    "        'method', 'approach', 'technique', 'analysis', 'system', 'model',\n",
    "        'process', 'procedure', 'strategy', 'framework', 'methodology', 'study',\n",
    "        'research', 'paper', 'work', 'application', 'use', 'data', 'result',\n",
    "        'performance', 'evaluation', 'assessment'\n",
    "    }\n",
    "    filtered_terms = []\n",
    "    for term, freq in sorted_terms:\n",
    "        words = term.split()\n",
    "        if len(words) == 1:\n",
    "            if len(term) > 6 and term not in generic_words:\n",
    "                filtered_terms.append(term)\n",
    "        else:\n",
    "            significant_words = [w for w in words if len(w) > 4 and w not in generic_words]\n",
    "            if significant_words and freq >= max(1, len(words) - 2):\n",
    "                filtered_terms.append(term)\n",
    "    logger.info(f\"Filtered {len(filtered_terms)} specific terms from {len(sorted_terms)} total candidates\")\n",
    "    return filtered_terms\n",
    "\n",
    "def extract_candidate_terms(df, text_col='processed_text', max_features=1000):\n",
    "    \"\"\"Extract candidate keywords and n-grams from processed text for LLM prompt testing\"\"\"\n",
    "    vectorizer = CountVectorizer(\n",
    "        ngram_range=(1, 3),\n",
    "        max_df=0.95,\n",
    "        min_df=2,\n",
    "        max_features=max_features,\n",
    "        token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "    matrix = vectorizer.fit_transform(df[text_col].fillna(''))\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    freqs = matrix.sum(axis=0).A1\n",
    "    # Sort terms by frequency descending\n",
    "    sorted_terms = sorted(zip(terms, freqs), key=lambda x: x[1], reverse=True)\n",
    "    return [term for term, freq in sorted_terms]\n",
    "\n",
    "def get_method_phrases(corpus_terms, client, model_type, credit_tracker):\n",
    "    \"\"\"LLM filters candidate n-grams to only methods/techniques, excluding general concepts\"\"\"\n",
    "    import ast\n",
    "    sample_terms = ', '.join(corpus_terms[:50])\n",
    "    prompt = f\"\"\"Here are the most frequent terms from a corpus of scientific papers:\n",
    "{sample_terms}\n",
    "\n",
    "Based on these, this is a corpus about power systems/electrical engineering and reliability analysis.\n",
    "\n",
    "From the full list of terms: {', '.join(corpus_terms)}\n",
    "\n",
    "Extract ONLY the terms that represent specific methodologies, techniques, or named technical approaches,\n",
    "NOT general topics or components. \n",
    "\n",
    "Do not include generic phrases (\"analysis\", \"system\", \"generation\"), company/product names, equipment, or phenomena.\n",
    "\n",
    "Do include: things like \"monte carlo simulation\", \"optimal power flow\", \"state estimation\", \"fault tree analysis\", \"genetic algorithm\", \"unit commitment\", \"markov chain monte carlo\", etc.\n",
    "\n",
    "Return as a single Python list of strings, no code blocks or extra output.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_type,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "    try:\n",
    "        return ast.literal_eval(content)\n",
    "    except Exception:\n",
    "        # Robust fallback parsing if not pure Python list\n",
    "        content = content.replace('[','').replace(']','').replace('\"','').replace(\"'\",'')\n",
    "        return [term.strip() for term in content.split(',') if len(term.strip()) > 2]\n",
    "\n",
    "def get_method_abbreviation_dict(method_phrases, client, model_type, credit_tracker, batch_size=100):\n",
    "    \"\"\"\n",
    "    Uses OpenAI to match each method phrase to a list of abbreviations/variants, in manageable batches.\n",
    "    Returns {canonical: [abbr, alias, ...]}\n",
    "    \"\"\"\n",
    "    import ast, re\n",
    "    results = {}\n",
    "    for i in range(0, len(method_phrases), batch_size):\n",
    "        batch = method_phrases[i:i+batch_size]\n",
    "        prompt = f\"\"\"For each of the following phrases, extract ONLY specific named computational, statistical, or engineering methods, techniques, or algorithms. Examples: 'monte carlo simulation', 'optimal power flow', 'support vector machine', 'markov chain monte carlo', 'unit commitment', 'fault tree analysis', 'finite element method', etc.\n",
    "\n",
    "DO NOT return categories or families such as 'Power system analysis methods', 'Statistical methods', or 'Reliability analysis techniques'.\n",
    "\n",
    "For each method, provide all common abbreviations, acronyms, and alternative names as used in engineering and scientific literature.\n",
    "\n",
    "Format your response strictly as a Python dictionary, with only method names as keys and all abbreviations/aliases/alternatives as a list (see below):\n",
    "\n",
    "{{\n",
    "  \"optimal power flow\": [\"opf\", \"ac opf\", \"dc opf\", \"optimal power flow analysis\"],\n",
    "  \"monte carlo simulation\": [\"monte carlo\", \"mcs\", \"mc simulation\"],\n",
    "  \"unit commitment\": [\"uc\", \"unit commit\", \"unit commitment problem\"],\n",
    "  \"automatic generation control\": [\"agc\"],\n",
    "  \"markov chain monte carlo\": [\"mcmc\"],\n",
    "  \"fault tree analysis\": [\"fta\"],\n",
    "  \"finite element method\": [\"fem\", \"finite element analysis\", \"fea\"],\n",
    "  \"principal component analysis\": [\"pca\"]\n",
    "}}\n",
    "\n",
    "Important requirements:\n",
    "- DO NOT use umbrella categories of methods.\n",
    "- Each dictionary key must be a real, specific, technical method phrase.\n",
    "- Do NOT include any explanations, categories, or code blocks.\n",
    "- Only output the dictionary.\n",
    "Methods:\n",
    "{chr(10).join(batch)}\n",
    "\"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_type,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a scientific abbreviation expert.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        # print(content)  # DEBUG if desired\n",
    "        start, end = content.find('{'), content.rfind('}')+1\n",
    "        method_dict = {}\n",
    "        if start >= 0 and end > start:\n",
    "            try:\n",
    "                method_dict = ast.literal_eval(content[start:end])\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to parse dictionary from LLM batch: {e}\")\n",
    "        results.update(method_dict)\n",
    "    logger.info(f\"LLM mapped {len(results)} methods to abbreviations/variants.\")\n",
    "    return results\n",
    "\n",
    "def expand_method_abbreviations_with_llm(method_dict, client, model_type, credit_tracker):\n",
    "    \"\"\"Use LLM to expand abbreviations for any methods missing comprehensive variants\"\"\"\n",
    "    methods_needing_expansion = [m for m, v in method_dict.items() if len(v) < 2]\n",
    "    if not methods_needing_expansion:\n",
    "        logger.info(\"All methods have sufficient abbreviation variants\")\n",
    "        return method_dict\n",
    "    logger.info(f\"Expanding abbreviations for {len(methods_needing_expansion)} methods\")\n",
    "    expansion_prompt = f\"\"\"For the following scientific/engineering methods, provide ALL common abbreviations, acronyms, and alternative names.\n",
    "\n",
    "Methods to expand:\n",
    "{', '.join(methods_needing_expansion[:100])}\n",
    "\n",
    "For each method, provide a comprehensive list including:\n",
    "- Official abbreviations/acronyms\n",
    "- Common shortened forms\n",
    "- Alternative spellings (US/UK variants like optimization/optimisation)\n",
    "- Related terms that refer to the very same method\n",
    "- Field-specific variations\n",
    "\n",
    "Format your response EXACTLY as a valid Python dictionary, for example:\n",
    "{{\n",
    "  \"reinforcement learning\": [\"rl\", \"deep reinforcement learning\", \"drl\", \"reinforcement learning algorithm\"],\n",
    "  \"wavelet transform\": [\"wt\", \"discrete wavelet transform\", \"dwt\", \"continuous wavelet transform\", \"cwt\", \"wavelet analysis\"],\n",
    "  \"optimization\": [\"optimisation\", \"optimize\", \"optimise\", \"optimal\", \"optimization algorithm\"]\n",
    "}}\n",
    "\n",
    "Important requirements:\n",
    "- Your ENTIRE reply must be a single Python dictionary. \n",
    "- Do NOT include explanations, commentary, introductions, or code blocks.\n",
    "- Do NOT use triple backticks or headings of any kind.\n",
    "- The first character you output must be '{{' and the last must be '}}'.\n",
    "- If you have only one method, your dictionary should still use the same format.\n",
    "\n",
    "Return ONLY the dictionary, with keys as method names and values as lists of abbreviations/variants.\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_type,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in scientific terminology...\"},\n",
    "                {\"role\": \"user\", \"content\": expansion_prompt}\n",
    "            ]\n",
    "        )\n",
    "        content = response.choices.message.content.strip()\n",
    "        credit_tracker.update(len(content.split()))\n",
    "        if content.startswith('```python'):\n",
    "            content = content.replace('``````', '')\n",
    "        elif content.startswith('```'):\n",
    "            content = content.replace('```', '')\n",
    "        start = content.find('{')\n",
    "        end = content.rfind('}') + 1\n",
    "        if start >= 0 and end > start:\n",
    "            content = content[start:end]\n",
    "        expansion_dict = ast.literal_eval(content)\n",
    "        for method, new_variants in expansion_dict.items():\n",
    "            if method in method_dict:\n",
    "                all_variants = list(set(method_dict[method] + new_variants))\n",
    "                method_dict[method] = all_variants\n",
    "        logger.info(f\"Successfully expanded abbreviations for {len(expansion_dict)} methods\")\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Failed to expand abbreviations: {e}\")\n",
    "    return method_dict\n",
    "\n",
    "def build_abbr_to_canonical_map(method_dict):\n",
    "    abbr_map = {}\n",
    "    for canonical, variants in method_dict.items():\n",
    "        abbr_map[canonical.lower()] = canonical\n",
    "        for v in variants:\n",
    "            abbr_map[v.lower()] = canonical\n",
    "    return abbr_map\n",
    "\n",
    "import re\n",
    "def standardize_methods_in_text(text, abbr_to_canonical):\n",
    "    # Sort by descending length, so longest patterns are replaced first\n",
    "    sorted_vars = sorted(abbr_to_canonical, key=lambda x: -len(x))\n",
    "    for var in sorted_vars:\n",
    "        pattern = r'\\b' + re.escape(var) + r'\\b'  # whole word, case-insensitive\n",
    "        text = re.sub(pattern, abbr_to_canonical[var], text, flags=re.IGNORECASE)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "264a1cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 10:13:12,413 - INFO - Filtered 7659 specific terms from 10000 total candidates\n",
      "2025-08-20 10:13:19,830 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:13:22,750 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:13:27,299 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:13:33,041 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:13:36,209 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:13:36,209 - INFO - LLM mapped 97 methods to abbreviations/variants.\n"
     ]
    }
   ],
   "source": [
    "# partiall workflow, use rahter the new one further down...\n",
    "# Extract method phrases (customize max_features as token budget allows)\n",
    "candidate_terms = extract_candidate_terms_enhanced(df, text_col='processed_text', max_features=10000)\n",
    "top_cands = candidate_terms[:500]  # or whatever fits in prompt batch\n",
    "\n",
    "# LLM abbreviation mapping (in manageable batches if necessary)\n",
    "method_dict = get_method_abbreviation_dict(top_cands, client, model_type, credit_tracker, batch_size=100)\n",
    "\n",
    "# Build alias→canonical map\n",
    "abbr_to_canonical_map = build_abbr_to_canonical_map(method_dict)\n",
    "\n",
    "# Standardize all texts before actual analysis\n",
    "df['standardized_text'] = df['processed_text'].apply(\n",
    "    lambda t: standardize_methods_in_text(t, abbr_to_canonical_map)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d431ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "190e8094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Execute enhanced method scoring with primary method mapping\\nlogger.info(\"Starting enhanced method scoring with primary method mapping...\")\\ndf, primary_combined_scores, tfidf_primary_scores, compound_primary_scores, primary_methods = compute_method_scores_streamlined_enhanced(\\n    df, method_phrases_aug, method_to_primary_map, processed_col=\\'standardized_text\\', \\n    w_tfidf=0.6, w_compound=0.4, top_k=3\\n)\\n\\ndf = assign_primary_method_and_confidence_enhanced(\\n    df, primary_combined_scores, primary_methods, \\n    th_super=0.85, th_high=0.6, th_low=0.2\\n)\\n\\nlogger.info(\"✓ Enhanced method scoring completed without fragmentation warnings\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Multi-Label Method Scoring (Enhanced with Primary Method Mapping)\n",
    "def compute_method_scores_streamlined_enhanced(df, vocab, method_to_primary_map, processed_col='processed_text', \n",
    "                                             w_tfidf=0.6, w_compound=0.4, top_k=3):\n",
    "    \"\"\"\n",
    "    Compute combined scores for all methods with streamlined output and primary method mapping.\n",
    "    \"\"\"\n",
    "    n_docs = len(df)\n",
    "    n_methods = len(vocab)\n",
    "    \n",
    "    logger.info(f\"Computing method scores for {n_docs} documents and {n_methods} methods\")\n",
    "    \n",
    "    # TF-IDF scores\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        vocabulary=vocab, ngram_range=(1, 5), min_df=1, max_df=0.999,  # Extended to 5-grams\n",
    "        norm='l2', token_pattern=r'\\b[\\w_-]+\\b'\n",
    "    )\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df[processed_col])\n",
    "    tfidf_scores = tfidf_matrix.toarray()\n",
    "    \n",
    "    # Compound/proximity scores\n",
    "    compound_scores = compute_compound_scores_enhanced(df, vocab, processed_col)\n",
    "    \n",
    "    # Combined scores\n",
    "    combined_scores = w_tfidf * tfidf_scores + w_compound * compound_scores\n",
    "    \n",
    "    # Group scores by primary method (combine abbreviations and variants)\n",
    "    primary_methods = list(set(method_to_primary_map.values()))\n",
    "    primary_combined_scores = np.zeros((n_docs, len(primary_methods)))\n",
    "    primary_method_index = {method: i for i, method in enumerate(primary_methods)}\n",
    "    \n",
    "    # Aggregate scores for each primary method\n",
    "    for j, variant in enumerate(vocab):\n",
    "        primary_method = method_to_primary_map.get(variant, variant)\n",
    "        if primary_method in primary_method_index:\n",
    "            primary_idx = primary_method_index[primary_method]\n",
    "            primary_combined_scores[:, primary_idx] = np.maximum(\n",
    "                primary_combined_scores[:, primary_idx], \n",
    "                combined_scores[:, j]\n",
    "            )\n",
    "    \n",
    "    # Prepare ALL new columns at once to avoid fragmentation\n",
    "    logger.info(\"Preparing all new columns for efficient addition...\")\n",
    "    new_columns = {}\n",
    "    \n",
    "    # 1. Primary method score columns (aggregated)\n",
    "    for i, method in enumerate(primary_methods):\n",
    "        safe_name = f\"method_{method.replace(' ', '_').replace('-', '_').replace('(', '').replace(')', '').replace(',', '')}\"\n",
    "        if len(safe_name) > 50:\n",
    "            safe_name = safe_name[:50]\n",
    "        new_columns[safe_name] = primary_combined_scores[:, i]\n",
    "    \n",
    "    # 2. Top-k columns based on primary methods\n",
    "    tfidf_primary_scores = np.zeros((n_docs, len(primary_methods)))\n",
    "    compound_primary_scores = np.zeros((n_docs, len(primary_methods)))\n",
    "    \n",
    "    # Aggregate TF-IDF and compound scores for primary methods\n",
    "    for j, variant in enumerate(vocab):\n",
    "        primary_method = method_to_primary_map.get(variant, variant)\n",
    "        if primary_method in primary_method_index:\n",
    "            primary_idx = primary_method_index[primary_method]\n",
    "            tfidf_primary_scores[:, primary_idx] = np.maximum(\n",
    "                tfidf_primary_scores[:, primary_idx], \n",
    "                tfidf_scores[:, j]\n",
    "            )\n",
    "            compound_primary_scores[:, primary_idx] = np.maximum(\n",
    "                compound_primary_scores[:, primary_idx], \n",
    "                compound_scores[:, j]\n",
    "            )\n",
    "    \n",
    "    tfidf_topk_idx = np.argsort(tfidf_primary_scores, axis=1)[:, -top_k:][:, ::-1]\n",
    "    compound_topk_idx = np.argsort(compound_primary_scores, axis=1)[:, -top_k:][:, ::-1]\n",
    "    \n",
    "    for k in range(top_k):\n",
    "        new_columns[f'tfidf_top_{k+1}_method'] = [primary_methods[idx[k]] for idx in tfidf_topk_idx]\n",
    "        new_columns[f'tfidf_top_{k+1}_score'] = [tfidf_primary_scores[i, idx[k]] for i, idx in enumerate(tfidf_topk_idx)]\n",
    "        new_columns[f'compound_top_{k+1}_method'] = [primary_methods[idx[k]] for idx in compound_topk_idx]\n",
    "        new_columns[f'compound_top_{k+1}_score'] = [compound_primary_scores[i, idx[k]] for i, idx in enumerate(compound_topk_idx)]\n",
    "    \n",
    "    # Add all columns at once using efficient concatenation\n",
    "    logger.info(f\"Adding {len(new_columns)} columns efficiently...\")\n",
    "    new_df = pd.DataFrame(new_columns, index=df.index)\n",
    "    df = pd.concat([df, new_df], axis=1)\n",
    "    \n",
    "    logger.info(f\"✓ Added {len(primary_methods)} primary method columns and {top_k*4} top-k columns efficiently\")\n",
    "    return df, primary_combined_scores, tfidf_primary_scores, compound_primary_scores, primary_methods\n",
    "\n",
    "def compute_compound_scores_enhanced(df, vocab, processed_col='processed_text', window=300, ratio_thresh=0.5):\n",
    "    \"\"\"Enhanced compound/proximity scores with better phrase detection.\"\"\"\n",
    "    n_docs = len(df)\n",
    "    n_terms = len(vocab)\n",
    "    scores = np.zeros((n_docs, n_terms), dtype=np.float32)\n",
    "    \n",
    "    docs = df[processed_col].fillna('').str.lower().tolist()\n",
    "    \n",
    "    logger.info(f\"Computing enhanced compound scores for {n_terms} method phrases...\")\n",
    "    \n",
    "    for j, phrase in enumerate(vocab):\n",
    "        if j % 10 == 0:\n",
    "            logger.info(f\"Processing phrase {j+1}/{n_terms}\")\n",
    "            \n",
    "        phrase_l = phrase.lower()\n",
    "        phrase_words = [w for w in phrase_l.split() if len(w) > 0]\n",
    "        sig_words = [w for w in phrase_words if len(w) > 3]\n",
    "        \n",
    "        for i, text in enumerate(docs):\n",
    "            # Exact phrase match\n",
    "            if phrase_l in text:\n",
    "                scores[i, j] = 1.0\n",
    "                continue\n",
    "            \n",
    "            # Multi-word phrase processing\n",
    "            if len(phrase_words) > 1:\n",
    "                present = sum(1 for w in sig_words if w in text) if sig_words else 0\n",
    "                coverage = present / len(sig_words) if sig_words else 0.0\n",
    "                \n",
    "                # Enhanced proximity check with flexible ordering\n",
    "                prox_hit = False\n",
    "                for k in range(len(phrase_words)-1):\n",
    "                    w1, w2 = phrase_words[k], phrase_words[k+1]\n",
    "                    pos = text.find(w1)\n",
    "                    if pos >= 0:\n",
    "                        # Check both directions within window\n",
    "                        nearby = text[max(0, pos-window//2):pos+window]\n",
    "                        if w2 in nearby:\n",
    "                            prox_hit = True\n",
    "                            break\n",
    "                \n",
    "                # Score based on coverage and proximity\n",
    "                if coverage >= ratio_thresh or prox_hit:\n",
    "                    base_score = 0.6 + 0.4 * coverage\n",
    "                    if prox_hit:\n",
    "                        base_score = min(1.0, base_score * 1.2)  # Bonus for proximity\n",
    "                    scores[i, j] = max(scores[i, j], base_score)\n",
    "            else:\n",
    "                # Single technical term with context bonus\n",
    "                if len(phrase_l) > 6 and phrase_l in text:\n",
    "                    # Check for technical context (nearby technical words)\n",
    "                    pos = text.find(phrase_l)\n",
    "                    context = text[max(0, pos-50):pos+50]\n",
    "                    technical_indicators = ['algorithm', 'method', 'analysis', 'model', 'system', 'technique']\n",
    "                    context_bonus = 1.1 if any(ind in context for ind in technical_indicators) else 1.0\n",
    "                    scores[i, j] = max(scores[i, j], min(1.0, 0.7 * context_bonus))\n",
    "    \n",
    "    logger.info(\"✓ Enhanced compound scores computed\")\n",
    "    return scores\n",
    "\n",
    "def assign_primary_method_and_confidence_enhanced(df, combined_scores, primary_methods, \n",
    "                                                th_super=0.85, th_high=0.6, th_low=0.2):\n",
    "    \"\"\"Assign primary method and confidence level using primary method aggregation.\"\"\"\n",
    "    n_docs = len(df)\n",
    "    assigned_methods = []\n",
    "    confidences = []\n",
    "    \n",
    "    for i in range(n_docs):\n",
    "        scores = combined_scores[i]\n",
    "        max_idx = np.argmax(scores)\n",
    "        max_score = scores[max_idx]\n",
    "        best_method = primary_methods[max_idx]\n",
    "        \n",
    "        if max_score >= th_super:\n",
    "            confidence = 'super_high'\n",
    "        elif max_score >= th_high:\n",
    "            confidence = 'high'\n",
    "        elif max_score >= th_low:\n",
    "            confidence = 'low'\n",
    "        else:\n",
    "            confidence = 'not_detected'\n",
    "            best_method = 'LowConfidence'\n",
    "        \n",
    "        assigned_methods.append(best_method)\n",
    "        confidences.append(confidence)\n",
    "    \n",
    "    # Add these final columns efficiently\n",
    "    final_columns = {\n",
    "        'Primary_Method': assigned_methods,\n",
    "        'Method_Confidence': confidences\n",
    "    }\n",
    "    \n",
    "    final_df = pd.DataFrame(final_columns, index=df.index)\n",
    "    df = pd.concat([df, final_df], axis=1)\n",
    "    \n",
    "    return df\n",
    "\"\"\"\n",
    "# Execute enhanced method scoring with primary method mapping\n",
    "logger.info(\"Starting enhanced method scoring with primary method mapping...\")\n",
    "df, primary_combined_scores, tfidf_primary_scores, compound_primary_scores, primary_methods = compute_method_scores_streamlined_enhanced(\n",
    "    df, method_phrases_aug, method_to_primary_map, processed_col='standardized_text', \n",
    "    w_tfidf=0.6, w_compound=0.4, top_k=3\n",
    ")\n",
    "\n",
    "df = assign_primary_method_and_confidence_enhanced(\n",
    "    df, primary_combined_scores, primary_methods, \n",
    "    th_super=0.85, th_high=0.6, th_low=0.2\n",
    ")\n",
    "\n",
    "logger.info(\"✓ Enhanced method scoring completed without fragmentation warnings\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4c47358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 10:16:12,350 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:16:23,624 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 10:16:23,645 - INFO - LLM mapped 55 methods to abbreviations/variants.\n",
      "2025-08-20 10:17:33,470 - INFO - Computing enhanced compound scores for 55 method phrases...\n",
      "2025-08-20 10:17:33,470 - INFO - Processing phrase 1/55\n",
      "2025-08-20 10:17:35,607 - INFO - Processing phrase 11/55\n",
      "2025-08-20 10:17:37,642 - INFO - Processing phrase 21/55\n",
      "2025-08-20 10:17:39,658 - INFO - Processing phrase 31/55\n",
      "2025-08-20 10:17:41,502 - INFO - Processing phrase 41/55\n",
      "2025-08-20 10:17:42,886 - INFO - Processing phrase 51/55\n",
      "2025-08-20 10:17:43,847 - INFO - ✓ Enhanced compound scores computed\n"
     ]
    }
   ],
   "source": [
    "# 1. Extract broad candidate n-grams from the corpus\n",
    "candidate_terms = extract_candidate_terms(df, text_col='processed_text', max_features=10000)\n",
    "\n",
    "# 2. Use LLM to filter for method/technique phrases only\n",
    "method_phrases = get_method_phrases(candidate_terms, client, model_type, credit_tracker)\n",
    "\n",
    "# 3. Use LLM to build abbreviation/synonym dictionary\n",
    "method_dict = get_method_abbreviation_dict(method_phrases, client, model_type, credit_tracker, batch_size=100)\n",
    "\n",
    "abbr_to_canonical_map = build_abbr_to_canonical_map(method_dict)\n",
    "\n",
    "# 4. Standardize text: replace all abbreviations/variants with full canonical names\n",
    "df['standardized_text'] = df['processed_text'].apply(\n",
    "    lambda t: standardize_methods_in_text(t, abbr_to_canonical_map)\n",
    ")\n",
    "\n",
    "# 5. Build method vocabulary for analysis\n",
    "method_vocabulary = sorted(method_dict.keys())\n",
    "\n",
    "# 6. TF-IDF and compound analysis WITH NO AGGREGATION\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    vocabulary=method_vocabulary,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=1,\n",
    "    max_df=0.999,\n",
    "    norm='l2',\n",
    "    token_pattern=r'\\b[\\w\\s_-]+\\b'\n",
    ")\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['standardized_text'])\n",
    "tfidf_scores = tfidf_matrix.toarray()\n",
    "\n",
    "compound_scores = compute_compound_scores_enhanced(df, method_vocabulary, processed_col='standardized_text')\n",
    "\n",
    "# 7. Combine scores, and assign top/method columns as you like!\n",
    "w_tfidf = 0.6\n",
    "w_compound = 0.4\n",
    "combined_scores = w_tfidf * tfidf_scores + w_compound * compound_scores\n",
    "\n",
    "def assign_top_method_and_confidence(df, combined_scores, method_vocabulary, th_super=0.85, th_high=0.6, th_low=0.2):\n",
    "    n_docs = len(df)\n",
    "    top_methods = []\n",
    "    confidences = []\n",
    "    for i in range(n_docs):\n",
    "        idx = np.argmax(combined_scores[i])\n",
    "        max_score = combined_scores[i, idx]\n",
    "        method = method_vocabulary[idx]\n",
    "        if max_score >= th_super:\n",
    "            conf = 'super_high'\n",
    "        elif max_score >= th_high:\n",
    "            conf = 'high'\n",
    "        elif max_score >= th_low:\n",
    "            conf = 'low'\n",
    "        else:\n",
    "            conf = 'not_detected'\n",
    "            method = 'LowConfidence'\n",
    "        top_methods.append(method)\n",
    "        confidences.append(conf)\n",
    "    df['Primary_Method'] = top_methods\n",
    "    df['Method_Confidence'] = confidences\n",
    "    return df\n",
    "\n",
    "df = assign_top_method_and_confidence(df, combined_scores, method_vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8e5e74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adaptive control', 'automatic generation control', 'clustering algorithm', 'cognitive radio', 'contingency analysis', 'decision support', 'deep reinforcement learning', 'detection technique', 'distributed consensus', 'dynamic line rating', 'dynamic programming', 'emergency response modeling', 'energy management strategy', 'fault tree analysis', 'feedback control', 'forensic analysis', 'fuzzy logic', 'genetic algorithm', 'grid optimization', 'historical data analysis', 'interference management', 'linear programming', 'load flow analysis', 'load forecasting', 'machine learning', 'markov chain monte carlo', 'model predictive control', 'monte carlo simulation', 'multi-agent systems', 'multi-objective optimization', 'network resource allocation', 'neural network', 'optimal power flow', 'optimal scheduling', 'particle swarm optimization', 'path planning', 'performance assessment', 'power system optimization', 'reliability analysis', 'risk assessment', 'sensitivity analysis', 'signal processing', 'signaling protocol', 'simulation-based', 'state estimation', 'statistical analysis', 'stochastic programming', 'supply-side management', 'synchronization technique', 'synthetic data generation', 'system reliability evaluation', 'topological optimization', 'traffic modeling', 'transactive control', 'unit commitment']\n"
     ]
    }
   ],
   "source": [
    "print(method_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e60db2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 10:17:44,193 - INFO - ✓ Author analysis completed\n"
     ]
    }
   ],
   "source": [
    "# Author Analysis\n",
    "def get_top_papers(paper_classifications, df_field, n_top=5):\n",
    "    \"\"\"Get top papers per topic with author analysis\"\"\"\n",
    "    top_papers = {}\n",
    "    author_topic_stats = {}\n",
    "    \n",
    "    for topic in set(p['primary_topic'] for p in paper_classifications):\n",
    "        topic_papers = [p for p in paper_classifications if p['primary_topic'] == topic]\n",
    "        topic_papers.sort(key=lambda x: x['dominance_ratio'], reverse=True)\n",
    "        top_papers[topic] = []\n",
    "        \n",
    "        for p in topic_papers[:n_top]:\n",
    "            paper_idx = p['paper_idx']\n",
    "            try:\n",
    "                authors = df_field.iloc[paper_idx]['authors']\n",
    "                \n",
    "                if isinstance(authors, str):\n",
    "                    try:\n",
    "                        authors = ast.literal_eval(authors)\n",
    "                    except (ValueError, SyntaxError):\n",
    "                        authors = []\n",
    "                \n",
    "                if isinstance(authors, list):\n",
    "                    author_list = []\n",
    "                    for author in authors:\n",
    "                        if isinstance(author, dict):\n",
    "                            author_list.append({\n",
    "                                'name': author.get('name', 'Unknown'),\n",
    "                                'id': author.get('authorId', 'Unknown')\n",
    "                            })\n",
    "                else:\n",
    "                    author_list = []\n",
    "                \n",
    "                top_papers[topic].append({\n",
    "                    'paperId': df_field.iloc[paper_idx]['paperId'],\n",
    "                    'title': df_field.iloc[paper_idx]['title'],\n",
    "                    'abstract': df_field.iloc[paper_idx]['abstract'],\n",
    "                    'authors': author_list,\n",
    "                    'score': float(p['primary_score']),\n",
    "                    'dominance_ratio': float(p['dominance_ratio'])\n",
    "                })\n",
    "                \n",
    "                # Author statistics\n",
    "                for author in author_list:\n",
    "                    author_id = author['id']\n",
    "                    if author_id not in author_topic_stats:\n",
    "                        author_topic_stats[author_id] = {\n",
    "                            'name': author['name'],\n",
    "                            'topics': {},\n",
    "                            'total_papers': 0,\n",
    "                            'top_papers': 0\n",
    "                        }\n",
    "                    \n",
    "                    if topic not in author_topic_stats[author_id]['topics']:\n",
    "                        author_topic_stats[author_id]['topics'][topic] = {\n",
    "                            'paper_count': 0,\n",
    "                            'avg_dominance': 0,\n",
    "                            'top_papers': []\n",
    "                        }\n",
    "                    \n",
    "                    author_stats = author_topic_stats[author_id]['topics'][topic]\n",
    "                    author_stats['paper_count'] += 1\n",
    "                    author_stats['avg_dominance'] = (\n",
    "                        (author_stats['avg_dominance'] * (author_stats['paper_count'] - 1) + \n",
    "                         float(p['dominance_ratio'])) / author_stats['paper_count']\n",
    "                    )\n",
    "                    author_stats['top_papers'].append({\n",
    "                        'title': df_field.iloc[paper_idx]['title'],\n",
    "                        'dominance_ratio': float(p['dominance_ratio'])\n",
    "                    })\n",
    "                    \n",
    "                    author_topic_stats[author_id]['total_papers'] += 1\n",
    "                    author_topic_stats[author_id]['top_papers'] += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error processing paper {paper_idx}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return top_papers, author_topic_stats\n",
    "\n",
    "def save_author_analysis(author_stats, filename):\n",
    "    \"\"\"Save author analysis to CSV\"\"\"\n",
    "    author_data = []\n",
    "    for author_id, stats in author_stats.items():\n",
    "        if stats['total_papers'] >= 2:  # Only authors with multiple papers\n",
    "            for topic, topic_stats in stats['topics'].items():\n",
    "                author_data.append({\n",
    "                    'author_id': author_id,\n",
    "                    'author_name': stats['name'],\n",
    "                    'topic': topic,\n",
    "                    'paper_count': topic_stats['paper_count'],\n",
    "                    'avg_dominance': topic_stats['avg_dominance'],\n",
    "                    'total_papers': stats['total_papers']\n",
    "                })\n",
    "    \n",
    "    author_df = pd.DataFrame(author_data)\n",
    "    author_df.to_csv(filename, index=False)\n",
    "    logger.info(f\"Author analysis saved to {filename}\")\n",
    "\n",
    "# Perform author analysis\n",
    "top_papers, author_stats = get_top_papers(paper_classifications, df, n_top=5)\n",
    "logger.info(\"✓ Author analysis completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e03542fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_diagnostics_granular(\n",
    "    df,\n",
    "    combined_scores,\n",
    "    tfidf_scores,\n",
    "    compound_scores,\n",
    "    method_vocabulary,\n",
    "    method_dict=None\n",
    "):\n",
    "    n_docs = len(df)\n",
    "    n_methods = len(method_vocabulary)\n",
    "\n",
    "    print(\"=== METHOD ASSIGNMENT DIAGNOSTICS ===\")\n",
    "    print(f\"Total documents: {n_docs}\")\n",
    "    print(f\"Total unique methods (canonical): {n_methods}\")\n",
    "\n",
    "    if method_dict is not None:\n",
    "        n_variants = sum(1 + len(variants) for variants in method_dict.values())\n",
    "        print(f\"Total method variants (including abbreviations): {n_variants}\")\n",
    "\n",
    "    # Coverage statistics\n",
    "    tfidf_nonzero = (tfidf_scores > 0).any(axis=1).sum()\n",
    "    compound_nonzero = (compound_scores > 0).any(axis=1).sum()\n",
    "    combined_nonzero = (combined_scores > 0).any(axis=1).sum()\n",
    "    print(\"\\nCoverage:\")\n",
    "    print(f\"  TF-IDF coverage: {tfidf_nonzero}/{n_docs} ({100*tfidf_nonzero/n_docs:.1f}%)\")\n",
    "    print(f\"  Compound coverage: {compound_nonzero}/{n_docs} ({100*compound_nonzero/n_docs:.1f}%)\")\n",
    "    print(f\"  Combined coverage: {combined_nonzero}/{n_docs} ({100*combined_nonzero/n_docs:.1f}%)\")\n",
    "\n",
    "    # Confidence distribution (robust, always force to Series)\n",
    "    if 'Method_Confidence' in df.columns:\n",
    "        col = df['Method_Confidence']\n",
    "        # Ensure it's a Series, not a DataFrame (should be 1D)\n",
    "        if isinstance(col, pd.DataFrame):\n",
    "            col = col.iloc[:, 0]\n",
    "        conf_dist = col.value_counts()\n",
    "        print(\"\\nConfidence distribution:\")\n",
    "        for conf, count in conf_dist.items():\n",
    "            print(f\"  {conf}: {count} ({100*count/n_docs:.1f}%)\")\n",
    "\n",
    "    # Top assigned methods\n",
    "    if 'Primary_Method' in df.columns:\n",
    "        col = df['Primary_Method']\n",
    "        if isinstance(col, pd.DataFrame):\n",
    "            col = col.iloc[:, 0]\n",
    "        method_dist = col.value_counts().head(20)\n",
    "        print(\"\\nTop 20 assigned methods:\")\n",
    "        for method, count in method_dist.items():\n",
    "            print(f\"  {method}: {count}\")\n",
    "\n",
    "    # Show sample methods\n",
    "    print(\"\\nSample methods (from canonical method vocabulary):\")\n",
    "    for method in method_vocabulary[:10]:\n",
    "        print(f\"  {method}\")\n",
    "\n",
    "    if method_dict is not None:\n",
    "        print(\"\\nAbbreviation mapping examples:\")\n",
    "        for i, (canonical, variants) in enumerate(list(method_dict.items())[:5]):\n",
    "            print(f\"  {canonical}: {', '.join(variants[:5])}\")\n",
    "\n",
    "    # Score statistics\n",
    "    print(\"\\nScore statistics (all methods):\")\n",
    "    print(f\"  Combined scores - Mean: {combined_scores.mean():.4f}, Std: {combined_scores.std():.4f}\")\n",
    "    print(f\"  TF-IDF scores - Mean: {tfidf_scores.mean():.4f}, Std: {tfidf_scores.std():.4f}\")\n",
    "    print(f\"  Compound scores - Mean: {compound_scores.mean():.4f}, Std: {compound_scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8e06462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== METHOD ASSIGNMENT DIAGNOSTICS ===\n",
      "Total documents: 28934\n",
      "Total unique methods (canonical): 55\n",
      "Total method variants (including abbreviations): 118\n",
      "\n",
      "Coverage:\n",
      "  TF-IDF coverage: 0/28934 (0.0%)\n",
      "  Compound coverage: 28423/28934 (98.2%)\n",
      "  Combined coverage: 28423/28934 (98.2%)\n",
      "\n",
      "Confidence distribution:\n",
      "  low: 28423 (98.2%)\n",
      "  not_detected: 511 (1.8%)\n",
      "\n",
      "Top 20 assigned methods:\n",
      "  power system optimization: 9708\n",
      "  distributed consensus: 1746\n",
      "  optimal power flow: 1634\n",
      "  automatic generation control: 1289\n",
      "  energy management strategy: 1269\n",
      "  dynamic line rating: 1251\n",
      "  historical data analysis: 1003\n",
      "  system reliability evaluation: 977\n",
      "  grid optimization: 935\n",
      "  network resource allocation: 674\n",
      "  adaptive control: 654\n",
      "  reliability analysis: 599\n",
      "  detection technique: 585\n",
      "  load flow analysis: 561\n",
      "  LowConfidence: 511\n",
      "  decision support: 469\n",
      "  genetic algorithm: 446\n",
      "  performance assessment: 436\n",
      "  monte carlo simulation: 408\n",
      "  machine learning: 350\n",
      "\n",
      "Sample methods (from canonical method vocabulary):\n",
      "  adaptive control\n",
      "  automatic generation control\n",
      "  clustering algorithm\n",
      "  cognitive radio\n",
      "  contingency analysis\n",
      "  decision support\n",
      "  deep reinforcement learning\n",
      "  detection technique\n",
      "  distributed consensus\n",
      "  dynamic line rating\n",
      "\n",
      "Abbreviation mapping examples:\n",
      "  monte carlo simulation: monte carlo, mcs, mc simulation\n",
      "  optimal power flow: opf, ac opf, dc opf, optimal power flow analysis\n",
      "  state estimation: state estimator\n",
      "  fault tree analysis: fta\n",
      "  genetic algorithm: ga\n",
      "\n",
      "Score statistics (all methods):\n",
      "  Combined scores - Mean: 0.0624, Std: 0.1326\n",
      "  TF-IDF scores - Mean: 0.0000, Std: 0.0000\n",
      "  Compound scores - Mean: 0.1561, Std: 0.3316\n"
     ]
    }
   ],
   "source": [
    "comprehensive_diagnostics_granular(\n",
    "    df,\n",
    "    combined_scores,\n",
    "    tfidf_scores,\n",
    "    compound_scores,\n",
    "    method_vocabulary,\n",
    "    method_dict=method_dict\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de2f7533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 10:17:48,604 - INFO - Author analysis saved to Saved_files_new\\author_analysis_2025_08_20reliability_resilience_power_systems.csv\n",
      "2025-08-20 10:17:48,606 - INFO - ✓ All enhanced supporting files saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎉 Enhanced analysis completed successfully!\n",
      "Main results saved to: Saved_files_new\\semantic_scholar_2025_08_20reliability_resilience_power_systems_enhanced_analysis.csv\n",
      "Method abbreviation dictionary saved with 55 primary methods\n",
      "Total method variants: 63\n",
      "API token usage: {'total_tokens': 8890, 'total_cost': 0.0013}\n",
      "\n",
      "Sample enhanced results:\n",
      "                  Primary_Method Method_Confidence  \\\n",
      "0           reliability analysis               low   \n",
      "1  system reliability evaluation               low   \n",
      "2               load forecasting               low   \n",
      "3               decision support               low   \n",
      "4      power system optimization               low   \n",
      "5      power system optimization               low   \n",
      "6      power system optimization               low   \n",
      "7      power system optimization               low   \n",
      "8          distributed consensus               low   \n",
      "9      power system optimization               low   \n",
      "\n",
      "                    Primary_Topic  \n",
      "0         Power Converter Systems  \n",
      "1       Memory System Performance  \n",
      "2  Wireless Communication Systems  \n",
      "3   Resilience Management Systems  \n",
      "4  Energy Generation Technologies  \n",
      "5         Power Converter Systems  \n",
      "6  Energy Generation Technologies  \n",
      "7  Wireless Communication Systems  \n",
      "8         Power Converter Systems  \n",
      "9  Wireless Communication Systems  \n",
      "\n",
      "Method abbreviation examples:\n",
      "  monte carlo simulation: monte carlo, mcs, mc simulation\n",
      "  optimal power flow: opf, ac opf, dc opf, optimal power flow analysis\n",
      "  state estimation: state estimator\n",
      "  fault tree analysis: fta\n",
      "  genetic algorithm: ga\n"
     ]
    }
   ],
   "source": [
    "# Save Results and Supporting Files\n",
    "# %%\n",
    "def save_supporting_files_enhanced(lda_model, vectorizer, topic_distributions, suffix_string, \n",
    "                                 author_stats, top_papers, topic_keywords, tfidf_ngrams, method_dict):\n",
    "    \"\"\"Save all supporting analysis files including method dictionary\"\"\"\n",
    "    \n",
    "    # Save topic terms\n",
    "    topic_terms_serializable = {}\n",
    "    for topic_idx, keywords in topic_keywords.items():\n",
    "        topic_terms_serializable[int(topic_idx)] = {\n",
    "            'top_words': keywords['top_words'],\n",
    "            'word_weights': [(word, float(weight)) for word, weight in keywords['word_weights']]\n",
    "        }\n",
    "    \n",
    "    topic_filename = os.path.join(SAVE_DIR, f\"lda_topic_terms_{suffix_string}.json\")\n",
    "    with open(topic_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(topic_terms_serializable, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Save TF-IDF terms\n",
    "    tfidf_filename = os.path.join(SAVE_DIR, f\"tfidf_topic_terms_{suffix_string}.json\")\n",
    "    with open(tfidf_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump({int(k): [(term, float(score)) for term, score in v] \n",
    "                  for k, v in tfidf_ngrams.items()}, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Save method dictionary with abbreviations\n",
    "    method_dict_filename = os.path.join(SAVE_DIR, f\"method_abbreviations_{suffix_string}.json\")\n",
    "    with open(method_dict_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(method_dict, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Save LDA components\n",
    "    lda_filename = os.path.join(SAVE_DIR, f\"lda_model_{suffix_string}.joblib\")\n",
    "    joblib.dump(lda_model, lda_filename)\n",
    "    \n",
    "    vectorizer_filename = os.path.join(SAVE_DIR, f\"vectorizer_{suffix_string}.joblib\")\n",
    "    joblib.dump(vectorizer, vectorizer_filename)\n",
    "    \n",
    "    distributions_filename = os.path.join(SAVE_DIR, f\"topic_distributions_{suffix_string}.npy\")\n",
    "    np.save(distributions_filename, topic_distributions)\n",
    "    \n",
    "    # Save top papers\n",
    "    top_papers_filename = os.path.join(SAVE_DIR, f\"top_papers_{suffix_string}.json\")\n",
    "    with open(top_papers_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump({int(k): v for k, v in top_papers.items()}, f, ensure_ascii=False, indent=2, default=str)\n",
    "    \n",
    "    # Save author analysis\n",
    "    author_filename = os.path.join(SAVE_DIR, f\"author_analysis_{suffix_string}.csv\")\n",
    "    save_author_analysis(author_stats, author_filename)\n",
    "    \n",
    "    logger.info(\"✓ All enhanced supporting files saved\")\n",
    "\n",
    "# Save main results\n",
    "current_date = datetime.now().strftime(\"%Y_%m_%d\")\n",
    "keyword_str = keywords_to_filename_part(search_keywords) if search_keywords else \"\"\n",
    "suffix_string = f\"{current_date}{keyword_str}\"\n",
    "\n",
    "output_filename = os.path.join(SAVE_DIR, f\"semantic_scholar_{suffix_string}_enhanced_analysis.csv\")\n",
    "df.to_csv(output_filename, sep=';', encoding='utf-8', quoting=csv.QUOTE_NONNUMERIC, escapechar='\\\\')\n",
    "\n",
    "# Save supporting files\n",
    "save_supporting_files_enhanced(\n",
    "    lda_model=lda_model,\n",
    "    vectorizer=vectorizer, \n",
    "    topic_distributions=topic_distributions,\n",
    "    suffix_string=suffix_string,\n",
    "    author_stats=author_stats,\n",
    "    top_papers=top_papers,\n",
    "    topic_keywords=topic_keywords,\n",
    "    tfidf_ngrams=tfidf_ngrams,\n",
    "    method_dict=method_dict\n",
    ")\n",
    "\n",
    "print(f\"\\n🎉 Enhanced analysis completed successfully!\")\n",
    "print(f\"Main results saved to: {output_filename}\")\n",
    "print(f\"Method abbreviation dictionary saved with {len(method_dict)} primary methods\")\n",
    "print(f\"Total method variants: {sum(len(variants) for variants in method_dict.values())}\")\n",
    "print(f\"API token usage: {credit_tracker.get_stats()}\")\n",
    "\n",
    "# Display sample results\n",
    "display_cols = ['Primary_Method', 'Method_Confidence', 'Primary_Topic', \n",
    "                'tfidf_top_1_method', 'tfidf_top_1_score', \n",
    "                'compound_top_1_method', 'compound_top_1_score']\n",
    "available_cols = [col for col in display_cols if col in df.columns]\n",
    "print(f\"\\nSample enhanced results:\")\n",
    "print(df[available_cols].head(10))\n",
    "\n",
    "# Show some method examples\n",
    "print(f\"\\nMethod abbreviation examples:\")\n",
    "for i, (primary, variants) in enumerate(list(method_dict.items())[:5]):\n",
    "    print(f\"  {primary}: {', '.join(variants)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "literature-search-and-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
