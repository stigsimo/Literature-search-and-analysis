{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74701ba5",
   "metadata": {},
   "source": [
    "# Software mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4856d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\git_repos\\Literature-search-and-analysis\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "import openai\n",
    "import anthropic\n",
    "import json\n",
    "import time\n",
    "import configparser\n",
    "import tiktoken\n",
    "from typing import List, Dict, Tuple, Optional, Callable\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, asdict\n",
    "import google.generativeai as genai\n",
    "from itertools import combinations\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import traceback\n",
    "import pandas as pd\n",
    "from difflib import get_close_matches, SequenceMatcher\n",
    "\n",
    "\n",
    "output_dir = Path(\"software_analysis_final\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2db008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Initialization functions defined\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# CONFIGURATION & INITIALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "def initialize_openai():\n",
    "    \"\"\"Initialize OpenAI client from config file\"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config_LLM.txt')\n",
    "    api_key = config['LLM'].get('OPENAI_API_KEY')\n",
    "    model_type = config['LLM'].get('MODEL_TYPE_adv', 'gpt-4o-mini')\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    return client, model_type\n",
    "\n",
    "def initialize_anthropic():\n",
    "    \"\"\"Initialize Anthropic client from config file\"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config_LLM.txt')\n",
    "    api_key = config['LLM'].get('ANTHROPIC_API_KEY')\n",
    "    client = anthropic.Anthropic(api_key=api_key) if api_key else None\n",
    "    return client\n",
    "\n",
    "def initialize_google():\n",
    "    \"\"\"Initialize Google Gemini client from config file\"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config_LLM.txt')\n",
    "    api_key = config['LLM'].get('GOOGLE_API_KEY')\n",
    "    if api_key:\n",
    "        genai.configure(api_key=api_key)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "print(\"✓ Initialization functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76adce0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Token counting utilities defined\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# TOKEN COUNTING UTILITIES\n",
    "# =============================================================================\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    \"\"\"Get token count with fallback for unsupported models\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model_name)\n",
    "        return len(encoding.encode(string))\n",
    "    except KeyError:\n",
    "        if model_name.startswith('gpt-5'):\n",
    "            encoding = tiktoken.get_encoding(\"o200k_base\")\n",
    "            return len(encoding.encode(string))\n",
    "        elif model_name.startswith('gpt-4'):\n",
    "            encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "            return len(encoding.encode(string))\n",
    "        elif model_name.startswith('claude'):\n",
    "            return int(len(string) / 3.5)\n",
    "        elif model_name.startswith('models/gemini') or model_name.startswith('gemini'):\n",
    "            return int(len(string) / 4)\n",
    "        else:\n",
    "            return len(string) // 4\n",
    "\n",
    "def count_tokens_in_messages(messages: List[Dict], model: str) -> int:\n",
    "    \"\"\"Count tokens in a list of messages\"\"\"\n",
    "    total_tokens = 0\n",
    "    for message in messages:\n",
    "        if isinstance(message.get('content'), str):\n",
    "            total_tokens += num_tokens_from_string(message['content'], model)\n",
    "        total_tokens += 4  # Message overhead\n",
    "    total_tokens += 3  # Completion overhead\n",
    "    return total_tokens\n",
    "\n",
    "print(\"✓ Token counting utilities defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4092181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CreditTracker class defined\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# CREDIT TRACKER\n",
    "# =============================================================================\n",
    "\n",
    "class CreditTracker:\n",
    "    \"\"\"Track API usage and costs across all models\"\"\"\n",
    "    \n",
    "    PRICING = {\n",
    "        # OpenAI\n",
    "        'gpt-4o': {'input': 1.25, 'output': 5.00},\n",
    "        'gpt-4o-mini': {'input': 0.075, 'output': 0.30},\n",
    "        \n",
    "        # Claude\n",
    "        'claude-3-haiku-20240307': {'input': 0.25, 'output': 1.25},\n",
    "        'claude-3-5-haiku-20241022': {'input': 0.80, 'output': 4.00},\n",
    "        'claude-3-5-sonnet-20241022': {'input': 3.00, 'output': 15.00},\n",
    "        'claude-sonnet-4-20250514': {'input': 3.00, 'output': 15.00},\n",
    "        \n",
    "        # Google\n",
    "        'models/gemini-2.5-flash': {'input': 0.075, 'output': 0.30},\n",
    "        'models/gemini-2.0-flash': {'input': 0.075, 'output': 0.30},\n",
    "        'models/gemini-2.0-flash-001': {'input': 0.075, 'output': 0.30},\n",
    "        'gemini-2.0-flash': {'input': 0.075, 'output': 0.30},\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        self.total_input_tokens = 0\n",
    "        self.total_output_tokens = 0\n",
    "        self.total_cached_tokens = 0\n",
    "        self.total_cost = 0\n",
    "        self.model_usage = {}\n",
    "        self.call_count = 0\n",
    "\n",
    "    def update(self, model: str, input_tokens: int, output_tokens: int, cached_tokens: int = 0):\n",
    "        \"\"\"Update usage statistics\"\"\"\n",
    "        self.total_input_tokens += input_tokens\n",
    "        self.total_output_tokens += output_tokens\n",
    "        self.total_cached_tokens += cached_tokens\n",
    "        self.call_count += 1\n",
    "\n",
    "        pricing = self.PRICING.get(model, {'input': 0.00015, 'output': 0.0006})\n",
    "        \n",
    "        input_cost = (input_tokens / 1_000_000) * pricing['input']\n",
    "        output_cost = (output_tokens / 1_000_000) * pricing['output']\n",
    "        call_cost = input_cost + output_cost\n",
    "        self.total_cost += call_cost\n",
    "\n",
    "        if model not in self.model_usage:\n",
    "            self.model_usage[model] = {\n",
    "                'calls': 0, 'input_tokens': 0, 'output_tokens': 0,\n",
    "                'cached_tokens': 0, 'cost': 0\n",
    "            }\n",
    "\n",
    "        self.model_usage[model]['calls'] += 1\n",
    "        self.model_usage[model]['input_tokens'] += input_tokens\n",
    "        self.model_usage[model]['output_tokens'] += output_tokens\n",
    "        self.model_usage[model]['cached_tokens'] += cached_tokens\n",
    "        self.model_usage[model]['cost'] += call_cost\n",
    "\n",
    "    def get_stats(self):\n",
    "        \"\"\"Get current statistics\"\"\"\n",
    "        return {\n",
    "            \"total_calls\": self.call_count,\n",
    "            \"total_input_tokens\": self.total_input_tokens,\n",
    "            \"total_output_tokens\": self.total_output_tokens,\n",
    "            \"total_tokens\": self.total_input_tokens + self.total_output_tokens,\n",
    "            \"total_cost\": round(self.total_cost, 4),\n",
    "            \"average_cost_per_call\": round(self.total_cost / max(self.call_count, 1), 4),\n",
    "            \"model_breakdown\": {\n",
    "                model: {\n",
    "                    'calls': stats['calls'],\n",
    "                    'total_tokens': stats['input_tokens'] + stats['output_tokens'],\n",
    "                    'cost': round(stats['cost'], 4)\n",
    "                }\n",
    "                for model, stats in self.model_usage.items()\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def print_summary(self):\n",
    "        \"\"\"Print formatted summary\"\"\"\n",
    "        stats = self.get_stats()\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"API USAGE SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Total API Calls: {stats['total_calls']}\")\n",
    "        print(f\"Total Tokens: {stats['total_tokens']:,}\")\n",
    "        print(f\"  - Input: {stats['total_input_tokens']:,}\")\n",
    "        print(f\"  - Output: {stats['total_output_tokens']:,}\")\n",
    "        if self.total_cached_tokens > 0:\n",
    "            print(f\"  - Cached: {self.total_cached_tokens:,}\")\n",
    "        print(f\"\\nTotal Cost: ${stats['total_cost']:.4f}\")\n",
    "        print(f\"Average Cost per Call: ${stats['average_cost_per_call']:.4f}\")\n",
    "\n",
    "        if self.model_usage:\n",
    "            print(\"\\nBreakdown by Model:\")\n",
    "            print(\"-\" * 60)\n",
    "            for model, breakdown in stats['model_breakdown'].items():\n",
    "                print(f\"  {model}:\")\n",
    "                print(f\"    Calls: {breakdown['calls']}\")\n",
    "                print(f\"    Tokens: {breakdown['total_tokens']:,}\")\n",
    "                print(f\"    Cost: ${breakdown['cost']:.4f}\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "print(\"✓ CreditTracker class defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390050ac",
   "metadata": {},
   "source": [
    "## The method assessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0631f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data structures defined\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# DATA STRUCTURES\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class AssessmentResult:\n",
    "    \"\"\"Single LLM assessment result\"\"\"\n",
    "    software: str\n",
    "    method: str\n",
    "    rank: int\n",
    "    reasoning: str\n",
    "    sources: List[str]\n",
    "    llm_provider: str\n",
    "    input_tokens: int = 0\n",
    "    output_tokens: int = 0\n",
    "\n",
    "@dataclass\n",
    "class ConsensusResult:\n",
    "    \"\"\"Consensus across multiple LLMs\"\"\"\n",
    "    software: str\n",
    "    method: str\n",
    "    final_rank: int\n",
    "    confidence: float\n",
    "    individual_ranks: Dict[str, int]\n",
    "    individual_reasoning: Dict[str, str]\n",
    "    individual_sources: Dict[str, List[str]]\n",
    "    agreement_level: str\n",
    "    total_tokens: int = 0\n",
    "    total_cost: float = 0.0\n",
    "\n",
    "print(\"✓ Data structures defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7397873c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SoftwareMethodAssessor class initialized (Part 1)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# MAIN ASSESSOR CLASS - PART 1: Core Functions\n",
    "# =============================================================================\n",
    "\n",
    "class SoftwareMethodAssessor:\n",
    "    \"\"\"Main class for software-method assessment using multiple LLMs\"\"\"\n",
    "    \n",
    "    def __init__(self, use_config: bool = True, timeout: int = 180, max_retries: int = 3):\n",
    "        \"\"\"Initialize assessor with API clients\"\"\"\n",
    "        if use_config:\n",
    "            self.openai_client, self.default_model = initialize_openai()\n",
    "            self.anthropic_client = initialize_anthropic()\n",
    "            self.google_enabled = initialize_google()\n",
    "        else:\n",
    "            self.openai_client = None\n",
    "            self.anthropic_client = None\n",
    "            self.google_enabled = False\n",
    "            self.default_model = \"gpt-4o-mini\"\n",
    "        \n",
    "        self.credit_tracker = CreditTracker()\n",
    "        self.timeout = timeout\n",
    "        self.max_retries = max_retries\n",
    "        \n",
    "        # System prompt for assessments\n",
    "        self.system_prompt = \"\"\"You are a technical software assessment expert specialized in power systems analysis software.\n",
    "\n",
    "Use this ranking scale:\n",
    "0 = No support (method cannot be implemented at all)\n",
    "1 = Limited possibility for implementation or extension (requires significant workarounds)\n",
    "2 = Indirectly supported through APIs or extensions (requires external tools/plugins)\n",
    "3 = Directly implemented (native feature in the software)\n",
    "\n",
    "CRITICAL: You MUST search for and provide actual references. Your assessment must be based on real, verifiable sources.\n",
    "\n",
    "For each assessment:\n",
    "1. Search for scientific papers demonstrating implementation (IEEE Xplore, ScienceDirect, arXiv, Google Scholar)\n",
    "2. Find official documentation from the software vendor or project website\n",
    "3. Look for GitHub repositories with code examples or open-source implementations\n",
    "4. Check API documentation or extension/plugin capabilities\n",
    "5. Review user forums, technical blogs, Stack Overflow, or case studies\n",
    "\n",
    "Return your response in VALID JSON format with this exact structure:\n",
    "{\n",
    "    \"rank\": <0-3>,\n",
    "    \"reasoning\": \"<detailed explanation citing specific sources by number, e.g., 'According to [1], PSS/E supports...'>\",\n",
    "    \"sources\": [\n",
    "        \"https://example.com/documentation - Official PSS/E Manual on OPF\",\n",
    "        \"https://doi.org/10.1109/... - Paper title by Author et al.\",\n",
    "        \"https://github.com/org/repo/file.py - Implementation example\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "Each source must include both the URL and a brief description separated by ' - '.\n",
    "Minimum 2 sources required for ranks 2-3, minimum 1 source for rank 1.\"\"\"\n",
    "\n",
    "    def calculate_confidence(self, ranks: List[int]) -> Tuple[float, str]:\n",
    "        \"\"\"Calculate confidence score from multiple assessments\"\"\"\n",
    "        if not ranks:\n",
    "            return 0.0, \"no_data\"\n",
    "        \n",
    "        rank_counts = Counter(ranks)\n",
    "        most_common_count = rank_counts.most_common(1)[0][1]\n",
    "        total_ranks = len(ranks)\n",
    "        confidence = most_common_count / total_ranks\n",
    "        \n",
    "        if total_ranks == 1:\n",
    "            agreement_level = \"single_assessment\"\n",
    "        elif confidence == 1.0:\n",
    "            agreement_level = \"perfect_agreement\"\n",
    "        elif confidence >= 0.75:\n",
    "            agreement_level = \"strong_agreement\"\n",
    "        elif confidence >= 0.5:\n",
    "            agreement_level = \"moderate_agreement\"\n",
    "        else:\n",
    "            agreement_level = \"weak_agreement\"\n",
    "        \n",
    "        return confidence, agreement_level\n",
    "\n",
    "    def export_results(self, results: List[ConsensusResult], filename: str):\n",
    "        \"\"\"Export results to JSON file\"\"\"\n",
    "        output_data = [asdict(result) for result in results]\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(output_data, f, indent=2)\n",
    "        print(f\"\\nResults exported to {filename}\")\n",
    "\n",
    "print(\"✓ SoftwareMethodAssessor class initialized (Part 1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2debcef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Batch prompt creation added\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# MAIN ASSESSOR CLASS - PART 2: Batch Assessment Methods\n",
    "# =============================================================================\n",
    "\n",
    "def create_batch_assessment_prompt(self, batch_items: List[Tuple[str, str]], batch_size: int = None) -> str:\n",
    "    \"\"\"Create a structured prompt for batch assessment\"\"\"\n",
    "    batch_size = batch_size or len(batch_items)\n",
    "    \n",
    "    items_text = \"\"\n",
    "    for idx, (software, method) in enumerate(batch_items, 1):\n",
    "        items_text += f\"\\n{idx}. Software: {software}\\n   Method: {method}\\n\"\n",
    "    \n",
    "    prompt = f\"\"\"You must assess {len(batch_items)} software-method combinations independently.\n",
    "\n",
    "CRITICAL INSTRUCTIONS:\n",
    "- Treat each pair as completely independent\n",
    "- Do NOT let one assessment influence another\n",
    "- Provide the SAME quality of research and reasoning for ALL items\n",
    "- Each assessment must have its own sources\n",
    "\n",
    "Items to assess:{items_text}\n",
    "\n",
    "For EACH item above, perform independent research and provide sources with URLs.\n",
    "\n",
    "Return a JSON array with exactly {len(batch_items)} objects:\n",
    "[\n",
    "  {{\n",
    "    \"software\": \"<software name>\",\n",
    "    \"method\": \"<method name>\",\n",
    "    \"rank\": <0-3>,\n",
    "    \"reasoning\": \"<detailed explanation citing sources [1], [2], etc.>\",\n",
    "    \"sources\": [\n",
    "      \"https://... - Description\",\n",
    "      \"https://... - Description\"\n",
    "    ]\n",
    "  }},\n",
    "  ...\n",
    "]\n",
    "\n",
    "IMPORTANT: Return ONLY the JSON array, no other text.\"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Add to SoftwareMethodAssessor class\n",
    "SoftwareMethodAssessor.create_batch_assessment_prompt = create_batch_assessment_prompt\n",
    "\n",
    "print(\"✓ Batch prompt creation added\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37795839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenAI assessment method added\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# OPENAI ASSESSMENT METHOD\n",
    "# =============================================================================\n",
    "\n",
    "def assess_batch_with_openai(self, batch_items: List[Tuple[str, str]], \n",
    "                             model: str = None, debug: bool = False) -> List[AssessmentResult]:\n",
    "    \"\"\"Assess a batch of items with OpenAI\"\"\"\n",
    "    if model is None:\n",
    "        model = self.default_model\n",
    "    \n",
    "    try:\n",
    "        prompt = self.create_batch_assessment_prompt(batch_items)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  DEBUG: Batch size: {len(batch_items)}\")\n",
    "        \n",
    "        response = self.openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0.3,\n",
    "            max_tokens=4096,\n",
    "            timeout=self.timeout,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        usage = response.usage\n",
    "        cached_tokens = 0\n",
    "        if hasattr(usage, 'prompt_tokens_details') and usage.prompt_tokens_details:\n",
    "            cached_tokens = getattr(usage.prompt_tokens_details, 'cached_tokens', 0)\n",
    "        \n",
    "        self.credit_tracker.update(\n",
    "            model=model,\n",
    "            input_tokens=usage.prompt_tokens,\n",
    "            output_tokens=usage.completion_tokens,\n",
    "            cached_tokens=cached_tokens\n",
    "        )\n",
    "        \n",
    "        content = response.choices[0].message.content\n",
    "        \n",
    "        # Parse JSON\n",
    "        try:\n",
    "            parsed = json.loads(content)\n",
    "            if isinstance(parsed, dict):\n",
    "                if 'assessments' in parsed:\n",
    "                    results_data = parsed['assessments']\n",
    "                elif 'results' in parsed:\n",
    "                    results_data = parsed['results']\n",
    "                else:\n",
    "                    results_data = next(v for v in parsed.values() if isinstance(v, list))\n",
    "            else:\n",
    "                results_data = parsed\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR parsing batch response: {e}\")\n",
    "            return []\n",
    "        \n",
    "        # Convert to AssessmentResult objects\n",
    "        assessment_results = []\n",
    "        for item_data in results_data:\n",
    "            rank = int(item_data.get(\"rank\", 0))\n",
    "            sources = item_data.get(\"sources\", [])\n",
    "            reasoning = item_data.get(\"reasoning\", \"\")\n",
    "            \n",
    "            if rank > 0 and len(sources) == 0:\n",
    "                rank = 0\n",
    "                reasoning += \" [Rank lowered to 0: no sources]\"\n",
    "            \n",
    "            assessment_results.append(AssessmentResult(\n",
    "                software=item_data.get(\"software\", \"\"),\n",
    "                method=item_data.get(\"method\", \"\"),\n",
    "                rank=rank,\n",
    "                reasoning=reasoning,\n",
    "                sources=sources,\n",
    "                llm_provider=f\"openai_{model}\",\n",
    "                input_tokens=usage.prompt_tokens // len(batch_items),\n",
    "                output_tokens=usage.completion_tokens // len(batch_items)\n",
    "            ))\n",
    "        \n",
    "        return assessment_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR in OpenAI batch assessment: {e}\")\n",
    "        return []\n",
    "\n",
    "# Add to class\n",
    "SoftwareMethodAssessor.assess_batch_with_openai = assess_batch_with_openai\n",
    "\n",
    "print(\"✓ OpenAI assessment method added\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31f626ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Claude assessment method added\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# CLAUDE ASSESSMENT METHOD\n",
    "# =============================================================================\n",
    "\n",
    "def assess_batch_with_claude(self, batch_items: List[Tuple[str, str]], \n",
    "                             model: str = \"claude-3-5-haiku-20241022\", \n",
    "                             debug: bool = False) -> List[AssessmentResult]:\n",
    "    \"\"\"Assess a batch of items with Claude\"\"\"\n",
    "    if not self.anthropic_client:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        prompt = self.create_batch_assessment_prompt(batch_items)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  DEBUG: Batch size: {len(batch_items)}\")\n",
    "        \n",
    "        response = self.anthropic_client.messages.create(\n",
    "            model=model,\n",
    "            max_tokens=4096,\n",
    "            temperature=0.3,\n",
    "            timeout=self.timeout,\n",
    "            system=self.system_prompt,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        self.credit_tracker.update(\n",
    "            model=model,\n",
    "            input_tokens=response.usage.input_tokens,\n",
    "            output_tokens=response.usage.output_tokens\n",
    "        )\n",
    "        \n",
    "        content = response.content[0].text\n",
    "        \n",
    "        # Clean markdown code blocks\n",
    "        content = content.strip()\n",
    "        if content.startswith('```'):\n",
    "            lines = content.split('\\n')\n",
    "            start_idx = 0\n",
    "            end_idx = len(lines)\n",
    "            for i, line in enumerate(lines):\n",
    "                if line.strip().startswith('```'):\n",
    "                    if start_idx == 0:\n",
    "                        start_idx = i + 1\n",
    "                    else:\n",
    "                        end_idx = i\n",
    "                        break\n",
    "            content = '\\n'.join(lines[start_idx:end_idx])\n",
    "        \n",
    "        # Parse JSON\n",
    "        try:\n",
    "            parsed = json.loads(content)\n",
    "            if isinstance(parsed, dict):\n",
    "                if 'assessments' in parsed:\n",
    "                    results_data = parsed['assessments']\n",
    "                elif 'results' in parsed:\n",
    "                    results_data = parsed['results']\n",
    "                else:\n",
    "                    results_data = next(v for v in parsed.values() if isinstance(v, list))\n",
    "            else:\n",
    "                results_data = parsed\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR parsing Claude batch response: {e}\")\n",
    "            return []\n",
    "        \n",
    "        # Convert to AssessmentResult objects\n",
    "        assessment_results = []\n",
    "        for item_data in results_data:\n",
    "            rank = int(item_data.get(\"rank\", 0))\n",
    "            sources = item_data.get(\"sources\", [])\n",
    "            reasoning = item_data.get(\"reasoning\", \"\")\n",
    "            \n",
    "            if rank > 0 and len(sources) == 0:\n",
    "                rank = 0\n",
    "                reasoning += \" [Rank lowered to 0: no sources]\"\n",
    "            \n",
    "            assessment_results.append(AssessmentResult(\n",
    "                software=item_data.get(\"software\", \"\"),\n",
    "                method=item_data.get(\"method\", \"\"),\n",
    "                rank=rank,\n",
    "                reasoning=reasoning,\n",
    "                sources=sources,\n",
    "                llm_provider=f\"claude_{model}\",\n",
    "                input_tokens=response.usage.input_tokens // len(batch_items),\n",
    "                output_tokens=response.usage.output_tokens // len(batch_items)\n",
    "            ))\n",
    "        \n",
    "        return assessment_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR in Claude batch assessment: {e}\")\n",
    "        return []\n",
    "\n",
    "# Add to class\n",
    "SoftwareMethodAssessor.assess_batch_with_claude = assess_batch_with_claude\n",
    "\n",
    "print(\"✓ Claude assessment method added\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a212a3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Google assessment method added\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# GOOGLE ASSESSMENT METHOD\n",
    "# =============================================================================\n",
    "\n",
    "def assess_batch_with_google(self, batch_items: List[Tuple[str, str]], \n",
    "                             model: str = \"models/gemini-2.0-flash\", \n",
    "                             debug: bool = False) -> List[AssessmentResult]:\n",
    "    \"\"\"Assess a batch of items with Google Gemini\"\"\"\n",
    "    if not self.google_enabled:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        prompt = self.create_batch_assessment_prompt(batch_items)\n",
    "        \n",
    "        if not model.startswith('models/'):\n",
    "            model = f\"models/{model}\"\n",
    "        \n",
    "        gemini_model = genai.GenerativeModel(\n",
    "            model_name=model,\n",
    "            generation_config={\n",
    "                \"temperature\": 0.3,\n",
    "                \"max_output_tokens\": 4096,\n",
    "            },\n",
    "            system_instruction=self.system_prompt\n",
    "        )\n",
    "        \n",
    "        response = gemini_model.generate_content(\n",
    "            prompt,\n",
    "            generation_config={\n",
    "                \"temperature\": 0.3,\n",
    "                \"max_output_tokens\": 4096,\n",
    "            },\n",
    "            request_options={'timeout': self.timeout}\n",
    "        )\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  DEBUG: Successfully used model: {model}\")\n",
    "        \n",
    "        # Extract token counts\n",
    "        try:\n",
    "            input_tokens = response.usage_metadata.prompt_token_count\n",
    "            output_tokens = response.usage_metadata.candidates_token_count\n",
    "        except AttributeError:\n",
    "            input_tokens = int(len(prompt.split()) * 1.3)\n",
    "            output_tokens = int(len(response.text.split()) * 1.3)\n",
    "        \n",
    "        self.credit_tracker.update(\n",
    "            model=model,\n",
    "            input_tokens=int(input_tokens),\n",
    "            output_tokens=int(output_tokens)\n",
    "        )\n",
    "        \n",
    "        content = response.text.strip()\n",
    "        \n",
    "        # Clean markdown\n",
    "        if content.startswith('```'):\n",
    "            lines = content.split('\\n')\n",
    "            start_idx = 0\n",
    "            end_idx = len(lines)\n",
    "            for i, line in enumerate(lines):\n",
    "                if line.strip().startswith('```'):\n",
    "                    if start_idx == 0:\n",
    "                        start_idx = i + 1\n",
    "                    else:\n",
    "                        end_idx = i\n",
    "                        break\n",
    "            content = '\\n'.join(lines[start_idx:end_idx])\n",
    "        \n",
    "        # Parse JSON\n",
    "        try:\n",
    "            parsed = json.loads(content)\n",
    "            if isinstance(parsed, dict):\n",
    "                if 'assessments' in parsed:\n",
    "                    results_data = parsed['assessments']\n",
    "                elif 'results' in parsed:\n",
    "                    results_data = parsed['results']\n",
    "                else:\n",
    "                    results_data = next(v for v in parsed.values() if isinstance(v, list))\n",
    "            else:\n",
    "                results_data = parsed\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR parsing Google batch response: {e}\")\n",
    "            return []\n",
    "        \n",
    "        # Convert to AssessmentResult objects\n",
    "        assessment_results = []\n",
    "        for item_data in results_data:\n",
    "            rank = int(item_data.get(\"rank\", 0))\n",
    "            sources = item_data.get(\"sources\", [])\n",
    "            reasoning = item_data.get(\"reasoning\", \"\")\n",
    "            \n",
    "            if rank > 0 and len(sources) == 0:\n",
    "                rank = 0\n",
    "                reasoning += \" [Rank lowered to 0: no sources]\"\n",
    "            \n",
    "            assessment_results.append(AssessmentResult(\n",
    "                software=item_data.get(\"software\", \"\"),\n",
    "                method=item_data.get(\"method\", \"\"),\n",
    "                rank=rank,\n",
    "                reasoning=reasoning,\n",
    "                sources=sources,\n",
    "                llm_provider=f\"google_{model.replace('models/', '')}\",\n",
    "                input_tokens=int(input_tokens) // len(batch_items),\n",
    "                output_tokens=int(output_tokens) // len(batch_items)\n",
    "            ))\n",
    "        \n",
    "        return assessment_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR in Google batch assessment: {e}\")\n",
    "        return []\n",
    "\n",
    "# Add to class\n",
    "SoftwareMethodAssessor.assess_batch_with_google = assess_batch_with_google\n",
    "\n",
    "print(\"✓ Google assessment method added\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fe144c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Batch creation method corrected\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# BATCH CREATION METHOD (CORRECTED)\n",
    "# =============================================================================\n",
    "\n",
    "def create_batches(self, software_list: List[str], method_list: List[str],\n",
    "                  strategy: str = \"by_software\", batch_size: int = 50) -> List[List[Tuple[str, str]]]:\n",
    "    \"\"\"\n",
    "    Create batches of (software, method) pairs\n",
    "    \n",
    "    Args:\n",
    "        software_list: List of software names\n",
    "        method_list: List of methods\n",
    "        strategy: Batching strategy\n",
    "        batch_size: Size for fixed_size batching\n",
    "    \n",
    "    Returns:\n",
    "        List of batches\n",
    "    \"\"\"\n",
    "    batches = []\n",
    "    \n",
    "    if strategy == \"by_software\":\n",
    "        # One batch per software with all its methods\n",
    "        for software in software_list:\n",
    "            batch = [(software, method) for method in method_list]\n",
    "            batches.append(batch)\n",
    "    \n",
    "    elif strategy == \"by_method\":\n",
    "        # One batch per method with all software\n",
    "        for method in method_list:\n",
    "            batch = [(software, method) for software in software_list]\n",
    "            batches.append(batch)\n",
    "    \n",
    "    elif strategy == \"mixed\":\n",
    "        # Alternate between by_software and by_method\n",
    "        for i, software in enumerate(software_list[:len(software_list)//2 + 1]):\n",
    "            batch = [(software, method) for method in method_list]\n",
    "            batches.append(batch)\n",
    "        for method in method_list:\n",
    "            batch = [(software, method) for software in software_list[len(software_list)//2 + 1:]]\n",
    "            if batch:\n",
    "                batches.append(batch)\n",
    "    \n",
    "    elif strategy == \"fixed_size\":\n",
    "        # Create fixed-size batches across all pairs\n",
    "        all_items = [(sw, method) for sw in software_list for method in method_list]\n",
    "        # ↓↓↓ THIS IS THE FIX ↓↓↓\n",
    "        for i in range(0, len(all_items), batch_size):\n",
    "            batch = all_items[i:i + batch_size]\n",
    "            batches.append(batch)\n",
    "        # ↑↑↑ THIS IS THE FIX ↑↑↑\n",
    "    \n",
    "    return batches\n",
    "\n",
    "# Add to class\n",
    "SoftwareMethodAssessor.create_batches = create_batches\n",
    "\n",
    "print(\"✓ Batch creation method corrected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdb48282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Main batched assessment method added\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# MAIN BATCHED ASSESSMENT METHOD\n",
    "# =============================================================================\n",
    "\n",
    "def assess_multiple_batched(self, software_list: List[str], method_list: List[str],\n",
    "                           batch_strategy: str = \"by_software\",\n",
    "                           batch_size: int = 100,\n",
    "                           overlap_percentage: float = 0.0,\n",
    "                           use_openai: bool = True,\n",
    "                           use_claude: bool = True,\n",
    "                           use_google: bool = True,\n",
    "                           openai_model: str = None,\n",
    "                           claude_model: str = \"claude-3-5-haiku-20241022\",\n",
    "                           google_model: str = \"models/gemini-2.0-flash\",\n",
    "                           debug: bool = False) -> List[ConsensusResult]:\n",
    "    \"\"\"\n",
    "    Assess multiple software-method combinations using batch processing\n",
    "    \"\"\"\n",
    "    total_items = len(software_list) * len(method_list)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"BATCH ASSESSMENT MODE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total items: {total_items}\")\n",
    "    print(f\"Strategy: {batch_strategy}\")\n",
    "    print(f\"LLMs: OpenAI={use_openai}, Claude={use_claude}, Google={use_google}\")\n",
    "    \n",
    "    # Create batches\n",
    "    batches = self.create_batches(software_list, method_list, batch_strategy)\n",
    "    \n",
    "    print(f\"\\nCreated {len(batches)} batches\")\n",
    "    for i, batch in enumerate(batches, 1):\n",
    "        print(f\"  Batch {i}: {len(batch)} items\")\n",
    "    \n",
    "    # Store all individual assessments\n",
    "    all_assessments = {}  # (software, method) -> list of AssessmentResult\n",
    "    \n",
    "    print(f\"\\n{'-'*70}\")\n",
    "    print(f\"Processing batches...\")\n",
    "    print(f\"{'-'*70}\")\n",
    "    \n",
    "    # Process each batch with each LLM\n",
    "    for batch_idx, batch in enumerate(batches, 1):\n",
    "        print(f\"\\n[Batch {batch_idx}/{len(batches)}] {len(batch)} items\")\n",
    "        \n",
    "        batch_results = []\n",
    "        \n",
    "        if use_openai and self.openai_client:\n",
    "            print(f\"  Assessing with OpenAI...\")\n",
    "            results = self.assess_batch_with_openai(batch, openai_model, debug)\n",
    "            batch_results.extend(results)\n",
    "            time.sleep(1)\n",
    "        \n",
    "        if use_claude and self.anthropic_client:\n",
    "            print(f\"  Assessing with Claude...\")\n",
    "            results = self.assess_batch_with_claude(batch, claude_model, debug)\n",
    "            batch_results.extend(results)\n",
    "            time.sleep(1)\n",
    "        \n",
    "        if use_google and self.google_enabled:\n",
    "            print(f\"  Assessing with Google...\")\n",
    "            results = self.assess_batch_with_google(batch, google_model, debug)\n",
    "            batch_results.extend(results)\n",
    "            time.sleep(1)\n",
    "        \n",
    "        # Store results\n",
    "        for result in batch_results:\n",
    "            key = (result.software, result.method)\n",
    "            if key not in all_assessments:\n",
    "                all_assessments[key] = []\n",
    "            all_assessments[key].append(result)\n",
    "        \n",
    "        # Show progress\n",
    "        stats = self.credit_tracker.get_stats()\n",
    "        print(f\"  Running cost: ${stats['total_cost']:.4f} ({stats['total_tokens']:,} tokens)\")\n",
    "    \n",
    "    # Create consensus results\n",
    "    print(f\"\\n{'-'*70}\")\n",
    "    print(f\"Creating consensus results...\")\n",
    "    print(f\"{'-'*70}\")\n",
    "    \n",
    "    consensus_results = []\n",
    "    \n",
    "    for (software, method), assessments in all_assessments.items():\n",
    "        if len(assessments) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Group by LLM provider (handle duplicates)\n",
    "        by_provider = {}\n",
    "        for assessment in assessments:\n",
    "            if assessment.llm_provider not in by_provider:\n",
    "                by_provider[assessment.llm_provider] = assessment\n",
    "        \n",
    "        assessments = list(by_provider.values())\n",
    "        \n",
    "        ranks = [a.rank for a in assessments]\n",
    "        confidence, agreement_level = self.calculate_confidence(ranks)\n",
    "        \n",
    "        rank_counts = Counter(ranks)\n",
    "        final_rank = rank_counts.most_common(1)[0][0]\n",
    "        \n",
    "        individual_ranks = {a.llm_provider: a.rank for a in assessments}\n",
    "        individual_reasoning = {a.llm_provider: a.reasoning for a in assessments}\n",
    "        individual_sources = {a.llm_provider: a.sources for a in assessments}\n",
    "        \n",
    "        total_tokens = sum(a.input_tokens + a.output_tokens for a in assessments)\n",
    "        \n",
    "        # Calculate cost\n",
    "        total_cost = sum([\n",
    "            self.credit_tracker.PRICING.get(\n",
    "                a.llm_provider.replace('openai_', '').replace('claude_', '').replace('google_', ''),\n",
    "                {'input': 0, 'output': 0}\n",
    "            )['input'] * a.input_tokens / 1_000_000 +\n",
    "            self.credit_tracker.PRICING.get(\n",
    "                a.llm_provider.replace('openai_', '').replace('claude_', '').replace('google_', ''),\n",
    "                {'input': 0, 'output': 0}\n",
    "            )['output'] * a.output_tokens / 1_000_000\n",
    "            for a in assessments\n",
    "        ])\n",
    "        \n",
    "        consensus_results.append(ConsensusResult(\n",
    "            software=software,\n",
    "            method=method,\n",
    "            final_rank=final_rank,\n",
    "            confidence=confidence,\n",
    "            individual_ranks=individual_ranks,\n",
    "            individual_reasoning=individual_reasoning,\n",
    "            individual_sources=individual_sources,\n",
    "            agreement_level=agreement_level,\n",
    "            total_tokens=total_tokens,\n",
    "            total_cost=total_cost\n",
    "        ))\n",
    "    \n",
    "    print(f\"\\nCompleted {len(consensus_results)} assessments\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return consensus_results\n",
    "\n",
    "# Add to class\n",
    "SoftwareMethodAssessor.assess_multiple_batched = assess_multiple_batched\n",
    "\n",
    "print(\"✓ Main batched assessment method added\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cccc9c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Result merger added\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# RESULT MERGER\n",
    "# =============================================================================\n",
    "\n",
    "def merge_assessment_results(self, *result_files: str, output_file: str = \"merged_results.json\",\n",
    "                            merge_strategy: str = \"union\") -> List[ConsensusResult]:\n",
    "    \"\"\"\n",
    "    Merge multiple assessment result JSON files\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"MERGING ASSESSMENT RESULTS\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Strategy: {merge_strategy}\")\n",
    "    print(f\"Input files: {len(result_files)}\")\n",
    "    \n",
    "    merged_data = {}\n",
    "    \n",
    "    for file_idx, file_path in enumerate(result_files, 1):\n",
    "        print(f\"\\nProcessing file {file_idx}/{len(result_files)}: {file_path}\")\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                results = json.load(f)\n",
    "            \n",
    "            print(f\"  Loaded {len(results)} assessments\")\n",
    "            \n",
    "            for result in results:\n",
    "                software = result['software']\n",
    "                method = result['method']\n",
    "                key = (software, method)\n",
    "                \n",
    "                if key not in merged_data:\n",
    "                    merged_data[key] = result\n",
    "                else:\n",
    "                    # Merge: combine all LLM assessments\n",
    "                    merged_data[key]['individual_ranks'].update(result['individual_ranks'])\n",
    "                    merged_data[key]['individual_reasoning'].update(result['individual_reasoning'])\n",
    "                    merged_data[key]['individual_sources'].update(result['individual_sources'])\n",
    "                    merged_data[key]['total_tokens'] += result['total_tokens']\n",
    "                    merged_data[key]['total_cost'] += result['total_cost']\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR loading {file_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Recalculate consensus\n",
    "    print(f\"\\nRecalculating consensus for merged results...\")\n",
    "    merged_results_list = list(merged_data.values())\n",
    "    \n",
    "    for result in merged_results_list:\n",
    "        ranks = list(result['individual_ranks'].values())\n",
    "        rank_counts = Counter(ranks)\n",
    "        result['final_rank'] = rank_counts.most_common(1)[0][0]\n",
    "        \n",
    "        # Calculate confidence\n",
    "        most_common_count = rank_counts.most_common(1)[0][1]\n",
    "        result['confidence'] = most_common_count / len(ranks)\n",
    "        \n",
    "        if result['confidence'] == 1.0:\n",
    "            result['agreement_level'] = \"perfect_agreement\"\n",
    "        elif result['confidence'] >= 0.75:\n",
    "            result['agreement_level'] = \"strong_agreement\"\n",
    "        elif result['confidence'] >= 0.5:\n",
    "            result['agreement_level'] = \"moderate_agreement\"\n",
    "        else:\n",
    "            result['agreement_level'] = \"weak_agreement\"\n",
    "    \n",
    "    # Save merged results\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(merged_results_list, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n✓ Merged results saved to: {output_file}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Convert to ConsensusResult objects\n",
    "    consensus_results = []\n",
    "    for result in merged_results_list:\n",
    "        consensus_results.append(ConsensusResult(\n",
    "            software=result['software'],\n",
    "            method=result['method'],\n",
    "            final_rank=result['final_rank'],\n",
    "            confidence=result['confidence'],\n",
    "            individual_ranks=result['individual_ranks'],\n",
    "            individual_reasoning=result['individual_reasoning'],\n",
    "            individual_sources=result['individual_sources'],\n",
    "            agreement_level=result['agreement_level'],\n",
    "            total_tokens=result['total_tokens'],\n",
    "            total_cost=result['total_cost']\n",
    "        ))\n",
    "    \n",
    "    return consensus_results\n",
    "\n",
    "# Add to class\n",
    "SoftwareMethodAssessor.merge_assessment_results = merge_assessment_results\n",
    "\n",
    "print(\"✓ Result merger added\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "822fb865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# LOAD METHOD LIST FROM JSON\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def load_method_list(json_file: str = \"method_variant_groups.json\") -> list:\n",
    "    \"\"\"\n",
    "    Load canonical method names from variant groups JSON\n",
    "    \n",
    "    Args:\n",
    "        json_file: Path to method variant groups JSON file\n",
    "        \n",
    "    Returns:\n",
    "        List of canonical method names (the keys from JSON)\n",
    "    \"\"\"\n",
    "    json_path = Path(json_file)\n",
    "    \n",
    "    if not json_path.exists():\n",
    "        raise FileNotFoundError(f\"Method groups file not found: {json_file}\")\n",
    "    \n",
    "    # Load JSON and extract keys\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        method_groups = json.load(f)\n",
    "    \n",
    "    # The keys are the canonical method names\n",
    "    method_list = list(method_groups.keys())\n",
    "    \n",
    "    print(f\"✓ Loaded {len(method_list)} methods from: {json_file}\")\n",
    "    \n",
    "    return method_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf323714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 36 software\n",
      "✓ Loaded 189 methods\n",
      "✓ Total pairs to assess: 6804\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# LOAD YOUR SOFTWARE AND METHOD LISTS\n",
    "# =============================================================================\n",
    "\n",
    "# Replace with your actual data loading\n",
    "# Example:\n",
    "# software_list_all = pd.read_csv('software_list.csv')['Name'].tolist()\n",
    "# method_list_all = pd.read_csv('method_list.csv')['Method'].tolist()\n",
    "\n",
    "\n",
    "software_list_all = [\n",
    "    'Power Factory Digisilent','DINIS','ERACS','Distribution Network Analysis - ETAP','IPSA',\n",
    "'Power World','PSS/E','PSSE/SINCAL','SKM Power Tools','OpenDSS','Matlab & Simulink','DYMOLA','MathPower',\n",
    "'RelyPES','GridLAB-D','PyPSA (Python for Power System Analysis)','TARA','PyPower/Pandapower','GridCal Sk','MatDyn',\n",
    "'NEPLAN','PSAT','CYMEDIST','Synergi Electric','Dynawo','OpenModellica',\n",
    "'Sienna(PowerModels.jl PowerSystems.jl & PowerSimulations.jl PowerFlows.jl)','POWSYBL','Hitachi Network Manager','Spectrum Power',\n",
    "'CIMPLICITY Scada','eTerra','Netbas','Trimble NIS','GAMS','Promaps'\n",
    "]\n",
    "\n",
    "method_list_all = [\n",
    "'power flow analysis','security-constrained optimal power flow','security constrained unit commitment',\n",
    "'Non Linear Optimal Power Flow','Multi-Period  Optimisation ','unit commitment','genetic algorithm','neural network',\n",
    "'kalman filter','monte-carlo','random forest','deep-learning','particle swarm optimization','fuzzy logic','time series',\n",
    "'artificial bee colony','stochastic simulation','fault analysis','reinforcement learning','linear programming','mixed integer linear programming',\n",
    "'support vector machine','ensemble-learning','graph-neural network','numerical solvers','global optimization','economic dispatch ED',\n",
    "'probabilistic-forecasting','General Optimization','data envelopment analysis','machine learning','deep neural network','voltage stability',\n",
    "'probabilistic analysis','real-time data analysis','optimal power flow','demand response','optimal capacity configuration','sensitivity analysis',\n",
    "'sequential monte carlo','fuzzy logic','load forecasting','load balancing','power forecasting','state estimation','hosting capacity',\n",
    "'error estimation techniques','stochastic model','failure modeling','loss of load expectancy','system identification','economic dispatch',\n",
    "'time series analysis','multi-objective optimization','expected energy not served','power system flexibility','decision tree',\n",
    "'contingency analysis','load frequency control','power factor correction','voltage control strategy','multi-agent system',\n",
    "'system average interruption duration index','dynamic line rating','static var compensator','dynamic programming','model predictive control',\n",
    "'k-means clustering','linear regression','principal component analysis','fault detection classification',\n",
    "'system average interruption frequency index','stochastic optimization','cost-benefit analysis','fuzzy inference system',\n",
    "'differential evolution','multi-state model','fault tree analysis','reliability economics','short-term load forecasting',\n",
    "'dynamic voltage restorer','dynamic reactive power compensation','shunt active power filter','fault detection diagnosis',\n",
    "'phase-locked loop','power system restoration','load carrying capability elcc','wind power prediction','discrete wavelet transform',\n",
    "'dynamic resource allocation','space vector pulse width modulation','logistic regression','game theory','binary particle swarm',\n",
    "'power system stabilizer','firefly algorithm','sliding mode control','modified ieee rts','heuristic optimization','partial discharge pd',\n",
    "'stochastic programming','simulated annealing','support vector regression','two-stage stochastic','adaptive neuro-fuzzy inference',\n",
    "'predictive modeling','short-term memory lstm network','load shifting','cuckoo search','automatic generation control agc','quantum computing',\n",
    "'power quality disturbance','doubly-fed induction','convolutional neural network cnns','empirical mode decomposition','evolution algorithm',\n",
    "'deep reinforcement learning drl','minimal cut set','tabu search','generative adversarial network','gated recurrent unit',\n",
    "'approximate computing','demand side management dsm','frequency variation','markov chain monte carlo','ant colony optimization',\n",
    "'predictive controller','multi-objective particle swarm optimization','power generation modeling','quantile regression','dynamic pricing',\n",
    "'wavelet transform dwt','modal analysis','power quality assessment','reactive power sharing','quadratic programming','stochastic unit commitment',\n",
    "'interior point method','process regression','second-order cone','energy resilience analysis','metaheuristics','bayesian optimization',\n",
    "'clustering analysis','power transfer distribution factor','harmony search','optimization gwo','fuzzy comprehensive evaluation',\n",
    "'deep deterministic','gaussian process regression','svd','bat algorithm','cumulative distribution function','deep deterministic policy gradient',\n",
    "'genetic programming','sequential quadratic programming','energy demand forecasting','supply chain optimization','levelized cost of energy lcoe',\n",
    "'frequency nadir','multi-output','hybrid system modeling','proton exchange membrane','hybrid acdc microgrid','multiple-input-multiple-output mimo',\n",
    "'alternating direction method','hybrid optimization model','load shedding analysis','non-dominated sorting genetic','deep q-network',\n",
    "'line outage distribution factor','multi-criteria decision analysis','closed-form expression','energy transition modeling','point estimate method',\n",
    "'signal noise ratio','agent-based modeling','environmental impact assessment','data-driven optimization','energy consumption modeling',\n",
    "'state-space modeling','quadrature pase shift keying','multi-fidelity model','stochastic geometry','quadrature amplitude modulation',\n",
    "'orthogonal frequency-division multiplexing','minimum mean square','adaptive modulation','error rate ber performance', ]\n",
    "\n",
    "print(f\"✓ Loaded {len(software_list_all)} software\")\n",
    "print(f\"✓ Loaded {len(method_list_all)} methods\")\n",
    "print(f\"✓ Total pairs to assess: {len(software_list_all) * len(method_list_all)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e10bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RUN 1: OpenAI + Google (batch_size=20)\n",
      "======================================================================\n",
      "Total pairs: 6615\n",
      "Total batches: 331\n",
      "Expected time: 6-8 hours\n",
      "======================================================================\n",
      "\n",
      "[Batch 1/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 190 column 18 (char 17028)\n",
      " ✓ 0\n",
      "[Batch 2/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 192 column 18 (char 18012)\n",
      " ✓ 0\n",
      "[Batch 3/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 4/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 180 column 5 (char 17366)\n",
      " ✓ 0\n",
      "[Batch 5/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 6/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 7/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 179 column 7 (char 18159)\n",
      " ✓ 0\n",
      "[Batch 8/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 175 column 574 (char 17896)\n",
      " ✓ 0\n",
      "[Batch 9/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 166 column 5 (char 17782)\n",
      " ✓ 0\n",
      "[Batch 10/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 16738)\n",
      " ✓ 0\n",
      "  Progress: $0.02 | 199 unique pairs\n",
      "[Batch 11/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 12/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 176 column 18 (char 18643)\n",
      " ✓ 0\n",
      "[Batch 13/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 14/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 15/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 192 column 4 (char 16876)\n",
      " ✓ 0\n",
      "[Batch 16/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 17/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 18/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 19/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 20/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.04 | 400 unique pairs\n",
      "[Batch 21/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 22/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 17518)\n",
      " ✓ 0\n",
      "[Batch 23/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 24/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting value: line 187 column 15 (char 18091)\n",
      " ✓ 0\n",
      "[Batch 25/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 15660)\n",
      " ✓ 0\n",
      "[Batch 26/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 27/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 28/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 176 column 18 (char 17647)\n",
      " ✓ 0\n",
      "[Batch 29/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 30/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.06 | 620 unique pairs\n",
      "[Batch 31/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 17687)\n",
      " ✓ 0\n",
      "[Batch 32/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 33/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 34/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 35/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 36/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 37/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 179 column 7 (char 16462)\n",
      " ✓ 0\n",
      "[Batch 38/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 39/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 40/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.08 | 935 unique pairs\n",
      "[Batch 41/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 42/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 43/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting value: line 197 column 17 (char 17352)\n",
      " ✓ 0\n",
      "[Batch 44/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 45/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 185 column 5 (char 17165)\n",
      " ✓ 0\n",
      "[Batch 46/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 47/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 17225)\n",
      " ✓ 0\n",
      "[Batch 48/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 49/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 7 (char 17854)\n",
      " ✓ 0\n",
      "[Batch 50/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.10 | 1135 unique pairs\n",
      "  💾 Checkpoint saved: checkpoint_50.pkl\n",
      "[Batch 51/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 182 column 7 (char 17623)\n",
      " ✓ 0\n",
      "[Batch 52/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 53/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 54/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 55/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 56/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 57/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 198 column 7 (char 16977)\n",
      " ✓ 0\n",
      "[Batch 58/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 59/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 190 column 18 (char 15749)\n",
      " ✓ 0\n",
      "[Batch 60/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 171 column 7 (char 16519)\n",
      " ✓ 0\n",
      "  Progress: $0.12 | 1334 unique pairs\n",
      "[Batch 61/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 176 column 18 (char 15863)\n",
      " ✓ 0\n",
      "[Batch 62/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 63/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 199 column 18 (char 14870)\n",
      " ✓ 0\n",
      "[Batch 64/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 166 column 7 (char 15273)\n",
      " ✓ 0\n",
      "[Batch 65/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 169 column 7 (char 15715)\n",
      " ✓ 0\n",
      "[Batch 66/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 67/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 174 column 15 (char 15304)\n",
      " ✓ 0\n",
      "[Batch 68/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 189 column 7 (char 15469)\n",
      " ✓ 0\n",
      "[Batch 69/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 189 column 7 (char 16162)\n",
      " ✓ 0\n",
      "[Batch 70/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 177 column 340 (char 16524)\n",
      " ✓ 0\n",
      "  Progress: $0.15 | 1534 unique pairs\n",
      "[Batch 71/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 166 column 18 (char 16045)\n",
      " ✓ 0\n",
      "[Batch 72/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 146 column 18 (char 14769)\n",
      " ✓ 0\n",
      "[Batch 73/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 146 column 18 (char 16278)\n",
      " ✓ 0\n",
      "[Batch 74/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 14648)\n",
      " ✓ 0\n",
      "[Batch 75/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 156 column 18 (char 15504)\n",
      " ✓ 0\n",
      "[Batch 76/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 168 column 7 (char 16443)\n",
      " ✓ 0\n",
      "[Batch 77/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 78/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 79/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 80/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.17 | 1733 unique pairs\n",
      "[Batch 81/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 82/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 83/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 84/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 85/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 86/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 199 column 105 (char 16809)\n",
      " ✓ 0\n",
      "[Batch 87/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 171 column 18 (char 17035)\n",
      " ✓ 0\n",
      "[Batch 88/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 89/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 90/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.19 | 1933 unique pairs\n",
      "[Batch 91/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 92/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 93/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 148 column 7 (char 17370)\n",
      " ✓ 0\n",
      "[Batch 94/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 184 column 15 (char 17120)\n",
      " ✓ 0\n",
      "[Batch 95/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 96/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 97/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 98/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 179 column 7 (char 18010)\n",
      " ✓ 0\n",
      "[Batch 99/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 171 column 18 (char 17324)\n",
      " ✓ 0\n",
      "[Batch 100/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 195 column 18 (char 16796)\n",
      " ✓ 0\n",
      "  Progress: $0.21 | 2134 unique pairs\n",
      "  💾 Checkpoint saved: checkpoint_100.pkl\n",
      "[Batch 101/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 102/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting value: line 197 column 125 (char 16272)\n",
      " ✓ 0\n",
      "[Batch 103/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 104/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 105/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 189 column 7 (char 16813)\n",
      " ✓ 0\n",
      "[Batch 106/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 107/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 184 column 18 (char 16834)\n",
      " ✓ 0\n",
      "[Batch 108/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting value: line 188 column 148 (char 17756)\n",
      " ✓ 0\n",
      "[Batch 109/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 110/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 16131)\n",
      " ✓ 0\n",
      "  Progress: $0.23 | 2334 unique pairs\n",
      "[Batch 111/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 193 column 148 (char 16516)\n",
      " ✓ 0\n",
      "[Batch 112/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 113/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 114/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 198 column 7 (char 16676)\n",
      " ✓ 0\n",
      "[Batch 115/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 116/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 117/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 118/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 119/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 120/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.25 | 2533 unique pairs\n",
      "[Batch 121/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 122/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 123/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 124/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 125/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 126/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 127/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 128/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 129/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 130/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 176 column 180 (char 13842)\n",
      " ✓ 0\n",
      "  Progress: $0.27 | 2734 unique pairs\n",
      "[Batch 131/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 132/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 17572)\n",
      " ✓ 0\n",
      "[Batch 133/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 134/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 135/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 136/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 137/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 138/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 139/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 193 column 17 (char 16065)\n",
      " ✓ 0\n",
      "[Batch 140/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 199 column 7 (char 15586)\n",
      " ✓ 0\n",
      "  Progress: $0.29 | 2934 unique pairs\n",
      "[Batch 141/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 198 column 7 (char 16323)\n",
      " ✓ 0\n",
      "[Batch 142/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 143/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 144/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 145/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 182 column 7 (char 18047)\n",
      " ✓ 0\n",
      "[Batch 146/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 191 column 18 (char 16545)\n",
      " ✓ 0\n",
      "[Batch 147/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 174 column 18 (char 17901)\n",
      " ✓ 0\n",
      "[Batch 148/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 149/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 177 column 5 (char 17818)\n",
      " ✓ 0\n",
      "[Batch 150/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.31 | 3218 unique pairs\n",
      "  💾 Checkpoint saved: checkpoint_150.pkl\n",
      "[Batch 151/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 152/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 194 column 7 (char 17307)\n",
      " ✓ 0\n",
      "[Batch 153/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 154/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 155/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 156/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 157/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 16499)\n",
      " ✓ 0\n",
      "[Batch 158/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 159/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 160/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 189 column 7 (char 17234)\n",
      " ✓ 0\n",
      "  Progress: $0.33 | 3437 unique pairs\n",
      "[Batch 161/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 162/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 185 column 18 (char 15956)\n",
      " ✓ 0\n",
      "[Batch 163/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 175 column 5 (char 17083)\n",
      " ✓ 0\n",
      "[Batch 164/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 169 column 18 (char 16338)\n",
      " ✓ 0\n",
      "[Batch 165/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 180 column 18 (char 16367)\n",
      " ✓ 0\n",
      "[Batch 166/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 167/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 168/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 169/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 184 column 7 (char 17599)\n",
      " ✓ 0\n",
      "[Batch 170/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 187 column 7 (char 16982)\n",
      " ✓ 0\n",
      "  Progress: $0.35 | 3638 unique pairs\n",
      "[Batch 171/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 172/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 173/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 174/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 175/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 196 column 114 (char 13443)\n",
      " ✓ 0\n",
      "[Batch 176/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 177/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 178/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 179/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 180/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.37 | 3839 unique pairs\n",
      "[Batch 181/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 182/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 198 column 7 (char 17227)\n",
      " ✓ 0\n",
      "[Batch 183/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 198 column 7 (char 18275)\n",
      " ✓ 0\n",
      "[Batch 184/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 185/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 186/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 17071)\n",
      " ✓ 0\n",
      "[Batch 187/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 188/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 17702)\n",
      " ✓ 0\n",
      "[Batch 189/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 183 column 5 (char 17267)\n",
      " ✓ 0\n",
      "[Batch 190/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.39 | 4039 unique pairs\n",
      "[Batch 191/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 192/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 152 column 525 (char 16256)\n",
      " ✓ 0\n",
      "[Batch 193/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 194/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 195/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 196/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting value: line 198 column 145 (char 17966)\n",
      " ✓ 0\n",
      "[Batch 197/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 198/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 199/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 200/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.41 | 4240 unique pairs\n",
      "  💾 Checkpoint saved: checkpoint_200.pkl\n",
      "[Batch 201/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 202/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 203/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 204/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 205/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 206/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 176 column 18 (char 16188)\n",
      " ✓ 0\n",
      "[Batch 207/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 208/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 183 column 18 (char 16747)\n",
      " ✓ 0\n",
      "[Batch 209/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 199 column 7 (char 15714)\n",
      " ✓ 0\n",
      "[Batch 210/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.43 | 4438 unique pairs\n",
      "[Batch 211/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 212/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 213/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 214/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 176 column 18 (char 16451)\n",
      " ✓ 0\n",
      "[Batch 215/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 16107)\n",
      " ✓ 0\n",
      "[Batch 216/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 16353)\n",
      " ✓ 0\n",
      "[Batch 217/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 185 column 18 (char 16095)\n",
      " ✓ 0\n",
      "[Batch 218/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 16819)\n",
      " ✓ 0\n",
      "[Batch 219/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 220/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 184 column 18 (char 18056)\n",
      " ✓ 0\n",
      "  Progress: $0.45 | 4637 unique pairs\n",
      "[Batch 221/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 179 column 7 (char 17246)\n",
      " ✓ 0\n",
      "[Batch 222/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 168 column 7 (char 17469)\n",
      " ✓ 0\n",
      "[Batch 223/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 199 column 7 (char 17577)\n",
      " ✓ 0\n",
      "[Batch 224/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting value: line 156 column 17 (char 17375)\n",
      " ✓ 0\n",
      "[Batch 225/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 226/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 16641)\n",
      " ✓ 0\n",
      "[Batch 227/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 228/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 229/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 230/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.47 | 4838 unique pairs\n",
      "[Batch 231/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 15207)\n",
      " ✓ 0\n",
      "[Batch 232/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 166 column 18 (char 16191)\n",
      " ✓ 0\n",
      "[Batch 233/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting value: line 177 column 15 (char 14689)\n",
      " ✓ 0\n",
      "[Batch 234/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 176 column 18 (char 16977)\n",
      " ✓ 0\n",
      "[Batch 235/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 194 column 5 (char 16667)\n",
      " ✓ 0\n",
      "[Batch 236/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 198 column 7 (char 16779)\n",
      " ✓ 0\n",
      "[Batch 237/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 186 column 14 (char 16138)\n",
      " ✓ 0\n",
      "[Batch 238/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 239/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 240/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 185 column 18 (char 17739)\n",
      " ✓ 0\n",
      "  Progress: $0.50 | 5037 unique pairs\n",
      "[Batch 241/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 242/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 243/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 244/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 245/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 173 column 33 (char 16766)\n",
      " ✓ 0\n",
      "[Batch 246/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 184 column 4 (char 17534)\n",
      " ✓ 0\n",
      "[Batch 247/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 160 column 17 (char 16638)\n",
      " ✓ 0\n",
      "[Batch 248/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 249/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 171 column 18 (char 17314)\n",
      " ✓ 0\n",
      "[Batch 250/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 173 column 17 (char 17226)\n",
      " ✓ 0\n",
      "  Progress: $0.52 | 5236 unique pairs\n",
      "  💾 Checkpoint saved: checkpoint_250.pkl\n",
      "[Batch 251/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 184 column 18 (char 16762)\n",
      " ✓ 0\n",
      "[Batch 252/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 253/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 16737)\n",
      " ✓ 0\n",
      "[Batch 254/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 188 column 7 (char 16507)\n",
      " ✓ 0\n",
      "[Batch 255/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 256/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 257/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 258/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting value: line 168 column 110 (char 17434)\n",
      " ✓ 0\n",
      "[Batch 259/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 180 column 7 (char 16820)\n",
      " ✓ 0\n",
      "[Batch 260/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.54 | 5437 unique pairs\n",
      "[Batch 261/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 188 column 17 (char 16369)\n",
      " ✓ 0\n",
      "[Batch 262/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 263/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 264/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 185 column 15 (char 17358)\n",
      " ✓ 0\n",
      "[Batch 265/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 266/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 267/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 268/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 269/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 17713)\n",
      " ✓ 0\n",
      "[Batch 270/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.56 | 5638 unique pairs\n",
      "[Batch 271/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 17744)\n",
      " ✓ 0\n",
      "[Batch 272/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 273/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 274/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 275/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 179 column 7 (char 16794)\n",
      " ✓ 0\n",
      "[Batch 276/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 190 column 7 (char 17356)\n",
      " ✓ 0\n",
      "[Batch 277/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 146 column 18 (char 18147)\n",
      " ✓ 0\n",
      "[Batch 278/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting value: line 170 column 12 (char 16291)\n",
      " ✓ 0\n",
      "[Batch 279/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 168 column 7 (char 16237)\n",
      " ✓ 0\n",
      "[Batch 280/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 199 column 7 (char 17094)\n",
      " ✓ 0\n",
      "  Progress: $0.58 | 5838 unique pairs\n",
      "[Batch 281/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 176 column 18 (char 18180)\n",
      " ✓ 0\n",
      "[Batch 282/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 283/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 173 column 34 (char 17147)\n",
      " ✓ 0\n",
      "[Batch 284/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 285/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 286/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 287/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 148 column 7 (char 15164)\n",
      " ✓ 0\n",
      "[Batch 288/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 166 column 18 (char 16770)\n",
      " ✓ 0\n",
      "[Batch 289/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 169 column 7 (char 16538)\n",
      " ✓ 0\n",
      "[Batch 290/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 16018)\n",
      " ✓ 0\n",
      "  Progress: $0.60 | 6039 unique pairs\n",
      "[Batch 291/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 156 column 18 (char 14150)\n",
      " ✓ 0\n",
      "[Batch 292/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 179 column 7 (char 16542)\n",
      " ✓ 0\n",
      "[Batch 293/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 197 column 5 (char 16125)\n",
      " ✓ 0\n",
      "[Batch 294/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 295/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 296/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 297/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 199 column 7 (char 16289)\n",
      " ✓ 0\n",
      "[Batch 298/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 299/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 300/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.62 | 6239 unique pairs\n",
      "  💾 Checkpoint saved: checkpoint_300.pkl\n",
      "[Batch 301/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 302/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 303/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting value: line 168 column 186 (char 16863)\n",
      " ✓ 0\n",
      "[Batch 304/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 305/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 306/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 307/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 308/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 309/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 310/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.64 | 6438 unique pairs\n",
      "[Batch 311/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 312/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 180 column 6 (char 18175)\n",
      " ✓ 0\n",
      "[Batch 313/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 314/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 315/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 316/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 317/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 318/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 319/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 320/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.66 | 6638 unique pairs\n",
      "[Batch 321/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 322/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 323/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 324/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 325/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 144 column 7 (char 17174)\n",
      " ✓ 0\n",
      "[Batch 326/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 327/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 178 column 5 (char 16941)\n",
      " ✓ 0\n",
      "[Batch 328/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 329/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 175 column 15 (char 17346)\n",
      " ✓ 0\n",
      "[Batch 330/331] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 188 column 18 (char 16732)\n",
      " ✓ 0\n",
      "  Progress: $0.68 | 6839 unique pairs\n",
      "[Batch 331/331] 15 items\n",
      "  OpenAI... ✓ 15\n",
      "  Google... ✓ 15\n",
      "\n",
      "======================================================================\n",
      "Creating consensus results...\n",
      "======================================================================\n",
      "\n",
      "Results exported to software_analysis_final\\run1_openai_google_20251019_015733.json\n",
      "\n",
      "============================================================\n",
      "API USAGE SUMMARY\n",
      "============================================================\n",
      "Total API Calls: 662\n",
      "Total Tokens: 2,697,446\n",
      "  - Input: 562,734\n",
      "  - Output: 2,134,712\n",
      "\n",
      "Total Cost: $0.6826\n",
      "Average Cost per Call: $0.0010\n",
      "\n",
      "Breakdown by Model:\n",
      "------------------------------------------------------------\n",
      "  gpt-4o-mini:\n",
      "    Calls: 331\n",
      "    Tokens: 1,156,214\n",
      "    Cost: $0.2849\n",
      "  models/gemini-2.0-flash:\n",
      "    Calls: 331\n",
      "    Tokens: 1,541,232\n",
      "    Cost: $0.3977\n",
      "============================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "RUN 1 COMPLETE\n",
      "======================================================================\n",
      "✓ Completed: 6855 unique assessments\n",
      "✗ Failed batches: 0\n",
      "\n",
      "Files:\n",
      "  JSON: software_analysis_final\\run1_openai_google_20251019_015733.json\n",
      "  CSV: software_analysis_final\\run1_openai_google_20251019_015733.csv\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# WORKING SOLUTION: Direct batch processing (GUARANTEED TO WORK)\n",
    "# =============================================================================\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "assessor = SoftwareMethodAssessor(use_config=True, timeout=180)\n",
    "\n",
    "# Create batches manually with batch_size=20\n",
    "all_pairs = [(sw, method) for sw in software_list_all for method in method_list_all]\n",
    "batch_size = 20\n",
    "batches = [all_pairs[i:i + batch_size] for i in range(0, len(all_pairs), batch_size)]\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"RUN 1: OpenAI + Google (batch_size={batch_size})\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total pairs: {len(all_pairs)}\")\n",
    "print(f\"Total batches: {len(batches)}\")\n",
    "print(f\"Expected time: 6-8 hours\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "all_assessments = {}\n",
    "failed_batches = []\n",
    "\n",
    "for batch_idx, batch in enumerate(batches, 1):\n",
    "    print(f\"[Batch {batch_idx}/{len(batches)}] {len(batch)} items\", flush=True)\n",
    "    \n",
    "    # OpenAI\n",
    "    try:\n",
    "        print(f\"  OpenAI...\", end='', flush=True)\n",
    "        openai_results = assessor.assess_batch_with_openai(batch, 'gpt-4o-mini', debug=False)\n",
    "        for result in openai_results:\n",
    "            key = (result.software, result.method)\n",
    "            if key not in all_assessments:\n",
    "                all_assessments[key] = []\n",
    "            all_assessments[key].append(result)\n",
    "        print(f\" ✓ {len(openai_results)}\", flush=True)\n",
    "    except Exception as e:\n",
    "        print(f\" ✗ {str(e)[:50]}\", flush=True)\n",
    "        failed_batches.append(('openai', batch_idx))\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Google\n",
    "    try:\n",
    "        print(f\"  Google...\", end='', flush=True)\n",
    "        google_results = assessor.assess_batch_with_google(batch, 'models/gemini-2.0-flash', debug=False)\n",
    "        for result in google_results:\n",
    "            key = (result.software, result.method)\n",
    "            if key not in all_assessments:\n",
    "                all_assessments[key] = []\n",
    "            all_assessments[key].append(result)\n",
    "        print(f\" ✓ {len(google_results)}\", flush=True)\n",
    "    except Exception as e:\n",
    "        print(f\" ✗ {str(e)[:50]}\", flush=True)\n",
    "        failed_batches.append(('google', batch_idx))\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Progress\n",
    "    if batch_idx % 10 == 0:\n",
    "        stats = assessor.credit_tracker.get_stats()\n",
    "        print(f\"  Progress: ${stats['total_cost']:.2f} | {len(all_assessments)} unique pairs\")\n",
    "    \n",
    "    # Checkpoint every 50 batches\n",
    "    if batch_idx % 50 == 0:\n",
    "        checkpoint_file = output_dir / f\"checkpoint_{batch_idx}.pkl\"\n",
    "        with open(checkpoint_file, 'wb') as f:\n",
    "            pickle.dump(all_assessments, f)\n",
    "        print(f\"  💾 Checkpoint saved: {checkpoint_file.name}\")\n",
    "\n",
    "# Create consensus\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Creating consensus results...\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "consensus_results = []\n",
    "for (software, method), assessments in all_assessments.items():\n",
    "    # Remove duplicates by provider\n",
    "    by_provider = {}\n",
    "    for a in assessments:\n",
    "        if a.llm_provider not in by_provider:\n",
    "            by_provider[a.llm_provider] = a\n",
    "    assessments = list(by_provider.values())\n",
    "    \n",
    "    if len(assessments) == 0:\n",
    "        continue\n",
    "    \n",
    "    ranks = [a.rank for a in assessments]\n",
    "    confidence, agreement_level = assessor.calculate_confidence(ranks)\n",
    "    rank_counts = Counter(ranks)\n",
    "    final_rank = rank_counts.most_common(1)[0][0]\n",
    "    \n",
    "    consensus_results.append(ConsensusResult(\n",
    "        software=software,\n",
    "        method=method,\n",
    "        final_rank=final_rank,\n",
    "        confidence=confidence,\n",
    "        individual_ranks={a.llm_provider: a.rank for a in assessments},\n",
    "        individual_reasoning={a.llm_provider: a.reasoning for a in assessments},\n",
    "        individual_sources={a.llm_provider: a.sources for a in assessments},\n",
    "        agreement_level=agreement_level,\n",
    "        total_tokens=sum(a.input_tokens + a.output_tokens for a in assessments),\n",
    "        total_cost=0.0\n",
    "    ))\n",
    "\n",
    "# Save results\n",
    "run1_file = output_dir / f\"run1_openai_google_{timestamp}.json\"\n",
    "assessor.export_results(consensus_results, str(run1_file))\n",
    "\n",
    "results_df = pd.DataFrame([{\n",
    "    'software': r.software,\n",
    "    'method': r.method,\n",
    "    'final_rank': r.final_rank,\n",
    "    'confidence': r.confidence,\n",
    "    'agreement_level': r.agreement_level,\n",
    "    'num_llms': len(r.individual_ranks)\n",
    "} for r in consensus_results])\n",
    "\n",
    "csv_file = output_dir / f\"run1_openai_google_{timestamp}.csv\"\n",
    "results_df.to_csv(csv_file, index=False)\n",
    "\n",
    "# Final summary\n",
    "assessor.credit_tracker.print_summary()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"RUN 1 COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"✓ Completed: {len(consensus_results)} unique assessments\")\n",
    "print(f\"✗ Failed batches: {len(failed_batches)}\")\n",
    "if failed_batches:\n",
    "    print(f\"  Failed: {failed_batches[:5]}{'...' if len(failed_batches) > 5 else ''}\")\n",
    "print(f\"\\nFiles:\")\n",
    "print(f\"  JSON: {run1_file}\")\n",
    "print(f\"  CSV: {csv_file}\")\n",
    "print(f\"{'='*70}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c9146f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RUN 2: Claude + Google Assessment\n",
      "======================================================================\n",
      "NOTE: Google appears in both runs for validation\n",
      "\n",
      "======================================================================\n",
      "BATCH ASSESSMENT MODE\n",
      "======================================================================\n",
      "Total items: 6615\n",
      "Strategy: by_software\n",
      "LLMs: OpenAI=False, Claude=True, Google=True\n",
      "\n",
      "Created 35 batches\n",
      "  Batch 1: 189 items\n",
      "  Batch 2: 189 items\n",
      "  Batch 3: 189 items\n",
      "  Batch 4: 189 items\n",
      "  Batch 5: 189 items\n",
      "  Batch 6: 189 items\n",
      "  Batch 7: 189 items\n",
      "  Batch 8: 189 items\n",
      "  Batch 9: 189 items\n",
      "  Batch 10: 189 items\n",
      "  Batch 11: 189 items\n",
      "  Batch 12: 189 items\n",
      "  Batch 13: 189 items\n",
      "  Batch 14: 189 items\n",
      "  Batch 15: 189 items\n",
      "  Batch 16: 189 items\n",
      "  Batch 17: 189 items\n",
      "  Batch 18: 189 items\n",
      "  Batch 19: 189 items\n",
      "  Batch 20: 189 items\n",
      "  Batch 21: 189 items\n",
      "  Batch 22: 189 items\n",
      "  Batch 23: 189 items\n",
      "  Batch 24: 189 items\n",
      "  Batch 25: 189 items\n",
      "  Batch 26: 189 items\n",
      "  Batch 27: 189 items\n",
      "  Batch 28: 189 items\n",
      "  Batch 29: 189 items\n",
      "  Batch 30: 189 items\n",
      "  Batch 31: 189 items\n",
      "  Batch 32: 189 items\n",
      "  Batch 33: 189 items\n",
      "  Batch 34: 189 items\n",
      "  Batch 35: 189 items\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Processing batches...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "[Batch 1/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 217 column 15 (char 17584)\n",
      "  Running cost: $0.0056 (12,671 tokens)\n",
      "\n",
      "[Batch 2/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 246 column 289 (char 15200)\n",
      "  Running cost: $0.0105 (23,926 tokens)\n",
      "\n",
      "[Batch 3/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 307 column 18 (char 16601)\n",
      "  Running cost: $0.0154 (35,206 tokens)\n",
      "\n",
      "[Batch 4/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 297 column 18 (char 15809)\n",
      "  Running cost: $0.0209 (47,941 tokens)\n",
      "\n",
      "[Batch 5/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 249 column 7 (char 15963)\n",
      "  Running cost: $0.0256 (59,188 tokens)\n",
      "\n",
      "[Batch 6/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 210 column 18 (char 17088)\n",
      "  Running cost: $0.0304 (70,294 tokens)\n",
      "\n",
      "[Batch 7/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 207 column 18 (char 15229)\n",
      "  Running cost: $0.0352 (81,835 tokens)\n",
      "\n",
      "[Batch 8/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 14535)\n",
      "  Running cost: $0.0406 (94,286 tokens)\n",
      "\n",
      "[Batch 9/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 269 column 7 (char 15380)\n",
      "  Running cost: $0.0457 (106,141 tokens)\n",
      "\n",
      "[Batch 10/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 241 column 18 (char 15574)\n",
      "  Running cost: $0.0506 (117,545 tokens)\n",
      "\n",
      "[Batch 11/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 223 column 17 (char 16430)\n",
      "  Running cost: $0.0560 (129,769 tokens)\n",
      "\n",
      "[Batch 12/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 206 column 18 (char 16146)\n",
      "  Running cost: $0.0610 (141,412 tokens)\n",
      "\n",
      "[Batch 13/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 226 column 5 (char 16899)\n",
      "  Running cost: $0.0659 (152,825 tokens)\n",
      "\n",
      "[Batch 14/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 315 column 5 (char 15515)\n",
      "  Running cost: $0.0708 (164,257 tokens)\n",
      "\n",
      "[Batch 15/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Expecting ',' delimiter: line 220 column 6 (char 15692)\n",
      "  Running cost: $0.0763 (176,510 tokens)\n",
      "\n",
      "[Batch 16/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 233 column 361 (char 16069)\n",
      "  Running cost: $0.0823 (190,624 tokens)\n",
      "\n",
      "[Batch 17/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 333 column 24 (char 15258)\n",
      "  Running cost: $0.0874 (201,957 tokens)\n",
      "\n",
      "[Batch 18/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 226 column 18 (char 14609)\n",
      "  Running cost: $0.0931 (214,657 tokens)\n",
      "\n",
      "[Batch 19/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Expecting value: line 306 column 12 (char 16888)\n",
      "  Running cost: $0.0984 (226,600 tokens)\n",
      "\n",
      "[Batch 20/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 286 column 18 (char 17907)\n",
      "  Running cost: $0.1033 (237,866 tokens)\n",
      "\n",
      "[Batch 21/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 266 column 18 (char 16562)\n",
      "  Running cost: $0.1081 (249,124 tokens)\n",
      "\n",
      "[Batch 22/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 272 column 18 (char 16097)\n",
      "  Running cost: $0.1130 (260,412 tokens)\n",
      "\n",
      "[Batch 23/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 228 column 7 (char 14996)\n",
      "  Running cost: $0.1179 (272,010 tokens)\n",
      "\n",
      "[Batch 24/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 193 column 36 (char 16657)\n",
      "  Running cost: $0.1230 (283,795 tokens)\n",
      "\n",
      "[Batch 25/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 270 column 18 (char 15718)\n",
      "  Running cost: $0.1281 (295,250 tokens)\n",
      "\n",
      "[Batch 26/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 207 column 18 (char 17164)\n",
      "  Running cost: $0.1332 (306,927 tokens)\n",
      "\n",
      "[Batch 27/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 209 column 5 (char 16456)\n",
      "  Running cost: $0.1426 (326,900 tokens)\n",
      "\n",
      "[Batch 28/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 277 column 5 (char 15154)\n",
      "  Running cost: $0.1480 (338,706 tokens)\n",
      "\n",
      "[Batch 29/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 213 column 17 (char 17799)\n",
      "  Running cost: $0.1532 (350,543 tokens)\n",
      "\n",
      "[Batch 30/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 250 column 7 (char 16284)\n",
      "  Running cost: $0.1581 (361,832 tokens)\n",
      "\n",
      "[Batch 31/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 183 column 17 (char 16737)\n",
      "  Running cost: $0.1638 (374,584 tokens)\n",
      "\n",
      "[Batch 32/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Expecting ',' delimiter: line 255 column 14 (char 17039)\n",
      "  Running cost: $0.1689 (385,866 tokens)\n",
      "\n",
      "[Batch 33/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 368 column 7 (char 15822)\n",
      "  Running cost: $0.1739 (397,329 tokens)\n",
      "\n",
      "[Batch 34/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 228 column 7 (char 17146)\n",
      "  Running cost: $0.1793 (408,987 tokens)\n",
      "\n",
      "[Batch 35/35] 189 items\n",
      "  Assessing with Claude...\n",
      "  ERROR parsing Claude batch response: Expecting value: line 1 column 1 (char 0)\n",
      "  Assessing with Google...\n",
      "  ERROR parsing Google batch response: Unterminated string starting at: line 203 column 18 (char 15267)\n",
      "  Running cost: $0.1842 (420,259 tokens)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Creating consensus results...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Completed 0 assessments\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Results exported to software_analysis_final\\run2_claude_google_20251019_015733.json\n",
      "\n",
      "============================================================\n",
      "API USAGE SUMMARY\n",
      "============================================================\n",
      "Total API Calls: 70\n",
      "Total Tokens: 420,259\n",
      "  - Input: 272,517\n",
      "  - Output: 147,742\n",
      "\n",
      "Total Cost: $0.1842\n",
      "Average Cost per Call: $0.0026\n",
      "\n",
      "Breakdown by Model:\n",
      "------------------------------------------------------------\n",
      "  claude-3-5-haiku-20241022:\n",
      "    Calls: 35\n",
      "    Tokens: 144,610\n",
      "    Cost: $0.1314\n",
      "  models/gemini-2.0-flash:\n",
      "    Calls: 35\n",
      "    Tokens: 275,649\n",
      "    Cost: $0.0528\n",
      "============================================================\n",
      "\n",
      "\n",
      "✓ Run 2 complete!\n",
      "  JSON: software_analysis_final\\run2_claude_google_20251019_015733.json\n",
      "  CSV: software_analysis_final\\run2_claude_google_20251019_015733.csv\n",
      "  Completed 0 assessments\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# EXECUTION: RUN 2 - Claude + Google (for overlap validation)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RUN 2: Claude + Google Assessment\")\n",
    "print(\"=\"*70)\n",
    "print(\"NOTE: Google appears in both runs for validation\")\n",
    "\n",
    "# Create fresh assessor to reset token tracking\n",
    "assessor_run2 = SoftwareMethodAssessor(use_config=True, timeout=180)\n",
    "\n",
    "# Run assessment\n",
    "results_run2 = assessor_run2.assess_multiple_batched(\n",
    "    software_list=software_list_all,\n",
    "    method_list=method_list_all,\n",
    "    batch_strategy=\"by_software\",\n",
    "    use_openai=False,\n",
    "    use_google=True,  # Google overlap with Run 1\n",
    "    use_claude=True,\n",
    "    claude_model='claude-3-5-haiku-20241022',\n",
    "    google_model='models/gemini-2.0-flash'\n",
    ")\n",
    "\n",
    "# Save results\n",
    "run2_file = output_dir / f\"run2_claude_google_{timestamp}.json\"\n",
    "assessor_run2.export_results(results_run2, str(run2_file))\n",
    "\n",
    "# Save as CSV\n",
    "results_df2 = pd.DataFrame([{\n",
    "    'software': r.software,\n",
    "    'method': r.method,\n",
    "    'final_rank': r.final_rank,\n",
    "    'confidence': r.confidence,\n",
    "    'agreement_level': r.agreement_level,\n",
    "    'num_llms': len(r.individual_ranks)\n",
    "} for r in results_run2])\n",
    "\n",
    "csv_file2 = output_dir / f\"run2_claude_google_{timestamp}.csv\"\n",
    "results_df2.to_csv(csv_file2, index=False)\n",
    "\n",
    "# Print summary\n",
    "assessor_run2.credit_tracker.print_summary()\n",
    "print(f\"\\n✓ Run 2 complete!\")\n",
    "print(f\"  JSON: {run2_file}\")\n",
    "print(f\"  CSV: {csv_file2}\")\n",
    "print(f\"  Completed {len(results_run2)} assessments\")\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e78e825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MERGING RUN 1 AND RUN 2\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "MERGING ASSESSMENT RESULTS\n",
      "======================================================================\n",
      "Strategy: union\n",
      "Input files: 2\n",
      "\n",
      "Processing file 1/2: software_analysis_final\\run1_openai_google_20251019_015733.json\n",
      "  Loaded 6855 assessments\n",
      "\n",
      "Processing file 2/2: software_analysis_final\\run2_claude_google_20251019_015733.json\n",
      "  Loaded 0 assessments\n",
      "\n",
      "Recalculating consensus for merged results...\n",
      "\n",
      "✓ Merged results saved to: software_analysis_final\\merged_final_20251019_015733.json\n",
      "======================================================================\n",
      "\n",
      "\n",
      "✓ Merged 6855 unique assessments\n",
      "✓ Merged CSV saved to: software_analysis_final\\merged_final_20251019_015733.csv\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# MERGE BOTH RUNS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MERGING RUN 1 AND RUN 2\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create merger instance\n",
    "merger = SoftwareMethodAssessor(use_config=True)\n",
    "\n",
    "# Merge results\n",
    "merged_results = merger.merge_assessment_results(\n",
    "    str(run1_file),\n",
    "    str(run2_file),\n",
    "    output_file=str(output_dir / f\"merged_final_{timestamp}.json\"),\n",
    "    merge_strategy=\"union\"\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Merged {len(merged_results)} unique assessments\")\n",
    "\n",
    "# Create summary CSV\n",
    "merged_df = pd.DataFrame([{\n",
    "    'software': r.software,\n",
    "    'method': r.method,\n",
    "    'final_rank': r.final_rank,\n",
    "    'confidence': r.confidence,\n",
    "    'agreement_level': r.agreement_level,\n",
    "    'num_llms': len(r.individual_ranks),\n",
    "    'llms_used': ', '.join(r.individual_ranks.keys()),\n",
    "    'total_cost': r.total_cost\n",
    "} for r in merged_results])\n",
    "\n",
    "merged_csv = output_dir / f\"merged_final_{timestamp}.csv\"\n",
    "merged_df.to_csv(merged_csv, index=False)\n",
    "\n",
    "print(f\"✓ Merged CSV saved to: {merged_csv}\")\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39ae55c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "GOOGLE OVERLAP VALIDATION\n",
      "======================================================================\n",
      "Checking consistency of Google assessments across both runs...\n",
      "\n",
      "⚠ No Google overlap found in merged results\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# GOOGLE OVERLAP VALIDATION ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GOOGLE OVERLAP VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"Checking consistency of Google assessments across both runs...\")\n",
    "\n",
    "google_consistency = []\n",
    "\n",
    "for result in merged_results:\n",
    "    # Find Google assessments from both runs\n",
    "    google_ranks = []\n",
    "    google_providers = []\n",
    "    \n",
    "    for llm, rank in result.individual_ranks.items():\n",
    "        if 'google' in llm.lower():\n",
    "            google_ranks.append(rank)\n",
    "            google_providers.append(llm)\n",
    "    \n",
    "    if len(google_ranks) == 2:  # Google assessed twice\n",
    "        consistency_record = {\n",
    "            'software': result.software,\n",
    "            'method': result.method,\n",
    "            'google_rank_run1': google_ranks[0],\n",
    "            'google_rank_run2': google_ranks[1],\n",
    "            'difference': abs(google_ranks[0] - google_ranks[1]),\n",
    "            'consistent': google_ranks[0] == google_ranks[1],\n",
    "            'final_rank': result.final_rank,\n",
    "            'confidence': result.confidence\n",
    "        }\n",
    "        google_consistency.append(consistency_record)\n",
    "\n",
    "# Create consistency report\n",
    "consistency_df = pd.DataFrame(google_consistency)\n",
    "consistency_file = output_dir / f\"google_consistency_{timestamp}.csv\"\n",
    "consistency_df.to_csv(consistency_file, index=False)\n",
    "\n",
    "# Calculate statistics\n",
    "if len(google_consistency) > 0:\n",
    "    perfect_consistency = sum(1 for c in google_consistency if c['consistent'])\n",
    "    within_one = sum(1 for c in google_consistency if c['difference'] <= 1)\n",
    "    \n",
    "    print(f\"\\nGoogle Consistency Statistics:\")\n",
    "    print(f\"  Total pairs assessed by Google in both runs: {len(google_consistency)}\")\n",
    "    print(f\"  Perfect consistency (exact same rank): {perfect_consistency} ({perfect_consistency/len(google_consistency)*100:.1f}%)\")\n",
    "    print(f\"  Within ±1 rank: {within_one} ({within_one/len(google_consistency)*100:.1f}%)\")\n",
    "    print(f\"  Average rank difference: {consistency_df['difference'].mean():.2f}\")\n",
    "    print(f\"  Max rank difference: {consistency_df['difference'].max()}\")\n",
    "    \n",
    "    # Show distribution of differences\n",
    "    print(f\"\\nDifference distribution:\")\n",
    "    diff_counts = consistency_df['difference'].value_counts().sort_index()\n",
    "    for diff, count in diff_counts.items():\n",
    "        print(f\"    Difference {int(diff)}: {count} pairs ({count/len(google_consistency)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n✓ Consistency report saved to: {consistency_file}\")\n",
    "else:\n",
    "    print(\"\\n⚠ No Google overlap found in merged results\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7cb87251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FINAL RESULTS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Total unique pairs assessed: 6855\n",
      "\n",
      "LLM Coverage Distribution:\n",
      "  2 LLMs: 3,622 pairs (52.8%)\n",
      "  1 LLMs: 3,233 pairs (47.2%)\n",
      "\n",
      "Average Confidence: 84.99%\n",
      "\n",
      "Agreement Level Distribution:\n",
      "  perfect_agreement: 4,797 pairs (70.0%)\n",
      "  moderate_agreement: 2,058 pairs (30.0%)\n",
      "\n",
      "Rank Distribution:\n",
      "  Rank 0: 1,662 pairs (24.2%)\n",
      "  Rank 1: 2,202 pairs (32.1%)\n",
      "  Rank 2: 1,928 pairs (28.1%)\n",
      "  Rank 3: 1,063 pairs (15.5%)\n",
      "\n",
      "Cost Breakdown:\n",
      "  Run 1 (OpenAI + Google): $0.00\n",
      "  Run 2 (Claude + Google): $0.00\n",
      "  Total: $0.00\n",
      "  Average per pair: $0.0000\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# FINAL RESULTS ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# LLM coverage analysis\n",
    "print(f\"\\nTotal unique pairs assessed: {len(merged_results)}\")\n",
    "\n",
    "llm_coverage = {}\n",
    "for result in merged_results:\n",
    "    num_llms = len(result.individual_ranks)\n",
    "    llm_coverage[num_llms] = llm_coverage.get(num_llms, 0) + 1\n",
    "\n",
    "print(f\"\\nLLM Coverage Distribution:\")\n",
    "for num_llms in sorted(llm_coverage.keys(), reverse=True):\n",
    "    print(f\"  {num_llms} LLMs: {llm_coverage[num_llms]:,} pairs ({llm_coverage[num_llms]/len(merged_results)*100:.1f}%)\")\n",
    "\n",
    "# Confidence analysis\n",
    "avg_confidence = sum(r.confidence for r in merged_results) / len(merged_results)\n",
    "print(f\"\\nAverage Confidence: {avg_confidence:.2%}\")\n",
    "\n",
    "confidence_levels = Counter([r.agreement_level for r in merged_results])\n",
    "print(f\"\\nAgreement Level Distribution:\")\n",
    "for level, count in confidence_levels.most_common():\n",
    "    print(f\"  {level}: {count:,} pairs ({count/len(merged_results)*100:.1f}%)\")\n",
    "\n",
    "# Rank distribution\n",
    "rank_dist = Counter([r.final_rank for r in merged_results])\n",
    "print(f\"\\nRank Distribution:\")\n",
    "for rank in sorted(rank_dist.keys()):\n",
    "    print(f\"  Rank {rank}: {rank_dist[rank]:,} pairs ({rank_dist[rank]/len(merged_results)*100:.1f}%)\")\n",
    "\n",
    "# Cost analysis\n",
    "total_cost_run1 = sum(r.total_cost for r in results_run1)\n",
    "total_cost_run2 = sum(r.total_cost for r in results_run2)\n",
    "total_cost_combined = total_cost_run1 + total_cost_run2\n",
    "\n",
    "print(f\"\\nCost Breakdown:\")\n",
    "print(f\"  Run 1 (OpenAI + Google): ${total_cost_run1:.2f}\")\n",
    "print(f\"  Run 2 (Claude + Google): ${total_cost_run2:.2f}\")\n",
    "print(f\"  Total: ${total_cost_combined:.2f}\")\n",
    "print(f\"  Average per pair: ${total_cost_combined/len(merged_results):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f916f229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CREATING SUMMARY REPORT\n",
      "======================================================================\n",
      "✓ Summary report saved to: software_analysis_final\\_SUMMARY_20251019_015733.json\n",
      "\n",
      "======================================================================\n",
      "ALL OUTPUT FILES\n",
      "======================================================================\n",
      "\n",
      "Directory: c:\\git_repos\\Literature-search-and-analysis\\software_analysis_final\n",
      "\n",
      "Assessment Results:\n",
      "  1. run1_openai_google_20251019_015733.json - Run 1 results (JSON)\n",
      "  2. run1_openai_google_20251019_015733.csv - Run 1 results (CSV)\n",
      "  3. run2_claude_google_20251019_015733.json - Run 2 results (JSON)\n",
      "  4. run2_claude_google_20251019_015733.csv - Run 2 results (CSV)\n",
      "  5. merged_final_20251019_015733.json - Combined results (JSON)\n",
      "  6. merged_final_20251019_015733.csv - Combined results (CSV)\n",
      "\n",
      "Quality Reports:\n",
      "  7. google_consistency_20251019_015733.csv - Google validation\n",
      "  8. _SUMMARY_20251019_015733.json - Master summary\n",
      "\n",
      "======================================================================\n",
      "✓ ASSESSMENT COMPLETE!\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# CREATE COMPREHENSIVE SUMMARY REPORT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREATING SUMMARY REPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary_report = {\n",
    "    'timestamp': timestamp,\n",
    "    'assessment_info': {\n",
    "        'total_software': len(software_list_all),\n",
    "        'total_methods': len(method_list_all),\n",
    "        'total_pairs_assessed': len(merged_results),\n",
    "        'expected_pairs': len(software_list_all) * len(method_list_all)\n",
    "    },\n",
    "    'runs': {\n",
    "        'run1': {\n",
    "            'llms': 'OpenAI + Google',\n",
    "            'pairs_assessed': len(results_run1),\n",
    "            'cost': round(total_cost_run1, 4)\n",
    "        },\n",
    "        'run2': {\n",
    "            'llms': 'Claude + Google',\n",
    "            'pairs_assessed': len(results_run2),\n",
    "            'cost': round(total_cost_run2, 4)\n",
    "        }\n",
    "    },\n",
    "    'validation': {\n",
    "        'google_overlap_pairs': len(google_consistency),\n",
    "        'google_perfect_consistency_rate': perfect_consistency/len(google_consistency) if len(google_consistency) > 0 else 0,\n",
    "        'google_within_one_rate': within_one/len(google_consistency) if len(google_consistency) > 0 else 0\n",
    "    },\n",
    "    'quality_metrics': {\n",
    "        'average_confidence': round(avg_confidence, 4),\n",
    "        'llm_coverage': {str(k): v for k, v in llm_coverage.items()},\n",
    "        'agreement_levels': {k: v for k, v in confidence_levels.items()},\n",
    "        'rank_distribution': {str(k): v for k, v in rank_dist.items()}\n",
    "    },\n",
    "    'costs': {\n",
    "        'total_cost': round(total_cost_combined, 4),\n",
    "        'cost_per_pair': round(total_cost_combined/len(merged_results), 6),\n",
    "        'run1_cost': round(total_cost_run1, 4),\n",
    "        'run2_cost': round(total_cost_run2, 4)\n",
    "    },\n",
    "    'files': {\n",
    "        'run1_json': str(run1_file.name),\n",
    "        'run1_csv': str(csv_file.name),\n",
    "        'run2_json': str(run2_file.name),\n",
    "        'run2_csv': str(csv_file2.name),\n",
    "        'merged_json': f\"merged_final_{timestamp}.json\",\n",
    "        'merged_csv': f\"merged_final_{timestamp}.csv\",\n",
    "        'consistency_report': str(consistency_file.name)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save summary report\n",
    "summary_file = output_dir / f\"_SUMMARY_{timestamp}.json\"\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary_report, f, indent=2)\n",
    "\n",
    "print(f\"✓ Summary report saved to: {summary_file}\")\n",
    "\n",
    "# Print final file list\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ALL OUTPUT FILES\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nDirectory: {output_dir.absolute()}\\n\")\n",
    "print(\"Assessment Results:\")\n",
    "print(f\"  1. {run1_file.name} - Run 1 results (JSON)\")\n",
    "print(f\"  2. {csv_file.name} - Run 1 results (CSV)\")\n",
    "print(f\"  3. {run2_file.name} - Run 2 results (JSON)\")\n",
    "print(f\"  4. {csv_file2.name} - Run 2 results (CSV)\")\n",
    "print(f\"  5. merged_final_{timestamp}.json - Combined results (JSON)\")\n",
    "print(f\"  6. {merged_csv.name} - Combined results (CSV)\")\n",
    "print(f\"\\nQuality Reports:\")\n",
    "print(f\"  7. {consistency_file.name} - Google validation\")\n",
    "print(f\"  8. {summary_file.name} - Master summary\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"✓ ASSESSMENT COMPLETE!\")\n",
    "print(f\"{'='*70}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "745873f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ResultCSVMerger class defined\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# CSV MERGER - INTEGRATE WITH YOUR EXISTING DATA\n",
    "# =============================================================================\n",
    "\n",
    "class ResultCSVMerger:\n",
    "    \"\"\"Merge LLM results into existing CSV\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file: str, delimiter: str = ';', \n",
    "                 software_name_column: str = 'Name',\n",
    "                 method_start_column: str = 'Numerical-solvers'):\n",
    "        \"\"\"Initialize merger\"\"\"\n",
    "        self.csv_file = Path(csv_file)\n",
    "        self.delimiter = delimiter\n",
    "        self.software_name_column = software_name_column\n",
    "        self.method_start_column = method_start_column\n",
    "        \n",
    "        # Load CSV\n",
    "        self.df = pd.read_csv(csv_file, delimiter=delimiter, encoding='utf-8-sig')\n",
    "        \n",
    "        # Identify columns\n",
    "        self.info_columns = []\n",
    "        self.method_columns = []\n",
    "        found_methods = False\n",
    "        \n",
    "        for col in self.df.columns:\n",
    "            if col == method_start_column:\n",
    "                found_methods = True\n",
    "            if found_methods:\n",
    "                self.method_columns.append(col)\n",
    "            else:\n",
    "                self.info_columns.append(col)\n",
    "        \n",
    "        print(f\"✓ CSV Merger initialized:\")\n",
    "        print(f\"  File: {csv_file}\")\n",
    "        print(f\"  Software rows: {len(self.df)}\")\n",
    "        print(f\"  Info columns: {len(self.info_columns)}\")\n",
    "        print(f\"  Method columns: {len(self.method_columns)}\")\n",
    "    \n",
    "    def _normalize_name(self, name: str) -> str:\n",
    "        \"\"\"Normalize name for matching\"\"\"\n",
    "        if pd.isna(name):\n",
    "            return \"\"\n",
    "        name = str(name).lower()\n",
    "        name = ''.join(c if c.isalnum() or c in ' -' else ' ' for c in name)\n",
    "        return ' '.join(name.split())\n",
    "    \n",
    "    def merge_llm_results(self, llm_results_file: str, output_file: str,\n",
    "                         min_confidence: float = 0.5,\n",
    "                         overwrite_existing: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"Merge LLM results into CSV\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(\"MERGING LLM RESULTS INTO EXISTING CSV\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Load LLM results\n",
    "        with open(llm_results_file, 'r') as f:\n",
    "            llm_results = json.load(f)\n",
    "        \n",
    "        print(f\"Loaded {len(llm_results)} LLM assessments\")\n",
    "        \n",
    "        # Create working copy\n",
    "        df_merged = self.df.copy()\n",
    "        \n",
    "        # Track updates\n",
    "        updates = 0\n",
    "        skipped_low_conf = 0\n",
    "        skipped_not_found = 0\n",
    "        \n",
    "        for result in llm_results:\n",
    "            if result['confidence'] < min_confidence:\n",
    "                skipped_low_conf += 1\n",
    "                continue\n",
    "            \n",
    "            # Find matching software row\n",
    "            software_norm = self._normalize_name(result['software'])\n",
    "            df_norm = self.df[self.software_name_column].apply(self._normalize_name)\n",
    "            \n",
    "            matches = df_norm[df_norm == software_norm]\n",
    "            if len(matches) == 0:\n",
    "                skipped_not_found += 1\n",
    "                continue\n",
    "            \n",
    "            row_idx = matches.index[0]\n",
    "            \n",
    "            # Find matching method column\n",
    "            method_norm = self._normalize_name(result['method'])\n",
    "            method_cols_norm = {self._normalize_name(col): col for col in self.method_columns}\n",
    "            \n",
    "            if method_norm not in method_cols_norm:\n",
    "                skipped_not_found += 1\n",
    "                continue\n",
    "            \n",
    "            method_col = method_cols_norm[method_norm]\n",
    "            \n",
    "            # Update value\n",
    "            if overwrite_existing or pd.isna(df_merged.at[row_idx, method_col]):\n",
    "                df_merged.at[row_idx, method_col] = result['final_rank']\n",
    "                updates += 1\n",
    "        \n",
    "        # Save\n",
    "        df_merged.to_csv(output_file, sep=self.delimiter, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(f\"\\nMerge Statistics:\")\n",
    "        print(f\"  Updated: {updates}\")\n",
    "        print(f\"  Skipped (low confidence): {skipped_low_conf}\")\n",
    "        print(f\"  Skipped (not found): {skipped_not_found}\")\n",
    "        print(f\"\\n✓ Updated CSV saved to: {output_file}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        return df_merged\n",
    "\n",
    "print(\"✓ ResultCSVMerger class defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e0bb16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CSV Merger initialized:\n",
      "  File: software_analysis_output\\software_methods_updated.csv\n",
      "  Software rows: 39\n",
      "  Info columns: 21\n",
      "  Method columns: 190\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'timestamp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m\n\u001b[0;32m      9\u001b[0m csv_merger \u001b[38;5;241m=\u001b[39m ResultCSVMerger(\n\u001b[0;32m     10\u001b[0m     csv_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftware_analysis_output\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msoftware_methods_updated.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m     software_name_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m     method_start_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumerical-solvers\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Merge results into your CSV\u001b[39;00m\n\u001b[0;32m     17\u001b[0m updated_csv \u001b[38;5;241m=\u001b[39m csv_merger\u001b[38;5;241m.\u001b[39mmerge_llm_results(\n\u001b[1;32m---> 18\u001b[0m     llm_results_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(output_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerged_final_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtimestamp\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     19\u001b[0m     output_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(output_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftware_methods_updated_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     20\u001b[0m     min_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m,  \u001b[38;5;66;03m# Only use results with ≥60% confidence\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     overwrite_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Overwrite existing scores\u001b[39;00m\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✓ Your CSV has been updated with LLM assessment results!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'timestamp' is not defined"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# FINAL STEP: MERGE INTO YOUR EXISTING CSV\n",
    "# =============================================================================\n",
    "\n",
    "# Run this AFTER both assessment runs are complete\n",
    "output_dir=\"software_analysis_output\"\n",
    "# Initialize CSV merger with YOUR file\n",
    "csv_merger = ResultCSVMerger(\n",
    "    csv_file=\"software_analysis_output\\software_methods_updated.csv\",  #\n",
    "    delimiter=';',\n",
    "    software_name_column='Name',\n",
    "    method_start_column='Numerical-solvers'\n",
    ")\n",
    "\n",
    "# Merge results into your CSV\n",
    "updated_csv = csv_merger.merge_llm_results(\n",
    "    llm_results_file=str(output_dir / f\"merged_final_{timestamp}.json\"),\n",
    "    output_file=str(output_dir / f\"software_methods_updated_{timestamp}.csv\"),\n",
    "    min_confidence=0.4,  # Only use results with ≥60% confidence\n",
    "    overwrite_existing=True  # Overwrite existing scores\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Your CSV has been updated with LLM assessment results!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ba41d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# FIXED METHOD MIS CALCULATOR - HANDLES EUROPEAN DECIMALS\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "class MethodMISCalculator:\n",
    "    \"\"\"\n",
    "    Calculate Method Implementation Score (MIS) for each METHOD\n",
    "    and update the MIS row in CSV (handles European decimal format)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file: str, delimiter: str = ';',\n",
    "                 software_name_column: str = 'Name',\n",
    "                 osmm_column: str = 'OSMM Score',\n",
    "                 method_start_column: str = 'Numerical-solvers',\n",
    "                 mis_row_name: str = 'Gjennomsnittlig score (MIS)'):\n",
    "        \"\"\"Initialize MIS calculator\"\"\"\n",
    "        self.csv_file = Path(csv_file)\n",
    "        self.delimiter = delimiter\n",
    "        self.software_name_column = software_name_column\n",
    "        self.osmm_column = osmm_column\n",
    "        self.mis_row_name = mis_row_name\n",
    "        \n",
    "        # Load CSV - don't try to parse decimals automatically\n",
    "        self.df = pd.read_csv(csv_file, delimiter=delimiter, encoding='utf-8-sig', \n",
    "                              dtype=str)  # ← Read everything as string first\n",
    "        \n",
    "        # Identify method columns\n",
    "        self.info_columns = []\n",
    "        self.method_columns = []\n",
    "        found_methods = False\n",
    "        \n",
    "        for col in self.df.columns:\n",
    "            if col == method_start_column:\n",
    "                found_methods = True\n",
    "            if found_methods:\n",
    "                self.method_columns.append(col)\n",
    "            else:\n",
    "                self.info_columns.append(col)\n",
    "        \n",
    "        print(f\"✓ Method MIS Calculator initialized:\")\n",
    "        print(f\"  File: {csv_file}\")\n",
    "        print(f\"  Software: {len(self.df)}\")\n",
    "        print(f\"  Methods: {len(self.method_columns)}\")\n",
    "    \n",
    "    \n",
    "    def _convert_to_float(self, value) -> float:\n",
    "        \"\"\"\n",
    "        Convert value to float, handling European format (comma as decimal)\n",
    "        \n",
    "        Args:\n",
    "            value: Value to convert (can be string with comma or period)\n",
    "        \n",
    "        Returns:\n",
    "            Float value or 0.0 if conversion fails\n",
    "        \"\"\"\n",
    "        if pd.isna(value) or value == '' or value == ' ':\n",
    "            return 0.0\n",
    "        \n",
    "        try:\n",
    "            # Convert to string and clean\n",
    "            value_str = str(value).strip()\n",
    "            \n",
    "            # Replace comma with period for European decimals\n",
    "            value_str = value_str.replace(',', '.')\n",
    "            \n",
    "            # Remove any spaces\n",
    "            value_str = value_str.replace(' ', '')\n",
    "            \n",
    "            # Convert to float\n",
    "            return float(value_str)\n",
    "        except (ValueError, TypeError):\n",
    "            return 0.0\n",
    "    \n",
    "    \n",
    "    def calculate_method_mis_scores(self, output_file: str = None,\n",
    "                                    include_details: bool = True,\n",
    "                                    exclude_mis_row: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"Calculate MIS scores for each METHOD\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"CALCULATING MIS SCORES PER METHOD\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        method_results = []\n",
    "        detailed_results = []\n",
    "        \n",
    "        for method_col in self.method_columns:\n",
    "            method_name = method_col\n",
    "            method_scores = []\n",
    "            software_scores = []\n",
    "            \n",
    "            for idx, row in self.df.iterrows():\n",
    "                software_name = row[self.software_name_column]\n",
    "                \n",
    "                # Skip MIS row if requested\n",
    "                if exclude_mis_row and software_name == self.mis_row_name:\n",
    "                    continue\n",
    "                \n",
    "                # Convert OSMM score using helper function\n",
    "                osmm_score = self._convert_to_float(row[self.osmm_column])\n",
    "                \n",
    "                # Convert method rank using helper function\n",
    "                method_rank = self._convert_to_float(row[method_col])\n",
    "                \n",
    "                # Calculate score: OSMM × method_rank\n",
    "                score = osmm_score * method_rank\n",
    "                method_scores.append(score)\n",
    "                \n",
    "                # Store detailed result\n",
    "                if include_details:\n",
    "                    detailed_results.append({\n",
    "                        'method': method_name,\n",
    "                        'software': software_name,\n",
    "                        'osmm_score': osmm_score,\n",
    "                        'method_rank': method_rank,\n",
    "                        'contribution_to_mis': score\n",
    "                    })\n",
    "                \n",
    "                software_scores.append({\n",
    "                    'software': software_name,\n",
    "                    'osmm': osmm_score,\n",
    "                    'rank': method_rank,\n",
    "                    'score': score\n",
    "                })\n",
    "            \n",
    "            # Calculate MIS for this method\n",
    "            mis_score = np.mean(method_scores) if method_scores else 0.0\n",
    "            \n",
    "            # Statistics\n",
    "            software_with_implementation = sum(1 for s in software_scores if s['rank'] > 0)\n",
    "            total_software = len(software_scores)\n",
    "            coverage = (software_with_implementation / total_software * 100) if total_software > 0 else 0.0\n",
    "            \n",
    "            # Rank distribution\n",
    "            rank_counts = Counter([s['rank'] for s in software_scores])\n",
    "            \n",
    "            method_results.append({\n",
    "                'method': method_name,\n",
    "                'mis_score': round(mis_score, 4),\n",
    "                'software_with_implementation': software_with_implementation,\n",
    "                'total_software': total_software,\n",
    "                'coverage_percentage': round(coverage, 2),\n",
    "                'avg_rank': round(np.mean([s['rank'] for s in software_scores]), 2),\n",
    "                'rank_0_count': rank_counts.get(0.0, 0),\n",
    "                'rank_1_count': rank_counts.get(1.0, 0),\n",
    "                'rank_2_count': rank_counts.get(2.0, 0),\n",
    "                'rank_3_count': rank_counts.get(3.0, 0),\n",
    "                'max_score': round(max(method_scores), 4) if method_scores else 0.0,\n",
    "                'min_score': round(min(method_scores), 4) if method_scores else 0.0\n",
    "            })\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        results_df = pd.DataFrame(method_results)\n",
    "        results_df = results_df.sort_values('mis_score', ascending=False)\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"METHOD MIS CALCULATION COMPLETE\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"\\nTop 20 Methods by MIS Score:\")\n",
    "        print(results_df[['method', 'mis_score', 'coverage_percentage', 'avg_rank']].head(20).to_string(index=False))\n",
    "        \n",
    "        # Save if requested\n",
    "        if output_file:\n",
    "            results_df.to_csv(output_file, index=False)\n",
    "            print(f\"\\n✓ Method MIS scores saved to: {output_file}\")\n",
    "            \n",
    "            if include_details:\n",
    "                detailed_df = pd.DataFrame(detailed_results)\n",
    "                detail_file = Path(output_file).parent / f\"{Path(output_file).stem}_detailed.csv\"\n",
    "                detailed_df.to_csv(detail_file, index=False)\n",
    "                print(f\"✓ Detailed method scores saved to: {detail_file}\")\n",
    "        \n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    \n",
    "    def update_mis_row_in_csv(self, output_file: str = None, \n",
    "                              use_comma_as_decimal: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Update the MIS row in the CSV with calculated MIS scores\n",
    "        \n",
    "        Args:\n",
    "            output_file: Output file path (if None, overwrites original)\n",
    "            use_comma_as_decimal: If True, format MIS values with comma as decimal (European)\n",
    "        \n",
    "        Returns:\n",
    "            Updated DataFrame\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"UPDATING MIS ROW IN CSV\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Calculate MIS scores per method\n",
    "        print(f\"\\nCalculating MIS scores for each method...\")\n",
    "        \n",
    "        method_mis_scores = {}\n",
    "        \n",
    "        for method_col in self.method_columns:\n",
    "            method_scores = []\n",
    "            \n",
    "            for idx, row in self.df.iterrows():\n",
    "                software_name = row[self.software_name_column]\n",
    "                \n",
    "                # Skip the MIS row itself\n",
    "                if software_name == self.mis_row_name:\n",
    "                    continue\n",
    "                \n",
    "                # Convert using helper function\n",
    "                osmm_score = self._convert_to_float(row[self.osmm_column])\n",
    "                method_rank = self._convert_to_float(row[method_col])\n",
    "                \n",
    "                # Calculate score\n",
    "                score = osmm_score * method_rank\n",
    "                method_scores.append(score)\n",
    "            \n",
    "            # Calculate average MIS for this method\n",
    "            mis_score = np.mean(method_scores) if method_scores else 0.0\n",
    "            method_mis_scores[method_col] = mis_score\n",
    "        \n",
    "        print(f\"  Calculated MIS for {len(method_mis_scores)} methods\")\n",
    "        \n",
    "        # Find the MIS row\n",
    "        mis_row_idx = self.df[self.df[self.software_name_column] == self.mis_row_name].index\n",
    "        \n",
    "        if len(mis_row_idx) == 0:\n",
    "            print(f\"\\n⚠ MIS row '{self.mis_row_name}' not found in CSV!\")\n",
    "            print(f\"  Creating new row...\")\n",
    "            \n",
    "            # Create new row\n",
    "            new_row = {col: '' for col in self.df.columns}\n",
    "            new_row[self.software_name_column] = self.mis_row_name\n",
    "            \n",
    "            # Add to dataframe\n",
    "            self.df = pd.concat([self.df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "            mis_row_idx = self.df[self.df[self.software_name_column] == self.mis_row_name].index\n",
    "        \n",
    "        mis_row_idx = mis_row_idx[0]\n",
    "        \n",
    "        print(f\"\\n✓ Found MIS row at index {mis_row_idx}\")\n",
    "        print(f\"  Updating {len(method_mis_scores)} method columns...\")\n",
    "        \n",
    "        # Update each method column with its MIS score\n",
    "        updates_made = 0\n",
    "        for method_col, mis_score in method_mis_scores.items():\n",
    "            if method_col in self.df.columns:\n",
    "                old_value = self.df.at[mis_row_idx, method_col]\n",
    "                \n",
    "                # Format the score\n",
    "                if use_comma_as_decimal:\n",
    "                    # European format: comma as decimal, 4 decimals\n",
    "                    formatted_score = f\"{mis_score:.4f}\".replace('.', ',')\n",
    "                else:\n",
    "                    # US format: period as decimal, 4 decimals\n",
    "                    formatted_score = f\"{mis_score:.4f}\"\n",
    "                \n",
    "                self.df.at[mis_row_idx, method_col] = formatted_score\n",
    "                updates_made += 1\n",
    "                \n",
    "                # Show some examples\n",
    "                if updates_made <= 5:\n",
    "                    old_display = str(old_value) if old_value else 'empty'\n",
    "                    print(f\"    {method_col}: {old_display} → {formatted_score}\")\n",
    "        \n",
    "        if updates_made > 5:\n",
    "            print(f\"    ... and {updates_made - 5} more\")\n",
    "        \n",
    "        # Clear OSMM Score column for MIS row\n",
    "        if self.osmm_column in self.df.columns:\n",
    "            self.df.at[mis_row_idx, self.osmm_column] = ''\n",
    "        \n",
    "        # Determine output file\n",
    "        if output_file is None:\n",
    "            output_file = self.csv_file\n",
    "        \n",
    "        # Save updated CSV\n",
    "        self.df.to_csv(output_file, sep=self.delimiter, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(f\"\\n✓ Updated CSV saved to: {output_file}\")\n",
    "        print(f\"  Total updates: {updates_made} method columns\")\n",
    "        print(f\"  Decimal format: {'Comma (European)' if use_comma_as_decimal else 'Period (US)'}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    \n",
    "    def show_mis_row_preview(self):\n",
    "        \"\"\"Show preview of the MIS row values\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"MIS ROW PREVIEW\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Calculate MIS scores\n",
    "        method_mis_scores = {}\n",
    "        \n",
    "        for method_col in self.method_columns:\n",
    "            method_scores = []\n",
    "            \n",
    "            for idx, row in self.df.iterrows():\n",
    "                software_name = row[self.software_name_column]\n",
    "                \n",
    "                # Skip the MIS row\n",
    "                if software_name == self.mis_row_name:\n",
    "                    continue\n",
    "                \n",
    "                osmm_score = self._convert_to_float(row[self.osmm_column])\n",
    "                method_rank = self._convert_to_float(row[method_col])\n",
    "                \n",
    "                score = osmm_score * method_rank\n",
    "                method_scores.append(score)\n",
    "            \n",
    "            mis_score = np.mean(method_scores) if method_scores else 0.0\n",
    "            method_mis_scores[method_col] = mis_score\n",
    "        \n",
    "        # Sort by MIS score\n",
    "        sorted_methods = sorted(method_mis_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"\\nTop 20 Methods by MIS Score:\")\n",
    "        print(f\"{'Method':<50} {'MIS Score':>10}\")\n",
    "        print(f\"{'-'*61}\")\n",
    "        for method, score in sorted_methods[:20]:\n",
    "            method_display = method[:47] + \"...\" if len(method) > 50 else method\n",
    "            print(f\"{method_display:<50} {score:>10.4f}\")\n",
    "        \n",
    "        print(f\"\\nBottom 10 Methods by MIS Score:\")\n",
    "        print(f\"{'Method':<50} {'MIS Score':>10}\")\n",
    "        print(f\"{'-'*61}\")\n",
    "        for method, score in sorted_methods[-10:]:\n",
    "            method_display = method[:47] + \"...\" if len(method) > 50 else method\n",
    "            print(f\"{method_display:<50} {score:>10.4f}\")\n",
    "        \n",
    "        print(f\"\\nStatistics:\")\n",
    "        scores = list(method_mis_scores.values())\n",
    "        print(f\"  Total methods: {len(scores)}\")\n",
    "        print(f\"  Mean MIS: {np.mean(scores):.4f}\")\n",
    "        print(f\"  Median MIS: {np.median(scores):.4f}\")\n",
    "        print(f\"  Std Dev: {np.std(scores):.4f}\")\n",
    "        print(f\"  Min: {min(scores):.4f}\")\n",
    "        print(f\"  Max: {max(scores):.4f}\")\n",
    "        \n",
    "        print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    \n",
    "    def create_method_comparison_report(self, output_file: str = \"method_mis_comparison.csv\"):\n",
    "        \"\"\"Create comprehensive comparison report\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"CREATING METHOD COMPARISON REPORT\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        comparison_data = []\n",
    "        \n",
    "        for method_col in self.method_columns:\n",
    "            implementations = []\n",
    "            \n",
    "            for idx, row in self.df.iterrows():\n",
    "                software_name = row[self.software_name_column]\n",
    "                \n",
    "                # Skip MIS row\n",
    "                if software_name == self.mis_row_name:\n",
    "                    continue\n",
    "                \n",
    "                osmm_score = self._convert_to_float(row[self.osmm_column])\n",
    "                method_rank = self._convert_to_float(row[method_col])\n",
    "                \n",
    "                implementations.append({\n",
    "                    'osmm': osmm_score,\n",
    "                    'rank': method_rank,\n",
    "                    'score': osmm_score * method_rank\n",
    "                })\n",
    "            \n",
    "            # Calculate statistics\n",
    "            mis_score = np.mean([imp['score'] for imp in implementations])\n",
    "            implemented = sum(1 for imp in implementations if imp['rank'] > 0)\n",
    "            direct_impl = sum(1 for imp in implementations if imp['rank'] == 3.0)\n",
    "            indirect_impl = sum(1 for imp in implementations if imp['rank'] == 2.0)\n",
    "            limited_impl = sum(1 for imp in implementations if imp['rank'] == 1.0)\n",
    "            \n",
    "            implementing_osmm = [imp['osmm'] for imp in implementations if imp['rank'] > 0]\n",
    "            avg_implementing_osmm = np.mean(implementing_osmm) if implementing_osmm else 0.0\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'method': method_col,\n",
    "                'mis_score': round(mis_score, 4),\n",
    "                'total_software': len(implementations),\n",
    "                'implemented_in': implemented,\n",
    "                'coverage_pct': round(implemented / len(implementations) * 100, 2),\n",
    "                'direct_implementations': direct_impl,\n",
    "                'indirect_implementations': indirect_impl,\n",
    "                'limited_implementations': limited_impl,\n",
    "                'not_supported': len(implementations) - implemented,\n",
    "                'avg_implementation_rank': round(np.mean([imp['rank'] for imp in implementations]), 2),\n",
    "                'avg_osmm_of_implementers': round(avg_implementing_osmm, 2),\n",
    "                'implementation_maturity_score': round(avg_implementing_osmm * (implemented / len(implementations)), 2)\n",
    "            })\n",
    "        \n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        comparison_df = comparison_df.sort_values('mis_score', ascending=False)\n",
    "        comparison_df.to_csv(output_file, index=False)\n",
    "        \n",
    "        print(f\"\\n✓ Method comparison report saved to: {output_file}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        return comparison_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c249e4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Method MIS Calculator initialized:\n",
      "  File: software_analysis_output/software_methods_updated.csv\n",
      "  Software: 39\n",
      "  Methods: 190\n",
      "\n",
      "======================================================================\n",
      "MIS ROW PREVIEW\n",
      "======================================================================\n",
      "\n",
      "Top 20 Methods by MIS Score:\n",
      "Method                                              MIS Score\n",
      "-------------------------------------------------------------\n",
      "power flow analysis                                    1.1734\n",
      "numerical solvers                                      1.0308\n",
      "contingency analysis                                   0.9961\n",
      "voltage control strategy                               0.9705\n",
      "automatic generation control agc                       0.9705\n",
      "power system stabilizer                                0.9595\n",
      "static var compensator                                 0.9453\n",
      "voltage stability                                      0.9413\n",
      "load balancing                                         0.9395\n",
      "security constrained unit commitment                   0.9311\n",
      "frequency nadir                                        0.9268\n",
      "dynamic reactive power compensation                    0.9174\n",
      "reactive power sharing                                 0.9174\n",
      "power quality disturbance                              0.9034\n",
      "power forecasting                                      0.9018\n",
      "load shedding analysis                                 0.9018\n",
      "state-space modeling                                   0.8945\n",
      "fault analysis                                         0.8847\n",
      "frequency variation                                    0.8837\n",
      "optimal capacity configuration                         0.8818\n",
      "\n",
      "Bottom 10 Methods by MIS Score:\n",
      "Method                                              MIS Score\n",
      "-------------------------------------------------------------\n",
      "empirical mode decomposition                           0.0684\n",
      "gated recurrent unit                                   0.0684\n",
      "data envelopment analysis                              0.0642\n",
      "quantum computing                                      0.0632\n",
      "deep deterministic policy gradient                     0.0616\n",
      "deep q-network                                         0.0616\n",
      "deep reinforcement learning drl                        0.0547\n",
      "generative adversarial network                         0.0521\n",
      "deep deterministic                                     0.0479\n",
      "Numerical-solvers                                      0.0000\n",
      "\n",
      "Statistics:\n",
      "  Total methods: 190\n",
      "  Mean MIS: 0.5318\n",
      "  Median MIS: 0.5689\n",
      "  Std Dev: 0.2884\n",
      "  Min: 0.0000\n",
      "  Max: 1.1734\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# USAGE WITH FIXED DECIMAL HANDLING\n",
    "# =============================================================================\n",
    "\n",
    "# Initialize calculator\n",
    "method_mis_calc = MethodMISCalculator(\n",
    "    csv_file=\"software_analysis_output/software_methods_updated.csv\",\n",
    "    delimiter=';',\n",
    "    software_name_column='Name',\n",
    "    osmm_column='OSMM Score',\n",
    "    method_start_column='Numerical-solvers',\n",
    "    mis_row_name='Gjennomsnittlig score (MIS)'\n",
    ")\n",
    "\n",
    "# Preview\n",
    "method_mis_calc.show_mis_row_preview()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5e79d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "UPDATING MIS ROW IN CSV\n",
      "======================================================================\n",
      "\n",
      "Calculating MIS scores for each method...\n",
      "  Calculated MIS for 190 methods\n",
      "\n",
      "✓ Found MIS row at index 36\n",
      "  Updating 190 method columns...\n",
      "    Numerical-solvers: nan → 0,0000\n",
      "    power flow analysis:  1,2726  → 1,1734\n",
      "    security-constrained optimal power flow:  0,9437  → 0,8587\n",
      "    security constrained unit commitment:  1,0415  → 0,9311\n",
      "    Non Linear Optimal Power Flow:  0,7133  → 0,6574\n",
      "    ... and 185 more\n",
      "\n",
      "✓ Updated CSV saved to: software_methods_with_mis_updated.csv\n",
      "  Total updates: 190 method columns\n",
      "  Decimal format: Comma (European)\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "CALCULATING MIS SCORES PER METHOD\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "METHOD MIS CALCULATION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Top 20 Methods by MIS Score:\n",
      "                              method  mis_score  coverage_percentage  avg_rank\n",
      "                 power flow analysis     1.1734                97.37      3.84\n",
      "                   numerical solvers     1.0308                92.11      3.40\n",
      "                contingency analysis     0.9961                92.11      3.16\n",
      "    automatic generation control agc     0.9705               100.00      3.08\n",
      "            voltage control strategy     0.9705               100.00      3.08\n",
      "             power system stabilizer     0.9595               100.00      3.04\n",
      "              static var compensator     0.9453               100.00      2.97\n",
      "                   voltage stability     0.9413               100.00      3.00\n",
      "                      load balancing     0.9395               100.00      2.97\n",
      "security constrained unit commitment     0.9311               100.00      2.99\n",
      "                     frequency nadir     0.9268               100.00      2.93\n",
      " dynamic reactive power compensation     0.9174               100.00      2.89\n",
      "              reactive power sharing     0.9174               100.00      2.89\n",
      "           power quality disturbance     0.9034                94.74      2.85\n",
      "              load shedding analysis     0.9018               100.00      2.85\n",
      "                   power forecasting     0.9018               100.00      2.90\n",
      "                state-space modeling     0.8945               100.00      2.84\n",
      "                      fault analysis     0.8847                89.47      2.96\n",
      "                 frequency variation     0.8837                94.74      2.78\n",
      "      optimal capacity configuration     0.8818               100.00      2.83\n",
      "\n",
      "✓ Method MIS scores saved to: method_mis_scores.csv\n",
      "✓ Detailed method scores saved to: method_mis_scores_detailed.csv\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "CREATING METHOD COMPARISON REPORT\n",
      "======================================================================\n",
      "\n",
      "✓ Method comparison report saved to: method_mis_comparison.csv\n",
      "======================================================================\n",
      "\n",
      "\n",
      "✓ All MIS calculations complete with proper decimal handling!\n"
     ]
    }
   ],
   "source": [
    "# Update CSV with European format (comma as decimal)\n",
    "updated_df = method_mis_calc.update_mis_row_in_csv(\n",
    "    output_file=\"software_methods_with_mis_updated.csv\",\n",
    "    use_comma_as_decimal=True  # ← European format\n",
    ")\n",
    "\n",
    "# Create reports\n",
    "method_mis_scores = method_mis_calc.calculate_method_mis_scores(\n",
    "    output_file=\"method_mis_scores.csv\",\n",
    "    include_details=True\n",
    ")\n",
    "\n",
    "method_comparison = method_mis_calc.create_method_comparison_report(\n",
    "    output_file=\"method_mis_comparison.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\n✓ All MIS calculations complete with proper decimal handling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1329806",
   "metadata": {},
   "source": [
    "### Adding new softwares or methods to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "beaab826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ MappingGapAnalyzer class defined\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# GAP ANALYSIS - CHECK FOR MISSING MAPPINGS\n",
    "# =============================================================================\n",
    "\n",
    "class MappingGapAnalyzer:\n",
    "    \"\"\"\n",
    "    Analyze gaps in software-method mappings\n",
    "    \n",
    "    Identifies:\n",
    "    - Missing software (in list but not in results)\n",
    "    - Missing methods (in list but not in results)\n",
    "    - Missing pairs (software-method combinations not assessed)\n",
    "    - New software/methods that need assessment\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, results_csv: str, software_list: List[str], method_list: List[str],\n",
    "                 delimiter: str = ';', software_col: str = 'software', method_col: str = 'method'):\n",
    "        \"\"\"\n",
    "        Initialize gap analyzer\n",
    "        \n",
    "        Args:\n",
    "            results_csv: Path to results CSV file\n",
    "            software_list: Complete list of software to assess\n",
    "            method_list: Complete list of methods to assess\n",
    "            delimiter: CSV delimiter\n",
    "            software_col: Column name for software in results\n",
    "            method_col: Column name for method in results\n",
    "        \"\"\"\n",
    "        self.results_csv = Path(results_csv)\n",
    "        self.software_list = set(software_list)\n",
    "        self.method_list = set(method_list)\n",
    "        self.delimiter = delimiter\n",
    "        self.software_col = software_col\n",
    "        self.method_col = method_col\n",
    "        \n",
    "        # Load existing results\n",
    "        try:\n",
    "            self.results_df = pd.read_csv(results_csv, delimiter=delimiter, encoding='utf-8-sig')\n",
    "            print(f\"✓ Loaded results from: {results_csv}\")\n",
    "            print(f\"  Total rows: {len(self.results_df)}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"⚠ Results file not found: {results_csv}\")\n",
    "            print(f\"  Creating empty results DataFrame\")\n",
    "            self.results_df = pd.DataFrame(columns=[software_col, method_col])\n",
    "        \n",
    "        # Get existing mappings\n",
    "        self.existing_software = set(self.results_df[software_col].unique())\n",
    "        self.existing_methods = set(self.results_df[method_col].unique())\n",
    "        self.existing_pairs = set(zip(self.results_df[software_col], self.results_df[method_col]))\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"GAP ANALYSIS INITIALIZATION\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Expected software: {len(self.software_list)}\")\n",
    "        print(f\"Expected methods: {len(self.method_list)}\")\n",
    "        print(f\"Expected pairs: {len(self.software_list) * len(self.method_list)}\")\n",
    "        print(f\"\\nExisting in results:\")\n",
    "        print(f\"  Software: {len(self.existing_software)}\")\n",
    "        print(f\"  Methods: {len(self.existing_methods)}\")\n",
    "        print(f\"  Pairs: {len(self.existing_pairs)}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    \n",
    "    def _normalize_name(self, name: str) -> str:\n",
    "        \"\"\"Normalize names for matching\"\"\"\n",
    "        if pd.isna(name):\n",
    "            return \"\"\n",
    "        name = str(name).lower().strip()\n",
    "        name = ''.join(c if c.isalnum() or c in ' -' else ' ' for c in name)\n",
    "        return ' '.join(name.split())\n",
    "    \n",
    "    \n",
    "    def find_missing_software(self) -> Dict[str, any]:\n",
    "        \"\"\"Find software in list but not in results\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ANALYZING MISSING SOFTWARE\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Normalize for comparison\n",
    "        expected_norm = {self._normalize_name(s): s for s in self.software_list}\n",
    "        existing_norm = {self._normalize_name(s) for s in self.existing_software}\n",
    "        \n",
    "        # Find missing\n",
    "        missing_norm = set(expected_norm.keys()) - existing_norm\n",
    "        missing_software = [expected_norm[m] for m in missing_norm]\n",
    "        \n",
    "        # Find close matches (possible typos)\n",
    "        close_matches = {}\n",
    "        for missing in missing_norm:\n",
    "            matches = get_close_matches(missing, existing_norm, n=3, cutoff=0.6)\n",
    "            if matches:\n",
    "                close_matches[expected_norm[missing]] = [\n",
    "                    next(s for s in self.existing_software if self._normalize_name(s) == m)\n",
    "                    for m in matches\n",
    "                ]\n",
    "        \n",
    "        print(f\"\\nMissing software: {len(missing_software)}\")\n",
    "        if missing_software:\n",
    "            print(\"\\nSoftware in list but not in results:\")\n",
    "            for sw in sorted(missing_software):\n",
    "                print(f\"  - {sw}\")\n",
    "                if sw in close_matches:\n",
    "                    print(f\"    Possible matches in results: {', '.join(close_matches[sw])}\")\n",
    "        \n",
    "        # Find extra software (in results but not in list)\n",
    "        extra_norm = existing_norm - set(expected_norm.keys())\n",
    "        extra_software = [s for s in self.existing_software if self._normalize_name(s) in extra_norm]\n",
    "        \n",
    "        if extra_software:\n",
    "            print(f\"\\n⚠ Extra software (in results but not in list): {len(extra_software)}\")\n",
    "            for sw in sorted(extra_software):\n",
    "                print(f\"  - {sw}\")\n",
    "        \n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        return {\n",
    "            'missing': missing_software,\n",
    "            'close_matches': close_matches,\n",
    "            'extra': extra_software\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def find_missing_methods(self) -> Dict[str, any]:\n",
    "        \"\"\"Find methods in list but not in results\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ANALYZING MISSING METHODS\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Normalize for comparison\n",
    "        expected_norm = {self._normalize_name(m): m for m in self.method_list}\n",
    "        existing_norm = {self._normalize_name(m) for m in self.existing_methods}\n",
    "        \n",
    "        # Find missing\n",
    "        missing_norm = set(expected_norm.keys()) - existing_norm\n",
    "        missing_methods = [expected_norm[m] for m in missing_norm]\n",
    "        \n",
    "        # Find close matches\n",
    "        close_matches = {}\n",
    "        for missing in missing_norm:\n",
    "            matches = get_close_matches(missing, existing_norm, n=3, cutoff=0.6)\n",
    "            if matches:\n",
    "                close_matches[expected_norm[missing]] = [\n",
    "                    next(m for m in self.existing_methods if self._normalize_name(m) == match)\n",
    "                    for match in matches\n",
    "                ]\n",
    "        \n",
    "        print(f\"\\nMissing methods: {len(missing_methods)}\")\n",
    "        if missing_methods:\n",
    "            print(\"\\nMethods in list but not in results:\")\n",
    "            for method in sorted(missing_methods):\n",
    "                print(f\"  - {method}\")\n",
    "                if method in close_matches:\n",
    "                    print(f\"    Possible matches in results: {', '.join(close_matches[method])}\")\n",
    "        \n",
    "        # Find extra methods\n",
    "        extra_norm = existing_norm - set(expected_norm.keys())\n",
    "        extra_methods = [m for m in self.existing_methods if self._normalize_name(m) in extra_norm]\n",
    "        \n",
    "        if extra_methods:\n",
    "            print(f\"\\n⚠ Extra methods (in results but not in list): {len(extra_methods)}\")\n",
    "            for method in sorted(extra_methods):\n",
    "                print(f\"  - {method}\")\n",
    "        \n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        return {\n",
    "            'missing': missing_methods,\n",
    "            'close_matches': close_matches,\n",
    "            'extra': extra_methods\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def find_missing_pairs(self, filter_by_software: List[str] = None,\n",
    "                          filter_by_method: List[str] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Find software-method pairs that haven't been assessed\n",
    "        \n",
    "        Args:\n",
    "            filter_by_software: Only check these software (optional)\n",
    "            filter_by_method: Only check these methods (optional)\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with missing pairs\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"ANALYZING MISSING PAIRS\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Determine which software/methods to check\n",
    "        software_to_check = filter_by_software if filter_by_software else list(self.software_list)\n",
    "        methods_to_check = filter_by_method if filter_by_method else list(self.method_list)\n",
    "        \n",
    "        # Create expected pairs\n",
    "        expected_pairs = set((sw, m) for sw in software_to_check for m in methods_to_check)\n",
    "        \n",
    "        # Create normalized mapping\n",
    "        software_norm_map = {self._normalize_name(s): s for s in software_to_check}\n",
    "        method_norm_map = {self._normalize_name(m): m for m in methods_to_check}\n",
    "        \n",
    "        # Normalize existing pairs\n",
    "        existing_pairs_norm = set()\n",
    "        for sw, m in self.existing_pairs:\n",
    "            sw_norm = self._normalize_name(sw)\n",
    "            m_norm = self._normalize_name(m)\n",
    "            if sw_norm in software_norm_map and m_norm in method_norm_map:\n",
    "                existing_pairs_norm.add((software_norm_map[sw_norm], method_norm_map[m_norm]))\n",
    "        \n",
    "        # Find missing\n",
    "        missing_pairs = expected_pairs - existing_pairs_norm\n",
    "        \n",
    "        print(f\"\\nExpected pairs: {len(expected_pairs)}\")\n",
    "        print(f\"Existing pairs: {len(existing_pairs_norm)}\")\n",
    "        print(f\"Missing pairs: {len(missing_pairs)}\")\n",
    "        \n",
    "        if len(missing_pairs) > 0:\n",
    "            # Create DataFrame\n",
    "            missing_df = pd.DataFrame(list(missing_pairs), columns=['software', 'method'])\n",
    "            missing_df = missing_df.sort_values(['software', 'method'])\n",
    "            \n",
    "            # Summary by software\n",
    "            print(f\"\\nMissing pairs by software:\")\n",
    "            software_counts = missing_df['software'].value_counts()\n",
    "            for sw, count in software_counts.items():\n",
    "                print(f\"  {sw}: {count} methods\")\n",
    "            \n",
    "            # Summary by method\n",
    "            print(f\"\\nTop 10 methods with most missing software:\")\n",
    "            method_counts = missing_df['method'].value_counts().head(10)\n",
    "            for method, count in method_counts.items():\n",
    "                print(f\"  {method}: {count} software\")\n",
    "            \n",
    "            print(f\"{'='*70}\\n\")\n",
    "            \n",
    "            return missing_df\n",
    "        else:\n",
    "            print(f\"\\n✓ No missing pairs - all combinations have been assessed!\")\n",
    "            print(f\"{'='*70}\\n\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    def create_assessment_batch_list(self, missing_pairs_df: pd.DataFrame,\n",
    "                                     batch_size: int = 20,\n",
    "                                     output_file: str = \"missing_pairs_batches.json\") -> List[List[Tuple[str, str]]]:\n",
    "        \"\"\"\n",
    "        Create batches for assessing missing pairs\n",
    "        \n",
    "        Args:\n",
    "            missing_pairs_df: DataFrame with missing pairs\n",
    "            batch_size: Number of pairs per batch\n",
    "            output_file: File to save batch list\n",
    "        \n",
    "        Returns:\n",
    "            List of batches\n",
    "        \"\"\"\n",
    "        if len(missing_pairs_df) == 0:\n",
    "            print(\"No missing pairs to batch\")\n",
    "            return []\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"CREATING ASSESSMENT BATCHES FOR MISSING PAIRS\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Convert to list of tuples\n",
    "        missing_pairs = list(zip(missing_pairs_df['software'], missing_pairs_df['method']))\n",
    "        \n",
    "        # Create batches\n",
    "        batches = [missing_pairs[i:i + batch_size] for i in range(0, len(missing_pairs), batch_size)]\n",
    "        \n",
    "        print(f\"\\nTotal missing pairs: {len(missing_pairs)}\")\n",
    "        print(f\"Batch size: {batch_size}\")\n",
    "        print(f\"Total batches: {len(batches)}\")\n",
    "        \n",
    "        # Save to file\n",
    "        batch_data = {\n",
    "            'timestamp': datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "            'total_pairs': len(missing_pairs),\n",
    "            'batch_size': batch_size,\n",
    "            'total_batches': len(batches),\n",
    "            'batches': [\n",
    "                {\n",
    "                    'batch_id': idx + 1,\n",
    "                    'pairs': batch\n",
    "                }\n",
    "                for idx, batch in enumerate(batches)\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        with open(output_file, 'w') as f:\n",
    "            json.dump(batch_data, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n✓ Batch list saved to: {output_file}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        return batches\n",
    "    \n",
    "    \n",
    "    def generate_complete_gap_report(self, output_dir: str = \"gap_analysis\"):\n",
    "        \"\"\"\n",
    "        Generate comprehensive gap analysis report\n",
    "        \n",
    "        Args:\n",
    "            output_dir: Directory to save reports\n",
    "        \"\"\"\n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(exist_ok=True)\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"GENERATING COMPLETE GAP ANALYSIS REPORT\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Analyze software\n",
    "        software_gaps = self.find_missing_software()\n",
    "        \n",
    "        # Save software report\n",
    "        sw_report = pd.DataFrame({\n",
    "            'status': ['missing'] * len(software_gaps['missing']) + ['extra'] * len(software_gaps['extra']),\n",
    "            'software': software_gaps['missing'] + software_gaps['extra'],\n",
    "            'possible_matches': [', '.join(software_gaps['close_matches'].get(sw, [])) \n",
    "                               for sw in software_gaps['missing']] + [''] * len(software_gaps['extra'])\n",
    "        })\n",
    "        sw_report_file = output_path / f\"software_gaps_{timestamp}.csv\"\n",
    "        sw_report.to_csv(sw_report_file, index=False)\n",
    "        print(f\"✓ Software gaps saved to: {sw_report_file}\")\n",
    "        \n",
    "        # Analyze methods\n",
    "        method_gaps = self.find_missing_methods()\n",
    "        \n",
    "        # Save method report\n",
    "        method_report = pd.DataFrame({\n",
    "            'status': ['missing'] * len(method_gaps['missing']) + ['extra'] * len(method_gaps['extra']),\n",
    "            'method': method_gaps['missing'] + method_gaps['extra'],\n",
    "            'possible_matches': [', '.join(method_gaps['close_matches'].get(m, [])) \n",
    "                               for m in method_gaps['missing']] + [''] * len(method_gaps['extra'])\n",
    "        })\n",
    "        method_report_file = output_path / f\"method_gaps_{timestamp}.csv\"\n",
    "        method_report.to_csv(method_report_file, index=False)\n",
    "        print(f\"✓ Method gaps saved to: {method_report_file}\")\n",
    "        \n",
    "        # Analyze pairs\n",
    "        missing_pairs = self.find_missing_pairs()\n",
    "        \n",
    "        if len(missing_pairs) > 0:\n",
    "            # Save missing pairs\n",
    "            pairs_file = output_path / f\"missing_pairs_{timestamp}.csv\"\n",
    "            missing_pairs.to_csv(pairs_file, index=False)\n",
    "            print(f\"✓ Missing pairs saved to: {pairs_file}\")\n",
    "            \n",
    "            # Create assessment batches\n",
    "            batches = self.create_assessment_batch_list(\n",
    "                missing_pairs,\n",
    "                batch_size=20,\n",
    "                output_file=str(output_path / f\"missing_pairs_batches_{timestamp}.json\")\n",
    "            )\n",
    "        \n",
    "        # Create summary\n",
    "        summary = {\n",
    "            'timestamp': timestamp,\n",
    "            'analysis': {\n",
    "                'expected_software': len(self.software_list),\n",
    "                'expected_methods': len(self.method_list),\n",
    "                'expected_pairs': len(self.software_list) * len(self.method_list),\n",
    "                'existing_software': len(self.existing_software),\n",
    "                'existing_methods': len(self.existing_methods),\n",
    "                'existing_pairs': len(self.existing_pairs)\n",
    "            },\n",
    "            'gaps': {\n",
    "                'missing_software': len(software_gaps['missing']),\n",
    "                'extra_software': len(software_gaps['extra']),\n",
    "                'missing_methods': len(method_gaps['missing']),\n",
    "                'extra_methods': len(method_gaps['extra']),\n",
    "                'missing_pairs': len(missing_pairs) if len(missing_pairs) > 0 else 0\n",
    "            },\n",
    "            'coverage': {\n",
    "                'software_coverage': round(len(self.existing_software) / len(self.software_list) * 100, 2),\n",
    "                'method_coverage': round(len(self.existing_methods) / len(self.method_list) * 100, 2),\n",
    "                'pair_coverage': round(len(self.existing_pairs) / (len(self.software_list) * len(self.method_list)) * 100, 2)\n",
    "            },\n",
    "            'files': {\n",
    "                'software_gaps': str(sw_report_file.name),\n",
    "                'method_gaps': str(method_report_file.name),\n",
    "                'missing_pairs': str(pairs_file.name) if len(missing_pairs) > 0 else None,\n",
    "                'batch_list': f\"missing_pairs_batches_{timestamp}.json\" if len(missing_pairs) > 0 else None\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        summary_file = output_path / f\"gap_analysis_summary_{timestamp}.json\"\n",
    "        with open(summary_file, 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n✓ Gap analysis summary saved to: {summary_file}\")\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"GAP ANALYSIS COMPLETE\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Coverage:\")\n",
    "        print(f\"  Software: {summary['coverage']['software_coverage']:.1f}%\")\n",
    "        print(f\"  Methods: {summary['coverage']['method_coverage']:.1f}%\")\n",
    "        print(f\"  Pairs: {summary['coverage']['pair_coverage']:.1f}%\")\n",
    "        print(f\"\\nFiles saved in: {output_path.absolute()}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        return summary\n",
    "\n",
    "\n",
    "print(\"✓ MappingGapAnalyzer class defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89fff724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 224 methods from: Saved_files_new\\method_variant_groups.json\n",
      "✓ Loaded 36 software\n",
      "✓ Loaded 224 methods\n",
      "✓ Total pairs to assess: 8064\n"
     ]
    }
   ],
   "source": [
    "# update the methods and/or software list:\n",
    "\n",
    "software_list_all = [\n",
    "    'Power Factory Digisilent','DINIS','ERACS','Distribution Network Analysis - ETAP','IPSA',\n",
    "'Power World','PSS/E','PSSE/SINCAL','SKM Power Tools','OpenDSS','Matlab & Simulink','DYMOLA','MathPower',\n",
    "'RelyPES','GridLAB-D','PyPSA (Python for Power System Analysis)','TARA','PyPower/Pandapower','GridCal Sk','MatDyn',\n",
    "'NEPLAN','PSAT','CYMEDIST','Synergi Electric','Dynawo','OpenModellica',\n",
    "'Sienna(PowerModels.jl PowerSystems.jl & PowerSimulations.jl PowerFlows.jl)','POWSYBL','Hitachi Network Manager','Spectrum Power',\n",
    "'CIMPLICITY Scada','eTerra','Netbas','Trimble NIS','GAMS','Promaps'\n",
    "]\n",
    "\n",
    "method_list_all = load_method_list(\"Saved_files_new\\method_variant_groups.json\")\n",
    "\n",
    "print(f\"✓ Loaded {len(software_list_all)} software\")\n",
    "print(f\"✓ Loaded {len(method_list_all)} methods\")\n",
    "print(f\"✓ Total pairs to assess: {len(software_list_all) * len(method_list_all)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbfb17af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded results from: software_analysis_final\\merged_final_20251019_015733.csv\n",
      "  Total rows: 6855\n",
      "\n",
      "======================================================================\n",
      "GAP ANALYSIS INITIALIZATION\n",
      "======================================================================\n",
      "Expected software: 36\n",
      "Expected methods: 224\n",
      "Expected pairs: 8064\n",
      "\n",
      "Existing in results:\n",
      "  Software: 37\n",
      "  Methods: 190\n",
      "  Pairs: 6855\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "GENERATING COMPLETE GAP ANALYSIS REPORT\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "ANALYZING MISSING SOFTWARE\n",
      "======================================================================\n",
      "\n",
      "Missing software: 1\n",
      "\n",
      "Software in list but not in results:\n",
      "  - Promaps\n",
      "\n",
      "⚠ Extra software (in results but not in list): 2\n",
      "  - ETAP\n",
      "  - PyPSA\n",
      "======================================================================\n",
      "\n",
      "✓ Software gaps saved to: gap_analysis\\software_gaps_20251110_182805.csv\n",
      "\n",
      "======================================================================\n",
      "ANALYZING MISSING METHODS\n",
      "======================================================================\n",
      "\n",
      "Missing methods: 54\n",
      "\n",
      "Methods in list but not in results:\n",
      "  - analytic hierarchy process ahp\n",
      "  - artificial bee colony algorithm\n",
      "    Possible matches in results: artificial bee colony, firefly algorithm, evolution algorithm\n",
      "  - capacity credit\n",
      "  - capacity prediction\n",
      "    Possible matches in results: wind power prediction\n",
      "  - cascading failure\n",
      "  - congestion management\n",
      "  - data mining\n",
      "  - doubly-fed induction generation\n",
      "    Possible matches in results: doubly-fed induction\n",
      "  - energy efficiency modeling\n",
      "    Possible matches in results: energy consumption modeling, predictive modeling, energy transition modeling\n",
      "  - energy market forecasting\n",
      "    Possible matches in results: energy demand forecasting, power forecasting, load forecasting\n",
      "  - energy policy analysis\n",
      "    Possible matches in results: energy resilience analysis, probabilistic analysis, time series analysis\n",
      "  - energy pricing strategy\n",
      "  - energy production forecasting\n",
      "    Possible matches in results: energy demand forecasting, energy transition modeling, energy consumption modeling\n",
      "  - energy supply chain analysis\n",
      "    Possible matches in results: energy resilience analysis\n",
      "  - energy system monitoring\n",
      "    Possible matches in results: power system restoration, energy demand forecasting, hybrid system modeling\n",
      "  - ensemble methods\n",
      "  - event-driven simulation\n",
      "    Possible matches in results: data-driven optimization, adaptive modulation\n",
      "  - feedback control\n",
      "    Possible matches in results: model predictive control\n",
      "  - frequency hopping\n",
      "    Possible matches in results: frequency nadir, frequency variation, load frequency control\n",
      "  - generalized autoregressive conditional heteroskedasticity\n",
      "  - generation outage modeling\n",
      "    Possible matches in results: power generation modeling, energy transition modeling, energy consumption modeling\n",
      "  - grid failure modeling\n",
      "    Possible matches in results: failure modeling, hybrid system modeling, predictive modeling\n",
      "  - hybrid energy storage\n",
      "  - injection shift factors\n",
      "  - load curtailment\n",
      "  - maximum power point tracking\n",
      "  - mixed-integer nonlinear programming\n",
      "    Possible matches in results: mixed integer linear programming, linear programming\n",
      "  - multi-agent\n",
      "    Possible matches in results: multi-agent system, multi-output\n",
      "  - multi-energy complementary system\n",
      "    Possible matches in results: multi-agent system\n",
      "  - multi-modal energy systems\n",
      "    Possible matches in results: multi-agent system\n",
      "  - multi-user detection\n",
      "    Possible matches in results: Multi-Period Optimisation\n",
      "  - multiobjective optimization\n",
      "    Possible matches in results: multi-objective optimization, multi-objective particle swarm optimization, Multi-Period Optimisation\n",
      "  - network topology optimization\n",
      "    Possible matches in results: ant colony optimization, General Optimization, heuristic optimization\n",
      "  - non-orthogonal multiple access noma\n",
      "  - optimal dispatch\n",
      "    Possible matches in results: economic dispatch, partial discharge pd, economic dispatch ED\n",
      "  - optimal power allocation\n",
      "    Possible matches in results: optimal power flow, Non Linear Optimal Power Flow\n",
      "  - optimal reactive power\n",
      "    Possible matches in results: optimal power flow, reactive power sharing\n",
      "  - optimal utilization\n",
      "    Possible matches in results: optimization gwo, global optimization, General Optimization\n",
      "  - phase shift keying\n",
      "    Possible matches in results: quadrature phase shift keying, quadrature pase shift keying, load shifting\n",
      "  - power spectral density\n",
      "  - probabilistic power flow\n",
      "    Possible matches in results: optimal power flow, probabilistic analysis, probabilistic-forecasting\n",
      "  - security-constrained economic dispatch\n",
      "    Possible matches in results: security constrained unit commitment, security-constrained optimal power flow, economic dispatch\n",
      "  - security-constrained unit commitment\n",
      "    Possible matches in results: security constrained unit commitment, security-constrained optimal power flow, stochastic unit commitment\n",
      "  - self-interference\n",
      "  - successive interference cancellation\n",
      "  - time-frequency\n",
      "    Possible matches in results: frequency nadir\n",
      "  - topology optimization\n",
      "    Possible matches in results: ant colony optimization, global optimization, supply chain optimization\n",
      "  - value of lost load\n",
      "  - variable energy resource modeling\n",
      "    Possible matches in results: energy transition modeling, failure modeling\n",
      "  - voltage reactive power\n",
      "    Possible matches in results: reactive power sharing, dynamic voltage restorer\n",
      "  - voltage scaling\n",
      "    Possible matches in results: voltage stability\n",
      "  - weather dependent outage\n",
      "  - zero energy\n",
      "  - zero-forcing\n",
      "    Possible matches in results: power forecasting\n",
      "\n",
      "⚠ Extra methods (in results but not in list): 20\n",
      "  - General Optimization\n",
      "  - Multi-Period  Optimisation\n",
      "  - Multi-Period Optimisation\n",
      "  - Non Linear Optimal Power Flow\n",
      "  - artificial bee colony\n",
      "  - data envelopment analysis\n",
      "  - deep-learning\n",
      "  - doubly-fed induction\n",
      "  - economic dispatch ED\n",
      "  - ensemble-learning\n",
      "  - fault analysis\n",
      "  - global optimization\n",
      "  - graph-neural network\n",
      "  - load balancing\n",
      "  - probabilistic-forecasting\n",
      "  - quadrature phase shift keying\n",
      "  - security constrained unit commitment\n",
      "  - short-term load forecasting\n",
      "  - stochastic simulation\n",
      "  - time series\n",
      "======================================================================\n",
      "\n",
      "✓ Method gaps saved to: gap_analysis\\method_gaps_20251110_182805.csv\n",
      "\n",
      "======================================================================\n",
      "ANALYZING MISSING PAIRS\n",
      "======================================================================\n",
      "\n",
      "Expected pairs: 8064\n",
      "Existing pairs: 5813\n",
      "Missing pairs: 2251\n",
      "\n",
      "Missing pairs by software:\n",
      "  Promaps: 224 methods\n",
      "  PyPSA (Python for Power System Analysis): 137 methods\n",
      "  Distribution Network Analysis - ETAP: 92 methods\n",
      "  CIMPLICITY Scada: 55 methods\n",
      "  Netbas: 55 methods\n",
      "  RelyPES: 55 methods\n",
      "  PyPower/Pandapower: 55 methods\n",
      "  Power World: 55 methods\n",
      "  Power Factory Digisilent: 55 methods\n",
      "  PSSE/SINCAL: 55 methods\n",
      "  PSAT: 55 methods\n",
      "  CYMEDIST: 55 methods\n",
      "  OpenModellica: 55 methods\n",
      "  eTerra: 55 methods\n",
      "  Dynawo: 55 methods\n",
      "  MatDyn: 55 methods\n",
      "  IPSA: 55 methods\n",
      "  DYMOLA: 55 methods\n",
      "  ERACS: 55 methods\n",
      "  Trimble NIS: 54 methods\n",
      "  TARA: 54 methods\n",
      "  Synergi Electric: 54 methods\n",
      "  Spectrum Power: 54 methods\n",
      "  Sienna(PowerModels.jl PowerSystems.jl & PowerSimulations.jl PowerFlows.jl): 54 methods\n",
      "  SKM Power Tools: 54 methods\n",
      "  DINIS: 54 methods\n",
      "  MathPower: 54 methods\n",
      "  Matlab & Simulink: 54 methods\n",
      "  GridCal Sk: 54 methods\n",
      "  GridLAB-D: 54 methods\n",
      "  PSS/E: 54 methods\n",
      "  Hitachi Network Manager: 54 methods\n",
      "  POWSYBL: 54 methods\n",
      "  OpenDSS: 54 methods\n",
      "  NEPLAN: 54 methods\n",
      "  GAMS: 54 methods\n",
      "\n",
      "Top 10 methods with most missing software:\n",
      "  analytic hierarchy process ahp: 36 software\n",
      "  security-constrained unit commitment: 36 software\n",
      "  multi-user detection: 36 software\n",
      "  network topology optimization: 36 software\n",
      "  non-orthogonal multiple access noma: 36 software\n",
      "  optimal dispatch: 36 software\n",
      "  optimal power allocation: 36 software\n",
      "  optimal reactive power: 36 software\n",
      "  optimal utilization: 36 software\n",
      "  phase shift keying: 36 software\n",
      "======================================================================\n",
      "\n",
      "✓ Missing pairs saved to: gap_analysis\\missing_pairs_20251110_182805.csv\n",
      "\n",
      "======================================================================\n",
      "CREATING ASSESSMENT BATCHES FOR MISSING PAIRS\n",
      "======================================================================\n",
      "\n",
      "Total missing pairs: 2251\n",
      "Batch size: 20\n",
      "Total batches: 113\n",
      "\n",
      "✓ Batch list saved to: gap_analysis\\missing_pairs_batches_20251110_182805.json\n",
      "======================================================================\n",
      "\n",
      "\n",
      "✓ Gap analysis summary saved to: gap_analysis\\gap_analysis_summary_20251110_182805.json\n",
      "\n",
      "======================================================================\n",
      "GAP ANALYSIS COMPLETE\n",
      "======================================================================\n",
      "Coverage:\n",
      "  Software: 102.8%\n",
      "  Methods: 84.8%\n",
      "  Pairs: 85.0%\n",
      "\n",
      "Files saved in: c:\\git_repos\\Literature-search-and-analysis\\gap_analysis\n",
      "======================================================================\n",
      "\n",
      "\n",
      "⚠ Found 2251 missing pairs!\n",
      "Load batch list from: gap_analysis/missing_pairs_batches_*.json\n",
      "Then run assessment on those pairs\n",
      "\n",
      "Ready to assess missing pairs...\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# RUN GAP ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "# Initialize gap analyzer with your results and lists\n",
    "gap_analyzer = MappingGapAnalyzer(\n",
    "    results_csv=\"software_analysis_final\\merged_final_20251019_015733.csv\",  # Your results CSV\n",
    "    software_list=software_list_all,  # Your software list\n",
    "    method_list=method_list_all,      # Your method list\n",
    "    delimiter=',',                     # CSV delimiter\n",
    "    software_col='software',           # Column name in results CSV\n",
    "    method_col='method'                # Column name in results CSV\n",
    ")\n",
    "\n",
    "# Generate complete gap analysis report\n",
    "summary = gap_analyzer.generate_complete_gap_report(\n",
    "    output_dir=\"gap_analysis\"\n",
    ")\n",
    "\n",
    "# If there are missing pairs, you can assess them:\n",
    "if summary['gaps']['missing_pairs'] > 0:\n",
    "    print(f\"\\n⚠ Found {summary['gaps']['missing_pairs']} missing pairs!\")\n",
    "    print(f\"Load batch list from: gap_analysis/missing_pairs_batches_*.json\")\n",
    "    print(f\"Then run assessment on those pairs\")\n",
    "    \n",
    "    # Load missing pairs for assessment\n",
    "    missing_pairs_df = pd.read_csv(f\"gap_analysis/missing_pairs_{summary['timestamp']}.csv\")\n",
    "    \n",
    "    # Create assessment batches\n",
    "    missing_software = missing_pairs_df['software'].tolist()\n",
    "    missing_methods = missing_pairs_df['method'].tolist()\n",
    "    \n",
    "    # Run assessment on missing pairs\n",
    "    print(\"\\nReady to assess missing pairs...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce85609e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57d1be32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LOADING MISSING PAIRS\n",
      "======================================================================\n",
      "Loading from: gap_analysis\\missing_pairs_20251110_182805.csv\n",
      "\n",
      "✓ Found 2251 missing pairs to assess\n",
      "\n",
      "Breakdown by software:\n",
      "  Promaps: 224 methods\n",
      "  PyPSA (Python for Power System Analysis): 137 methods\n",
      "  Distribution Network Analysis - ETAP: 92 methods\n",
      "  CIMPLICITY Scada: 55 methods\n",
      "  Netbas: 55 methods\n",
      "  RelyPES: 55 methods\n",
      "  PyPower/Pandapower: 55 methods\n",
      "  Power World: 55 methods\n",
      "  Power Factory Digisilent: 55 methods\n",
      "  PSSE/SINCAL: 55 methods\n",
      "  ... and 26 more software\n",
      "\n",
      "Breakdown by method:\n",
      "  analytic hierarchy process ahp: 36 software\n",
      "  security-constrained unit commitment: 36 software\n",
      "  multi-user detection: 36 software\n",
      "  network topology optimization: 36 software\n",
      "  non-orthogonal multiple access noma: 36 software\n",
      "  optimal dispatch: 36 software\n",
      "  optimal power allocation: 36 software\n",
      "  optimal reactive power: 36 software\n",
      "  optimal utilization: 36 software\n",
      "  phase shift keying: 36 software\n",
      "  ... and 214 more methods\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ASSESSING MISSING PAIRS\n",
      "======================================================================\n",
      "Total pairs: 2251\n",
      "Batch size: 20\n",
      "Total batches: 113\n",
      "Estimated time: 226 minutes\n",
      "\n",
      "======================================================================\n",
      "\n",
      "[Batch 1/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 179 column 7 (char 15672)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 2/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 156 column 569 (char 17124)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 3/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 178 column 7 (char 15830)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 4/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 5/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 189 column 7 (char 16965)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 6/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 16880)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 7/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 184 column 15 (char 16068)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 8/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 9/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 10/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.02 | 200 unique pairs assessed\n",
      "\n",
      "[Batch 11/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 156 column 266 (char 15190)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 12/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 164 column 7 (char 17935)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 13/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 14/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 184 column 7 (char 16730)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 15/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 16/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 17/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 189 column 7 (char 17233)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 18/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 16805)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 19/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 20/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 189 column 7 (char 18150)\n",
      " ✓ 0\n",
      "  Progress: $0.04 | 451 unique pairs assessed\n",
      "\n",
      "[Batch 21/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 22/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 189 column 15 (char 16905)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 23/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 155 column 5 (char 17115)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 24/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 107 column 319 (char 8848)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 25/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 26/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 27/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 28/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 29/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 186 column 85 (char 13445)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 30/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.06 | 652 unique pairs assessed\n",
      "\n",
      "[Batch 31/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 32/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 33/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 34/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 198 column 7 (char 17119)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 35/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 36/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 37/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 16428)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 38/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 39/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 40/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.08 | 852 unique pairs assessed\n",
      "\n",
      "[Batch 41/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 179 column 7 (char 17472)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 42/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 185 column 7 (char 16153)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 43/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 193 column 5 (char 17082)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 44/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 45/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 121 column 283 (char 9153)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 46/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 47/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 185 column 5 (char 16851)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 48/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 49/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 50/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.10 | 1053 unique pairs assessed\n",
      "  💾 Checkpoint saved\n",
      "\n",
      "[Batch 51/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 52/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 187 column 18 (char 18806)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 53/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 54/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 55/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 56/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 101 column 370 (char 7812)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 57/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 58/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 198 column 7 (char 15643)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 59/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 188 column 7 (char 16111)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 60/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 166 column 18 (char 16037)\n",
      " ✓ 0\n",
      "  Progress: $0.12 | 1254 unique pairs assessed\n",
      "\n",
      "[Batch 61/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 172 column 18 (char 16067)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 62/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 184 column 7 (char 15824)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 63/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 64/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 65/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 168 column 7 (char 16782)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 66/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 191 column 5 (char 18104)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 67/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 196 column 489 (char 17666)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 68/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 69/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 192 column 18 (char 17991)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 70/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.14 | 1456 unique pairs assessed\n",
      "\n",
      "[Batch 71/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 199 column 7 (char 18377)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 72/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 73/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 74/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 75/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 76/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 77/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 78/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 79/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 80/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.16 | 1657 unique pairs assessed\n",
      "\n",
      "[Batch 81/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 82/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 16964)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 83/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 7 (char 17774)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 84/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 85/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 86/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 17226)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 87/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 88/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 89/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting value: line 158 column 84 (char 17264)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 90/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting value: line 175 column 120 (char 16945)\n",
      " ✓ 0\n",
      "  Progress: $0.18 | 1937 unique pairs assessed\n",
      "\n",
      "[Batch 91/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 92/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 93/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 94/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 95/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 96/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 97/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 98/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 16895)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 99/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 100/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 179 column 199 (char 18619)\n",
      " ✓ 0\n",
      "  Progress: $0.20 | 2139 unique pairs assessed\n",
      "  💾 Checkpoint saved\n",
      "\n",
      "[Batch 101/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 176 column 18 (char 17241)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 102/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 5 (char 17643)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 103/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 104/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting value: line 184 column 5 (char 16527)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 105/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 106/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 107/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 189 column 7 (char 16624)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 108/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 109/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 196 column 233 (char 18554)\n",
      " ✓ 0\n",
      "\n",
      "[Batch 110/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "  Progress: $0.22 | 2339 unique pairs assessed\n",
      "\n",
      "[Batch 111/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 112/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "\n",
      "[Batch 113/113] 11 items\n",
      "  OpenAI... ✓ 11\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 76 column 554 (char 8269)\n",
      " ✓ 0\n",
      "\n",
      "======================================================================\n",
      "ASSESSMENT COMPLETE\n",
      "======================================================================\n",
      "✓ Assessed: 2391 unique pairs\n",
      "✗ Failed batches: 0\n",
      "\n",
      "============================================================\n",
      "API USAGE SUMMARY\n",
      "============================================================\n",
      "Total API Calls: 226\n",
      "Total Tokens: 894,272\n",
      "  - Input: 192,792\n",
      "  - Output: 701,480\n",
      "\n",
      "Total Cost: $0.2249\n",
      "Average Cost per Call: $0.0010\n",
      "\n",
      "Breakdown by Model:\n",
      "------------------------------------------------------------\n",
      "  gpt-4o-mini:\n",
      "    Calls: 113\n",
      "    Tokens: 373,205\n",
      "    Cost: $0.0908\n",
      "  models/gemini-2.0-flash:\n",
      "    Calls: 113\n",
      "    Tokens: 521,067\n",
      "    Cost: $0.1342\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# STEP 1: LOAD AND ANALYZE MISSING PAIRS\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# Load the missing pairs from gap analysis\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"LOADING MISSING PAIRS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Find the most recent gap analysis file\n",
    "gap_dir = Path(\"gap_analysis\")\n",
    "missing_pairs_files = list(gap_dir.glob(\"missing_pairs_*.csv\"))\n",
    "\n",
    "if len(missing_pairs_files) == 0:\n",
    "    print(\"⚠ No missing pairs found! Run gap analysis first.\")\n",
    "else:\n",
    "    # Get most recent file\n",
    "    latest_file = max(missing_pairs_files, key=lambda p: p.stat().st_mtime)\n",
    "    print(f\"Loading from: {latest_file}\")\n",
    "    \n",
    "    missing_pairs_df = pd.read_csv(latest_file)\n",
    "    print(f\"\\n✓ Found {len(missing_pairs_df)} missing pairs to assess\")\n",
    "    \n",
    "    # Show summary\n",
    "    print(f\"\\nBreakdown by software:\")\n",
    "    sw_counts = missing_pairs_df['software'].value_counts()\n",
    "    for sw, count in sw_counts.head(10).items():\n",
    "        print(f\"  {sw}: {count} methods\")\n",
    "    if len(sw_counts) > 10:\n",
    "        print(f\"  ... and {len(sw_counts) - 10} more software\")\n",
    "    \n",
    "    print(f\"\\nBreakdown by method:\")\n",
    "    method_counts = missing_pairs_df['method'].value_counts()\n",
    "    for method, count in method_counts.head(10).items():\n",
    "        print(f\"  {method}: {count} software\")\n",
    "    if len(method_counts) > 10:\n",
    "        print(f\"  ... and {len(method_counts) - 10} more methods\")\n",
    "    \n",
    "    print(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "# %%\n",
    "# =============================================================================\n",
    "# STEP 2: ASSESS MISSING PAIRS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ASSESSING MISSING PAIRS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Create list of pairs to assess\n",
    "missing_pairs_list = list(zip(missing_pairs_df['software'], missing_pairs_df['method']))\n",
    "\n",
    "# Initialize assessor\n",
    "assessor_missing = SoftwareMethodAssessor(use_config=True, timeout=180)\n",
    "\n",
    "# Create batches\n",
    "batch_size = 20\n",
    "batches = [missing_pairs_list[i:i + batch_size] for i in range(0, len(missing_pairs_list), batch_size)]\n",
    "\n",
    "print(f\"Total pairs: {len(missing_pairs_list)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Total batches: {len(batches)}\")\n",
    "print(f\"Estimated time: {len(batches) * 2} minutes\")\n",
    "print(f\"\\n{'='*70}\")\n",
    "\n",
    "# Storage for assessments\n",
    "all_assessments = {}\n",
    "failed_batches = []\n",
    "\n",
    "# Process each batch\n",
    "for batch_idx, batch in enumerate(batches, 1):\n",
    "    print(f\"\\n[Batch {batch_idx}/{len(batches)}] {len(batch)} items\", flush=True)\n",
    "    \n",
    "    # OpenAI assessment\n",
    "    try:\n",
    "        print(f\"  OpenAI...\", end='', flush=True)\n",
    "        openai_results = assessor_missing.assess_batch_with_openai(batch, 'gpt-4o-mini', debug=False)\n",
    "        for result in openai_results:\n",
    "            key = (result.software, result.method)\n",
    "            if key not in all_assessments:\n",
    "                all_assessments[key] = []\n",
    "            all_assessments[key].append(result)\n",
    "        print(f\" ✓ {len(openai_results)}\", flush=True)\n",
    "    except Exception as e:\n",
    "        print(f\" ✗ {str(e)[:50]}\", flush=True)\n",
    "        failed_batches.append(('openai', batch_idx, batch))\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Google assessment\n",
    "    try:\n",
    "        print(f\"  Google...\", end='', flush=True)\n",
    "        google_results = assessor_missing.assess_batch_with_google(batch, 'models/gemini-2.0-flash', debug=False)\n",
    "        for result in google_results:\n",
    "            key = (result.software, result.method)\n",
    "            if key not in all_assessments:\n",
    "                all_assessments[key] = []\n",
    "            all_assessments[key].append(result)\n",
    "        print(f\" ✓ {len(google_results)}\", flush=True)\n",
    "    except Exception as e:\n",
    "        print(f\" ✗ {str(e)[:50]}\", flush=True)\n",
    "        failed_batches.append(('google', batch_idx, batch))\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Progress update\n",
    "    if batch_idx % 10 == 0:\n",
    "        stats = assessor_missing.credit_tracker.get_stats()\n",
    "        print(f\"  Progress: ${stats['total_cost']:.2f} | {len(all_assessments)} unique pairs assessed\")\n",
    "    \n",
    "    # Checkpoint every 50 batches\n",
    "    if batch_idx % 50 == 0:\n",
    "        checkpoint_file = gap_dir / f\"checkpoint_missing_{batch_idx}.pkl\"\n",
    "        with open(checkpoint_file, 'wb') as f:\n",
    "            pickle.dump(all_assessments, f)\n",
    "        print(f\"  💾 Checkpoint saved\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ASSESSMENT COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"✓ Assessed: {len(all_assessments)} unique pairs\")\n",
    "print(f\"✗ Failed batches: {len(failed_batches)}\")\n",
    "\n",
    "assessor_missing.credit_tracker.print_summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61efd324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ASSESSING MISSING PAIRS\n",
      "======================================================================\n",
      "Found 2251 missing pairs to assess\n",
      "Total batches: 113\n",
      "======================================================================\n",
      "\n",
      "[Batch 1/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 2/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 176 column 18 (char 16853)\n",
      " ✓ 0\n",
      "[Batch 3/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 176 column 18 (char 17319)\n",
      " ✓ 0\n",
      "[Batch 4/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 177 column 7 (char 18221)\n",
      " ✓ 0\n",
      "[Batch 5/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 6/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 195 column 18 (char 17297)\n",
      " ✓ 0\n",
      "[Batch 7/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 8/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 9/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 188 column 7 (char 16334)\n",
      " ✓ 0\n",
      "[Batch 10/113] 20 items\n",
      "  OpenAI...  ERROR parsing batch response: Unterminated string starting at: line 57 column 20 (char 3280)\n",
      " ✓ 0\n",
      "  Google...  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 195 column 15 (char 17361)\n",
      " ✓ 0\n",
      "[Batch 11/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting value: line 188 column 132 (char 17076)\n",
      " ✓ 0\n",
      "[Batch 12/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 189 column 7 (char 16950)\n",
      " ✓ 0\n",
      "[Batch 13/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 14/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 15/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 16/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 76 column 76 (char 6746)\n",
      " ✓ 0\n",
      "[Batch 17/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 15973)\n",
      " ✓ 0\n",
      "[Batch 18/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 19/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 20/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 179 column 7 (char 17761)\n",
      " ✓ 0\n",
      "[Batch 21/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 22/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 156 column 18 (char 16967)\n",
      " ✓ 0\n",
      "[Batch 23/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 16116)\n",
      " ✓ 0\n",
      "[Batch 24/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 107 column 490 (char 8818)\n",
      " ✓ 0\n",
      "[Batch 25/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 26/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 27/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 28/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 191 column 18 (char 15108)\n",
      " ✓ 0\n",
      "[Batch 29/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 193 column 90 (char 15093)\n",
      " ✓ 0\n",
      "[Batch 30/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 31/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 32/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 33/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 185 column 18 (char 18302)\n",
      " ✓ 0\n",
      "[Batch 34/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 16747)\n",
      " ✓ 0\n",
      "[Batch 35/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 36/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 37/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 16669)\n",
      " ✓ 0\n",
      "[Batch 38/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 185 column 15 (char 17618)\n",
      " ✓ 0\n",
      "[Batch 39/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 40/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 41/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 176 column 18 (char 16574)\n",
      " ✓ 0\n",
      "[Batch 42/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 16462)\n",
      " ✓ 0\n",
      "[Batch 43/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 174 column 163 (char 15685)\n",
      " ✓ 0\n",
      "[Batch 44/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 45/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting value: line 178 column 106 (char 17061)\n",
      " ✓ 0\n",
      "[Batch 46/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 47/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 48/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 49/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 50/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 181 column 18 (char 17084)\n",
      " ✓ 0\n",
      "[Batch 51/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 16389)\n",
      " ✓ 0\n",
      "[Batch 52/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 187 column 18 (char 17778)\n",
      " ✓ 0\n",
      "[Batch 53/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 54/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 17082)\n",
      " ✓ 0\n",
      "[Batch 55/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 56/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 57/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 58/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 16437)\n",
      " ✓ 0\n",
      "[Batch 59/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 190 column 4 (char 16953)\n",
      " ✓ 0\n",
      "[Batch 60/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 61/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 173 column 7 (char 16619)\n",
      " ✓ 0\n",
      "[Batch 62/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 179 column 7 (char 15874)\n",
      " ✓ 0\n",
      "[Batch 63/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 188 column 7 (char 15726)\n",
      " ✓ 0\n",
      "[Batch 64/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 187 column 7 (char 15029)\n",
      " ✓ 0\n",
      "[Batch 65/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 172 column 4 (char 17200)\n",
      " ✓ 0\n",
      "[Batch 66/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 190 column 18 (char 17038)\n",
      " ✓ 0\n",
      "[Batch 67/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 68/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 69/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 188 column 7 (char 18882)\n",
      " ✓ 0\n",
      "[Batch 70/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 71/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 196 column 18 (char 16602)\n",
      " ✓ 0\n",
      "[Batch 72/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 73/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 74/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 75/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 76/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 77/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 199 column 7 (char 17755)\n",
      " ✓ 0\n",
      "[Batch 78/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 79/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 80/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 81/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 82/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 83/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting value: line 185 column 16 (char 17028)\n",
      " ✓ 0\n",
      "[Batch 84/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 85/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 16913)\n",
      " ✓ 0\n",
      "[Batch 86/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 92 column 72 (char 8249)\n",
      " ✓ 0\n",
      "[Batch 87/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 88/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 89/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 166 column 18 (char 17155)\n",
      " ✓ 0\n",
      "[Batch 90/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 16324)\n",
      " ✓ 0\n",
      "[Batch 91/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 136 column 80 (char 11086)\n",
      " ✓ 0\n",
      "[Batch 92/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 93/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 94/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 95/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 96/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 189 column 137 (char 18331)\n",
      " ✓ 0\n",
      "[Batch 97/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 98/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 183 column 7 (char 17339)\n",
      " ✓ 0\n",
      "[Batch 99/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 100/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting property name enclosed in double quotes: line 184 column 35 (char 18263)\n",
      " ✓ 0\n",
      "[Batch 101/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 170 column 18 (char 17113)\n",
      " ✓ 0\n",
      "[Batch 102/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 66 column 249 (char 6982)\n",
      " ✓ 0\n",
      "[Batch 103/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 104/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Expecting ',' delimiter: line 194 column 4 (char 17982)\n",
      " ✓ 0\n",
      "[Batch 105/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 106/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 107/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google...  ERROR parsing Google batch response: Unterminated string starting at: line 186 column 18 (char 16110)\n",
      " ✓ 0\n",
      "[Batch 108/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 109/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 110/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 111/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 112/113] 20 items\n",
      "  OpenAI... ✓ 20\n",
      "  Google... ✓ 20\n",
      "[Batch 113/113] 11 items\n",
      "  OpenAI... ✓ 11\n",
      "  Google... ✓ 11\n",
      "\n",
      "✓ Assessment complete: 2376 pairs\n",
      "\n",
      "============================================================\n",
      "API USAGE SUMMARY\n",
      "============================================================\n",
      "Total API Calls: 226\n",
      "Total Tokens: 903,016\n",
      "  - Input: 192,792\n",
      "  - Output: 710,224\n",
      "\n",
      "Total Cost: $0.2275\n",
      "Average Cost per Call: $0.0010\n",
      "\n",
      "Breakdown by Model:\n",
      "------------------------------------------------------------\n",
      "  gpt-4o-mini:\n",
      "    Calls: 113\n",
      "    Tokens: 380,323\n",
      "    Cost: $0.0929\n",
      "  models/gemini-2.0-flash:\n",
      "    Calls: 113\n",
      "    Tokens: 522,693\n",
      "    Cost: $0.1346\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: ASSESS AND MERGE MISSING PAIRS (USING EXISTING FUNCTIONS)\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ASSESSING MISSING PAIRS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Load missing pairs from gap analysis\n",
    "gap_dir = Path(\"gap_analysis\")\n",
    "missing_pairs_files = list(gap_dir.glob(\"missing_pairs_*.csv\"))\n",
    "latest_file = max(missing_pairs_files, key=lambda p: p.stat().st_mtime)\n",
    "missing_pairs_df = pd.read_csv(latest_file)\n",
    "\n",
    "print(f\"Found {len(missing_pairs_df)} missing pairs to assess\")\n",
    "\n",
    "# Create list of pairs\n",
    "missing_pairs_list = list(zip(missing_pairs_df['software'], missing_pairs_df['method']))\n",
    "\n",
    "# Initialize assessor\n",
    "assessor_missing = SoftwareMethodAssessor(use_config=True, timeout=180)\n",
    "\n",
    "# Create batches and assess (same as your existing assessment code)\n",
    "batch_size = 20\n",
    "batches = [missing_pairs_list[i:i + batch_size] for i in range(0, len(missing_pairs_list), batch_size)]\n",
    "\n",
    "print(f\"Total batches: {len(batches)}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Process batches\n",
    "all_assessments = {}\n",
    "failed_batches = []\n",
    "\n",
    "for batch_idx, batch in enumerate(batches, 1):\n",
    "    print(f\"[Batch {batch_idx}/{len(batches)}] {len(batch)} items\", flush=True)\n",
    "    \n",
    "    # OpenAI\n",
    "    try:\n",
    "        print(f\"  OpenAI...\", end='', flush=True)\n",
    "        openai_results = assessor_missing.assess_batch_with_openai(batch, 'gpt-4o-mini')\n",
    "        for result in openai_results:\n",
    "            key = (result.software, result.method)\n",
    "            if key not in all_assessments:\n",
    "                all_assessments[key] = []\n",
    "            all_assessments[key].append(result)\n",
    "        print(f\" ✓ {len(openai_results)}\", flush=True)\n",
    "    except Exception as e:\n",
    "        print(f\" ✗\", flush=True)\n",
    "        failed_batches.append(('openai', batch_idx))\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Google\n",
    "    try:\n",
    "        print(f\"  Google...\", end='', flush=True)\n",
    "        google_results = assessor_missing.assess_batch_with_google(batch, 'models/gemini-2.0-flash')\n",
    "        for result in google_results:\n",
    "            key = (result.software, result.method)\n",
    "            if key not in all_assessments:\n",
    "                all_assessments[key] = []\n",
    "            all_assessments[key].append(result)\n",
    "        print(f\" ✓ {len(google_results)}\", flush=True)\n",
    "    except Exception as e:\n",
    "        print(f\" ✗\", flush=True)\n",
    "        failed_batches.append(('google', batch_idx))\n",
    "    \n",
    "    time.sleep(2)\n",
    "\n",
    "print(f\"\\n✓ Assessment complete: {len(all_assessments)} pairs\")\n",
    "assessor_missing.credit_tracker.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64463f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CREATING CONSENSUS RESULTS\n",
      "======================================================================\n",
      "✓ Created 2376 consensus results\n",
      "\n",
      "Results exported to gap_analysis\\missing_pairs_assessed_20251111_025344.json\n",
      "✓ Saved to: gap_analysis\\missing_pairs_assessed_20251111_025344.json\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# STEP 4: CREATE CONSENSUS AND SAVE (REUSE EXISTING PATTERN)\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"CREATING CONSENSUS RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "consensus_results_missing = []\n",
    "\n",
    "for (software, method), assessments in all_assessments.items():\n",
    "    # Remove duplicates by provider\n",
    "    by_provider = {}\n",
    "    for a in assessments:\n",
    "        if a.llm_provider not in by_provider:\n",
    "            by_provider[a.llm_provider] = a\n",
    "    assessments = list(by_provider.values())\n",
    "    \n",
    "    if len(assessments) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Calculate consensus (using existing method)\n",
    "    ranks = [a.rank for a in assessments]\n",
    "    confidence, agreement_level = assessor_missing.calculate_confidence(ranks)\n",
    "    rank_counts = Counter(ranks)\n",
    "    final_rank = rank_counts.most_common(1)[0][0]\n",
    "    \n",
    "    consensus_results_missing.append(ConsensusResult(\n",
    "        software=software,\n",
    "        method=method,\n",
    "        final_rank=final_rank,\n",
    "        confidence=confidence,\n",
    "        individual_ranks={a.llm_provider: a.rank for a in assessments},\n",
    "        individual_reasoning={a.llm_provider: a.reasoning for a in assessments},\n",
    "        individual_sources={a.llm_provider: a.sources for a in assessments},\n",
    "        agreement_level=agreement_level,\n",
    "        total_tokens=sum(a.input_tokens + a.output_tokens for a in assessments),\n",
    "        total_cost=0.0\n",
    "    ))\n",
    "\n",
    "print(f\"✓ Created {len(consensus_results_missing)} consensus results\")\n",
    "\n",
    "# Save to JSON\n",
    "timestamp_missing = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "missing_results_file = gap_dir / f\"missing_pairs_assessed_{timestamp_missing}.json\"\n",
    "\n",
    "assessor_missing.export_results(consensus_results_missing, str(missing_results_file))\n",
    "print(f\"✓ Saved to: {missing_results_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84e156a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MERGING WITH EXISTING RESULTS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "MERGING ASSESSMENT RESULTS\n",
      "======================================================================\n",
      "Strategy: union\n",
      "Input files: 2\n",
      "\n",
      "Processing file 1/2: software_analysis_final\\merged_final_20251019_015733.json\n",
      "  Loaded 6855 assessments\n",
      "\n",
      "Processing file 2/2: gap_analysis\\missing_pairs_assessed_20251111_025344.json\n",
      "  Loaded 2376 assessments\n",
      "\n",
      "Recalculating consensus for merged results...\n",
      "\n",
      "✓ Merged results saved to: software_analysis_output/merged_complete_with_gaps_filled.json\n",
      "======================================================================\n",
      "\n",
      "✓ Merged 9095 total assessments\n",
      "✓ Also saved as CSV: software_analysis_output/merged_complete_with_gaps_filled.csv\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# IMPROVED: STEP 5 - MERGE AND SAVE BOTH FORMATS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"MERGING WITH EXISTING RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Use existing merge method\n",
    "merger_assessor = SoftwareMethodAssessor(use_config=True)\n",
    "\n",
    "existing_results_json = \"software_analysis_final\\merged_final_20251019_015733.json\"\n",
    "\n",
    "# Merge\n",
    "merged_complete_results = merger_assessor.merge_assessment_results(\n",
    "    existing_results_json,\n",
    "    str(missing_results_file),\n",
    "    output_file=\"software_analysis_output/merged_complete_with_gaps_filled.json\",\n",
    "    merge_strategy=\"union\"\n",
    ")\n",
    "\n",
    "print(f\"✓ Merged {len(merged_complete_results)} total assessments\")\n",
    "\n",
    "# Also save as CSV for gap analyzer\n",
    "merged_csv_path = \"software_analysis_output/merged_complete_with_gaps_filled.csv\"\n",
    "merged_df = pd.DataFrame([asdict(r) for r in merged_complete_results])\n",
    "merged_df.to_csv(merged_csv_path, index=False)\n",
    "print(f\"✓ Also saved as CSV: {merged_csv_path}\")\n",
    "\n",
    "print(f\"{'='*70}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3636ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VERIFYING COMPLETENESS\n",
      "======================================================================\n",
      "✓ Loaded results from: software_analysis_output/merged_complete_with_gaps_filled.csv\n",
      "  Total rows: 9095\n",
      "\n",
      "======================================================================\n",
      "GAP ANALYSIS INITIALIZATION\n",
      "======================================================================\n",
      "Expected software: 36\n",
      "Expected methods: 224\n",
      "Expected pairs: 8064\n",
      "\n",
      "Existing in results:\n",
      "  Software: 39\n",
      "  Methods: 244\n",
      "  Pairs: 9095\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ANALYZING MISSING PAIRS\n",
      "======================================================================\n",
      "\n",
      "Expected pairs: 8064\n",
      "Existing pairs: 7942\n",
      "Missing pairs: 122\n",
      "\n",
      "Missing pairs by software:\n",
      "  PyPSA (Python for Power System Analysis): 62 methods\n",
      "  Distribution Network Analysis - ETAP: 31 methods\n",
      "  DYMOLA: 21 methods\n",
      "  OpenModellica: 2 methods\n",
      "  CIMPLICITY Scada: 1 methods\n",
      "  IPSA: 1 methods\n",
      "  MatDyn: 1 methods\n",
      "  PSAT: 1 methods\n",
      "  PSSE/SINCAL: 1 methods\n",
      "  PyPower/Pandapower: 1 methods\n",
      "\n",
      "Top 10 methods with most missing software:\n",
      "  quadrature pase shift keying: 7 software\n",
      "  multi-user detection: 2 software\n",
      "  energy policy analysis: 2 software\n",
      "  energy market forecasting: 2 software\n",
      "  energy efficiency modeling: 2 software\n",
      "  energy supply chain analysis: 2 software\n",
      "  economic dispatch: 2 software\n",
      "  doubly-fed induction generation: 2 software\n",
      "  artificial bee colony algorithm: 2 software\n",
      "  analytic hierarchy process ahp: 2 software\n",
      "======================================================================\n",
      "\n",
      "\n",
      "⚠ Still 122 pairs missing\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 6: VERIFY COMPLETENESS\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"VERIFYING COMPLETENESS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Run gap analysis again\n",
    "gap_analyzer_verify = MappingGapAnalyzer(\n",
    "    results_csv=\"software_analysis_output/merged_complete_with_gaps_filled.csv\",\n",
    "    software_list=software_list_all,\n",
    "    method_list=method_list_all,\n",
    "    delimiter=',',\n",
    "    software_col='software',\n",
    "    method_col='method'\n",
    ")\n",
    "\n",
    "missing_pairs_verify = gap_analyzer_verify.find_missing_pairs()\n",
    "\n",
    "if len(missing_pairs_verify) == 0:\n",
    "    print(f\"\\n✓✓✓ SUCCESS! All pairs have been assessed ✓✓✓\")\n",
    "else:\n",
    "    print(f\"\\n⚠ Still {len(missing_pairs_verify)} pairs missing\")\n",
    "\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "765abd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "UPDATING MAIN CSV WITH ALL RESULTS\n",
      "======================================================================\n",
      "✓ CSV Merger initialized:\n",
      "  File: software_analysis_output\\software_methods_with_mis_updated.csv\n",
      "  Software rows: 39\n",
      "  Info columns: 21\n",
      "  Method columns: 189\n",
      "\n",
      "======================================================================\n",
      "MERGING LLM RESULTS INTO EXISTING CSV\n",
      "======================================================================\n",
      "Loaded 9095 LLM assessments\n",
      "\n",
      "Merge Statistics:\n",
      "  Updated: 5113\n",
      "  Skipped (low confidence): 0\n",
      "  Skipped (not found): 3982\n",
      "\n",
      "✓ Updated CSV saved to: software_analysis_output\\software_methods_with_mis_updated_extended.csv\n",
      "======================================================================\n",
      "\n",
      "\n",
      "✓ Main CSV updated with complete results!\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 7: UPDATE MAIN CSV (USING EXISTING ResultCSVMerger)\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"UPDATING MAIN CSV WITH ALL RESULTS\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "# Convert merged JSON to format compatible with CSV merger\n",
    "merged_complete_df = pd.DataFrame([asdict(r) for r in merged_complete_results])\n",
    "\n",
    "# Use EXISTING ResultCSVMerger class\n",
    "csv_merger = ResultCSVMerger(\n",
    "    csv_file=\"software_analysis_output\\software_methods_with_mis_updated.csv\",  \n",
    "    delimiter=';',\n",
    "    software_name_column='Name',\n",
    "    method_start_column='Numerical-solvers'\n",
    ")\n",
    "\n",
    "# Save merged results in format compatible with csv_merger\n",
    "temp_results_file = gap_dir / f\"all_results_for_csv_{timestamp_missing}.json\"\n",
    "merged_complete_df_simple = merged_complete_df[['software', 'method', 'final_rank', 'confidence']].copy()\n",
    "#merged_complete_df_simple.rename(columns={'final_rank': 'finalrank'}, inplace=True)\n",
    "merged_complete_df_simple.to_json(temp_results_file, orient='records')\n",
    "\n",
    "# Use EXISTING merge method\n",
    "updated_csv = csv_merger.merge_llm_results(\n",
    "    llm_results_file=str(temp_results_file),\n",
    "    output_file=\"software_analysis_output\\software_methods_with_mis_updated_extended.csv\",\n",
    "    min_confidence=0.5,\n",
    "    overwrite_existing=True\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Main CSV updated with complete results!\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428ceaf7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "literature-search-and-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
