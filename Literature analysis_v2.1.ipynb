{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74568855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import configparser\n",
    "import tiktoken\n",
    "import logging\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Phrases\n",
    "\n",
    "import openai  # <-- Import OpenAI\n",
    "\n",
    "SAVE_DIR = \"Saved_files_new\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdaddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CreditTracker:\n",
    "    def __init__(self):\n",
    "        self.total_tokens = 0\n",
    "        self.total_cost = 0\n",
    "        self.cost_per_1k_tokens = 0.00015\n",
    "    def update(self, tokens):\n",
    "        self.total_tokens += tokens\n",
    "        self.total_cost += (tokens / 1000) * self.cost_per_1k_tokens\n",
    "    def get_stats(self):\n",
    "        return {\"total_tokens\": self.total_tokens, \"total_cost\": round(self.total_cost, 4)}\n",
    "\n",
    "def initialize_openai():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config_LLM.txt')\n",
    "    api_key = config['LLM'].get('OPENAI_API_KEY')\n",
    "    model_type = config['LLM'].get('MODEL_TYPE')\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    return client, model_type\n",
    "\n",
    "client, model_type = initialize_openai()\n",
    "credit_tracker = CreditTracker()\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    return len(encoding.encode(string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "459d00f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_from_filename(filename):\n",
    "    base = os.path.splitext(os.path.basename(filename))[0]\n",
    "    parts = base.split('_')\n",
    "    keywords = [part for i, part in enumerate(parts) if i > 2 and part != 'results' and not part.isdigit()]\n",
    "    return keywords\n",
    "\n",
    "def keywords_to_filename_part(keywords):\n",
    "    return '_'.join([kw.lower().replace(' ', '_') for kw in keywords])\n",
    "\n",
    "def get_custom_stop_words(search_keywords=None):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words_to_keep = set()\n",
    "    if search_keywords:\n",
    "        for keyword in search_keywords:\n",
    "            keyword = keyword.lower()\n",
    "            words_to_keep.add(keyword)\n",
    "            for word in keyword.split():\n",
    "                words_to_keep.add(word)\n",
    "    stop_words = stop_words - words_to_keep\n",
    "    scientific_terms = {'et', 'al','ref','reference','references','cited','cite',\n",
    "        'fig','figure','figures','table','tables','chart','charts',\n",
    "        'published','journal','conference','proceedings','vol','volume','pp','page','pages','doi'}\n",
    "    stop_words = stop_words.union(scientific_terms)\n",
    "    return stop_words\n",
    "\n",
    "def initialize_openai():\n",
    "    import openai\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config_LLM.txt')\n",
    "    api_key = config['LLM'].get('OPENAI_API_KEY')\n",
    "    model_type = config['LLM'].get('MODEL_TYPE')\n",
    "    return openai.OpenAI(api_key=api_key), model_type\n",
    "\n",
    "class CreditTracker:\n",
    "    def __init__(self):\n",
    "        self.total_tokens = 0\n",
    "        self.total_cost = 0\n",
    "        self.cost_per_1k_tokens = 0.00015\n",
    "    def update(self, tokens):\n",
    "        self.total_tokens += tokens\n",
    "        self.total_cost += (tokens / 1000) * self.cost_per_1k_tokens\n",
    "    def get_stats(self):\n",
    "        return {\"total_tokens\": self.total_tokens, \"total_cost\": round(self.total_cost, 4)}\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    return len(encoding.encode(string))\n",
    "\n",
    "client, model_type = initialize_openai()\n",
    "credit_tracker = CreditTracker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07b89680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, search_keywords=None, min_word_length=2, remove_numbers=True):\n",
    "    if not isinstance(text, (str, int, float)):\n",
    "        return ''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    if remove_numbers:\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "    text = re.sub(r'--+', ' ', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = get_custom_stop_words(search_keywords)\n",
    "    tokens = [t for t in tokens if len(t) >= min_word_length and t not in stop_words and len(t) > 1 and not t.isdigit()]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    try:\n",
    "        tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    except:\n",
    "        pass\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_dataframe(df, text_col, search_keywords, processed_col='processed_text'):\n",
    "    df[text_col] = df[text_col].fillna('').astype(str)\n",
    "    df[processed_col] = df[text_col].apply(lambda x: preprocess_text(x, search_keywords))\n",
    "    return df[df[processed_col].str.strip() != '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0789ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"semantic_scholar_2025_02_14_reliability_resilience_power_systems_results.csv\"\n",
    "filepath = os.path.join(\"Saved_files\", filename)\n",
    "df = pd.read_csv(filepath, sep=\";\")\n",
    "df['text'] = df['title'].fillna('') + ' ' + df['abstract'].fillna('')\n",
    "search_keywords = extract_keywords_from_filename(filename)\n",
    "df = preprocess_dataframe(df, text_col='text', search_keywords=search_keywords)\n",
    "\n",
    "def clean_fields_of_study(s):\n",
    "    valid_fields = ['Computer Science', 'Economics', 'Engineering', 'Physics', 'Mathematics','Medicine','Business','Environmental Science','Chemistry','Materials Science','Geography','Biology','Geology','Political Science','Psychology','Com']\n",
    "    if pd.isna(s) or s == '[]':\n",
    "        return [\"Unknown\"]\n",
    "    if isinstance(s, str):\n",
    "        fields = [field.strip().strip(\"'\\\"\") for field in s.strip('[]').split(',')]\n",
    "        return [f if f in valid_fields else \"Unknown\" for f in fields] or [\"Unknown\"]\n",
    "    return [\"Unknown\"]\n",
    "df['fieldsOfStudy'] = df['fieldsOfStudy'].apply(clean_fields_of_study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20439ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 12:45:03,675 - INFO - collecting all words and their counts\n",
      "2025-08-18 12:45:03,677 - INFO - PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2025-08-18 12:45:05,780 - INFO - PROGRESS: at sentence #10000, processed 1524957 words and 863761 word types\n",
      "2025-08-18 12:45:07,973 - INFO - PROGRESS: at sentence #20000, processed 3004878 words and 1467564 word types\n",
      "2025-08-18 12:45:09,967 - INFO - collected 1902495 token types (unigram + bigrams) from a corpus of 4290297 words and 28934 sentences\n",
      "2025-08-18 12:45:09,970 - INFO - merged Phrases<1902495 vocab, min_count=10, threshold=50, max_vocab_size=40000000>\n",
      "2025-08-18 12:45:09,971 - INFO - Phrases lifecycle event {'msg': 'built Phrases<1902495 vocab, min_count=10, threshold=50, max_vocab_size=40000000> in 6.30s', 'datetime': '2025-08-18T12:45:09.971485', 'gensim': '4.3.2', 'python': '3.11.13 (main, Jun 12 2025, 12:41:34) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "2025-08-18 12:45:09,972 - INFO - collecting all words and their counts\n",
      "2025-08-18 12:45:09,973 - INFO - PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2025-08-18 12:45:14,733 - INFO - PROGRESS: at sentence #10000, processed 1471162 words and 886074 word types\n",
      "2025-08-18 12:45:19,427 - INFO - PROGRESS: at sentence #20000, processed 2890563 words and 1519087 word types\n",
      "2025-08-18 12:45:23,581 - INFO - collected 1981629 token types (unigram + bigrams) from a corpus of 4117577 words and 28934 sentences\n",
      "2025-08-18 12:45:23,582 - INFO - merged Phrases<1981629 vocab, min_count=5, threshold=50, max_vocab_size=40000000>\n",
      "2025-08-18 12:45:23,584 - INFO - Phrases lifecycle event {'msg': 'built Phrases<1981629 vocab, min_count=5, threshold=50, max_vocab_size=40000000> in 13.61s', 'datetime': '2025-08-18T12:45:23.584183', 'gensim': '4.3.2', 'python': '3.11.13 (main, Jun 12 2025, 12:41:34) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "def model_topics(df, num_topics=10, num_words=25):\n",
    "    tokenized_texts = df['processed_text'].apply(lambda x: x.split()).tolist()\n",
    "    bigram = Phrases(tokenized_texts, min_count=10, threshold=50, delimiter='_')\n",
    "    trigram = Phrases(bigram[tokenized_texts], threshold=50, delimiter='_')\n",
    "    phrased = []\n",
    "    for doc in tokenized_texts:\n",
    "        bigrams_ = [w for w in bigram[doc] if '_' in w]\n",
    "        trigrams_ = [w for w in trigram[bigram[doc]] if '_' in w]\n",
    "        combined = doc + bigrams_ + trigrams_\n",
    "        phrased.append(' '.join(combined))\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 1), token_pattern=r'\\b[\\w_-]+\\b', max_df=0.95, min_df=2, max_features=10000)\n",
    "    doc_term_matrix = vectorizer.fit_transform(phrased)\n",
    "    lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "    topic_distributions = lda_model.fit_transform(doc_term_matrix)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    topic_keywords = {}\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        top_indices = topic.argsort()[:-num_words-1:-1]\n",
    "        top_words = [feature_names[i] for i in top_indices]\n",
    "        word_weights = [(feature_names[i], topic[i]) for i in top_indices]\n",
    "        topic_keywords[topic_idx] = {'top_words': top_words, 'word_weights': word_weights}\n",
    "    return lda_model, vectorizer, topic_distributions, df, topic_keywords\n",
    "\n",
    "lda_model, vectorizer, topic_distributions, df_topic, topic_keywords = model_topics(df, num_topics=10, num_words=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fabcbd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 12:48:15,589 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top method phrases: ['monte carlo simulation', 'linear programming', 'signal processing techniques', 'load flow analysis', 'dynamic simulation', 'deep learning', 'fault tree analysis', 'power system state estimation', 'control theory applications', 'probabilistic methods', 'differential evolution', 'nonlinear programming', 'reliability assessment', 'contingency analysis', 'empirical modeling']\n"
     ]
    }
   ],
   "source": [
    "def extract_candidate_terms(df, text_col='processed_text', max_features=1000):\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 3), max_df=0.95, min_df=2, max_features=max_features, token_pattern=r'\\b[\\w-]+\\b')\n",
    "    matrix = vectorizer.fit_transform(df[text_col].fillna(''))\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    freqs = matrix.sum(axis=0).A1\n",
    "    return [term for term, freq in sorted(zip(terms, freqs), key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "def get_method_phrases(corpus_terms, client, model_type, credit_tracker):\n",
    "    sample_terms = ', '.join(corpus_terms[:150])\n",
    "    prompt = f\"\"\"Here are the most frequent terms from a corpus of scientific papers:\n",
    "{sample_terms}\n",
    "From the full list: {', '.join(corpus_terms)}\n",
    "Extract ONLY the terms that represent specific methodologies, techniques, or named approaches that would actually appear in this type of engineering research. Focus on:\n",
    "- Power system analysis methods\n",
    "- Reliability analysis techniques  \n",
    "- Engineering design approaches\n",
    "- Computational methods used in power/electrical engineering\n",
    "- Statistical methods for engineering\n",
    "\n",
    "Do NOT include: generic words like \"analysis\", \"method\", \"approach\", \"design\", \"system\" by themselves, nor general expressions such as \"distributed generation\", \"renewable resources\" that dont specifically describe a method.\n",
    "DO include: specific named methods like \"monte carlo simulation\", \"load flow analysis\", \"reliability assessment\", loss of load probability, probabilitstic methods, etc.\n",
    "\n",
    "Return as a simple Python list of strings, no code blocks or formatting.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_type,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    try:\n",
    "        return ast.literal_eval(response.choices[0].message.content)\n",
    "    except:\n",
    "        content = response.choices.message.content\n",
    "        content = content.replace('[', '').replace(']', '').replace('\"', '').replace(\"'\", '')\n",
    "        return [term.strip() for term in content.split(',') if len(term.strip()) > 3]\n",
    "\n",
    "\n",
    "def clean_method_phrases_fixed(method_phrases):\n",
    "    cleaned_phrases = []\n",
    "    for phrase in method_phrases:\n",
    "        cleaned = phrase.strip().replace('``````','').replace('[', '').replace(']', '').replace('\"', '').replace(\"'\", '').replace('\\n', ' ')\n",
    "        cleaned = ' '.join(cleaned.split())\n",
    "        if len(cleaned) > 2:\n",
    "            cleaned_phrases.append(cleaned.lower())\n",
    "    return list(set(cleaned_phrases))\n",
    "\n",
    "candidate_terms = extract_candidate_terms(df, text_col='processed_text')\n",
    "method_phrases = get_method_phrases(candidate_terms, client, model_type, credit_tracker)\n",
    "method_phrases = clean_method_phrases_fixed(method_phrases)\n",
    "print(\"Top method phrases:\", method_phrases[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d9bffec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-18 12:48:22,092 - INFO - Reducing method phrases (44) to top 30.\n"
     ]
    }
   ],
   "source": [
    "# --- TF-IDF Method Assignment ---\n",
    "def tfidf_method_assignment(df, method_phrases, processed_col='processed_text', min_score=0.05):\n",
    "    vectorizer = TfidfVectorizer(vocabulary=method_phrases, ngram_range=(1, 3), min_df=1, max_df=0.95, norm='l2')\n",
    "    tfidf_matrix = vectorizer.fit_transform(df[processed_col])\n",
    "    method_scores = tfidf_matrix.max(axis=1).toarray().ravel()\n",
    "    argmax_indices = tfidf_matrix.argmax(axis=1).A1\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    assigned = [feature_names[i] if score >= min_score else 'LowConfidence' for i, score in zip(argmax_indices, method_scores)]\n",
    "    df['Primary_Method_TFIDF'] = assigned\n",
    "    df['Method_TFIDF_Score'] = method_scores\n",
    "    # Store top 3 for optional use\n",
    "    topk = 3\n",
    "    for k in range(1, topk+1):\n",
    "        indices = np.argsort(tfidf_matrix.toarray(), axis=1)[:, -k:]\n",
    "        col_name = f'Top_{k}_TFIDF_Methods'\n",
    "        df[col_name] = [[feature_names[j] for j in idxs[::-1]] for idxs in indices]\n",
    "    return df\n",
    "\n",
    "df = tfidf_method_assignment(df, method_phrases, processed_col='processed_text', min_score=0.03)\n",
    "\n",
    "# --- LDA-based Method Assignment ---\n",
    "def lda_method_assignment(\n",
    "    df, method_phrases, processed_col='processed_text', max_method_topics=25, min_papers_per_topic=8\n",
    "):\n",
    "    # Reduce if many\n",
    "    if len(method_phrases) > max_method_topics:\n",
    "        logger.info(f\"Reducing method phrases ({len(method_phrases)}) to top {max_method_topics}.\")\n",
    "        tfidf_vectorizer = TfidfVectorizer(vocabulary=method_phrases, ngram_range=(1, 3), min_df=1, max_df=0.95, norm='l2')\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(df[processed_col])\n",
    "        total_method_scores = np.asarray(tfidf_matrix.sum(axis=0)).ravel()\n",
    "        phrase_ranking = np.argsort(total_method_scores)[-max_method_topics:][::-1]\n",
    "        best_phrases = [tfidf_vectorizer.get_feature_names_out()[i] for i in phrase_ranking]\n",
    "    else:\n",
    "        best_phrases = method_phrases\n",
    "    vectorizer = CountVectorizer(vocabulary=best_phrases, ngram_range=(1, 3), token_pattern=r'\\b[\\w-]+\\b')\n",
    "    doc_term_matrix = vectorizer.fit_transform(df[processed_col])\n",
    "    n_method_topics = len(best_phrases)\n",
    "    if n_method_topics < 2:\n",
    "        logger.warning(\"Not enough method phrases for LDA method assignment. Skipping.\")\n",
    "        df['Primary_Method_LDA'] = 'No_Method_Found'\n",
    "        df['Method_LDA_Score'] = 0.0\n",
    "        return df\n",
    "    lda = LatentDirichletAllocation(n_components=n_method_topics, learning_method='batch', random_state=42, max_iter=20)\n",
    "    doc_topic_dist = lda.fit_transform(doc_term_matrix)\n",
    "    topic_labels = best_phrases\n",
    "    best_topic_idx = doc_topic_dist.argmax(axis=1)\n",
    "    best_topic_val = doc_topic_dist[np.arange(len(df)), best_topic_idx]\n",
    "    assigned_methods = [topic_labels[i] if best_topic_val[j] > 1/n_method_topics+0.03 else 'LowConfidence' for j, i in enumerate(best_topic_idx)]\n",
    "    topic_assignment_counts = pd.Series(best_topic_idx).value_counts()\n",
    "    rare_topics = topic_assignment_counts[topic_assignment_counts < min_papers_per_topic].index.tolist()\n",
    "    assigned_methods = ['LowConfidence' if idx in rare_topics or label == 'LowConfidence' else topic_labels[idx] for (idx, label) in zip(best_topic_idx, assigned_methods)]\n",
    "    df['Primary_Method_LDA'] = assigned_methods\n",
    "    df['Method_LDA_Score'] = best_topic_val\n",
    "    df['Top_3_Methods_LDA'] = [\n",
    "        [topic_labels[i] for i in doc_topic_dist[j].argsort()[-3:][::-1]]\n",
    "        for j in range(doc_topic_dist.shape[0])\n",
    "    ]\n",
    "    df['Top_3_Methods_LDA_Scores'] = [\n",
    "        [doc_topic_dist[j, i] for i in doc_topic_dist[j].argsort()[-3:][::-1]]\n",
    "        for j in range(doc_topic_dist.shape[0])\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "\n",
    "df = lda_method_assignment(df, method_phrases, processed_col='processed_text', max_method_topics=40, min_papers_per_topic=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ff3caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_method_assignment(df):\n",
    "    # Add a new column for confidence label and unified prediction\n",
    "    super_confident = []\n",
    "    confident = []\n",
    "    low_confidence = []\n",
    "    final_method = []\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        tfidf_method = row['Primary_Method_TFIDF']\n",
    "        tfidf_score = row['Method_TFIDF_Score']\n",
    "        lda_method = row['Primary_Method_LDA']\n",
    "        lda_score = row['Method_LDA_Score']\n",
    "\n",
    "        # Both methods strong and agree\n",
    "        if tfidf_method != 'LowConfidence' and lda_method != 'LowConfidence' and tfidf_method == lda_method:\n",
    "            super_confident.append(True)\n",
    "            confident.append(False)\n",
    "            low_confidence.append(False)\n",
    "            final_method.append(tfidf_method)\n",
    "        # Prefer TF-IDF if it's strong\n",
    "        elif tfidf_method != 'LowConfidence':\n",
    "            super_confident.append(False)\n",
    "            confident.append(True)\n",
    "            low_confidence.append(False)\n",
    "            final_method.append(tfidf_method)\n",
    "        # Use LDA if TF-IDF is low or unclear, but LDA is strong\n",
    "        elif lda_method != 'LowConfidence':\n",
    "            super_confident.append(False)\n",
    "            confident.append(True)\n",
    "            low_confidence.append(False)\n",
    "            final_method.append(lda_method)\n",
    "        # Both weak: pick the best non-null candidate or fallback\n",
    "        else:\n",
    "            super_confident.append(False)\n",
    "            confident.append(False)\n",
    "            low_confidence.append(True)\n",
    "            # Try top-3 from either method; if unavailable, just mark as low confidence\n",
    "            candidates = set(row['Top_3_Methods_LDA']) | set(row['Top_1_TFIDF_Methods']) if 'Top_1_TFIDF_Methods' in row else set(row['Top_3_Methods_LDA'])\n",
    "            candidates = [w for w in candidates if w != 'LowConfidence']\n",
    "            final_method.append(candidates[0] if candidates else 'LowConfidence')\n",
    "\n",
    "    df['Method_Label'] = final_method\n",
    "    df['Method_Confidence'] = [\n",
    "        'super_confident' if s else 'confident' if c else 'low_confidence'\n",
    "        for s, c, l in zip(super_confident, confident, low_confidence)\n",
    "    ]\n",
    "    return df\n",
    "\n",
    "df = combined_method_assignment(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37e13154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Saved_files_new\\semantic_scholar_2025_08_18_final_combined_methods.csv\n",
      "Combined method label distribution:\n",
      "Method_Label\n",
      "particle swarm optimization    25785\n",
      "genetic algorithm                420\n",
      "monte carlo simulation           408\n",
      "deep learning                    332\n",
      "reliability assessment           295\n",
      "linear programming               295\n",
      "sensitivity analysis             239\n",
      "optimal power flow               185\n",
      "risk assessment                  128\n",
      "load forecasting                 117\n",
      "dynamic simulation                86\n",
      "state estimation                  78\n",
      "dynamic programming               75\n",
      "wavelet transform                 66\n",
      "nonlinear programming             57\n",
      "finite element method             53\n",
      "load flow analysis                47\n",
      "differential evolution            45\n",
      "contingency analysis              35\n",
      "network optimization              30\n",
      "fuzzy logic control               28\n",
      "fault tree analysis               27\n",
      "system identification             24\n",
      "time series analysis              22\n",
      "circuit simulation                19\n",
      "data envelopment analysis         11\n",
      "statistical modeling               7\n",
      "queuing theory                     6\n",
      "crow search algorithm              4\n",
      "hybrid modeling                    3\n",
      "empirical modeling                 3\n",
      "markov chain modeling              2\n",
      "statistical process control        1\n",
      "machine learning techniques        1\n",
      "Name: count, dtype: int64\n",
      "Confidence breakdown:\n",
      " Method_Confidence\n",
      "low_confidence     25331\n",
      "confident           3461\n",
      "super_confident      142\n",
      "Name: count, dtype: int64\n",
      "First 3 sample assigned methods:\n",
      "                  Method_Label Method_Confidence Primary_Method_TFIDF  \\\n",
      "0  particle swarm optimization    low_confidence        LowConfidence   \n",
      "1  particle swarm optimization    low_confidence        LowConfidence   \n",
      "2  particle swarm optimization    low_confidence        LowConfidence   \n",
      "3  particle swarm optimization    low_confidence        LowConfidence   \n",
      "4  particle swarm optimization    low_confidence        LowConfidence   \n",
      "\n",
      "  Primary_Method_LDA  \n",
      "0      LowConfidence  \n",
      "1      LowConfidence  \n",
      "2      LowConfidence  \n",
      "3      LowConfidence  \n",
      "4      LowConfidence  \n",
      "API token usage and cost: {'total_tokens': 0, 'total_cost': 0}\n"
     ]
    }
   ],
   "source": [
    "current_date = datetime.now().strftime(\"%Y_%m_%d\")\n",
    "output_filename = os.path.join(SAVE_DIR, f\"semantic_scholar_{current_date}_final_combined_methods.csv\")\n",
    "df.to_csv(output_filename, sep=';', encoding='utf-8', quoting=csv.QUOTE_NONNUMERIC, escapechar='\\\\')\n",
    "print(f\"Results saved to {output_filename}\")\n",
    "\n",
    "print(\"Combined method label distribution:\")\n",
    "print(df['Method_Label'].value_counts())\n",
    "print(\"Confidence breakdown:\\n\", df['Method_Confidence'].value_counts())\n",
    "print(\"First 3 sample assigned methods:\")\n",
    "print(df[['Method_Label', 'Method_Confidence', 'Primary_Method_TFIDF', 'Primary_Method_LDA']].head())\n",
    "\n",
    "print(\"API token usage and cost:\", credit_tracker.get_stats())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "literature-search-and-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
