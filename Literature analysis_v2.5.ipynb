{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52bdabc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import configparser\n",
    "import tiktoken\n",
    "import logging\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Phrases\n",
    "import openai\n",
    "\n",
    "SAVE_DIR = \"Saved_files_new\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6cfb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: OpenAI Setup\n",
    "class CreditTracker:\n",
    "    def __init__(self):\n",
    "        self.total_tokens = 0\n",
    "        self.total_cost = 0\n",
    "        self.cost_per_1k_tokens = 0.00015\n",
    "    def update(self, tokens):\n",
    "        self.total_tokens += tokens\n",
    "        self.total_cost += (tokens / 1000) * self.cost_per_1k_tokens\n",
    "    def get_stats(self):\n",
    "        return {\"total_tokens\": self.total_tokens, \"total_cost\": round(self.total_cost, 4)}\n",
    "\n",
    "def initialize_openai():\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config_LLM.txt')\n",
    "    api_key = config['LLM'].get('OPENAI_API_KEY')\n",
    "    model_type = config['LLM'].get('MODEL_TYPE')\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "    return client, model_type\n",
    "\n",
    "def num_tokens_from_string(string: str, model_name: str) -> int:\n",
    "    encoding = tiktoken.encoding_for_model(model_name)\n",
    "    return len(encoding.encode(string))\n",
    "\n",
    "client, model_type = initialize_openai()\n",
    "credit_tracker = CreditTracker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a168195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Utility Functions\n",
    "\n",
    "def extract_keywords_from_filename(filename):\n",
    "    base = os.path.splitext(os.path.basename(filename))[0]\n",
    "    parts = base.split('_')\n",
    "    return [part for i, part in enumerate(parts) if i > 2 and part != 'results' and not part.isdigit()]\n",
    "\n",
    "def get_custom_stop_words(search_keywords=None):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words_to_keep = set()\n",
    "    if search_keywords:\n",
    "        for keyword in search_keywords:\n",
    "            keyword = keyword.lower()\n",
    "            words_to_keep.add(keyword)\n",
    "            for word in keyword.split():\n",
    "                words_to_keep.add(word)\n",
    "    stop_words = stop_words - words_to_keep\n",
    "    scientific_terms = {'et', 'al', 'ref', 'reference', 'references', 'cited', 'cite',\n",
    "        'fig', 'figure', 'figures', 'table', 'tables', 'chart', 'charts',\n",
    "        'published', 'journal', 'conference', 'proceedings', 'vol', 'volume', 'pp', 'page', 'pages', 'doi'}\n",
    "    return stop_words.union(scientific_terms)\n",
    "\n",
    "def preprocess_text(text, search_keywords=None, min_word_length=2, remove_numbers=True):\n",
    "    if not isinstance(text, (str, int, float)):\n",
    "        return ''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    if remove_numbers:\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s-]', '', text)\n",
    "    text = re.sub(r'--+', ' ', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = get_custom_stop_words(search_keywords)\n",
    "    tokens = [t for t in tokens if len(t) >= min_word_length and t not in stop_words and len(t) > 1 and not t.isdigit()]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    try:\n",
    "        tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    except:\n",
    "        pass\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_dataframe(df, text_col, search_keywords, processed_col='processed_text'):\n",
    "    df[text_col] = df[text_col].fillna('').astype(str)\n",
    "    df[processed_col] = df[text_col].apply(lambda x: preprocess_text(x, search_keywords))\n",
    "    return df[df[processed_col].str.strip() != '']\n",
    "\n",
    "def clean_fields_of_study(s):\n",
    "    valid_fields = ['Computer Science', 'Economics', 'Engineering', 'Physics', 'Mathematics',\n",
    "        'Medicine','Business','Environmental Science','Chemistry','Materials Science',\n",
    "        'Geography','Biology','Geology','Political Science','Psychology','Com']\n",
    "    if pd.isna(s) or s == '[]':\n",
    "        return [\"Unknown\"]\n",
    "    if isinstance(s, str):\n",
    "        fields = [field.strip().strip(\"'\\\"\") for field in s.strip('[]').split(',')]\n",
    "        return [f if f in valid_fields else \"Unknown\" for f in fields] or [\"Unknown\"]\n",
    "    return [\"Unknown\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "197a86f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 22:36:57,205 - INFO - Loaded and preprocessed 28934 papers\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Data Loading & Cleaning\n",
    "filename = \"semantic_scholar_2025_02_14_reliability_resilience_power_systems_results.csv\"\n",
    "filepath = os.path.join(\"Saved_files\", filename)\n",
    "df = pd.read_csv(filepath, sep=\";\")\n",
    "df['text'] = df['title'].fillna('') + ' ' + df['abstract'].fillna('')\n",
    "search_keywords = extract_keywords_from_filename(filename)\n",
    "df = preprocess_dataframe(df, text_col='text', search_keywords=search_keywords)\n",
    "df['fieldsOfStudy'] = df['fieldsOfStudy'].apply(clean_fields_of_study)\n",
    "logger.info(f\"Loaded and preprocessed {len(df)} papers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee26c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Method Phrase Extraction & Standardization\n",
    "\n",
    "def extract_candidate_terms(df, text_col='processed_text', max_features=20000):\n",
    "    vectorizer = CountVectorizer(\n",
    "        ngram_range=(1, 4), max_df=0.95, min_df=2, max_features=max_features, token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "    matrix = vectorizer.fit_transform(df[text_col].fillna(''))\n",
    "    terms = vectorizer.get_feature_names_out()\n",
    "    freqs = matrix.sum(axis=0).A1\n",
    "    return [term for term, freq in sorted(zip(terms, freqs), key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "\n",
    "import ast\n",
    "import collections\n",
    "\n",
    "def get_method_phrases(\n",
    "    corpus_terms,\n",
    "    client,\n",
    "    model_type,\n",
    "    credit_tracker,\n",
    "    consensus_runs=3,\n",
    "    consensus_threshold=0.7,\n",
    "    temp=0\n",
    "):\n",
    "    \"\"\"\n",
    "    Calls LLM multiple times with temperature=0 and top_p=1, collecting method sets,\n",
    "    and retains only those terms that appear in at least consensus_threshold proportion of runs.\n",
    "    \"\"\"\n",
    "    sample_terms = ', '.join(corpus_terms[:100])\n",
    "    prompt = (\n",
    "        \"Here are the most frequent terms from a corpus of scientific papers:\\n\"\n",
    "        f\"{sample_terms}\\n\"\n",
    "        \"From the full list: \" + \", \".join(corpus_terms) + \"\\n\"\n",
    "        \"Extract ONLY the terms that represent specific methodologies, techniques, or named approaches. \"\n",
    "        \"Focus on computational, statistical, engineering, and reliability methods.\\n\"\n",
    "        \"DO include: e.g. 'monte carlo simulation', 'unit commitment', 'load flow analysis', 'genetic algorithm', \"\n",
    "        \"'neural network', 'stochastic optimization', 'reinforcement learning', 'fault tree analysis'.\\n\"\n",
    "        \"DO NOT include: 'framework', 'analysis', 'system', 'method', 'procedure', 'approach', 'application', 'performance', 'review'.\\n\"\n",
    "        \"Return as a single-line Python list; comma separated, no extra formatting.\"\n",
    "    )\n",
    "\n",
    "    all_results = []\n",
    "    for run_idx in range(consensus_runs):\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_type,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=temp,\n",
    "            top_p=1.0\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        try:\n",
    "            results = ast.literal_eval(content)\n",
    "        except Exception:\n",
    "            content = content.replace('[', '').replace(']', '').replace('\"', '').replace(\"'\", '')\n",
    "            results = [term.strip() for term in content.split(',') if len(term.strip()) > 3]\n",
    "        # Lowercase and strip for stable matching\n",
    "        all_results.append(set(t.lower() for t in results if t.strip()))\n",
    "        credit_tracker.update(len(content))\n",
    "        print(f\"Run {run_idx+1}: Found {len(results)} method phrases.\")\n",
    "\n",
    "    # Consensus: keep terms found in >= threshold * runs\n",
    "    counts = collections.Counter(term for result in all_results for term in result)\n",
    "    min_hits = max(1, int(consensus_runs * consensus_threshold))\n",
    "    stable_phrases = [term for term, cnt in counts.items() if cnt >= min_hits]\n",
    "\n",
    "    print(f\"\\n{len(stable_phrases)} consensus method phrases found in >= {min_hits}/{consensus_runs} runs.\")\n",
    "    if not stable_phrases:\n",
    "        print(\"Warning: No stable method phrases found. Consider lowering consensus threshold or increasing runs.\")\n",
    "    return sorted(stable_phrases)\n",
    "\n",
    "\n",
    "def get_method_abbreviation_dict(method_phrases, client, model_type, credit_tracker, batch_size=100):\n",
    "    import ast\n",
    "    results = {}\n",
    "    for i in range(0, len(method_phrases), batch_size):\n",
    "        batch = method_phrases[i:i+batch_size]\n",
    "        prompt = f\"\"\"For each of the following phrases, extract ALL common scientific abbreviations, synonyms, and aliases for methods/techniques.\n",
    "Methods:\\n{chr(10).join(batch)}\n",
    "Return as Python dict: {{'canonical method': [aliases, ...]}}\"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_type,\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a scientific abbreviation expert.\"},\n",
    "                      {\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        start, end = content.find('{'), content.rfind('}')+1\n",
    "        method_dict = {}\n",
    "        if start >= 0 and end > start:\n",
    "            try:\n",
    "                method_dict = ast.literal_eval(content[start:end])\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Failed to parse dictionary from LLM batch: {e}\")\n",
    "        results.update(method_dict)\n",
    "    logger.info(f\"LLM mapped {len(results)} methods to abbreviations/variants.\")\n",
    "    return results\n",
    "\n",
    "def build_abbr_to_canonical_map(method_dict):\n",
    "    abbr_map = {}\n",
    "    for canonical, variants in method_dict.items():\n",
    "        abbr_map[canonical.lower()] = canonical\n",
    "        for v in variants:\n",
    "            abbr_map[v.lower()] = canonical\n",
    "    return abbr_map\n",
    "\n",
    "def standardize_methods_in_text(text, abbr_to_canonical):\n",
    "    import re\n",
    "    sorted_vars = sorted(abbr_to_canonical, key=lambda x: -len(x))\n",
    "    for var in sorted_vars:\n",
    "        pattern = r'\\b' + re.escape(var) + r'\\b'\n",
    "        text = re.sub(pattern, abbr_to_canonical[var], text, flags=re.IGNORECASE)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c643efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Method Scoring Functions\n",
    "\n",
    "def compute_tfidf_scores(processed_texts, method_phrases, ngram_range=(1, 4), min_df=1, max_df=0.95, norm='l2'):\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        vocabulary=method_phrases, ngram_range=ngram_range,\n",
    "        min_df=min_df, max_df=max_df, norm=norm\n",
    "    )\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(processed_texts)\n",
    "    scores = tfidf_matrix.toarray()\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    return scores, feature_names\n",
    "\n",
    "def compute_lda_scores(processed_texts, method_phrases, ngram_range=(1, 3), n_topics=100, max_iter=20):\n",
    "    vectorizer = CountVectorizer(\n",
    "        vocabulary=method_phrases, ngram_range=ngram_range, token_pattern=r'\\b[\\w-]+\\b'\n",
    "    )\n",
    "    doc_term_matrix = vectorizer.fit_transform(processed_texts)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    if n_topics >= 2:\n",
    "        lda = LatentDirichletAllocation(n_components=n_topics, learning_method='batch',\n",
    "                                       random_state=42, max_iter=max_iter)\n",
    "        lda_matrix = lda.fit_transform(doc_term_matrix)\n",
    "    else:\n",
    "        lda_matrix = np.zeros((doc_term_matrix.shape[0], len(method_phrases)))\n",
    "    return lda_matrix, feature_names\n",
    "\n",
    "def compute_compound_scores(df, method_phrases, processed_col='standardized_text', window=150, min_word_len=4):\n",
    "    n_docs = len(df)\n",
    "    n_methods = len(method_phrases)\n",
    "    scores = np.zeros((n_docs, n_methods), dtype=np.float32)\n",
    "    docs = df[processed_col].fillna('').str.lower().tolist()\n",
    "    for j, phrase in enumerate(method_phrases):\n",
    "        phrase_l = phrase.lower()\n",
    "        words = [w for w in phrase_l.split() if len(w) >= min_word_len]\n",
    "        for i, text in enumerate(docs):\n",
    "            if phrase_l in text:\n",
    "                scores[i, j] = 1.0\n",
    "            elif len(words) > 1:\n",
    "                matches = sum(1 for w in words if w in text)\n",
    "                scores[i, j] = matches / len(words)\n",
    "    return scores\n",
    "\n",
    "def combine_method_scores(tfidf_scores, lda_scores, compound_scores, weights=(0.4, 0.3, 0.3)):\n",
    "    return weights[0]*tfidf_scores + weights[1]*lda_scores + weights[2]*compound_scores\n",
    "\n",
    "def assign_top_methods_by_total_score(df, total_scores, method_names, top_n=3, min_score=0.03):\n",
    "    for rank in range(top_n):\n",
    "        top_method = []\n",
    "        top_score = []\n",
    "        for row in total_scores:\n",
    "            idxs = np.argsort(row)[::-1]\n",
    "            nth_idx = idxs[rank] if rank < len(idxs) else None\n",
    "            if nth_idx is not None and row[nth_idx] >= min_score:\n",
    "                top_method.append(method_names[nth_idx])\n",
    "                top_score.append(row[nth_idx])\n",
    "            else:\n",
    "                top_method.append(\"LowConfidence\")\n",
    "                top_score.append(row[nth_idx] if nth_idx is not None else 0.0)\n",
    "        df[f'Top_{rank+1}_Method'] = top_method\n",
    "        df[f'Top_{rank+1}_Score'] = top_score\n",
    "    df['Primary_Method'] = df['Top_1_Method']\n",
    "    df['Primary_Method_Score'] = df['Top_1_Score']\n",
    "    conf = []\n",
    "    for m1, s1, m2, s2, m3, s3 in zip(\n",
    "        df['Top_1_Method'], df['Top_1_Score'], df['Top_2_Method'], df['Top_2_Score'], df['Top_3_Method'], df['Top_3_Score']\n",
    "    ):\n",
    "        if m1 != \"LowConfidence\" and s1 > 2 * max(0.05, s2):\n",
    "            conf.append(\"super_confident\")\n",
    "        elif m1 != \"LowConfidence\":\n",
    "            conf.append(\"confident\")\n",
    "        else:\n",
    "            conf.append(\"low_confidence\")\n",
    "    df['Method_Confidence'] = conf\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4499a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Topic Modeling + Naming + Author Functions\n",
    "\n",
    "def run_lda_topic_modeling(df, num_topics=10, num_words=25):\n",
    "    tokenized_texts = df['processed_text'].apply(lambda x: x.split()).tolist()\n",
    "    bigram = Phrases(tokenized_texts, min_count=10, threshold=50, delimiter='_')\n",
    "    trigram = Phrases(bigram[tokenized_texts], threshold=50, delimiter='_')\n",
    "    phrased = []\n",
    "    for doc in tokenized_texts:\n",
    "        bigrams_ = [w for w in bigram[doc] if '_' in w]\n",
    "        trigrams_ = [w for w in trigram[bigram[doc]] if '_' in w]\n",
    "        combined = doc + bigrams_ + trigrams_\n",
    "        phrased.append(' '.join(combined))\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 1), token_pattern=r'\\b[\\w_-]+\\b', max_df=0.95, min_df=2, max_features=10000)\n",
    "    doc_term_matrix = vectorizer.fit_transform(phrased)\n",
    "    lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "    topic_distributions = lda_model.fit_transform(doc_term_matrix)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    topic_keywords = {}\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        top_indices = topic.argsort()[:-num_words-1:-1]\n",
    "        top_words = [feature_names[i] for i in top_indices]\n",
    "        topic_keywords[topic_idx] = {'top_words': top_words}\n",
    "    return lda_model, vectorizer, topic_distributions, topic_keywords\n",
    "\n",
    "def assign_papers_to_topics(topic_distributions):\n",
    "    paper_classifications = []\n",
    "    for idx, dist in enumerate(topic_distributions):\n",
    "        top_2_topics = np.argsort(dist)[-2:][::-1]\n",
    "        primary_score = dist[top_2_topics[0]]\n",
    "        other_topics_sum = sum(dist) - primary_score\n",
    "        dominance_ratio = primary_score / (other_topics_sum + 1e-10)\n",
    "        paper_classifications.append({\n",
    "            'paper_idx': idx,\n",
    "            'primary_topic': top_2_topics[0],\n",
    "            'secondary_topic': top_2_topics[1],\n",
    "            'primary_score': primary_score,\n",
    "            'dominance_ratio': dominance_ratio\n",
    "        })\n",
    "    return paper_classifications\n",
    "\n",
    "def topic_name_llm(lda_keywords, tfidf_ngrams, top_titles, client, model_type, credit_tracker):\n",
    "    prompt = f\"\"\"Based on the following keywords and n-grams from LDA and TF-IDF, plus top titles, provide a concise topic name (bigram or trigram, single word if fitting):\n",
    "LDA: {', '.join(lda_keywords)}\n",
    "TFIDF: {', '.join(tfidf_ngrams)}\n",
    "TITLES: {', '.join(top_titles)}\n",
    "Return ONLY the topic name.\"\"\"\n",
    "    tokens = num_tokens_from_string(prompt, model_type)\n",
    "    credit_tracker.update(tokens)\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_type,\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a science topic-naming assistant.\"}, {\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    content = response.choices[0].message.content.strip()\n",
    "    credit_tracker.update(num_tokens_from_string(content, model_type))\n",
    "    return content\n",
    "\n",
    "def get_top_titles_for_topic(df, paper_classifications, topic_idx, n_titles=10):\n",
    "    dominant_papers = [p for p in paper_classifications if p['primary_topic'] == topic_idx]\n",
    "    paper_infos = [\n",
    "        (df.iloc[p['paper_idx']]['citationCount'] if 'citationCount' in df.columns else 0, df.iloc[p['paper_idx']]['title'])\n",
    "        for p in dominant_papers if not pd.isna(df.iloc[p['paper_idx']]['title'])\n",
    "    ]\n",
    "    top_titles = [title for _, title in sorted(paper_infos, key=lambda x: -x[0])[:n_titles]]\n",
    "    return top_titles\n",
    "\n",
    "def get_author_stats(paper_classifications, df_field, n_top=5):\n",
    "    top_papers = {}\n",
    "    author_topic_stats = {}\n",
    "    for topic in set(p['primary_topic'] for p in paper_classifications):\n",
    "        topic_papers = [p for p in paper_classifications if p['primary_topic'] == topic]\n",
    "        topic_papers.sort(key=lambda x: x['dominance_ratio'], reverse=True)\n",
    "        top_papers[topic] = []\n",
    "        for p in topic_papers[:n_top]:\n",
    "            paper_idx = p['paper_idx']\n",
    "            try:\n",
    "                authors = df_field.iloc[paper_idx]['authors']\n",
    "                if isinstance(authors, str):\n",
    "                    try: authors = ast.literal_eval(authors)\n",
    "                    except (ValueError, SyntaxError): authors = []\n",
    "                if isinstance(authors, list):\n",
    "                    author_list = []\n",
    "                    for author in authors:\n",
    "                        if isinstance(author, dict):\n",
    "                            author_list.append({'name': author.get('name', 'Unknown'), 'id': author.get('authorId', 'Unknown')})\n",
    "                else: author_list = []\n",
    "                top_papers[topic].append({\n",
    "                    'paperId': df_field.iloc[paper_idx].get('paperId',''),\n",
    "                    'title': df_field.iloc[paper_idx].get('title',''),\n",
    "                    'authors': author_list,\n",
    "                    'score': float(p['primary_score']),\n",
    "                    'dominance_ratio': float(p['dominance_ratio'])\n",
    "                })\n",
    "            except Exception as e: continue\n",
    "    return top_papers, author_topic_stats\n",
    "\n",
    "# Topic Modeling, Topic Naming, Author Analysis, and Topic-Specific TF-IDF Extraction\n",
    "\n",
    "def get_top_tfidf_ngrams_per_topic(df, tfidf_matrix, feature_names, topic_col='Primary_Topic_Index', top_k=10):\n",
    "    tfidf_ngrams = {}\n",
    "    for topic_idx in df[topic_col].dropna().unique():\n",
    "        topic_idx = int(topic_idx)\n",
    "        doc_indices = df[df[topic_col] == topic_idx].index\n",
    "        if len(doc_indices) == 0:\n",
    "            continue\n",
    "        topic_tfidf = np.asarray(tfidf_matrix[doc_indices].mean(axis=0)).ravel()\n",
    "        top_indices = topic_tfidf.argsort()[-top_k:][::-1]\n",
    "        top_terms = [(feature_names[i], topic_tfidf[i]) for i in top_indices if topic_tfidf[i] > 0]\n",
    "        tfidf_ngrams[topic_idx] = top_terms\n",
    "    return tfidf_ngrams\n",
    "\n",
    "def save_topic_analysis_outputs(\n",
    "    df, lda_model, lda_vectorizer, topic_distributions, topic_keywords, topic_names, topic_ngrams,\n",
    "    author_stats, top_papers, tfidf_ngrams, suffix_string\n",
    "):\n",
    "    # Save topic modeling components and naming results\n",
    "    topic_metadata = {\n",
    "        \"topics\": {int(k): v for k,v in topic_keywords.items()},\n",
    "        \"topic_names\": {int(k): v for k,v in topic_names.items()},\n",
    "        \"topic_ngrams\": {int(k): v for k,v in topic_ngrams.items()},\n",
    "    }\n",
    "    with open(os.path.join(SAVE_DIR, f\"topics_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(topic_metadata, f, indent=2)\n",
    "    with open(os.path.join(SAVE_DIR, f\"topic_names_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({int(k):v for k,v in topic_names.items()}, f, indent=2)\n",
    "    np.save(os.path.join(SAVE_DIR, f\"topic_distributions_{suffix_string}.npy\"), topic_distributions)\n",
    "    import joblib\n",
    "    joblib.dump(lda_model, os.path.join(SAVE_DIR, f\"lda_model_{suffix_string}.joblib\"))\n",
    "    joblib.dump(lda_vectorizer, os.path.join(SAVE_DIR, f\"lda_vectorizer_{suffix_string}.joblib\"))\n",
    "    # Save author and paper/topic info\n",
    "    with open(os.path.join(SAVE_DIR, f\"top_papers_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({int(k): v for k, v in top_papers.items()}, f, ensure_ascii=False, indent=2, default=str)\n",
    "    pd.DataFrame.from_dict(author_stats, orient='index').to_csv(\n",
    "        os.path.join(SAVE_DIR, f\"author_stats_{suffix_string}.csv\"))\n",
    "    # Topic-specific tfidf ngrams\n",
    "    with open(os.path.join(SAVE_DIR, f\"topic_specific_tfidf_ngrams_{suffix_string}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({int(k):[(term,float(score)) for term,score in v] for k,v in tfidf_ngrams.items()}, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ded8db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Diagnostics Function\n",
    "\n",
    "def diagnostics_with_scores(\n",
    "    df, tfidf_scores, lda_scores, compound_scores, combined_scores, method_names\n",
    "):\n",
    "    n_docs, n_methods = tfidf_scores.shape\n",
    "    print(\"=== DIAGNOSTICS ===\")\n",
    "    print(f\"Total documents: {n_docs}\")\n",
    "    print(f\"Methods: {n_methods}\")\n",
    "    print(f\"TF-IDF coverage: {(tfidf_scores > 0).any(axis=1).sum()}/{n_docs} ({100*(tfidf_scores>0).any(axis=1).mean():.1f}%)\")\n",
    "    print(f\"LDA coverage: {(lda_scores > 0).any(axis=1).sum()}/{n_docs} ({100*(lda_scores>0).any(axis=1).mean():.1f}%)\")\n",
    "    print(f\"Compound coverage: {(compound_scores > 0).any(axis=1).sum()}/{n_docs} ({100*(compound_scores>0).any(axis=1).mean():.1f}%)\")\n",
    "    print(f\"Combined coverage: {(combined_scores > 0).any(axis=1).sum()}/{n_docs} ({100*(combined_scores>0).any(axis=1).mean():.1f}%)\")\n",
    "    if 'Primary_Method' in df.columns:\n",
    "        print(\"\\nMethod label distribution (top 10):\")\n",
    "        print(df['Primary_Method'].value_counts().head(10))\n",
    "    if 'Method_Confidence' in df.columns:\n",
    "        print(\"\\nMethod confidence distribution:\")\n",
    "        print(df['Method_Confidence'].value_counts())\n",
    "    print(\"\\nMethod vocabulary sample:\", ', '.join(method_names[:10]))\n",
    "    print(f\"\\nTFIDF stats: mean={tfidf_scores.mean():.3f}, std={tfidf_scores.std():.3f}\")\n",
    "    print(f\"LDA stats: mean={lda_scores.mean():.3f}, std={lda_scores.std():.3f}\")\n",
    "    print(f\"Compound stats: mean={compound_scores.mean():.3f}, std={compound_scores.std():.3f}\")\n",
    "    print(f\"Combined stats: mean={combined_scores.mean():.3f}, std={combined_scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3ac292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 22:36:57,612 - INFO - collecting all words and their counts\n",
      "2025-08-20 22:36:57,612 - INFO - PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2025-08-20 22:36:59,000 - INFO - PROGRESS: at sentence #10000, processed 1524957 words and 863761 word types\n",
      "2025-08-20 22:37:00,554 - INFO - PROGRESS: at sentence #20000, processed 3004878 words and 1467564 word types\n",
      "2025-08-20 22:37:01,856 - INFO - collected 1902495 token types (unigram + bigrams) from a corpus of 4290297 words and 28934 sentences\n",
      "2025-08-20 22:37:01,857 - INFO - merged Phrases<1902495 vocab, min_count=10, threshold=50, max_vocab_size=40000000>\n",
      "2025-08-20 22:37:01,858 - INFO - Phrases lifecycle event {'msg': 'built Phrases<1902495 vocab, min_count=10, threshold=50, max_vocab_size=40000000> in 4.25s', 'datetime': '2025-08-20T22:37:01.858831', 'gensim': '4.3.2', 'python': '3.11.13 (main, Jun 12 2025, 12:41:34) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "2025-08-20 22:37:01,858 - INFO - collecting all words and their counts\n",
      "2025-08-20 22:37:01,859 - INFO - PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2025-08-20 22:37:05,079 - INFO - PROGRESS: at sentence #10000, processed 1471162 words and 886074 word types\n",
      "2025-08-20 22:37:08,503 - INFO - PROGRESS: at sentence #20000, processed 2890563 words and 1519087 word types\n",
      "2025-08-20 22:37:11,428 - INFO - collected 1981629 token types (unigram + bigrams) from a corpus of 4117577 words and 28934 sentences\n",
      "2025-08-20 22:37:11,429 - INFO - merged Phrases<1981629 vocab, min_count=5, threshold=50, max_vocab_size=40000000>\n",
      "2025-08-20 22:37:11,429 - INFO - Phrases lifecycle event {'msg': 'built Phrases<1981629 vocab, min_count=5, threshold=50, max_vocab_size=40000000> in 9.57s', 'datetime': '2025-08-20T22:37:11.429841', 'gensim': '4.3.2', 'python': '3.11.13 (main, Jun 12 2025, 12:41:34) [MSC v.1943 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.26100-SP0', 'event': 'created'}\n",
      "2025-08-20 22:39:31,270 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 22:39:31,276 - INFO - Topic 0: Solar Power Systems\n",
      "2025-08-20 22:39:32,474 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 22:39:32,477 - INFO - Topic 1: Wireless Communication Systems\n",
      "2025-08-20 22:39:34,023 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 22:39:34,027 - INFO - Topic 2: Cloud Resource Management\n",
      "2025-08-20 22:39:34,690 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 22:39:34,691 - INFO - Topic 3: Smart Grid Monitoring\n",
      "2025-08-20 22:39:36,196 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 22:39:36,221 - INFO - Topic 4: Power Control Systems\n",
      "2025-08-20 22:39:38,046 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 22:39:38,053 - INFO - Topic 5: Wind Power Systems\n",
      "2025-08-20 22:39:39,156 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 22:39:39,161 - INFO - Topic 6: Energy Storage Systems\n",
      "2025-08-20 22:39:40,156 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 22:39:40,163 - INFO - Topic 7: Power System Reliability\n",
      "2025-08-20 22:39:40,781 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 22:39:40,786 - INFO - Topic 8: Battery Performance Optimization\n",
      "2025-08-20 22:39:41,543 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 22:39:41,552 - INFO - Topic 9: Power System Optimization\n",
      "2025-08-20 22:39:42,269 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 22:39:42,273 - INFO - Topic 10: Energy Governance and Systems\n",
      "2025-08-20 22:39:42,846 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 22:39:42,849 - INFO - Topic 11: Thermal Energy Systems\n",
      "2025-08-20 22:39:42,856 - INFO - ✓ Topic naming and assignment completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample topics and names:\n",
      "{0: 'Solar Power Systems', 1: 'Wireless Communication Systems', 2: 'Cloud Resource Management', 3: 'Smart Grid Monitoring', 4: 'Power Control Systems'}\n",
      "\n",
      "Top authors and top papers by topic (first 2):\n",
      "{0: [{'paperId': '92dc35c9518014301149ff05aec8c715bab009b9', 'title': 'The Hybrid Cycle: Integration of a Fuel Cell With a Gas Turbine', 'authors': [{'name': 'J. Leeper', 'id': '98489278'}], 'score': 0.9947914327096009, 'dominance_ratio': 190.9913721272474}, {'paperId': '633d495adac1c6cfe8e7e20b2c052bb9c669640c', 'title': 'Study of Indonesia low rank coal utilization on modified fixed bed gasification for combined cycle power plant', 'authors': [{'name': 'T. Hardianto', 'id': '67067417'}, {'name': 'A. R. Amalia', 'id': '2128252791'}, {'name': 'A. Suwono', 'id': '72383274'}, {'name': 'P. Riauwindu', 'id': '101468093'}], 'score': 0.9947617556671915, 'dominance_ratio': 189.9036534906196}, {'paperId': '944f9353bd490f6f65bc2b540371b38a5b1b3564', 'title': 'Thermodynamic Optimization of Trigeneration Power System', 'authors': [{'name': 'Ladislao Eduardo Méndez-Cruz', 'id': '2161284874'}, {'name': 'M. Gutiérrez-Limón', 'id': '1413751263'}, {'name': 'R. Lugo-Leyte', 'id': '1403054876'}, {'name': 'Mauricio Sales-Cruz', 'id': '2307683612'}], 'score': 0.9943761023975856, 'dominance_ratio': 176.8126226710528}, {'paperId': 'b8c8e159f256a595ff60672a1493d1bac92f3cbf', 'title': 'The combination of once-through Fischer-Tropsch with baseload IGCC Technology', 'authors': [{'name': 'S. Tam', 'id': '50498999'}, {'name': 'D. Pollock', 'id': '103861177'}, {'name': 'J. Fox', 'id': '46802218'}], 'score': 0.9941237046084528, 'dominance_ratio': 169.17524076835033}, {'paperId': '33d7a4cb743b592607cd3dc25db98991097310fa', 'title': 'A feasibility study of CO 2 ‐based solar‐assisted Rankine cycle: a comparative case study for Isparta, Turkey', 'authors': [{'name': 'O. Kizilkan', 'id': '1441587675'}, {'name': 'H. Yamaguchi', 'id': '49110442'}], 'score': 0.9933086947587251, 'dominance_ratio': 148.44767113400005}], 1: [{'paperId': '4e5206acfe33cb7844714030ecc509218b5194df', 'title': 'Spectrally efficient Non-Orthogonal Multiple Access (NOMA) techniques for future generation mobile systems', 'authors': [{'name': 'I. Bukar', 'id': '2146795'}], 'score': 0.9980941875808241, 'dominance_ratio': 523.7105840885594}, {'paperId': '55d7ac3197cd81fc5abd2da8348fb2fed2cec270', 'title': 'High capacity multiuser multiantenna communication techniques', 'authors': [{'name': 'W. Al-Hussaibi', 'id': '1398322735'}], 'score': 0.9978730949778755, 'dominance_ratio': 469.1667176866215}, {'paperId': '240a0c65ecb21f8ad6ca2a975378bb38bd725ede', 'title': 'Performance Analysis of Cooperative Communication in the Presence of Co-channel Interference', 'authors': [{'name': 'Fei Xu', 'id': '2152479471'}, {'name': 'X. Rui', 'id': '2840748'}], 'score': 0.9978328800961065, 'dominance_ratio': 460.4419129090087}, {'paperId': '29b65ca9dbb0c821f33143a825deacb1a139cc4f', 'title': 'Multiuser Multi-Antenna Systems with Limited Feedback', 'authors': [{'name': 'M. Kountouris', 'id': '1746269'}], 'score': 0.9977421079890949, 'dominance_ratio': 441.89095801800346}, {'paperId': '34e10c41347ad8311da46ee06b51ddc5919e76d7', 'title': 'Turbo-coded CDMA-based two-way relaying', 'authors': [{'name': 'S. Ng', 'id': '144834528'}, {'name': 'Shangchao Liao', 'id': '2057399955'}], 'score': 0.9976127779820815, 'dominance_ratio': 417.8969231618178}]}\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Execute Topic Analysis Workflow (LDA, Topic Naming, Author Analysis, Topic N-grams)\n",
    "\n",
    "NUM_TOPICS = 12  # adjust as desired\n",
    "NUM_TOPIC_WORDS = 15\n",
    "\n",
    "# LDA topic modeling\n",
    "lda_model, lda_vectorizer, topic_distributions, topic_keywords = run_lda_topic_modeling(\n",
    "    df, num_topics=NUM_TOPICS, num_words=NUM_TOPIC_WORDS)\n",
    "\n",
    "# Paper-to-topic assignment\n",
    "paper_classifications = assign_papers_to_topics(topic_distributions)\n",
    "df['Primary_Topic_Index'] = [int(p['primary_topic'][0]) if isinstance(p['primary_topic'], (np.ndarray, list)) else int(p['primary_topic']) for p in paper_classifications]\n",
    "df['Primary_Score'] = [p['primary_score'] for p in paper_classifications]\n",
    "df['Dominance_Ratio'] = [p['dominance_ratio'] for p in paper_classifications]\n",
    "\n",
    "# Per-topic TF-IDF n-grams for naming/interpretation\n",
    "topic_tfidf_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 3), min_df=2, max_df=0.95, token_pattern=r'\\b[\\w_-]+\\b'\n",
    ")\n",
    "topic_tfidf_matrix = topic_tfidf_vectorizer.fit_transform(df['processed_text'])\n",
    "topic_tfidf_feature_names = topic_tfidf_vectorizer.get_feature_names_out()\n",
    "topic_ngrams = get_top_tfidf_ngrams_per_topic(\n",
    "    df, topic_tfidf_matrix, topic_tfidf_feature_names, topic_col='Primary_Topic_Index', top_k=10)\n",
    "\n",
    "# Generate topic names using LLM\n",
    "topic_names = {}\n",
    "for topic_idx, keywords in topic_keywords.items():\n",
    "    lda_ngrams = keywords['top_words'][:NUM_TOPIC_WORDS]\n",
    "    tfidf_ng = [ngram for ngram, _ in topic_ngrams.get(topic_idx, [])][:NUM_TOPIC_WORDS]\n",
    "    top_titles = get_top_titles_for_topic(df, paper_classifications, topic_idx, n_titles=10)\n",
    "    topic_name = topic_name_llm(\n",
    "        lda_ngrams, tfidf_ng, top_titles, client, model_type, credit_tracker\n",
    "    )\n",
    "    topic_names[topic_idx] = topic_name\n",
    "    logger.info(f\"Topic {topic_idx}: {topic_name if topic_name else 'Unnamed'}\")\n",
    "df['Primary_Topic'] = df['Primary_Topic_Index'].map(lambda x: topic_names.get(x, f\"Topic_{x}\"))\n",
    "logger.info(\"✓ Topic naming and assignment completed.\")\n",
    "\n",
    "# Author analysis and top papers per topic\n",
    "top_papers, author_stats = get_author_stats(paper_classifications, df, n_top=5)\n",
    "\n",
    "# Save all topic/author analysis results\n",
    "current_date = datetime.now().strftime(\"%Y_%m_%d\")\n",
    "keyword_str = '_'.join(search_keywords) if search_keywords else \"\"\n",
    "suffix_string = f\"{current_date}{keyword_str}\"\n",
    "save_topic_analysis_outputs(df, lda_model, lda_vectorizer, topic_distributions, topic_keywords, topic_names, topic_ngrams, author_stats, top_papers, topic_ngrams, suffix_string)\n",
    "\n",
    "# Show preview\n",
    "print(\"\\nSample topics and names:\")\n",
    "print({k: topic_names[k] for k in list(topic_names)[:5]})\n",
    "print(\"\\nTop authors and top papers by topic (first 2):\")\n",
    "print(dict(list(top_papers.items())[:2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18b181a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 22:39:43,018 - INFO - Starting pipeline for method detection and assignment...\n",
      "2025-08-20 22:40:26,780 - INFO - Step 1: Extracted 30000 candidate terms from the corpus.\n",
      "2025-08-20 22:45:22,379 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1: Found 68 method phrases.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 22:51:18,721 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 2: Found 112 method phrases.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 22:51:32,150 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 22:51:32,153 - INFO - Step 2: Extracted 81 method phrases from the corpus.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 3: Found 99 method phrases.\n",
      "\n",
      "81 consensus method phrases found in >= 2/3 runs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 22:51:53,048 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-08-20 22:51:53,062 - INFO - LLM mapped 81 methods to abbreviations/variants.\n",
      "2025-08-20 22:53:00,078 - INFO - Step 3: Built abbreviation map for 81 methods.\n",
      "2025-08-20 22:53:46,571 - INFO - Step 4: Computed method score matrices with 81 methods.\n",
      "2025-08-20 22:53:46,959 - INFO - Step 5: Assigned top 4 methods to 28934 papers with confidence levels.\n",
      "2025-08-20 22:53:54,441 - INFO - Step 6: Saved method score matrices to Saved_files_new.\n",
      "2025-08-20 22:53:54,498 - INFO - Step 7: Diagnostics completed.\n",
      "2025-08-20 22:53:54,504 - INFO - Step 8: Output preview of method assignments.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DIAGNOSTICS ===\n",
      "Total documents: 28934\n",
      "Methods: 81\n",
      "TF-IDF coverage: 6057/28934 (20.9%)\n",
      "LDA coverage: 28934/28934 (100.0%)\n",
      "Compound coverage: 28662/28934 (99.1%)\n",
      "Combined coverage: 28934/28934 (100.0%)\n",
      "\n",
      "Method label distribution (top 10):\n",
      "Primary_Method\n",
      "reliability analysis          3587\n",
      "multi-agent system            2806\n",
      "adaptive control              2674\n",
      "dynamic line rating           1307\n",
      "model predictive control       993\n",
      "load flow analysis             736\n",
      "resource allocation            688\n",
      "wavelet transform              630\n",
      "data mining                    626\n",
      "voltage stability analysis     614\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Method confidence distribution:\n",
      "Method_Confidence\n",
      "confident          23772\n",
      "super_confident     4890\n",
      "low_confidence       272\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Method vocabulary sample: adaptive control, adaptive neuro-fuzzy inference system, autoregressive integrated moving average, bayesian optimization, bootstrap, co-simulation, convolutional neural network, cooperative game theory, data envelopment analysis, data mining\n",
      "\n",
      "TFIDF stats: mean=0.003, std=0.051\n",
      "LDA stats: mean=0.012, std=0.028\n",
      "Compound stats: mean=0.120, std=0.208\n",
      "Combined stats: mean=0.029, std=0.054\n",
      "            Primary_Method  Primary_Method_Score Method_Confidence  \\\n",
      "0          unit commitment              0.103704         confident   \n",
      "1     reliability analysis              0.103704         confident   \n",
      "2  error correction coding              0.137037         confident   \n",
      "3    supply chain planning              0.137037         confident   \n",
      "4      supply chain design              0.137037         confident   \n",
      "\n",
      "              Top_1_Method  Top_1_Score  \n",
      "0          unit commitment     0.103704  \n",
      "1     reliability analysis     0.103704  \n",
      "2  error correction coding     0.137037  \n",
      "3    supply chain planning     0.137037  \n",
      "4      supply chain design     0.137037  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 22:53:58,494 - INFO - Step 9: Saved final DataFrame with method assignments to Saved_files_new.\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Main Pipeline (run in order) with Parameterization\n",
    "\n",
    "# ===== Parameter Choices: SET HERE =====\n",
    "# --- Extraction/scoring params\n",
    "MAX_FEATURES = 30000          # Number of n-grams for candidate extraction\n",
    "NGRAM_RANGE = (1, 4)          # For TF-IDF and LDA n-gram extraction\n",
    "WINDOW_COMPOUND = 150         # Window for compound/proximity scoring\n",
    "MIN_WORD_LEN = 4              # Minimum word length in compound scoring\n",
    "\n",
    "# --- Matrix and score params\n",
    "TFIDF_WEIGHT = 0.5            # Weight for TF-IDF scores in final matrix\n",
    "LDA_WEIGHT = 0.3              # Weight for LDA scores in final matrix\n",
    "COMPOUND_WEIGHT = 0.2         # Weight for compound scores in final matrix\n",
    "\n",
    "# --- Assignment/confidence params\n",
    "TOP_METHODS_PER_PAPER = 4     # Number of methods to assign per paper\n",
    "MIN_ASSIGN_SCORE = 0.02       # Min combined score to assign a method\n",
    "BATCH_SIZE_LLM = 100          # LLM batch size for abbreviations\n",
    "\n",
    "# --- File/output\n",
    "#suffix_string = f\"{datetime.now().strftime('%Y_%m_%d')}_your_keywords\" # Adjust as needed\n",
    "\n",
    "logger.info(\"Starting pipeline for method detection and assignment...\")\n",
    "\n",
    "# 1. Extract broad candidate n-grams from the corpus\n",
    "candidate_terms = extract_candidate_terms(\n",
    "    df, text_col='processed_text', max_features=MAX_FEATURES)\n",
    "logger.info(f\"Step 1: Extracted {len(candidate_terms)} candidate terms from the corpus.\")\n",
    "\n",
    "# 2. Use LLM to filter for method/technique phrases only\n",
    "method_phrases = get_method_phrases(\n",
    "    candidate_terms,\n",
    "    client,\n",
    "    model_type,\n",
    "    credit_tracker,\n",
    "    consensus_runs=3,           # Or 5, for very-high repeatability\n",
    "    consensus_threshold=0.7,    # Set to 1.0 for total agreement, 0.7 for majority\n",
    "    temp=0                      # Always set temperature to 0 for deterministic results\n",
    ")\n",
    "\n",
    "logger.info(f\"Step 2: Extracted {len(method_phrases)} method phrases from the corpus.\")\n",
    "\n",
    "# 3. Use LLM to build abbreviation/synonym dictionary\n",
    "method_dict = get_method_abbreviation_dict(\n",
    "    method_phrases, client, model_type, credit_tracker, batch_size=BATCH_SIZE_LLM)\n",
    "abbr_to_canonical_map = build_abbr_to_canonical_map(method_dict)\n",
    "df['standardized_text'] = df['processed_text'].apply(\n",
    "    lambda t: standardize_methods_in_text(t, abbr_to_canonical_map))\n",
    "method_vocabulary = sorted(method_dict.keys())\n",
    "logger.info(f\"Step 3: Built abbreviation map for {len(method_vocabulary)} methods.\")\n",
    "\n",
    "# 4. Compute all method score matrices\n",
    "tfidf_scores, method_names = compute_tfidf_scores(\n",
    "    df['standardized_text'], method_vocabulary, ngram_range=NGRAM_RANGE)\n",
    "lda_n_topics = min(len(method_vocabulary), 100)\n",
    "lda_scores, lda_names = compute_lda_scores(\n",
    "    df['standardized_text'], method_vocabulary, ngram_range=NGRAM_RANGE, n_topics=lda_n_topics)\n",
    "assert list(method_names) == list(lda_names)\n",
    "compound_scores = compute_compound_scores(\n",
    "    df, method_names, processed_col='standardized_text',\n",
    "    window=WINDOW_COMPOUND, min_word_len=MIN_WORD_LEN)\n",
    "combined_scores = combine_method_scores(\n",
    "    tfidf_scores, lda_scores, compound_scores,\n",
    "    weights=(TFIDF_WEIGHT, LDA_WEIGHT, COMPOUND_WEIGHT))\n",
    "logger.info(f\"Step 4: Computed method score matrices with {len(method_names)} methods.\")\n",
    "\n",
    "# 5. Assign methods to papers with confidence\n",
    "df = assign_top_methods_by_total_score(\n",
    "    df, combined_scores, method_names,\n",
    "    top_n=TOP_METHODS_PER_PAPER, min_score=MIN_ASSIGN_SCORE)\n",
    "logger.info(f\"Step 5: Assigned top {TOP_METHODS_PER_PAPER} methods to {len(df)} papers with confidence levels.\")\n",
    "\n",
    "# 6. Save all matrix DataFrames for visualization\n",
    "for scores, label in zip([tfidf_scores, lda_scores, compound_scores, combined_scores],\n",
    "                         [\"tfidf\", \"lda\", \"compound\", \"combined\"]):\n",
    "    pd.DataFrame(scores, columns=method_names, index=df.index).to_csv(\n",
    "        os.path.join(SAVE_DIR, f\"semantic_scholar_{suffix_string}_method_{label}_scores.csv\")\n",
    "    )\n",
    "logger.info(f\"Step 6: Saved method score matrices to {SAVE_DIR}.\")\n",
    "\n",
    "# 7. Run diagnostics\n",
    "diagnostics_with_scores(df, tfidf_scores, lda_scores, compound_scores, combined_scores, method_names)\n",
    "logger.info(f\"Step 7: Diagnostics completed.\")\n",
    "\n",
    "# 8. Output short preview\n",
    "print(df[['Primary_Method', 'Primary_Method_Score', 'Method_Confidence', 'Top_1_Method', 'Top_1_Score']].head())\n",
    "logger.info(f\"Step 8: Output preview of method assignments.\")\n",
    "\n",
    "# 9. Final saving of the DataFrame with method assignments\n",
    "df.to_csv(os.path.join(SAVE_DIR, f\"semantic_scholar_{suffix_string}_all_results.csv\"))\n",
    "logger.info(f\"Step 9: Saved final DataFrame with method assignments to {SAVE_DIR}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b239686f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "literature-search-and-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
